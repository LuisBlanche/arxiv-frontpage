{"created":"2024-01-10 18:59:53","title":"InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes","abstract":"We introduce InseRF, a novel method for generative object insertion in the NeRF reconstructions of 3D scenes. Based on a user-provided textual description and a 2D bounding box in a reference viewpoint, InseRF generates new objects in 3D scenes. Recently, methods for 3D scene editing have been profoundly transformed, owing to the use of strong priors of text-to-image diffusion models in 3D generative modeling. Existing methods are mostly effective in editing 3D scenes via style and appearance changes or removing existing objects. Generating new objects, however, remains a challenge for such methods, which we address in this study. Specifically, we propose grounding the 3D object insertion to a 2D object insertion in a reference view of the scene. The 2D edit is then lifted to 3D using a single-view object reconstruction method. The reconstructed object is then inserted into the scene, guided by the priors of monocular depth estimation methods. We evaluate our method on various 3D scenes and provide an in-depth analysis of the proposed components. Our experiments with generative insertion of objects in several 3D scenes indicate the effectiveness of our method compared to the existing methods. InseRF is capable of controllable and 3D-consistent object insertion without requiring explicit 3D information as input. Please visit our project page at https://mohamad-shahbazi.github.io/inserf.","sentences":["We introduce InseRF, a novel method for generative object insertion in the NeRF reconstructions of 3D scenes.","Based on a user-provided textual description and a 2D bounding box in a reference viewpoint, InseRF generates new objects in 3D scenes.","Recently, methods for 3D scene editing have been profoundly transformed, owing to the use of strong priors of text-to-image diffusion models in 3D generative modeling.","Existing methods are mostly effective in editing 3D scenes via style and appearance changes or removing existing objects.","Generating new objects, however, remains a challenge for such methods, which we address in this study.","Specifically, we propose grounding the 3D object insertion to a 2D object insertion in a reference view of the scene.","The 2D edit is then lifted to 3D using a single-view object reconstruction method.","The reconstructed object is then inserted into the scene, guided by the priors of monocular depth estimation methods.","We evaluate our method on various 3D scenes and provide an in-depth analysis of the proposed components.","Our experiments with generative insertion of objects in several 3D scenes indicate the effectiveness of our method compared to the existing methods.","InseRF is capable of controllable and 3D-consistent object insertion without requiring explicit 3D information as input.","Please visit our project page at https://mohamad-shahbazi.github.io/inserf."],"url":"http://arxiv.org/abs/2401.05335v1"}
{"created":"2024-01-10 18:59:53","title":"Towards Online Sign Language Recognition and Translation","abstract":"The objective of sign language recognition is to bridge the communication gap between the deaf and the hearing. Numerous previous works train their models using the well-established connectionist temporal classification (CTC) loss. During the inference stage, the CTC-based models typically take the entire sign video as input to make predictions. This type of inference scheme is referred to as offline recognition. In contrast, while mature speech recognition systems can efficiently recognize spoken words on the fly, sign language recognition still falls short due to the lack of practical online solutions. In this work, we take the first step towards filling this gap. Our approach comprises three phases: 1) developing a sign language dictionary encompassing all glosses present in a target sign language dataset; 2) training an isolated sign language recognition model on augmented signs using both conventional classification loss and our novel saliency loss; 3) employing a sliding window approach on the input sign sequence and feeding each sign clip to the well-optimized model for online recognition. Furthermore, our online recognition model can be extended to boost the performance of any offline model, and to support online translation by appending a gloss-to-text network onto the recognition model. By integrating our online framework with the previously best-performing offline model, TwoStream-SLR, we achieve new state-of-the-art performance on three benchmarks: Phoenix-2014, Phoenix-2014T, and CSL-Daily. Code and models will be available at https://github.com/FangyunWei/SLRT","sentences":["The objective of sign language recognition is to bridge the communication gap between the deaf and the hearing.","Numerous previous works train their models using the well-established connectionist temporal classification (CTC) loss.","During the inference stage, the CTC-based models typically take the entire sign video as input to make predictions.","This type of inference scheme is referred to as offline recognition.","In contrast, while mature speech recognition systems can efficiently recognize spoken words on the fly, sign language recognition still falls short due to the lack of practical online solutions.","In this work, we take the first step towards filling this gap.","Our approach comprises three phases: 1) developing a sign language dictionary encompassing all glosses present in a target sign language dataset; 2) training an isolated sign language recognition model on augmented signs using both conventional classification loss and our novel saliency loss; 3) employing a sliding window approach on the input sign sequence and feeding each sign clip to the well-optimized model for online recognition.","Furthermore, our online recognition model can be extended to boost the performance of any offline model, and to support online translation by appending a gloss-to-text network onto the recognition model.","By integrating our online framework with the previously best-performing offline model, TwoStream-SLR, we achieve new state-of-the-art performance on three benchmarks: Phoenix-2014, Phoenix-2014T, and CSL-Daily.","Code and models will be available at https://github.com/FangyunWei/SLRT"],"url":"http://arxiv.org/abs/2401.05336v1"}
{"created":"2024-01-10 18:59:51","title":"URHand: Universal Relightable Hands","abstract":"Existing photorealistic relightable hand models require extensive identity-specific observations in different views, poses, and illuminations, and face challenges in generalizing to natural illuminations and novel identities. To bridge this gap, we present URHand, the first universal relightable hand model that generalizes across viewpoints, poses, illuminations, and identities. Our model allows few-shot personalization using images captured with a mobile phone, and is ready to be photorealistically rendered under novel illuminations. To simplify the personalization process while retaining photorealism, we build a powerful universal relightable prior based on neural relighting from multi-view images of hands captured in a light stage with hundreds of identities. The key challenge is scaling the cross-identity training while maintaining personalized fidelity and sharp details without compromising generalization under natural illuminations. To this end, we propose a spatially varying linear lighting model as the neural renderer that takes physics-inspired shading as input feature. By removing non-linear activations and bias, our specifically designed lighting model explicitly keeps the linearity of light transport. This enables single-stage training from light-stage data while generalizing to real-time rendering under arbitrary continuous illuminations across diverse identities. In addition, we introduce the joint learning of a physically based model and our neural relighting model, which further improves fidelity and generalization. Extensive experiments show that our approach achieves superior performance over existing methods in terms of both quality and generalizability. We also demonstrate quick personalization of URHand from a short phone scan of an unseen identity.","sentences":["Existing photorealistic relightable hand models require extensive identity-specific observations in different views, poses, and illuminations, and face challenges in generalizing to natural illuminations and novel identities.","To bridge this gap, we present URHand, the first universal relightable hand model that generalizes across viewpoints, poses, illuminations, and identities.","Our model allows few-shot personalization using images captured with a mobile phone, and is ready to be photorealistically rendered under novel illuminations.","To simplify the personalization process while retaining photorealism, we build a powerful universal relightable prior based on neural relighting from multi-view images of hands captured in a light stage with hundreds of identities.","The key challenge is scaling the cross-identity training while maintaining personalized fidelity and sharp details without compromising generalization under natural illuminations.","To this end, we propose a spatially varying linear lighting model as the neural renderer that takes physics-inspired shading as input feature.","By removing non-linear activations and bias, our specifically designed lighting model explicitly keeps the linearity of light transport.","This enables single-stage training from light-stage data while generalizing to real-time rendering under arbitrary continuous illuminations across diverse identities.","In addition, we introduce the joint learning of a physically based model and our neural relighting model, which further improves fidelity and generalization.","Extensive experiments show that our approach achieves superior performance over existing methods in terms of both quality and generalizability.","We also demonstrate quick personalization of URHand from a short phone scan of an unseen identity."],"url":"http://arxiv.org/abs/2401.05334v1"}
{"created":"2024-01-10 18:54:13","title":"\\textit{SmartMME}: Implementation of Base Station Switching Off Strategy in ns-3","abstract":"In the landscape of next-generation cellular networks, a projected surge of over 12 billion subscriptions foreshadows a considerable upswing in the network's overall energy consumption. The proliferation of User Equipment (UE) drives this energy demand, urging 5G deployments to seek more energy-efficient methodologies. In this work, we propose SmartMME, as a pivotal solution aimed at optimizing Base Station (BS) energy usage. By harnessing and analyzing critical network states-such as UE connections, data traffic at individual UEs, and other pertinent metrics-our methodology intelligently orchestrates the BS's power states, making informed decisions on when to activate or deactivate the BS. This meticulous approach significantly curtails the network's overall energy consumption. In a bid to validate its efficiency, we seamlessly integrated our module into Network Simulator-3 (ns-3), conducting extensive testing to demonstrate its prowess in effectively managing and reducing net energy consumption. As advocates of collaborative progress, we've opted to open-source this module, inviting the engagement and feedback of the wider research community on GitHub.","sentences":["In the landscape of next-generation cellular networks, a projected surge of over 12 billion subscriptions foreshadows a considerable upswing in the network's overall energy consumption.","The proliferation of User Equipment (UE) drives this energy demand, urging 5G deployments to seek more energy-efficient methodologies.","In this work, we propose SmartMME, as a pivotal solution aimed at optimizing Base Station (BS) energy usage.","By harnessing and analyzing critical network states-such as UE connections, data traffic at individual UEs, and other pertinent metrics-our methodology intelligently orchestrates the BS's power states, making informed decisions on when to activate or deactivate the BS.","This meticulous approach significantly curtails the network's overall energy consumption.","In a bid to validate its efficiency, we seamlessly integrated our module into Network Simulator-3 (ns-3), conducting extensive testing to demonstrate its prowess in effectively managing and reducing net energy consumption.","As advocates of collaborative progress, we've opted to open-source this module, inviting the engagement and feedback of the wider research community on GitHub."],"url":"http://arxiv.org/abs/2401.05329v1"}
{"created":"2024-01-10 18:41:39","title":"Arrival Time Prediction for Autonomous Shuttle Services in the Real World: Evidence from Five Cities","abstract":"Urban mobility is on the cusp of transformation with the emergence of shared, connected, and cooperative automated vehicles. Yet, for them to be accepted by customers, trust in their punctuality is vital. Many pilot initiatives operate without a fixed schedule, thus enhancing the importance of reliable arrival time (AT) predictions. This study presents an AT prediction system for autonomous shuttles, utilizing separate models for dwell and running time predictions, validated on real-world data from five cities. Alongside established methods such as XGBoost, we explore the benefits of integrating spatial data using graph neural networks (GNN). To accurately handle the case of a shuttle bypassing a stop, we propose a hierarchical model combining a random forest classifier and a GNN. The results for the final AT prediction are promising, showing low errors even when predicting several stops ahead. Yet, no single model emerges as universally superior, and we provide insights into the characteristics of pilot sites that influence the model selection process. Finally, we identify dwell time prediction as the key determinant in overall AT prediction accuracy when autonomous shuttles are deployed in low-traffic areas or under regulatory speed limits. This research provides insights into the current state of autonomous public transport prediction models and paves the way for more data-informed decision-making as the field advances.","sentences":["Urban mobility is on the cusp of transformation with the emergence of shared, connected, and cooperative automated vehicles.","Yet, for them to be accepted by customers, trust in their punctuality is vital.","Many pilot initiatives operate without a fixed schedule, thus enhancing the importance of reliable arrival time (AT) predictions.","This study presents an AT prediction system for autonomous shuttles, utilizing separate models for dwell and running time predictions, validated on real-world data from five cities.","Alongside established methods such as XGBoost, we explore the benefits of integrating spatial data using graph neural networks (GNN).","To accurately handle the case of a shuttle bypassing a stop, we propose a hierarchical model combining a random forest classifier and a GNN.","The results for the final AT prediction are promising, showing low errors even when predicting several stops ahead.","Yet, no single model emerges as universally superior, and we provide insights into the characteristics of pilot sites that influence the model selection process.","Finally, we identify dwell time prediction as the key determinant in overall AT prediction accuracy when autonomous shuttles are deployed in low-traffic areas or under regulatory speed limits.","This research provides insights into the current state of autonomous public transport prediction models and paves the way for more data-informed decision-making as the field advances."],"url":"http://arxiv.org/abs/2401.05322v1"}
{"created":"2024-01-10 18:38:43","title":"Quantum Time-Space Tradeoffs for Matrix Problems","abstract":"We consider the time and space required for quantum computers to solve a wide variety of problems involving matrices, many of which have only been analyzed classically in prior work. Our main results show that for a range of linear algebra problems -- including matrix-vector product, matrix inversion, matrix multiplication and powering -- existing classical time-space tradeoffs, several of which are tight for every space bound, also apply to quantum algorithms. For example, for almost all matrices $A$, including the discrete Fourier transform (DFT) matrix, we prove that quantum circuits with at most $T$ input queries and $S$ qubits of memory require $T=\\Omega(n^2/S)$ to compute matrix-vector product $Ax$ for $x \\in \\{0,1\\}^n$. We similarly prove that matrix multiplication for $n\\times n$ binary matrices requires $T=\\Omega(n^3 / \\sqrt{S})$. Because many of our lower bounds match deterministic algorithms with the same time and space complexity, we show that quantum computers cannot provide any asymptotic advantage for these problems with any space bound. We obtain matching lower bounds for the stronger notion of quantum cumulative memory complexity -- the sum of the space per layer of a circuit.   We also consider Boolean (i.e. AND-OR) matrix multiplication and matrix-vector products, improving the previous quantum time-space tradeoff lower bounds for $n\\times n$ Boolean matrix multiplication to $T=\\Omega(n^{2.5}/S^{1/3})$ from $T=\\Omega(n^{2.5}/S^{1/2})$.   Our improved lower bound for Boolean matrix multiplication is based on a new coloring argument that extracts more from the strong direct product theorem used in prior work. Our tight lower bounds for linear algebra problems require adding a new bucketing method to the recording-query technique of Zhandry that lets us apply classical arguments to upper bound the success probability of quantum circuits.","sentences":["We consider the time and space required for quantum computers to solve a wide variety of problems involving matrices, many of which have only been analyzed classically in prior work.","Our main results show that for a range of linear algebra problems -- including matrix-vector product, matrix inversion, matrix multiplication and powering -- existing classical time-space tradeoffs, several of which are tight for every space bound, also apply to quantum algorithms.","For example, for almost all matrices $A$, including the discrete Fourier transform (DFT) matrix, we prove that quantum circuits with at most $T$ input queries and $S$ qubits of memory require $T=\\Omega(n^2/S)$ to compute matrix-vector product $Ax$ for $x \\in \\{0,1\\}^n$. We similarly prove that matrix multiplication for $n\\times n$ binary matrices requires $T=\\Omega(n^3 / \\sqrt{S})$.","Because many of our lower bounds match deterministic algorithms with the same time and space complexity, we show that quantum computers cannot provide any asymptotic advantage for these problems with any space bound.","We obtain matching lower bounds for the stronger notion of quantum cumulative memory complexity -- the sum of the space per layer of a circuit.   ","We also consider Boolean (i.e. AND-OR) matrix multiplication and matrix-vector products, improving the previous quantum time-space tradeoff lower bounds for $n\\times n$ Boolean matrix multiplication to $T=\\Omega(n^{2.5}/S^{1/3})$ from $T=\\Omega(n^{2.5}/S^{1/2})$.   Our improved lower bound for Boolean matrix multiplication is based on a new coloring argument that extracts more from the strong direct product theorem used in prior work.","Our tight lower bounds for linear algebra problems require adding a new bucketing method to the recording-query technique of Zhandry that lets us apply classical arguments to upper bound the success probability of quantum circuits."],"url":"http://arxiv.org/abs/2401.05321v1"}
{"created":"2024-01-10 18:37:59","title":"Leveraging Print Debugging to Improve Code Generation in Large Language Models","abstract":"Large language models (LLMs) have made significant progress in code generation tasks, but their performance in tackling programming problems with complex data structures and algorithms remains suboptimal. To address this issue, we propose an in-context learning approach that guides LLMs to debug by using a \"print debugging\" method, which involves inserting print statements to trace and analysing logs for fixing the bug. We collect a Leetcode problem dataset and evaluate our method using the Leetcode online judging system. Experiments with GPT-4 demonstrate the effectiveness of our approach, outperforming rubber duck debugging in easy and medium-level Leetcode problems by 1.5% and 17.9%.","sentences":["Large language models (LLMs) have made significant progress in code generation tasks, but their performance in tackling programming problems with complex data structures and algorithms remains suboptimal.","To address this issue, we propose an in-context learning approach that guides LLMs to debug by using a \"print debugging\" method, which involves inserting print statements to trace and analysing logs for fixing the bug.","We collect a Leetcode problem dataset and evaluate our method using the Leetcode online judging system.","Experiments with GPT-4 demonstrate the effectiveness of our approach, outperforming rubber duck debugging in easy and medium-level Leetcode problems by 1.5% and 17.9%."],"url":"http://arxiv.org/abs/2401.05319v1"}
{"created":"2024-01-10 18:36:46","title":"Analytical Model and Experimental Testing of the SoftFoot: an Adaptive Robot Foot for Walking over Obstacles and Irregular Terrains","abstract":"Robot feet are crucial for maintaining dynamic stability and propelling the body during walking, especially on uneven terrains. Traditionally, robot feet were mostly designed as flat and stiff pieces of metal, which meets its limitations when the robot is required to step on irregular grounds, e.g. stones. While one could think that adding compliance under such feet would solve the problem, this is not the case. To address this problem, we introduced the SoftFoot, an adaptive foot design that can enhance walking performance over irregular grounds. The proposed design is completely passive and varies its shape and stiffness based on the exerted forces, through a system of pulley, tendons, and springs opportunely placed in the structure. This paper outlines the motivation behind the SoftFoot and describes the theoretical model which led to its final design. The proposed system has been experimentally tested and compared with two analogous conventional feet, a rigid one and a compliant one, with similar footprints and soles. The experimental validation focuses on the analysis of the standing performance, measured in terms of the equivalent support surface extension and the compensatory ankle angle, and the rejection of impulsive forces, which is important in events such as stepping on unforeseen obstacles. Results show that the SoftFoot has the largest equivalent support surface when standing on obstacles, and absorbs impulsive loads in a way almost as good as a compliant foot.","sentences":["Robot feet are crucial for maintaining dynamic stability and propelling the body during walking, especially on uneven terrains.","Traditionally, robot feet were mostly designed as flat and stiff pieces of metal, which meets its limitations when the robot is required to step on irregular grounds, e.g. stones.","While one could think that adding compliance under such feet would solve the problem, this is not the case.","To address this problem, we introduced the SoftFoot, an adaptive foot design that can enhance walking performance over irregular grounds.","The proposed design is completely passive and varies its shape and stiffness based on the exerted forces, through a system of pulley, tendons, and springs opportunely placed in the structure.","This paper outlines the motivation behind the SoftFoot and describes the theoretical model which led to its final design.","The proposed system has been experimentally tested and compared with two analogous conventional feet, a rigid one and a compliant one, with similar footprints and soles.","The experimental validation focuses on the analysis of the standing performance, measured in terms of the equivalent support surface extension and the compensatory ankle angle, and the rejection of impulsive forces, which is important in events such as stepping on unforeseen obstacles.","Results show that the SoftFoot has the largest equivalent support surface when standing on obstacles, and absorbs impulsive loads in a way almost as good as a compliant foot."],"url":"http://arxiv.org/abs/2401.05318v1"}
{"created":"2024-01-10 18:22:00","title":"Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks","abstract":"The deployment of federated learning (FL) within vertical heterogeneous networks, such as those enabled by high-altitude platform station (HAPS), offers the opportunity to engage a wide array of clients, each endowed with distinct communication and computational capabilities. This diversity not only enhances the training accuracy of FL models but also hastens their convergence. Yet, applying FL in these expansive networks presents notable challenges, particularly the significant non-IIDness in client data distributions. Such data heterogeneity often results in slower convergence rates and reduced effectiveness in model training performance. Our study introduces a client selection strategy tailored to address this issue, leveraging user network traffic behaviour. This strategy involves the prediction and classification of clients based on their network usage patterns while prioritizing user privacy. By strategically selecting clients whose data exhibit similar patterns for participation in FL training, our approach fosters a more uniform and representative data distribution across the network. Our simulations demonstrate that this targeted client selection methodology significantly reduces the training loss of FL models in HAPS networks, thereby effectively tackling a crucial challenge in implementing large-scale FL systems.","sentences":["The deployment of federated learning (FL) within vertical heterogeneous networks, such as those enabled by high-altitude platform station (HAPS), offers the opportunity to engage a wide array of clients, each endowed with distinct communication and computational capabilities.","This diversity not only enhances the training accuracy of FL models but also hastens their convergence.","Yet, applying FL in these expansive networks presents notable challenges, particularly the significant non-IIDness in client data distributions.","Such data heterogeneity often results in slower convergence rates and reduced effectiveness in model training performance.","Our study introduces a client selection strategy tailored to address this issue, leveraging user network traffic behaviour.","This strategy involves the prediction and classification of clients based on their network usage patterns while prioritizing user privacy.","By strategically selecting clients whose data exhibit similar patterns for participation in FL training, our approach fosters a more uniform and representative data distribution across the network.","Our simulations demonstrate that this targeted client selection methodology significantly reduces the training loss of FL models in HAPS networks, thereby effectively tackling a crucial challenge in implementing large-scale FL systems."],"url":"http://arxiv.org/abs/2401.05308v1"}
{"created":"2024-01-10 18:12:31","title":"Can Probabilistic Feedback Drive User Impacts in Online Platforms?","abstract":"A common explanation for negative user impacts of content recommender systems is misalignment between the platform's objective and user welfare. In this work, we show that misalignment in the platform's objective is not the only potential cause of unintended impacts on users: even when the platform's objective is fully aligned with user welfare, the platform's learning algorithm can induce negative downstream impacts on users. The source of these user impacts is that different pieces of content may generate observable user reactions (feedback information) at different rates; these feedback rates may correlate with content properties, such as controversiality or demographic similarity of the creator, that affect the user experience. Since differences in feedback rates can impact how often the learning algorithm engages with different content, the learning algorithm may inadvertently promote content with certain such properties. Using the multi-armed bandit framework with probabilistic feedback, we examine the relationship between feedback rates and a learning algorithm's engagement with individual arms for different no-regret algorithms. We prove that no-regret algorithms can exhibit a wide range of dependencies: if the feedback rate of an arm increases, some no-regret algorithms engage with the arm more, some no-regret algorithms engage with the arm less, and other no-regret algorithms engage with the arm approximately the same number of times. From a platform design perspective, our results highlight the importance of looking beyond regret when measuring an algorithm's performance, and assessing the nature of a learning algorithm's engagement with different types of content as well as their resulting downstream impacts.","sentences":["A common explanation for negative user impacts of content recommender systems is misalignment between the platform's objective and user welfare.","In this work, we show that misalignment in the platform's objective is not the only potential cause of unintended impacts on users: even when the platform's objective is fully aligned with user welfare, the platform's learning algorithm can induce negative downstream impacts on users.","The source of these user impacts is that different pieces of content may generate observable user reactions (feedback information) at different rates; these feedback rates may correlate with content properties, such as controversiality or demographic similarity of the creator, that affect the user experience.","Since differences in feedback rates can impact how often the learning algorithm engages with different content, the learning algorithm may inadvertently promote content with certain such properties.","Using the multi-armed bandit framework with probabilistic feedback, we examine the relationship between feedback rates and a learning algorithm's engagement with individual arms for different no-regret algorithms.","We prove that no-regret algorithms can exhibit a wide range of dependencies: if the feedback rate of an arm increases, some no-regret algorithms engage with the arm more, some no-regret algorithms engage with the arm less, and other no-regret algorithms engage with the arm approximately the same number of times.","From a platform design perspective, our results highlight the importance of looking beyond regret when measuring an algorithm's performance, and assessing the nature of a learning algorithm's engagement with different types of content as well as their resulting downstream impacts."],"url":"http://arxiv.org/abs/2401.05304v1"}
{"created":"2024-01-10 18:09:36","title":"Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?","abstract":"Large Language Models have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of Large Language Models especially on Theory of Mind (ToM) abilities in Large Language Models. While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences : Human Robot Interaction. In this work, we explore the task of Perceived Behavior Recognition, where a robot employs a Large Language Model (LLM) to assess the robot's generated behavior in a manner similar to human observer. We focus on four behavior types, namely - explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors. The LLMs goal is, therefore to be a human proxy to the agent, and to answer how a certain agent behavior would be perceived by the human in the loop, for example \"Given a robot's behavior X, would the human observer find it explicable?\". We conduct a human subject study to verify that the users are able to correctly answer such a question in the curated situations (robot setting and plan) across five domains. A first analysis of the belief test yields extremely positive results inflating ones expectations of LLMs possessing ToM abilities. We then propose and perform a suite of perturbation tests which breaks this illusion, i.e. Inconsistent Belief, Uninformative Context and Conviction Test. We conclude that, the high score of LLMs on vanilla prompts showcases its potential use in HRI settings, however to possess ToM demands invariance to trivial or irrelevant perturbations in the context which LLMs lack.","sentences":["Large Language Models have shown exceptional generative abilities in various natural language and generation tasks.","However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of Large Language Models especially on Theory of Mind (ToM) abilities in Large Language Models.","While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences : Human Robot Interaction.","In this work, we explore the task of Perceived Behavior Recognition, where a robot employs a Large Language Model (LLM) to assess the robot's generated behavior in a manner similar to human observer.","We focus on four behavior types, namely - explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors.","The LLMs goal is, therefore to be a human proxy to the agent, and to answer how a certain agent behavior would be perceived by the human in the loop, for example \"Given a robot's behavior X, would the human observer find it explicable?\".","We conduct a human subject study to verify that the users are able to correctly answer such a question in the curated situations (robot setting and plan) across five domains.","A first analysis of the belief test yields extremely positive results inflating ones expectations of LLMs possessing ToM abilities.","We then propose and perform a suite of perturbation tests which breaks this illusion, i.e. Inconsistent Belief, Uninformative Context and Conviction Test.","We conclude that, the high score of LLMs on vanilla prompts showcases its potential use in HRI settings, however to possess ToM demands invariance to trivial or irrelevant perturbations in the context which LLMs lack."],"url":"http://arxiv.org/abs/2401.05302v1"}
{"created":"2024-01-10 18:06:27","title":"I am a Strange Dataset: Metalinguistic Tests for Language Models","abstract":"Statements involving metalinguistic self-reference (\"This paper has six sections.\") are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present \"I am a Strange Dataset\", a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like \"The penultimate word in this sentence is\" (where a correct continuation is \"is\"). In verification, models judge the truth of statements like \"The penultimate word in this sentence is sentence.\" (false). We also provide minimally different metalinguistic non-self-reference examples to complement the main dataset by probing for whether models can handle metalinguistic language at all. The dataset is hand-crafted by experts and validated by non-expert annotators. We test a variety of open-source LLMs (7B to 70B parameters) as well as closed-source LLMs through APIs. All models perform close to chance across both subtasks and even on the non-self-referential metalinguistic control data, though we find some steady improvement with model scale. GPT 4 is the only model to consistently do significantly better than chance, and it is still only in the 60% range, while our untrained human annotators score well in the 89-93% range. The dataset and evaluation toolkit are available at https://github.com/TristanThrush/i-am-a-strange-dataset.","sentences":["Statements involving metalinguistic self-reference (\"This paper has six sections.\") are prevalent in many domains.","Can large language models (LLMs) handle such language?","In this paper, we present \"I am a Strange Dataset\", a new dataset for addressing this question.","There are two subtasks: generation and verification.","In generation, models continue statements like \"The penultimate word in this sentence is\" (where a correct continuation is \"is\").","In verification, models judge the truth of statements like \"The penultimate word in this sentence is sentence.\"","(false).","We also provide minimally different metalinguistic non-self-reference examples to complement the main dataset by probing for whether models can handle metalinguistic language at all.","The dataset is hand-crafted by experts and validated by non-expert annotators.","We test a variety of open-source LLMs (7B to 70B parameters) as well as closed-source LLMs through APIs.","All models perform close to chance across both subtasks and even on the non-self-referential metalinguistic control data, though we find some steady improvement with model scale.","GPT 4 is the only model to consistently do significantly better than chance, and it is still only in the 60% range, while our untrained human annotators score well in the 89-93% range.","The dataset and evaluation toolkit are available at https://github.com/TristanThrush/i-am-a-strange-dataset."],"url":"http://arxiv.org/abs/2401.05300v1"}
{"created":"2024-01-10 17:53:59","title":"Enhanced Muscle and Fat Segmentation for CT-Based Body Composition Analysis: A Comparative Study","abstract":"Purpose: Body composition measurements from routine abdominal CT can yield personalized risk assessments for asymptomatic and diseased patients. In particular, attenuation and volume measures of muscle and fat are associated with important clinical outcomes, such as cardiovascular events, fractures, and death. This study evaluates the reliability of an Internal tool for the segmentation of muscle and fat (subcutaneous and visceral) as compared to the well-established public TotalSegmentator tool.   Methods: We assessed the tools across 900 CT series from the publicly available SAROS dataset, focusing on muscle, subcutaneous fat, and visceral fat. The Dice score was employed to assess accuracy in subcutaneous fat and muscle segmentation. Due to the lack of ground truth segmentations for visceral fat, Cohen's Kappa was utilized to assess segmentation agreement between the tools.   Results: Our Internal tool achieved a 3% higher Dice (83.8 vs. 80.8) for subcutaneous fat and a 5% improvement (87.6 vs. 83.2) for muscle segmentation respectively. A Wilcoxon signed-rank test revealed that our results were statistically different with p<0.01. For visceral fat, the Cohen's kappa score of 0.856 indicated near-perfect agreement between the two tools. Our internal tool also showed very strong correlations for muscle volume (R^2=0.99), muscle attenuation (R^2=0.93), and subcutaneous fat volume (R^2=0.99) with a moderate correlation for subcutaneous fat attenuation (R^2=0.45).   Conclusion: Our findings indicated that our Internal tool outperformed TotalSegmentator in measuring subcutaneous fat and muscle. The high Cohen's Kappa score for visceral fat suggests a reliable level of agreement between the two tools. These results demonstrate the potential of our tool in advancing the accuracy of body composition analysis.","sentences":["Purpose: Body composition measurements from routine abdominal CT can yield personalized risk assessments for asymptomatic and diseased patients.","In particular, attenuation and volume measures of muscle and fat are associated with important clinical outcomes, such as cardiovascular events, fractures, and death.","This study evaluates the reliability of an Internal tool for the segmentation of muscle and fat (subcutaneous and visceral) as compared to the well-established public TotalSegmentator tool.   ","Methods: We assessed the tools across 900 CT series from the publicly available SAROS dataset, focusing on muscle, subcutaneous fat, and visceral fat.","The Dice score was employed to assess accuracy in subcutaneous fat and muscle segmentation.","Due to the lack of ground truth segmentations for visceral fat, Cohen's Kappa was utilized to assess segmentation agreement between the tools.   ","Results:","Our Internal tool achieved a 3% higher Dice (83.8 vs. 80.8) for subcutaneous fat and a 5% improvement (87.6 vs. 83.2) for muscle segmentation respectively.","A Wilcoxon signed-rank test revealed that our results were statistically different with p<0.01.","For visceral fat, the Cohen's kappa score of 0.856 indicated near-perfect agreement between the two tools.","Our internal tool also showed very strong correlations for muscle volume (R^2=0.99), muscle attenuation (R^2=0.93), and subcutaneous fat volume (R^2=0.99) with a moderate correlation for subcutaneous fat attenuation (R^2=0.45).   ","Conclusion: Our findings indicated that our Internal tool outperformed TotalSegmentator in measuring subcutaneous fat and muscle.","The high Cohen's Kappa score for visceral fat suggests a reliable level of agreement between the two tools.","These results demonstrate the potential of our tool in advancing the accuracy of body composition analysis."],"url":"http://arxiv.org/abs/2401.05294v1"}
{"created":"2024-01-10 17:51:46","title":"Score Distillation Sampling with Learned Manifold Corrective","abstract":"Score Distillation Sampling (SDS) is a recent but already widely popular method that relies on an image diffusion model to control optimization problems using text prompts. In this paper, we conduct an in-depth analysis of the SDS loss function, identify an inherent problem with its formulation, and propose a surprisingly easy but effective fix. Specifically, we decompose the loss into different factors and isolate the component responsible for noisy gradients. In the original formulation, high text guidance is used to account for the noise, leading to unwanted side effects. Instead, we train a shallow network mimicking the timestep-dependent denoising deficiency of the image diffusion model in order to effectively factor it out. We demonstrate the versatility and the effectiveness of our novel loss formulation through several qualitative and quantitative experiments, including optimization-based image synthesis and editing, zero-shot image translation network training, and text-to-3D synthesis.","sentences":["Score Distillation Sampling (SDS) is a recent but already widely popular method that relies on an image diffusion model to control optimization problems using text prompts.","In this paper, we conduct an in-depth analysis of the SDS loss function, identify an inherent problem with its formulation, and propose a surprisingly easy but effective fix.","Specifically, we decompose the loss into different factors and isolate the component responsible for noisy gradients.","In the original formulation, high text guidance is used to account for the noise, leading to unwanted side effects.","Instead, we train a shallow network mimicking the timestep-dependent denoising deficiency of the image diffusion model in order to effectively factor it out.","We demonstrate the versatility and the effectiveness of our novel loss formulation through several qualitative and quantitative experiments, including optimization-based image synthesis and editing, zero-shot image translation network training, and text-to-3D synthesis."],"url":"http://arxiv.org/abs/2401.05293v1"}
{"created":"2024-01-10 17:38:21","title":"Analysis and Perspectives on the ANA Avatar XPRIZE Competition","abstract":"The ANA Avatar XPRIZE was a four-year competition to develop a robotic \"avatar\" system to allow a human operator to sense, communicate, and act in a remote environment as though physically present. The competition featured a unique requirement that judges would operate the avatars after less than one hour of training on the human-machine interfaces, and avatar systems were judged on both objective and subjective scoring metrics. This paper presents a unified summary and analysis of the competition from technical, judging, and organizational perspectives. We study the use of telerobotics technologies and innovations pursued by the competing teams in their avatar systems, and correlate the use of these technologies with judges' task performance and subjective survey ratings. It also summarizes perspectives from team leads, judges, and organizers about the competition's execution and impact to inform the future development of telerobotics and telepresence.","sentences":["The ANA Avatar XPRIZE was a four-year competition to develop a robotic \"avatar\" system to allow a human operator to sense, communicate, and act in a remote environment as though physically present.","The competition featured a unique requirement that judges would operate the avatars after less than one hour of training on the human-machine interfaces, and avatar systems were judged on both objective and subjective scoring metrics.","This paper presents a unified summary and analysis of the competition from technical, judging, and organizational perspectives.","We study the use of telerobotics technologies and innovations pursued by the competing teams in their avatar systems, and correlate the use of these technologies with judges' task performance and subjective survey ratings.","It also summarizes perspectives from team leads, judges, and organizers about the competition's execution and impact to inform the future development of telerobotics and telepresence."],"url":"http://arxiv.org/abs/2401.05290v1"}
{"created":"2024-01-10 17:35:30","title":"A class of locally recoverable codes over finite chain rings","abstract":"Locally recoverable codes deal with the task of reconstructing a lost symbol by relying on a portion of the remaining coordinates smaller than an information set. We consider the case of codes over finite chain rings, generalizing known results and bounds for codes over fields. In particular, we propose a new family of locally recoverable codes by extending a construction proposed in 2014 by Tamo and Barg, and we discuss its optimality.","sentences":["Locally recoverable codes deal with the task of reconstructing a lost symbol by relying on a portion of the remaining coordinates smaller than an information set.","We consider the case of codes over finite chain rings, generalizing known results and bounds for codes over fields.","In particular, we propose a new family of locally recoverable codes by extending a construction proposed in 2014 by Tamo and Barg, and we discuss its optimality."],"url":"http://arxiv.org/abs/2401.05286v1"}
{"created":"2024-01-10 17:13:28","title":"INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges","abstract":"This paper introduces INACIA (Instru\\c{c}\\~ao Assistida com Intelig\\^encia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA's potential in extracting relevant information from case documents, evaluating its legal plausibility, and generating judicial recommendations. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents an innovative approach to assessing system performance, correlating highly with human judgment. The results highlight INACIA's proficiency in handling complex legal tasks, indicating its suitability for augmenting efficiency and judicial fairness within legal systems. The paper also discusses potential enhancements and future applications, positioning INACIA as a model for worldwide AI integration in legal domains.","sentences":["This paper introduces INACIA (Instru\\c{c}\\~ao Assistida com Intelig\\^encia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU).","The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation.","Through a series of experiments, we demonstrate INACIA's potential in extracting relevant information from case documents, evaluating its legal plausibility, and generating judicial recommendations.","Utilizing a validation dataset alongside LLMs, our evaluation methodology presents an innovative approach to assessing system performance, correlating highly with human judgment.","The results highlight INACIA's proficiency in handling complex legal tasks, indicating its suitability for augmenting efficiency and judicial fairness within legal systems.","The paper also discusses potential enhancements and future applications, positioning INACIA as a model for worldwide AI integration in legal domains."],"url":"http://arxiv.org/abs/2401.05273v1"}
{"created":"2024-01-10 17:07:17","title":"CineMPC: A Fully Autonomous Drone Cinematography System Incorporating Zoom, Focus, Pose, and Scene Composition","abstract":"We present CineMPC, a complete cinematographic system that autonomously controls a drone to film multiple targets recording user-specified aesthetic objectives. Existing solutions in autonomous cinematography control only the camera extrinsics, namely its position, and orientation. In contrast, CineMPC is the first solution that includes the camera intrinsic parameters in the control loop, which are essential tools for controlling cinematographic effects like focus, depth-of-field, and zoom. The system estimates the relative poses between the targets and the camera from an RGB-D image and optimizes a trajectory for the extrinsic and intrinsic camera parameters to film the artistic and technical requirements specified by the user. The drone and the camera are controlled in a nonlinear Model Predicted Control (MPC) loop by re-optimizing the trajectory at each time step in response to current conditions in the scene. The perception system of CineMPC can track the targets' position and orientation despite the camera effects. Experiments in a photorealistic simulation and with a real platform demonstrate the capabilities of the system to achieve a full array of cinematographic effects that are not possible without the control of the intrinsics of the camera. Code for CineMPC is implemented following a modular architecture in ROS and released to the community.","sentences":["We present CineMPC, a complete cinematographic system that autonomously controls a drone to film multiple targets recording user-specified aesthetic objectives.","Existing solutions in autonomous cinematography control only the camera extrinsics, namely its position, and orientation.","In contrast, CineMPC is the first solution that includes the camera intrinsic parameters in the control loop, which are essential tools for controlling cinematographic effects like focus, depth-of-field, and zoom.","The system estimates the relative poses between the targets and the camera from an RGB-D image and optimizes a trajectory for the extrinsic and intrinsic camera parameters to film the artistic and technical requirements specified by the user.","The drone and the camera are controlled in a nonlinear Model Predicted Control (MPC) loop by re-optimizing the trajectory at each time step in response to current conditions in the scene.","The perception system of CineMPC can track the targets' position and orientation despite the camera effects.","Experiments in a photorealistic simulation and with a real platform demonstrate the capabilities of the system to achieve a full array of cinematographic effects that are not possible without the control of the intrinsics of the camera.","Code for CineMPC is implemented following a modular architecture in ROS and released to the community."],"url":"http://arxiv.org/abs/2401.05272v1"}
{"created":"2024-01-10 16:57:24","title":"AUTOACT: Automatic Agent Learning from Scratch via Self-Planning","abstract":"Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to various strong baselines. We even notice that AutoAct, when using the Llama-2-13b model, can achieve performance comparable to that of the GPT-3.5-Turbo agent. Code will be available at https://github.com/zjunlp/AutoAct.","sentences":["Language agents have achieved considerable performance on various complex tasks.","Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions.","To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4).","Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models.","Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task.","We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to various strong baselines.","We even notice that AutoAct, when using the Llama-2-13b model, can achieve performance comparable to that of the GPT-3.5-Turbo agent.","Code will be available at https://github.com/zjunlp/AutoAct."],"url":"http://arxiv.org/abs/2401.05268v1"}
{"created":"2024-01-10 16:32:25","title":"Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination","abstract":"Although affective expressions of individuals have been extensively studied using social media, research has primarily focused on the Western context. There are substantial differences among cultures that contribute to their affective expressions. This paper examines the differences between Twitter (X) in the United States and Sina Weibo posts in China on two primary dimensions of affect - valence and arousal. We study the difference in the functional relationship between arousal and valence (so-called V-shaped) among individuals in the US and China and explore the associated content differences. Furthermore, we correlate word usage and topics in both platforms to interpret their differences. We observe that for Twitter users, the variation in emotional intensity is less distinct between negative and positive emotions compared to Weibo users, and there is a sharper escalation in arousal corresponding with heightened emotions. From language features, we discover that affective expressions are associated with personal life and feelings on Twitter, while on Weibo such discussions are about socio-political topics in the society. These results suggest a West-East difference in the V-shaped relationship between valence and arousal of affective expressions on social media influenced by content differences. Our findings have implications for applications and theories related to cultural differences in affective expressions.","sentences":["Although affective expressions of individuals have been extensively studied using social media, research has primarily focused on the Western context.","There are substantial differences among cultures that contribute to their affective expressions.","This paper examines the differences between Twitter (X) in the United States and Sina Weibo posts in China on two primary dimensions of affect - valence and arousal.","We study the difference in the functional relationship between arousal and valence (so-called V-shaped) among individuals in the US and China and explore the associated content differences.","Furthermore, we correlate word usage and topics in both platforms to interpret their differences.","We observe that for Twitter users, the variation in emotional intensity is less distinct between negative and positive emotions compared to Weibo users, and there is a sharper escalation in arousal corresponding with heightened emotions.","From language features, we discover that affective expressions are associated with personal life and feelings on Twitter, while on Weibo such discussions are about socio-political topics in the society.","These results suggest a West-East difference in the V-shaped relationship between valence and arousal of affective expressions on social media influenced by content differences.","Our findings have implications for applications and theories related to cultural differences in affective expressions."],"url":"http://arxiv.org/abs/2401.05254v1"}
{"created":"2024-01-10 16:27:38","title":"PIXART-\u03b4: Fast and Controllable Image Generation with Latent Consistency Models","abstract":"This technical report introduces PIXART-{\\delta}, a text-to-image synthesis framework that integrates the Latent Consistency Model (LCM) and ControlNet into the advanced PIXART-{\\alpha} model. PIXART-{\\alpha} is recognized for its ability to generate high-quality images of 1024px resolution through a remarkably efficient training process. The integration of LCM in PIXART-{\\delta} significantly accelerates the inference speed, enabling the production of high-quality images in just 2-4 steps. Notably, PIXART-{\\delta} achieves a breakthrough 0.5 seconds for generating 1024x1024 pixel images, marking a 7x improvement over the PIXART-{\\alpha}. Additionally, PIXART-{\\delta} is designed to be efficiently trainable on 32GB V100 GPUs within a single day. With its 8-bit inference capability (von Platen et al., 2023), PIXART-{\\delta} can synthesize 1024px images within 8GB GPU memory constraints, greatly enhancing its usability and accessibility. Furthermore, incorporating a ControlNet-like module enables fine-grained control over text-to-image diffusion models. We introduce a novel ControlNet-Transformer architecture, specifically tailored for Transformers, achieving explicit controllability alongside high-quality image generation. As a state-of-the-art, open-source image generation model, PIXART-{\\delta} offers a promising alternative to the Stable Diffusion family of models, contributing significantly to text-to-image synthesis.","sentences":["This technical report introduces PIXART-{\\delta}, a text-to-image synthesis framework that integrates the Latent Consistency Model (LCM) and ControlNet into the advanced PIXART-{\\alpha} model.","PIXART-{\\alpha} is recognized for its ability to generate high-quality images of 1024px resolution through a remarkably efficient training process.","The integration of LCM in PIXART-{\\delta} significantly accelerates the inference speed, enabling the production of high-quality images in just 2-4 steps.","Notably, PIXART-{\\delta} achieves a breakthrough 0.5 seconds for generating 1024x1024 pixel images, marking a 7x improvement over the PIXART-{\\alpha}.","Additionally, PIXART-{\\delta} is designed to be efficiently trainable on 32GB V100 GPUs within a single day.","With its 8-bit inference capability (von Platen et al., 2023), PIXART-{\\delta} can synthesize 1024px images within 8GB GPU memory constraints, greatly enhancing its usability and accessibility.","Furthermore, incorporating a ControlNet-like module enables fine-grained control over text-to-image diffusion models.","We introduce a novel ControlNet-Transformer architecture, specifically tailored for Transformers, achieving explicit controllability alongside high-quality image generation.","As a state-of-the-art, open-source image generation model, PIXART-{\\delta} offers a promising alternative to the Stable Diffusion family of models, contributing significantly to text-to-image synthesis."],"url":"http://arxiv.org/abs/2401.05252v1"}
{"created":"2024-01-10 16:27:30","title":"ReACT: Reinforcement Learning for Controller Parametrization using B-Spline Geometries","abstract":"Robust and performant controllers are essential for industrial applications. However, deriving controller parameters for complex and nonlinear systems is challenging and time-consuming. To facilitate automatic controller parametrization, this work presents a novel approach using deep reinforcement learning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on the control of parameter-variant systems, a class of systems with complex behavior which depends on the operating conditions. For this system class, gain-scheduling control structures are widely used in applications across industries due to well-known design principles. Facilitating the expensive controller parametrization task regarding these control structures, we deploy an DRL agent. Based on control system observations, the agent autonomously decides how to adapt the controller parameters. We make the adaptation process more efficient by introducing BSGs to map the controller parameters which may depend on numerous operating conditions. To preprocess time-series data and extract a fixed-length feature vector, we use a long short-term memory (LSTM) neural networks. Furthermore, this work contributes actor regularizations that are relevant to real-world environments which differ from training. Accordingly, we apply dropout layer normalization to the actor and critic networks of the truncated quantile critic (TQC) algorithm. To show our approach's working principle and effectiveness, we train and evaluate the DRL agent on the parametrization task of an industrial control structure with parameter lookup tables.","sentences":["Robust and performant controllers are essential for industrial applications.","However, deriving controller parameters for complex and nonlinear systems is challenging and time-consuming.","To facilitate automatic controller parametrization, this work presents a novel approach using deep reinforcement learning (DRL) with N-dimensional B-spline geometries (BSGs).","We focus on the control of parameter-variant systems, a class of systems with complex behavior which depends on the operating conditions.","For this system class, gain-scheduling control structures are widely used in applications across industries due to well-known design principles.","Facilitating the expensive controller parametrization task regarding these control structures, we deploy an DRL agent.","Based on control system observations, the agent autonomously decides how to adapt the controller parameters.","We make the adaptation process more efficient by introducing BSGs to map the controller parameters which may depend on numerous operating conditions.","To preprocess time-series data and extract a fixed-length feature vector, we use a long short-term memory (LSTM) neural networks.","Furthermore, this work contributes actor regularizations that are relevant to real-world environments which differ from training.","Accordingly, we apply dropout layer normalization to the actor and critic networks of the truncated quantile critic (TQC) algorithm.","To show our approach's working principle and effectiveness, we train and evaluate the DRL agent on the parametrization task of an industrial control structure with parameter lookup tables."],"url":"http://arxiv.org/abs/2401.05251v1"}
{"created":"2024-01-10 16:21:18","title":"CASA: Causality-driven Argument Sufficiency Assessment","abstract":"The argument sufficiency assessment task aims to determine if the premises of a given argument support its conclusion. To tackle this task, existing works often train a classifier on data annotated by humans. However, annotating data is laborious, and annotations are often inconsistent due to subjective criteria. Motivated by the probability of sufficiency (PS) definition in the causal literature, we propose CASA, a zero-shot causality-driven argument sufficiency assessment framework. PS measures how likely introducing the premise event would lead to the conclusion, when both the premise and conclusion events are absent. To estimate this probability, we propose to use large language models (LLMs) to generate contexts that are inconsistent with the premise and conclusion, and revise them by injecting the premise event. Experiments on two logical fallacy detection datasets demonstrate that CASA accurately identifies insufficient arguments. We further deploy CASA in a writing assistance application, and find that suggestions generated by CASA enhance the sufficiency of student-written arguments. Code and data are available at https://github.com/xxxiaol/CASA.","sentences":["The argument sufficiency assessment task aims to determine if the premises of a given argument support its conclusion.","To tackle this task, existing works often train a classifier on data annotated by humans.","However, annotating data is laborious, and annotations are often inconsistent due to subjective criteria.","Motivated by the probability of sufficiency (PS) definition in the causal literature, we propose CASA, a zero-shot causality-driven argument sufficiency assessment framework.","PS measures how likely introducing the premise event would lead to the conclusion, when both the premise and conclusion events are absent.","To estimate this probability, we propose to use large language models (LLMs) to generate contexts that are inconsistent with the premise and conclusion, and revise them by injecting the premise event.","Experiments on two logical fallacy detection datasets demonstrate that CASA accurately identifies insufficient arguments.","We further deploy CASA in a writing assistance application, and find that suggestions generated by CASA enhance the sufficiency of student-written arguments.","Code and data are available at https://github.com/xxxiaol/CASA."],"url":"http://arxiv.org/abs/2401.05249v1"}
{"created":"2024-01-10 16:20:12","title":"Computing efficiently a parity-check matrix for Zps-additive codes","abstract":"The Zps-additive codes of length n are subgroups of Zps^n , and can be seen as a generalization of linear codes over Z2, Z4, or more general over Z2s . In this paper, we show two methods for computing a parity-check matrix of a Zps-additive code from a generator matrix of the code in standard form. We also compare the performance of our results implemented in Magma with the current available function in Magma for codes over finite rings in general. A time complexity analysis is also shown.","sentences":["The Zps-additive codes of length n are subgroups of Zps^n , and can be seen as a generalization of linear codes over Z2, Z4, or more general over Z2s .","In this paper, we show two methods for computing a parity-check matrix of a Zps-additive code from a generator matrix of the code in standard form.","We also compare the performance of our results implemented in Magma with the current available function in Magma for codes over finite rings in general.","A time complexity analysis is also shown."],"url":"http://arxiv.org/abs/2401.05247v1"}
{"created":"2024-01-10 16:13:21","title":"Decoupling Decision-Making in Fraud Prevention through Classifier Calibration for Business Logic Action","abstract":"Machine learning models typically focus on specific targets like creating classifiers, often based on known population feature distributions in a business context. However, models calculating individual features adapt over time to improve precision, introducing the concept of decoupling: shifting from point evaluation to data distribution. We use calibration strategies as strategy for decoupling machine learning (ML) classifiers from score-based actions within business logic frameworks. To evaluate these strategies, we perform a comparative analysis using a real-world business scenario and multiple ML models. Our findings highlight the trade-offs and performance implications of the approach, offering valuable insights for practitioners seeking to optimize their decoupling efforts. In particular, the Isotonic and Beta calibration methods stand out for scenarios in which there is shift between training and testing data.","sentences":["Machine learning models typically focus on specific targets like creating classifiers, often based on known population feature distributions in a business context.","However, models calculating individual features adapt over time to improve precision, introducing the concept of decoupling: shifting from point evaluation to data distribution.","We use calibration strategies as strategy for decoupling machine learning (ML) classifiers from score-based actions within business logic frameworks.","To evaluate these strategies, we perform a comparative analysis using a real-world business scenario and multiple ML models.","Our findings highlight the trade-offs and performance implications of the approach, offering valuable insights for practitioners seeking to optimize their decoupling efforts.","In particular, the Isotonic and Beta calibration methods stand out for scenarios in which there is shift between training and testing data."],"url":"http://arxiv.org/abs/2401.05240v1"}
{"created":"2024-01-10 16:13:15","title":"Failures of public key infrastructure: 53 year survey","abstract":"The Public Key Infrastructure existed in critical infrastructure systems since the expansion of the World Wide Web, but to this day its limitations have not been completely solved. With the rise of government-driven digital identity in Europe, it is more important than ever to understand how PKI can be an efficient frame for eID and to learn from mistakes encountered by other countries in such critical systems. This survey aims to analyze the literature on the problems and risks that PKI exhibits, establish a brief timeline of its evolution in the last decades and study how it was implemented in digital identity projects.","sentences":["The Public Key Infrastructure existed in critical infrastructure systems since the expansion of the World Wide Web, but to this day its limitations have not been completely solved.","With the rise of government-driven digital identity in Europe, it is more important than ever to understand how PKI can be an efficient frame for eID and to learn from mistakes encountered by other countries in such critical systems.","This survey aims to analyze the literature on the problems and risks that PKI exhibits, establish a brief timeline of its evolution in the last decades and study how it was implemented in digital identity projects."],"url":"http://arxiv.org/abs/2401.05239v1"}
{"created":"2024-01-10 16:07:40","title":"Structure from Duplicates: Neural Inverse Graphics from a Pile of Objects","abstract":"Our world is full of identical objects (\\emphe.g., cans of coke, cars of same model). These duplicates, when seen together, provide additional and strong cues for us to effectively reason about 3D. Inspired by this observation, we introduce Structure from Duplicates (SfD), a novel inverse graphics framework that reconstructs geometry, material, and illumination from a single image containing multiple identical objects. SfD begins by identifying multiple instances of an object within an image, and then jointly estimates the 6DoF pose for all instances.An inverse graphics pipeline is subsequently employed to jointly reason about the shape, material of the object, and the environment light, while adhering to the shared geometry and material constraint across instances. Our primary contributions involve utilizing object duplicates as a robust prior for single-image inverse graphics and proposing an in-plane rotation-robust Structure from Motion (SfM) formulation for joint 6-DoF object pose estimation. By leveraging multi-view cues from a single image, SfD generates more realistic and detailed 3D reconstructions, significantly outperforming existing single image reconstruction models and multi-view reconstruction approaches with a similar or greater number of observations.","sentences":["Our world is full of identical objects (\\emphe.g., cans of coke, cars of same model).","These duplicates, when seen together, provide additional and strong cues for us to effectively reason about 3D. Inspired by this observation, we introduce Structure from Duplicates (SfD), a novel inverse graphics framework that reconstructs geometry, material, and illumination from a single image containing multiple identical objects.","SfD begins by identifying multiple instances of an object within an image, and then jointly estimates the 6DoF pose for all instances.","An inverse graphics pipeline is subsequently employed to jointly reason about the shape, material of the object, and the environment light, while adhering to the shared geometry and material constraint across instances.","Our primary contributions involve utilizing object duplicates as a robust prior for single-image inverse graphics and proposing an in-plane rotation-robust Structure from Motion (SfM) formulation for joint 6-DoF object pose estimation.","By leveraging multi-view cues from a single image, SfD generates more realistic and detailed 3D reconstructions, significantly outperforming existing single image reconstruction models and multi-view reconstruction approaches with a similar or greater number of observations."],"url":"http://arxiv.org/abs/2401.05236v1"}
{"created":"2024-01-10 16:01:55","title":"A Survey on Optimization Studies of Group Centrality Metrics","abstract":"Centrality metrics have become a popular concept in network science and optimization. Over the years, centrality has been used to assign importance and identify influential elements in various settings, including transportation, infrastructure, biological, and social networks, among others. That said, most of the literature has focused on nodal versions of centrality. Recently, group counterparts of centrality have started attracting scientific and practitioner interest. The identification of sets of nodes that are influential within a network is becoming increasingly more important. This is even more pronounced when these sets of nodes are required to induce a certain motif or structure. In this study, we review group centrality metrics from an operations research and optimization perspective for the first time. This is particularly interesting due to the rapid evolution and development of this area in the operations research community over the last decade. We first present a historical overview of how we have reached this point in the study of group centrality. We then discuss the different structures and motifs that appear prominently in the literature, alongside the techniques and methodologies that are popular. We finally present possible avenues and directions for future work, mainly in three areas: (i) probabilistic metrics to account for randomness along with stochastic optimization techniques; (ii) structures and relaxations that have not been yet studied; and (iii) new emerging applications that can take advantage of group centrality. Our survey offers a concise review of group centrality and its intersection with network analysis and optimization.","sentences":["Centrality metrics have become a popular concept in network science and optimization.","Over the years, centrality has been used to assign importance and identify influential elements in various settings, including transportation, infrastructure, biological, and social networks, among others.","That said, most of the literature has focused on nodal versions of centrality.","Recently, group counterparts of centrality have started attracting scientific and practitioner interest.","The identification of sets of nodes that are influential within a network is becoming increasingly more important.","This is even more pronounced when these sets of nodes are required to induce a certain motif or structure.","In this study, we review group centrality metrics from an operations research and optimization perspective for the first time.","This is particularly interesting due to the rapid evolution and development of this area in the operations research community over the last decade.","We first present a historical overview of how we have reached this point in the study of group centrality.","We then discuss the different structures and motifs that appear prominently in the literature, alongside the techniques and methodologies that are popular.","We finally present possible avenues and directions for future work, mainly in three areas: (i) probabilistic metrics to account for randomness along with stochastic optimization techniques; (ii) structures and relaxations that have not been yet studied; and (iii) new emerging applications that can take advantage of group centrality.","Our survey offers a concise review of group centrality and its intersection with network analysis and optimization."],"url":"http://arxiv.org/abs/2401.05235v1"}
{"created":"2024-01-10 16:01:08","title":"Taming \"data-hungry\" reinforcement learning? Stability in continuous state-action spaces","abstract":"We introduce a novel framework for analyzing reinforcement learning (RL) in continuous state-action spaces, and use it to prove fast rates of convergence in both off-line and on-line settings. Our analysis highlights two key stability properties, relating to how changes in value functions and/or policies affect the Bellman operator and occupation measures. We argue that these properties are satisfied in many continuous state-action Markov decision processes, and demonstrate how they arise naturally when using linear function approximation methods. Our analysis offers fresh perspectives on the roles of pessimism and optimism in off-line and on-line RL, and highlights the connection between off-line RL and transfer learning.","sentences":["We introduce a novel framework for analyzing reinforcement learning (RL) in continuous state-action spaces, and use it to prove fast rates of convergence in both off-line and on-line settings.","Our analysis highlights two key stability properties, relating to how changes in value functions and/or policies affect the Bellman operator and occupation measures.","We argue that these properties are satisfied in many continuous state-action Markov decision processes, and demonstrate how they arise naturally when using linear function approximation methods.","Our analysis offers fresh perspectives on the roles of pessimism and optimism in off-line and on-line RL, and highlights the connection between off-line RL and transfer learning."],"url":"http://arxiv.org/abs/2401.05233v1"}
{"created":"2024-01-10 15:59:59","title":"Measuring Natural Scenes SFR of Automotive Fisheye Cameras","abstract":"The Modulation Transfer Function (MTF) is an important image quality metric typically used in the automotive domain. However, despite the fact that optical quality has an impact on the performance of computer vision in vehicle automation, for many public datasets, this metric is unknown. Additionally, wide field-of-view (FOV) cameras have become increasingly popular, particularly for low-speed vehicle automation applications. To investigate image quality in datasets, this paper proposes an adaptation of the Natural Scenes Spatial Frequency Response (NS-SFR) algorithm to suit cameras with a wide field-of-view.","sentences":["The Modulation Transfer Function (MTF) is an important image quality metric typically used in the automotive domain.","However, despite the fact that optical quality has an impact on the performance of computer vision in vehicle automation, for many public datasets, this metric is unknown.","Additionally, wide field-of-view (FOV) cameras have become increasingly popular, particularly for low-speed vehicle automation applications.","To investigate image quality in datasets, this paper proposes an adaptation of the Natural Scenes Spatial Frequency Response (NS-SFR) algorithm to suit cameras with a wide field-of-view."],"url":"http://arxiv.org/abs/2401.05232v1"}
{"created":"2024-01-10 15:52:21","title":"TOVAC: Tele-operated Vehicle Admission Control and Routing","abstract":"Tele-operated Driving (ToD) is a challenging use case for mobile network operators. Video captured by the built-in vehicle cameras must be streamed meeting a latency requirement of 5 ms with a 99.999% reliability. Although 5G offers high bandwidth, ultra-low latencies and high reliability; ToD service requirements are violated due to bad channel conditions. Ignoring the channel state may lead to over-estimate the number of ToD vehicles that can meet the service requirements, hence comprising the vehicle security. To fill this gap, in this letter we propose TOVAC, an algorithm that guarantees ToD service requirements by taking adequate admission control and routing decisions. This is achieved by using a channel-based capacity graph that determines the maximum number of vehicles that can be tele-operated in any road section. We evaluate TOVAC considering cellular deployments from Turin and show that, unlike a state of the art solution, TOVAC guarantees the ToD service requirements.","sentences":["Tele-operated Driving (ToD) is a challenging use case for mobile network operators.","Video captured by the built-in vehicle cameras must be streamed meeting a latency requirement of 5 ms with a 99.999% reliability.","Although 5G offers high bandwidth, ultra-low latencies and high reliability; ToD service requirements are violated due to bad channel conditions.","Ignoring the channel state may lead to over-estimate the number of ToD vehicles that can meet the service requirements, hence comprising the vehicle security.","To fill this gap, in this letter we propose TOVAC, an algorithm that guarantees ToD service requirements by taking adequate admission control and routing decisions.","This is achieved by using a channel-based capacity graph that determines the maximum number of vehicles that can be tele-operated in any road section.","We evaluate TOVAC considering cellular deployments from Turin and show that, unlike a state of the art solution, TOVAC guarantees the ToD service requirements."],"url":"http://arxiv.org/abs/2401.05225v1"}
{"created":"2024-01-10 15:51:39","title":"Do Vision and Language Encoders Represent the World Similarly?","abstract":"Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks. Furthermore, modality-specific encoders achieve impressive performances in their respective domains. This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world? Analyzing the latent spaces structure of vision and language models on image-caption benchmarks using the Centered Kernel Alignment (CKA), we find that the representation spaces of unaligned and aligned encoders are semantically similar. In the absence of statistical similarity in aligned encoders like CLIP, we show that a possible matching of unaligned encoders exists without any training. We frame this as a seeded graph-matching problem exploiting the semantic similarity between graphs and propose two methods - a Fast Quadratic Assignment Problem optimization, and a novel localized CKA metric-based matching/retrieval. We demonstrate the effectiveness of this on several downstream tasks including cross-lingual, cross-domain caption matching and image classification.","sentences":["Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks.","Furthermore, modality-specific encoders achieve impressive performances in their respective domains.","This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world?","Analyzing the latent spaces structure of vision and language models on image-caption benchmarks using the Centered Kernel Alignment (CKA), we find that the representation spaces of unaligned and aligned encoders are semantically similar.","In the absence of statistical similarity in aligned encoders like CLIP, we show that a possible matching of unaligned encoders exists without any training.","We frame this as a seeded graph-matching problem exploiting the semantic similarity between graphs and propose two methods - a Fast Quadratic Assignment Problem optimization, and a novel localized CKA metric-based matching/retrieval.","We demonstrate the effectiveness of this on several downstream tasks including cross-lingual, cross-domain caption matching and image classification."],"url":"http://arxiv.org/abs/2401.05224v1"}
{"created":"2024-01-10 15:38:00","title":"Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud Detection","abstract":"The digital era has seen a marked increase in financial fraud. edge ML emerged as a promising solution for smartphone payment services fraud detection, enabling the deployment of ML models directly on edge devices. This approach enables a more personalized real-time fraud detection. However, a significant gap in current research is the lack of a robust system for monitoring data distribution shifts in these distributed edge ML applications. Our work bridges this gap by introducing a novel open-source framework designed for continuous monitoring of data distribution shifts on a network of edge devices. Our system includes an innovative calculation of the Kolmogorov-Smirnov (KS) test over a distributed network of edge devices, enabling efficient and accurate monitoring of users behavior shifts. We comprehensively evaluate the proposed framework employing both real-world and synthetic financial transaction datasets and demonstrate the framework's effectiveness.","sentences":["The digital era has seen a marked increase in financial fraud.","edge ML emerged as a promising solution for smartphone payment services fraud detection, enabling the deployment of ML models directly on edge devices.","This approach enables a more personalized real-time fraud detection.","However, a significant gap in current research is the lack of a robust system for monitoring data distribution shifts in these distributed edge ML applications.","Our work bridges this gap by introducing a novel open-source framework designed for continuous monitoring of data distribution shifts on a network of edge devices.","Our system includes an innovative calculation of the Kolmogorov-Smirnov (KS) test over a distributed network of edge devices, enabling efficient and accurate monitoring of users behavior shifts.","We comprehensively evaluate the proposed framework employing both real-world and synthetic financial transaction datasets and demonstrate the framework's effectiveness."],"url":"http://arxiv.org/abs/2401.05219v1"}
{"created":"2024-01-10 15:34:42","title":"Invariant Causal Prediction with Locally Linear Models","abstract":"We consider the task of identifying the causal parents of a target variable among a set of candidate variables from observational data. Our main assumption is that the candidate variables are observed in different environments which may, for example, correspond to different settings of a machine or different time intervals in a dynamical process. Under certain assumptions different environments can be regarded as interventions on the observed system. We assume a linear relationship between target and covariates, which can be different in each environment with the only restriction that the causal structure is invariant across environments. This is an extension of the ICP ($\\textbf{I}$nvariant $\\textbf{C}$ausal $\\textbf{P}$rediction) principle by Peters et al. [2016], who assumed a fixed linear relationship across all environments. Within our proposed setting we provide sufficient conditions for identifiability of the causal parents and introduce a practical method called LoLICaP ($\\textbf{Lo}$cally $\\textbf{L}$inear $\\textbf{I}$nvariant $\\textbf{Ca}$usal $\\textbf{P}$rediction), which is based on a hypothesis test for parent identification using a ratio of minimum and maximum statistics. We then show in a simplified setting that the statistical power of LoLICaP converges exponentially fast in the sample size, and finally we analyze the behavior of LoLICaP experimentally in more general settings.","sentences":["We consider the task of identifying the causal parents of a target variable among a set of candidate variables from observational data.","Our main assumption is that the candidate variables are observed in different environments which may, for example, correspond to different settings of a machine or different time intervals in a dynamical process.","Under certain assumptions different environments can be regarded as interventions on the observed system.","We assume a linear relationship between target and covariates, which can be different in each environment with the only restriction that the causal structure is invariant across environments.","This is an extension of the ICP ($\\textbf{I}$nvariant $\\textbf{C}$ausal $\\textbf{P}$rediction) principle by Peters et al.","[2016], who assumed a fixed linear relationship across all environments.","Within our proposed setting we provide sufficient conditions for identifiability of the causal parents and introduce a practical method called LoLICaP ($\\textbf{Lo}$cally $\\textbf{L}$inear $\\textbf{I}$nvariant $\\textbf{Ca}$usal $\\textbf{P}$rediction), which is based on a hypothesis test for parent identification using a ratio of minimum and maximum statistics.","We then show in a simplified setting that the statistical power of LoLICaP converges exponentially fast in the sample size, and finally we analyze the behavior of LoLICaP experimentally in more general settings."],"url":"http://arxiv.org/abs/2401.05218v1"}
{"created":"2024-01-10 15:30:19","title":"Exploring Vulnerabilities of No-Reference Image Quality Assessment Models: A Query-Based Black-Box Method","abstract":"No-Reference Image Quality Assessment (NR-IQA) aims to predict image quality scores consistent with human perception without relying on pristine reference images, serving as a crucial component in various visual tasks. Ensuring the robustness of NR-IQA methods is vital for reliable comparisons of different image processing techniques and consistent user experiences in recommendations. The attack methods for NR-IQA provide a powerful instrument to test the robustness of NR-IQA. However, current attack methods of NR-IQA heavily rely on the gradient of the NR-IQA model, leading to limitations when the gradient information is unavailable. In this paper, we present a pioneering query-based black box attack against NR-IQA methods. We propose the concept of \\emph{score boundary} and leverage an adaptive iterative approach with multiple score boundaries. Meanwhile, the initial attack directions are also designed to leverage the characteristics of the Human Visual System (HVS). Experiments show our attack method outperforms all compared state-of-the-art methods and is far ahead of previous black-box methods. The effective DBCNN model suffers a Spearman rank-order correlation coefficient (SROCC) decline of $0.6972$ attacked by our method, revealing the vulnerability of NR-IQA to black-box attacks. The proposed attack method also provides a potent tool for further exploration into NR-IQA robustness.","sentences":["No-Reference Image Quality Assessment (NR-IQA) aims to predict image quality scores consistent with human perception without relying on pristine reference images, serving as a crucial component in various visual tasks.","Ensuring the robustness of NR-IQA methods is vital for reliable comparisons of different image processing techniques and consistent user experiences in recommendations.","The attack methods for NR-IQA provide a powerful instrument to test the robustness of NR-IQA.","However, current attack methods of NR-IQA heavily rely on the gradient of the NR-IQA model, leading to limitations when the gradient information is unavailable.","In this paper, we present a pioneering query-based black box attack against NR-IQA methods.","We propose the concept of \\emph{score boundary} and leverage an adaptive iterative approach with multiple score boundaries.","Meanwhile, the initial attack directions are also designed to leverage the characteristics of the Human Visual System (HVS).","Experiments show our attack method outperforms all compared state-of-the-art methods and is far ahead of previous black-box methods.","The effective DBCNN model suffers a Spearman rank-order correlation coefficient (SROCC) decline of $0.6972$ attacked by our method, revealing the vulnerability of NR-IQA to black-box attacks.","The proposed attack method also provides a potent tool for further exploration into NR-IQA robustness."],"url":"http://arxiv.org/abs/2401.05217v1"}
{"created":"2024-01-10 15:27:41","title":"Pre-trained Large Language Models for Financial Sentiment Analysis","abstract":"Financial sentiment analysis refers to classifying financial text contents into sentiment categories (e.g. positive, negative, and neutral). In this paper, we focus on the classification of financial news title, which is a challenging task due to a lack of large amount of training samples. To overcome this difficulty, we propose to adapt the pretrained large language models (LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge amount of text corpora,have an advantage in text understanding and can be effectively adapted to domain-specific task while requiring very few amount of training samples. In particular, we adapt the open-source Llama2-7B model (2023) with the supervised fine-tuning (SFT) technique [4]. Experimental evaluation shows that even with the 7B model (which is relatively small for LLMs), our approach significantly outperforms the previous state-of-the-art algorithms.","sentences":["Financial sentiment analysis refers to classifying financial text contents into sentiment categories (e.g. positive, negative, and neutral).","In this paper, we focus on the classification of financial news title, which is a challenging task due to a lack of large amount of training samples.","To overcome this difficulty, we propose to adapt the pretrained large language models (LLMs)","[1, 2, 3] to solve this problem.","The LLMs, which are trained from huge amount of text corpora,have an advantage in text understanding and can be effectively adapted to domain-specific task while requiring very few amount of training samples.","In particular, we adapt the open-source Llama2-7B model (2023) with the supervised fine-tuning (SFT) technique [4].","Experimental evaluation shows that even with the 7B model (which is relatively small for LLMs), our approach significantly outperforms the previous state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2401.05215v1"}
{"created":"2024-01-10 15:02:35","title":"A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer","abstract":"The verbalizer, which serves to map label words to class labels, is an essential component of prompt-tuning. In this paper, we present a novel approach to constructing verbalizers. While existing methods for verbalizer construction mainly rely on augmenting and refining sets of synonyms or related words based on class names, this paradigm suffers from a narrow perspective and lack of abstraction, resulting in limited coverage and high bias in the label-word space. To address this issue, we propose a label-word construction process that incorporates scenario-specific concepts. Specifically, we extract rich concepts from task-specific scenarios as label-word candidates and then develop a novel cascade calibration module to refine the candidates into a set of label words for each class. We evaluate the effectiveness of our proposed approach through extensive experiments on {five} widely used datasets for zero-shot text classification. The results demonstrate that our method outperforms existing methods and achieves state-of-the-art results.","sentences":["The verbalizer, which serves to map label words to class labels, is an essential component of prompt-tuning.","In this paper, we present a novel approach to constructing verbalizers.","While existing methods for verbalizer construction mainly rely on augmenting and refining sets of synonyms or related words based on class names, this paradigm suffers from a narrow perspective and lack of abstraction, resulting in limited coverage and high bias in the label-word space.","To address this issue, we propose a label-word construction process that incorporates scenario-specific concepts.","Specifically, we extract rich concepts from task-specific scenarios as label-word candidates and then develop a novel cascade calibration module to refine the candidates into a set of label words for each class.","We evaluate the effectiveness of our proposed approach through extensive experiments on {five} widely used datasets for zero-shot text classification.","The results demonstrate that our method outperforms existing methods and achieves state-of-the-art results."],"url":"http://arxiv.org/abs/2401.05204v1"}
{"created":"2024-01-10 14:56:54","title":"Video-based Automatic Lameness Detection of Dairy Cows using Pose Estimation and Multiple Locomotion Traits","abstract":"This study presents an automated lameness detection system that uses deep-learning image processing techniques to extract multiple locomotion traits associated with lameness. Using the T-LEAP pose estimation model, the motion of nine keypoints was extracted from videos of walking cows. The videos were recorded outdoors, with varying illumination conditions, and T-LEAP extracted 99.6% of correct keypoints. The trajectories of the keypoints were then used to compute six locomotion traits: back posture measurement, head bobbing, tracking distance, stride length, stance duration, and swing duration. The three most important traits were back posture measurement, head bobbing, and tracking distance. For the ground truth, we showed that a thoughtful merging of the scores of the observers could improve intra-observer reliability and agreement. We showed that including multiple locomotion traits improves the classification accuracy from 76.6% with only one trait to 79.9% with the three most important traits and to 80.1% with all six locomotion traits.","sentences":["This study presents an automated lameness detection system that uses deep-learning image processing techniques to extract multiple locomotion traits associated with lameness.","Using the T-LEAP pose estimation model, the motion of nine keypoints was extracted from videos of walking cows.","The videos were recorded outdoors, with varying illumination conditions, and T-LEAP extracted 99.6% of correct keypoints.","The trajectories of the keypoints were then used to compute six locomotion traits: back posture measurement, head bobbing, tracking distance, stride length, stance duration, and swing duration.","The three most important traits were back posture measurement, head bobbing, and tracking distance.","For the ground truth, we showed that a thoughtful merging of the scores of the observers could improve intra-observer reliability and agreement.","We showed that including multiple locomotion traits improves the classification accuracy from 76.6% with only one trait to 79.9% with the three most important traits and to 80.1% with all six locomotion traits."],"url":"http://arxiv.org/abs/2401.05202v1"}
{"created":"2024-01-10 14:53:18","title":"Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking","abstract":"Managing knowledge efficiently is crucial for organizational success. In manufacturing, operating factories has become increasing knowledge-intensive putting strain on the factory's capacity to train and support new operators. In this paper, we introduce a Large Language Model (LLM)-based system designed to use the extensive knowledge contained in factory documentation. The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge. To assess its effectiveness, we conducted an evaluation in a factory setting. The results of this evaluation demonstrated the system's benefits; namely, in enabling quicker information retrieval and more efficient resolution of issues. However, the study also highlighted a preference for learning from a human expert when such an option is available. Furthermore, we benchmarked several closed and open-sourced LLMs for this system. GPT-4 consistently outperformed its counterparts, with open-source models like StableBeluga2 trailing closely, presenting an attractive option given its data privacy and customization benefits. Overall, this work offers preliminary insights for factories considering using LLM-tools for knowledge management.","sentences":["Managing knowledge efficiently is crucial for organizational success.","In manufacturing, operating factories has become increasing knowledge-intensive putting strain on the factory's capacity to train and support new operators.","In this paper, we introduce a Large Language Model (LLM)-based system designed to use the extensive knowledge contained in factory documentation.","The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge.","To assess its effectiveness, we conducted an evaluation in a factory setting.","The results of this evaluation demonstrated the system's benefits; namely, in enabling quicker information retrieval and more efficient resolution of issues.","However, the study also highlighted a preference for learning from a human expert when such an option is available.","Furthermore, we benchmarked several closed and open-sourced LLMs for this system.","GPT-4 consistently outperformed its counterparts, with open-source models like StableBeluga2 trailing closely, presenting an attractive option given its data privacy and customization benefits.","Overall, this work offers preliminary insights for factories considering using LLM-tools for knowledge management."],"url":"http://arxiv.org/abs/2401.05200v1"}
{"created":"2024-01-10 14:50:46","title":"Monte Carlo Tree Search for Recipe Generation using GPT-2","abstract":"Automatic food recipe generation methods provide a creative tool for chefs to explore and to create new, and interesting culinary delights. Given the recent success of large language models (LLMs), they have the potential to create new recipes that can meet individual preferences, dietary constraints, and adapt to what is in your refrigerator. Existing research on using LLMs to generate recipes has shown that LLMs can be finetuned to generate realistic-sounding recipes. However, on close examination, these generated recipes often fail to meet basic requirements like including chicken as an ingredient in chicken dishes. In this paper, we propose RecipeMC, a text generation method using GPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to define reward functions to put soft constraints on text generation and thus improve the credibility of the generated recipes. Our results show that human evaluators prefer recipes generated with RecipeMC more often than recipes generated with other baseline methods when compared with real recipes.","sentences":["Automatic food recipe generation methods provide a creative tool for chefs to explore and to create new, and interesting culinary delights.","Given the recent success of large language models (LLMs), they have the potential to create new recipes that can meet individual preferences, dietary constraints, and adapt to what is in your refrigerator.","Existing research on using LLMs to generate recipes has shown that LLMs can be finetuned to generate realistic-sounding recipes.","However, on close examination, these generated recipes often fail to meet basic requirements like including chicken as an ingredient in chicken dishes.","In this paper, we propose RecipeMC, a text generation method using GPT-2 that relies on Monte Carlo Tree Search (MCTS).","RecipeMC allows us to define reward functions to put soft constraints on text generation and thus improve the credibility of the generated recipes.","Our results show that human evaluators prefer recipes generated with RecipeMC more often than recipes generated with other baseline methods when compared with real recipes."],"url":"http://arxiv.org/abs/2401.05199v1"}
{"created":"2024-01-10 14:40:53","title":"Modelling, Positioning, and Deep Reinforcement Learning Path Tracking Control of Scaled Robotic Vehicles: Design and Experimental Validation","abstract":"Mobile robotic systems are becoming increasingly popular. These systems are used in various indoor applications, raging from warehousing and manufacturing to test benches for assessment of advanced control strategies, such as artificial intelligence (AI)-based control solutions, just to name a few. Scaled robotic cars are commonly equipped with a hierarchical control acthiecture that includes tasks dedicated to vehicle state estimation and control. This paper covers both aspects by proposing (i) a federeted extended Kalman filter (FEKF), and (ii) a novel deep reinforcement learning (DRL) path tracking controller trained via an expert demonstrator to expedite the learning phase and increase robustess to the simulation-to-reality gap. The paper also presents the formulation of a vehicle model along with an effective yet simple procedure for identifying tis paramters. The experimentally validated model is used for (i) supporting the design of the FEKF and (ii) serving as a digital twin for training the proposed DRL-based path tracking algorithm. Experimental results confirm the ability of the FEKF to improve the estimate of the mobile robot's position. Furthermore, the effectiveness of the DRL path tracking strateguy is experimentally tested along manoeuvres not considered during training, showing also the ability of the AI-based solution to outpeform model-based control strategies and the demonstrator. The comparison with benchmraking controllers is quantitavely evalueted through a set of key performance indicators.","sentences":["Mobile robotic systems are becoming increasingly popular.","These systems are used in various indoor applications, raging from warehousing and manufacturing to test benches for assessment of advanced control strategies, such as artificial intelligence (AI)-based control solutions, just to name a few.","Scaled robotic cars are commonly equipped with a hierarchical control acthiecture that includes tasks dedicated to vehicle state estimation and control.","This paper covers both aspects by proposing (i) a federeted extended Kalman filter (FEKF), and (ii) a novel deep reinforcement learning (DRL) path tracking controller trained via an expert demonstrator to expedite the learning phase and increase robustess to the simulation-to-reality gap.","The paper also presents the formulation of a vehicle model along with an effective yet simple procedure for identifying tis paramters.","The experimentally validated model is used for (i) supporting the design of the FEKF and (ii) serving as a digital twin for training the proposed DRL-based path tracking algorithm.","Experimental results confirm the ability of the FEKF to improve the estimate of the mobile robot's position.","Furthermore, the effectiveness of the DRL path tracking strateguy is experimentally tested along manoeuvres not considered during training, showing also the ability of the AI-based solution to outpeform model-based control strategies and the demonstrator.","The comparison with benchmraking controllers is quantitavely evalueted through a set of key performance indicators."],"url":"http://arxiv.org/abs/2401.05194v1"}
{"created":"2024-01-10 14:40:23","title":"Experiment Planning with Function Approximation","abstract":"We study the problem of experiment planning with function approximation in contextual bandit problems. In settings where there is a significant overhead to deploying adaptive algorithms -- for example, when the execution of the data collection policies is required to be distributed, or a human in the loop is needed to implement these policies -- producing in advance a set of policies for data collection is paramount. We study the setting where a large dataset of contexts but not rewards is available and may be used by the learner to design an effective data collection strategy. Although when rewards are linear this problem has been well studied, results are still missing for more complex reward models. In this work we propose two experiment planning strategies compatible with function approximation. The first is an eluder planning and sampling procedure that can recover optimality guarantees depending on the eluder dimension of the reward function class. For the second, we show that a uniform sampler achieves competitive optimality rates in the setting where the number of actions is small. We finalize our results introducing a statistical gap fleshing out the fundamental differences between planning and adaptive learning and provide results for planning with model selection.","sentences":["We study the problem of experiment planning with function approximation in contextual bandit problems.","In settings where there is a significant overhead to deploying adaptive algorithms -- for example, when the execution of the data collection policies is required to be distributed, or a human in the loop is needed to implement these policies -- producing in advance a set of policies for data collection is paramount.","We study the setting where a large dataset of contexts but not rewards is available and may be used by the learner to design an effective data collection strategy.","Although when rewards are linear this problem has been well studied, results are still missing for more complex reward models.","In this work we propose two experiment planning strategies compatible with function approximation.","The first is an eluder planning and sampling procedure that can recover optimality guarantees depending on the eluder dimension of the reward function class.","For the second, we show that a uniform sampler achieves competitive optimality rates in the setting where the number of actions is small.","We finalize our results introducing a statistical gap fleshing out the fundamental differences between planning and adaptive learning and provide results for planning with model selection."],"url":"http://arxiv.org/abs/2401.05193v1"}
{"created":"2024-01-10 14:38:47","title":"Adaptive Hardness Negative Sampling for Collaborative Filtering","abstract":"Negative sampling is essential for implicit collaborative filtering to provide proper negative training signals so as to achieve desirable performance. We experimentally unveil a common limitation of all existing negative sampling methods that they can only select negative samples of a fixed hardness level, leading to the false positive problem (FPP) and false negative problem (FNP). We then propose a new paradigm called adaptive hardness negative sampling (AHNS) and discuss its three key criteria. By adaptively selecting negative samples with appropriate hardnesses during the training process, AHNS can well mitigate the impacts of FPP and FNP. Next, we present a concrete instantiation of AHNS called AHNS_{p<0}, and theoretically demonstrate that AHNS_{p<0} can fit the three criteria of AHNS well and achieve a larger lower bound of normalized discounted cumulative gain. Besides, we note that existing negative sampling methods can be regarded as more relaxed cases of AHNS. Finally, we conduct comprehensive experiments, and the results show that AHNS_{p<0} can consistently and substantially outperform several state-of-the-art competitors on multiple datasets.","sentences":["Negative sampling is essential for implicit collaborative filtering to provide proper negative training signals so as to achieve desirable performance.","We experimentally unveil a common limitation of all existing negative sampling methods that they can only select negative samples of a fixed hardness level, leading to the false positive problem (FPP) and false negative problem (FNP).","We then propose a new paradigm called adaptive hardness negative sampling (AHNS) and discuss its three key criteria.","By adaptively selecting negative samples with appropriate hardnesses during the training process, AHNS can well mitigate the impacts of FPP and FNP.","Next, we present a concrete instantiation of AHNS called AHNS_{p<0}, and theoretically demonstrate that AHNS_{p<0} can fit the three criteria of AHNS well and achieve a larger lower bound of normalized discounted cumulative gain.","Besides, we note that existing negative sampling methods can be regarded as more relaxed cases of AHNS.","Finally, we conduct comprehensive experiments, and the results show that AHNS_{p<0} can consistently and substantially outperform several state-of-the-art competitors on multiple datasets."],"url":"http://arxiv.org/abs/2401.05191v1"}
{"created":"2024-01-10 14:38:46","title":"Divide and Conquer for Large Language Models Reasoning","abstract":"Large language models (LLMs) have shown impressive performance in various reasoning benchmarks with the emergence of Chain-of-Thought (CoT) and its derivative methods, particularly in tasks involving multi-choice questions (MCQs). However, current works all process data uniformly without considering the problem-solving difficulty, which means an excessive focus on simple questions while insufficient to intricate ones. To address this challenge, we inspired by humans using heuristic strategies to categorize tasks and handle them individually, propose to apply the Divide and Conquer to LLMs reasoning. First, we divide questions into different subsets based on the statistical confidence score ($\\mathcal{CS}$), then fix nearly resolved sets and conquer demanding nuanced process ones with elaborately designed methods, including Prior Knowledge based Reasoning (PKR) and Filter Choices based Reasoning (FCR), as well as their integration variants. Our experiments demonstrate that this proposed strategy significantly boosts the models' reasoning abilities across nine datasets involving arithmetic, commonsense, and logic tasks. For instance, compared to baseline, we make a striking improvement on low confidence subsets of 8.72\\% for AQuA, 15.07\\% for ARC Challenge and 7.71\\% for RiddleSense. In addition, through extensive analysis on length of rationale and number of options, we verify that longer reasoning paths in PKR could prevent models from referring infer-harmful shortcuts, and also find that removing irrelevant choices in FCR would substantially avoid models' confusion. The code is at \\url{https://github.com/AiMijie/Divide-and-Conquer}","sentences":["Large language models (LLMs) have shown impressive performance in various reasoning benchmarks with the emergence of Chain-of-Thought (CoT) and its derivative methods, particularly in tasks involving multi-choice questions (MCQs).","However, current works all process data uniformly without considering the problem-solving difficulty, which means an excessive focus on simple questions while insufficient to intricate ones.","To address this challenge, we inspired by humans using heuristic strategies to categorize tasks and handle them individually, propose to apply the Divide and Conquer to LLMs reasoning.","First, we divide questions into different subsets based on the statistical confidence score ($\\mathcal{CS}$), then fix nearly resolved sets and conquer demanding nuanced process ones with elaborately designed methods, including Prior Knowledge based Reasoning (PKR) and Filter Choices based Reasoning (FCR), as well as their integration variants.","Our experiments demonstrate that this proposed strategy significantly boosts the models' reasoning abilities across nine datasets involving arithmetic, commonsense, and logic tasks.","For instance, compared to baseline, we make a striking improvement on low confidence subsets of 8.72\\% for AQuA, 15.07\\% for ARC Challenge and 7.71\\% for RiddleSense.","In addition, through extensive analysis on length of rationale and number of options, we verify that longer reasoning paths in PKR could prevent models from referring infer-harmful shortcuts, and also find that removing irrelevant choices in FCR would substantially avoid models' confusion.","The code is at \\url{https://github.com/AiMijie/Divide-and-Conquer}"],"url":"http://arxiv.org/abs/2401.05190v1"}
{"created":"2024-01-10 14:32:30","title":"Integrated Sensing and Communication with Reconfigurable Distributed Antenna and Reflecting Surface: Joint Beamforming and Mode Selection","abstract":"This paper presents a new integrated sensing and communication (ISAC) framework, leveraging the recent advancements of reconfigurable distributed antenna and reflecting surface (RDARS). RDARS is a programmable surface structure comprising numerous elements, each of which can be flexibly configured to operate either in a reflection mode, resembling a passive reconfigurable intelligent surface (RIS), or in a connected mode, functioning as a remote transmit or receive antenna. Our RDARS-aided ISAC framework effectively mitigates the adverse impact of multiplicative fading when compared to the passive RIS-aided ISAC, and reduces cost and energy consumption when compared to the active RIS-aided ISAC. Within our RDARS-aided ISAC framework, we consider a radar output signal-to-noise ratio (SNR) maximization problem under communication constraints to jointly optimize the active transmit beamforming matrix of the base station (BS), the reflection and mode selection matrices of RDARS, and the receive filter. To tackle the inherent non-convexity and the binary integer optimization introduced by the mode selection in this optimization challenge, we propose an efficient iterative algorithm with proved convergence based on majorization minimization (MM) and penalty-based methods.Numerical and simulation results demonstrate the superior performance of our new framework, and clearly verify substantial distribution, reflection as well as selection gains obtained by properly configuring the RDARS.","sentences":["This paper presents a new integrated sensing and communication (ISAC) framework, leveraging the recent advancements of reconfigurable distributed antenna and reflecting surface (RDARS).","RDARS is a programmable surface structure comprising numerous elements, each of which can be flexibly configured to operate either in a reflection mode, resembling a passive reconfigurable intelligent surface (RIS), or in a connected mode, functioning as a remote transmit or receive antenna.","Our RDARS-aided ISAC framework effectively mitigates the adverse impact of multiplicative fading when compared to the passive RIS-aided ISAC, and reduces cost and energy consumption when compared to the active RIS-aided ISAC.","Within our RDARS-aided ISAC framework, we consider a radar output signal-to-noise ratio (SNR) maximization problem under communication constraints to jointly optimize the active transmit beamforming matrix of the base station (BS), the reflection and mode selection matrices of RDARS, and the receive filter.","To tackle the inherent non-convexity and the binary integer optimization introduced by the mode selection in this optimization challenge, we propose an efficient iterative algorithm with proved convergence based on majorization minimization (MM) and penalty-based methods.","Numerical and simulation results demonstrate the superior performance of our new framework, and clearly verify substantial distribution, reflection as well as selection gains obtained by properly configuring the RDARS."],"url":"http://arxiv.org/abs/2401.05182v1"}
{"created":"2024-01-10 14:20:33","title":"Can ChatGPT Rival Neural Machine Translation? A Comparative Study","abstract":"Inspired by the increasing interest in leveraging large language models for translation, this paper evaluates the capabilities of large language models (LLMs) represented by ChatGPT in comparison to the mainstream neural machine translation (NMT) engines in translating Chinese diplomatic texts into English. Specifically, we examine the translation quality of ChatGPT and NMT engines as measured by four automated metrics and human evaluation based on an error-typology and six analytic rubrics. Our findings show that automated metrics yield similar results for ChatGPT under different prompts and NMT systems, while human annotators tend to assign noticeably higher scores to ChatGPT when it is provided an example or contextual information about the translation task. Pairwise correlation between automated metrics and dimensions of human evaluation produces weak and non-significant results, suggesting the divergence between the two methods of translation quality assessment. These findings provide valuable insights into the potential of ChatGPT as a capable machine translator, and the influence of prompt engineering on its performance.","sentences":["Inspired by the increasing interest in leveraging large language models for translation, this paper evaluates the capabilities of large language models (LLMs) represented by ChatGPT in comparison to the mainstream neural machine translation (NMT) engines in translating Chinese diplomatic texts into English.","Specifically, we examine the translation quality of ChatGPT and NMT engines as measured by four automated metrics and human evaluation based on an error-typology and six analytic rubrics.","Our findings show that automated metrics yield similar results for ChatGPT under different prompts and NMT systems, while human annotators tend to assign noticeably higher scores to ChatGPT when it is provided an example or contextual information about the translation task.","Pairwise correlation between automated metrics and dimensions of human evaluation produces weak and non-significant results, suggesting the divergence between the two methods of translation quality assessment.","These findings provide valuable insights into the potential of ChatGPT as a capable machine translator, and the influence of prompt engineering on its performance."],"url":"http://arxiv.org/abs/2401.05176v1"}
{"created":"2024-01-10 14:06:50","title":"Multivariate Extreme Value Theory Based Rate Selection for Ultra-Reliable Communications","abstract":"Diversity schemes play a vital role in improving the performance of ultra-reliable communication systems by transmitting over two or more communication channels to combat fading and co-channel interference. Determining an appropriate transmission strategy that satisfies ultra-reliability constraint necessitates derivation of statistics of channel in ultra-reliable region and, subsequently, integration of these statistics into rate selection while incorporating a confidence interval to account for potential uncertainties that may arise during estimation. In this paper, we propose a novel framework for ultra-reliable real-time transmission considering both spatial diversities and ultra-reliable channel statistics based on multivariate extreme value theory. First, tail distribution of joint received power sequences obtained from different receivers is modeled while incorporating inter-relations of extreme events occurring rarely based on Poisson point process approach in MEVT. The optimum transmission strategies are then developed by determining optimum transmission rate based on estimated joint tail distribution and incorporating confidence intervals into estimations to cope with the availability of limited data. Finally, system reliability is assessed by utilizing outage probability metric. Through analysis of data obtained from the engine compartment of Fiat Linea, our study showcases the effectiveness of proposed methodology in surpassing traditional extrapolation-based approaches. This innovative method not only achieves a higher transmission rate, but also effectively addresses stringent requirements of ultra-reliability. The findings indicate that proposed rate selection framework offers a viable solution for achieving a desired target error probability by employing a higher transmission rate and reducing the amount of training data compared to conventional rate selection methods.","sentences":["Diversity schemes play a vital role in improving the performance of ultra-reliable communication systems by transmitting over two or more communication channels to combat fading and co-channel interference.","Determining an appropriate transmission strategy that satisfies ultra-reliability constraint necessitates derivation of statistics of channel in ultra-reliable region and, subsequently, integration of these statistics into rate selection while incorporating a confidence interval to account for potential uncertainties that may arise during estimation.","In this paper, we propose a novel framework for ultra-reliable real-time transmission considering both spatial diversities and ultra-reliable channel statistics based on multivariate extreme value theory.","First, tail distribution of joint received power sequences obtained from different receivers is modeled while incorporating inter-relations of extreme events occurring rarely based on Poisson point process approach in MEVT.","The optimum transmission strategies are then developed by determining optimum transmission rate based on estimated joint tail distribution and incorporating confidence intervals into estimations to cope with the availability of limited data.","Finally, system reliability is assessed by utilizing outage probability metric.","Through analysis of data obtained from the engine compartment of Fiat Linea, our study showcases the effectiveness of proposed methodology in surpassing traditional extrapolation-based approaches.","This innovative method not only achieves a higher transmission rate, but also effectively addresses stringent requirements of ultra-reliability.","The findings indicate that proposed rate selection framework offers a viable solution for achieving a desired target error probability by employing a higher transmission rate and reducing the amount of training data compared to conventional rate selection methods."],"url":"http://arxiv.org/abs/2401.05171v1"}
{"created":"2024-01-10 14:03:05","title":"CLIP-guided Source-free Object Detection in Aerial Images","abstract":"Domain adaptation is crucial in aerial imagery, as the visual representation of these images can significantly vary based on factors such as geographic location, time, and weather conditions. Additionally, high-resolution aerial images often require substantial storage space and may not be readily accessible to the public. To address these challenges, we propose a novel Source-Free Object Detection (SFOD) method. Specifically, our approach is built upon a self-training framework; however, self-training can lead to inaccurate learning in the absence of labeled training data. To address this issue, we further integrate Contrastive Language-Image Pre-training (CLIP) to guide the generation of pseudo-labels, termed CLIP-guided Aggregation. By leveraging CLIP's zero-shot classification capability, we use it to aggregate scores with the original predicted bounding boxes, enabling us to obtain refined scores for the pseudo-labels. To validate the effectiveness of our method, we constructed two new datasets from different domains based on the DIOR dataset, named DIOR-C and DIOR-Cloudy. Experiments demonstrate that our method outperforms other comparative algorithms.","sentences":["Domain adaptation is crucial in aerial imagery, as the visual representation of these images can significantly vary based on factors such as geographic location, time, and weather conditions.","Additionally, high-resolution aerial images often require substantial storage space and may not be readily accessible to the public.","To address these challenges, we propose a novel Source-Free Object Detection (SFOD) method.","Specifically, our approach is built upon a self-training framework; however, self-training can lead to inaccurate learning in the absence of labeled training data.","To address this issue, we further integrate Contrastive Language-Image Pre-training (CLIP) to guide the generation of pseudo-labels, termed CLIP-guided Aggregation.","By leveraging CLIP's zero-shot classification capability, we use it to aggregate scores with the original predicted bounding boxes, enabling us to obtain refined scores for the pseudo-labels.","To validate the effectiveness of our method, we constructed two new datasets from different domains based on the DIOR dataset, named DIOR-C and DIOR-Cloudy.","Experiments demonstrate that our method outperforms other comparative algorithms."],"url":"http://arxiv.org/abs/2401.05168v1"}
{"created":"2024-01-10 14:02:45","title":"Watermark Text Pattern Spotting in Document Images","abstract":"Watermark text spotting in document images can offer access to an often unexplored source of information, providing crucial evidence about a record's scope, audience and sometimes even authenticity. Stemming from the problem of text spotting, detecting and understanding watermarks in documents inherits the same hardships - in the wild, writing can come in various fonts, sizes and forms, making generic recognition a very difficult problem. To address the lack of resources in this field and propel further research, we propose a novel benchmark (K-Watermark) containing 65,447 data samples generated using Wrender, a watermark text patterns rendering procedure. A validity study using humans raters yields an authenticity score of 0.51 against pre-generated watermarked documents. To prove the usefulness of the dataset and rendering technique, we developed an end-to-end solution (Wextract) for detecting the bounding box instances of watermark text, while predicting the depicted text. To deal with this specific task, we introduce a variance minimization loss and a hierarchical self-attention mechanism. To the best of our knowledge, we are the first to propose an evaluation benchmark and a complete solution for retrieving watermarks from documents surpassing baselines by 5 AP points in detection and 4 points in character accuracy.","sentences":["Watermark text spotting in document images can offer access to an often unexplored source of information, providing crucial evidence about a record's scope, audience and sometimes even authenticity.","Stemming from the problem of text spotting, detecting and understanding watermarks in documents inherits the same hardships - in the wild, writing can come in various fonts, sizes and forms, making generic recognition a very difficult problem.","To address the lack of resources in this field and propel further research, we propose a novel benchmark (K-Watermark) containing 65,447 data samples generated using Wrender, a watermark text patterns rendering procedure.","A validity study using humans raters yields an authenticity score of 0.51 against pre-generated watermarked documents.","To prove the usefulness of the dataset and rendering technique, we developed an end-to-end solution (Wextract) for detecting the bounding box instances of watermark text, while predicting the depicted text.","To deal with this specific task, we introduce a variance minimization loss and a hierarchical self-attention mechanism.","To the best of our knowledge, we are the first to propose an evaluation benchmark and a complete solution for retrieving watermarks from documents surpassing baselines by 5 AP points in detection and 4 points in character accuracy."],"url":"http://arxiv.org/abs/2401.05167v1"}
{"created":"2024-01-10 14:01:51","title":"REACT 2024: the Second Multiple Appropriate Facial Reaction Generation Challenge","abstract":"In dyadic interactions, humans communicate their intentions and state of mind using verbal and non-verbal cues, where multiple different facial reactions might be appropriate in response to a specific speaker behaviour. Then, how to develop a machine learning (ML) model that can automatically generate multiple appropriate, diverse, realistic and synchronised human facial reactions from an previously unseen speaker behaviour is a challenging task. Following the successful organisation of the first REACT challenge (REACT 2023), this edition of the challenge (REACT 2024) employs a subset used by the previous challenge, which contains segmented 30-secs dyadic interaction clips originally recorded as part of the NOXI and RECOLA datasets, encouraging participants to develop and benchmark Machine Learning (ML) models that can generate multiple appropriate facial reactions (including facial image sequences and their attributes) given an input conversational partner's stimulus under various dyadic video conference scenarios. This paper presents: (i) the guidelines of the REACT 2024 challenge; (ii) the dataset utilized in the challenge; and (iii) the performance of the baseline systems on the two proposed sub-challenges: Offline Multiple Appropriate Facial Reaction Generation and Online Multiple Appropriate Facial Reaction Generation, respectively. The challenge baseline code is publicly available at https://github.com/reactmultimodalchallenge/baseline_react2024.","sentences":["In dyadic interactions, humans communicate their intentions and state of mind using verbal and non-verbal cues, where multiple different facial reactions might be appropriate in response to a specific speaker behaviour.","Then, how to develop a machine learning (ML) model that can automatically generate multiple appropriate, diverse, realistic and synchronised human facial reactions from an previously unseen speaker behaviour is a challenging task.","Following the successful organisation of the first REACT challenge (REACT 2023), this edition of the challenge (REACT 2024) employs a subset used by the previous challenge, which contains segmented 30-secs dyadic interaction clips originally recorded as part of the NOXI and RECOLA datasets, encouraging participants to develop and benchmark Machine Learning (ML) models that can generate multiple appropriate facial reactions (including facial image sequences and their attributes) given an input conversational partner's stimulus under various dyadic video conference scenarios.","This paper presents: (i) the guidelines of the REACT 2024 challenge; (ii) the dataset utilized in the challenge; and (iii) the performance of the baseline systems on the two proposed sub-challenges: Offline Multiple Appropriate Facial Reaction Generation and Online Multiple Appropriate Facial Reaction Generation, respectively.","The challenge baseline code is publicly available at https://github.com/reactmultimodalchallenge/baseline_react2024."],"url":"http://arxiv.org/abs/2401.05166v1"}
{"created":"2024-01-10 14:01:23","title":"Non-Numerical Weakly Relational Domains","abstract":"The weakly relational domain of Octagons offers a decent compromise between precision and efficiency for numerical properties. Here, we are concerned with the construction of non-numerical relational domains. We provide a general construction of weakly relational domains, which we exemplify with an extension of constant propagation by disjunctions. Since for the resulting domain of 2-disjunctive formulas, satisfiability is NP-complete, we provide a general construction for a further, more abstract weakly relational domain where the abstract operations of restriction and least upper bound can be efficiently implemented. In the second step, we consider a relational domain that tracks conjunctions of inequalities between variables, and between variables and constants for arbitrary partial orders of values. Examples are sub(multi)sets, as well as prefix, substring or scattered substring orderings on strings. When the partial order is a lattice, we provide precise polynomial algorithms for satisfiability, restriction, and the best abstraction of disjunction. Complementary to the constructions for lattices, we find that, in general, satisfiability of conjunctions is NP-complete. We therefore again provide polynomial abstract versions of restriction, conjunction, and join. By using our generic constructions, these domains are extended to weakly relational domains that additionally track disjunctions. For all our domains, we indicate how abstract transformers for assignments and guards can be constructed.","sentences":["The weakly relational domain of Octagons offers a decent compromise between precision and efficiency for numerical properties.","Here, we are concerned with the construction of non-numerical relational domains.","We provide a general construction of weakly relational domains, which we exemplify with an extension of constant propagation by disjunctions.","Since for the resulting domain of 2-disjunctive formulas, satisfiability is NP-complete, we provide a general construction for a further, more abstract weakly relational domain where the abstract operations of restriction and least upper bound can be efficiently implemented.","In the second step, we consider a relational domain that tracks conjunctions of inequalities between variables, and between variables and constants for arbitrary partial orders of values.","Examples are sub(multi)sets, as well as prefix, substring or scattered substring orderings on strings.","When the partial order is a lattice, we provide precise polynomial algorithms for satisfiability, restriction, and the best abstraction of disjunction.","Complementary to the constructions for lattices, we find that, in general, satisfiability of conjunctions is NP-complete.","We therefore again provide polynomial abstract versions of restriction, conjunction, and join.","By using our generic constructions, these domains are extended to weakly relational domains that additionally track disjunctions.","For all our domains, we indicate how abstract transformers for assignments and guards can be constructed."],"url":"http://arxiv.org/abs/2401.05165v1"}
{"created":"2024-01-10 13:56:52","title":"IRS Configuration Techniques for Ultra Wideband Signals and THz Communications","abstract":"Motivated by the challenges of future 6G communications where terahertz (THz) frequencies, intelligent reflective surfaces (IRSs) and ultra-wideband (UWB) signals coexist, we analyse and propose a set of efficient techniques for configuring the IRS when the signal bandwidth is a significant fraction of the central frequency (up to 50%). To the best of our knowledge this is the first time that IRS configuration techniques are analyzed for such huge bandwidths. In our work we take into account for the channel model, the power spectral density of the signal reflected by the IRS and the network geometry. We evaluate the proposed solutions in terms of achievable rate and compare it against an upper bound we derived. Our results hint rules for designing IRS-aided communication systems and allow to draw conclusions on the trade-off between performance and complexity required for configuring the IRS.","sentences":["Motivated by the challenges of future 6G communications where terahertz (THz) frequencies, intelligent reflective surfaces (IRSs) and ultra-wideband (UWB) signals coexist, we analyse and propose a set of efficient techniques for configuring the IRS when the signal bandwidth is a significant fraction of the central frequency (up to 50%).","To the best of our knowledge this is the first time that IRS configuration techniques are analyzed for such huge bandwidths.","In our work we take into account for the channel model, the power spectral density of the signal reflected by the IRS and the network geometry.","We evaluate the proposed solutions in terms of achievable rate and compare it against an upper bound we derived.","Our results hint rules for designing IRS-aided communication systems and allow to draw conclusions on the trade-off between performance and complexity required for configuring the IRS."],"url":"http://arxiv.org/abs/2401.05164v1"}
{"created":"2024-01-10 13:56:40","title":"MISS: A Generative Pretraining and Finetuning Approach for Med-VQA","abstract":"Medical visual question answering (VQA) is a challenging multimodal task, where Vision-Language Pre-training (VLP) models can effectively improve the generalization performance. However, most methods in the medical field treat VQA as an answer classification task which is difficult to transfer to practical application scenarios. Additionally, due to the privacy of medical images and the expensive annotation process, large-scale medical image-text pairs datasets for pretraining are severely lacking. In this paper, we propose a large-scale MultI-task Self-Supervised learning based framework (MISS) for medical VQA tasks. Unlike existing methods, we treat medical VQA as a generative task. We unify the text encoder and multimodal encoder and align image-text features through multi-task learning. Furthermore, we propose a Transfer-and-Caption method that extends the feature space of single-modal image datasets using large language models (LLMs), enabling those traditional medical vision field task data to be applied to VLP. Experiments show that our method achieves excellent results with fewer multimodal datasets and demonstrates the advantages of generative VQA models. The code and model weights will be released upon the paper's acceptance.","sentences":["Medical visual question answering (VQA) is a challenging multimodal task, where Vision-Language Pre-training (VLP) models can effectively improve the generalization performance.","However, most methods in the medical field treat VQA as an answer classification task which is difficult to transfer to practical application scenarios.","Additionally, due to the privacy of medical images and the expensive annotation process, large-scale medical image-text pairs datasets for pretraining are severely lacking.","In this paper, we propose a large-scale MultI-task Self-Supervised learning based framework (MISS) for medical VQA tasks.","Unlike existing methods, we treat medical VQA as a generative task.","We unify the text encoder and multimodal encoder and align image-text features through multi-task learning.","Furthermore, we propose a Transfer-and-Caption method that extends the feature space of single-modal image datasets using large language models (LLMs), enabling those traditional medical vision field task data to be applied to VLP.","Experiments show that our method achieves excellent results with fewer multimodal datasets and demonstrates the advantages of generative VQA models.","The code and model weights will be released upon the paper's acceptance."],"url":"http://arxiv.org/abs/2401.05163v1"}
{"created":"2024-01-10 13:46:03","title":"Derm-T2IM: Harnessing Synthetic Skin Lesion Data via Stable Diffusion Models for Enhanced Skin Disease Classification using ViT and CNN","abstract":"This study explores the utilization of Dermatoscopic synthetic data generated through stable diffusion models as a strategy for enhancing the robustness of machine learning model training. Synthetic data generation plays a pivotal role in mitigating challenges associated with limited labeled datasets, thereby facilitating more effective model training. In this context, we aim to incorporate enhanced data transformation techniques by extending the recent success of few-shot learning and a small amount of data representation in text-to-image latent diffusion models. The optimally tuned model is further used for rendering high-quality skin lesion synthetic data with diverse and realistic characteristics, providing a valuable supplement and diversity to the existing training data. We investigate the impact of incorporating newly generated synthetic data into the training pipeline of state-of-art machine learning models, assessing its effectiveness in enhancing model performance and generalization to unseen real-world data. Our experimental results demonstrate the efficacy of the synthetic data generated through stable diffusion models helps in improving the robustness and adaptability of end-to-end CNN and vision transformer models on two different real-world skin lesion datasets.","sentences":["This study explores the utilization of Dermatoscopic synthetic data generated through stable diffusion models as a strategy for enhancing the robustness of machine learning model training.","Synthetic data generation plays a pivotal role in mitigating challenges associated with limited labeled datasets, thereby facilitating more effective model training.","In this context, we aim to incorporate enhanced data transformation techniques by extending the recent success of few-shot learning and a small amount of data representation in text-to-image latent diffusion models.","The optimally tuned model is further used for rendering high-quality skin lesion synthetic data with diverse and realistic characteristics, providing a valuable supplement and diversity to the existing training data.","We investigate the impact of incorporating newly generated synthetic data into the training pipeline of state-of-art machine learning models, assessing its effectiveness in enhancing model performance and generalization to unseen real-world data.","Our experimental results demonstrate the efficacy of the synthetic data generated through stable diffusion models helps in improving the robustness and adaptability of end-to-end CNN and vision transformer models on two different real-world skin lesion datasets."],"url":"http://arxiv.org/abs/2401.05159v1"}
{"created":"2024-01-10 13:43:06","title":"Toward distortion-aware change detection in realistic scenarios","abstract":"In the conventional change detection (CD) pipeline, two manually registered and labeled remote sensing datasets serve as the input of the model for training and prediction. However, in realistic scenarios, data from different periods or sensors could fail to be aligned as a result of various coordinate systems. Geometric distortion caused by coordinate shifting remains a thorny issue for CD algorithms. In this paper, we propose a reusable self-supervised framework for bitemporal geometric distortion in CD tasks. The whole framework is composed of Pretext Representation Pre-training, Bitemporal Image Alignment, and Down-stream Decoder Fine-Tuning. With only single-stage pre-training, the key components of the framework can be reused for assistance in the bitemporal image alignment, while simultaneously enhancing the performance of the CD decoder. Experimental results in 2 large-scale realistic scenarios demonstrate that our proposed method can alleviate the bitemporal geometric distortion in CD tasks.","sentences":["In the conventional change detection (CD) pipeline, two manually registered and labeled remote sensing datasets serve as the input of the model for training and prediction.","However, in realistic scenarios, data from different periods or sensors could fail to be aligned as a result of various coordinate systems.","Geometric distortion caused by coordinate shifting remains a thorny issue for CD algorithms.","In this paper, we propose a reusable self-supervised framework for bitemporal geometric distortion in CD tasks.","The whole framework is composed of Pretext Representation Pre-training, Bitemporal Image Alignment, and Down-stream Decoder Fine-Tuning.","With only single-stage pre-training, the key components of the framework can be reused for assistance in the bitemporal image alignment, while simultaneously enhancing the performance of the CD decoder.","Experimental results in 2 large-scale realistic scenarios demonstrate that our proposed method can alleviate the bitemporal geometric distortion in CD tasks."],"url":"http://arxiv.org/abs/2401.05157v1"}
{"created":"2024-01-10 13:32:50","title":"An Optimizing Framework on MLIR for Efficient FPGA-based Accelerator Generation","abstract":"With the increasing demand for computing capability given limited resource and power budgets, it is crucial to deploy applications to customized accelerators like FPGAs. However, FPGA programming is non-trivial. Although existing high-level synthesis (HLS) tools improve productivity to a certain extent, they are limited in scope and capability to support sufficient FPGA-oriented optimizations. This paper focuses on FPGA-based accelerators and proposes POM, an optimizing framework built on multi-level intermediate representation (MLIR). POM has several features which demonstrate its scope and capability of performance optimization. First, most HLS tools depend exclusively on a single-level IR to perform all the optimizations, introducing excessive information into the IR and making debugging an arduous task. In contrast, POM introduces three layers of IR to perform operations at suitable abstraction levels, streamlining the implementation and debugging process and exhibiting better flexibility, extensibility, and systematicness. Second, POM integrates the polyhedral model into MLIR, enabling advanced dependence analysis and various FPGA-oriented loop transformations. By representing nested loops with integer sets and maps, loop transformations can be conducted conveniently through manipulations on polyhedral semantics. Finally, to further relieve design effort, POM has a user-friendly programming interface (DSL) that allows a concise description of computation and includes a rich collection of scheduling primitives. An automatic design space exploration (DSE) engine is provided to search for high-performance optimization schemes efficiently and generate optimized accelerators automatically. Experimental results show that POM achieves a $6.46\\times$ average speedup on typical benchmark suites and a $6.06\\times$ average speedup on real-world applications compared to the state-of-the-art.","sentences":["With the increasing demand for computing capability given limited resource and power budgets, it is crucial to deploy applications to customized accelerators like FPGAs.","However, FPGA programming is non-trivial.","Although existing high-level synthesis (HLS) tools improve productivity to a certain extent, they are limited in scope and capability to support sufficient FPGA-oriented optimizations.","This paper focuses on FPGA-based accelerators and proposes POM, an optimizing framework built on multi-level intermediate representation (MLIR).","POM has several features which demonstrate its scope and capability of performance optimization.","First, most HLS tools depend exclusively on a single-level IR to perform all the optimizations, introducing excessive information into the IR and making debugging an arduous task.","In contrast, POM introduces three layers of IR to perform operations at suitable abstraction levels, streamlining the implementation and debugging process and exhibiting better flexibility, extensibility, and systematicness.","Second, POM integrates the polyhedral model into MLIR, enabling advanced dependence analysis and various FPGA-oriented loop transformations.","By representing nested loops with integer sets and maps, loop transformations can be conducted conveniently through manipulations on polyhedral semantics.","Finally, to further relieve design effort, POM has a user-friendly programming interface (DSL) that allows a concise description of computation and includes a rich collection of scheduling primitives.","An automatic design space exploration (DSE) engine is provided to search for high-performance optimization schemes efficiently and generate optimized accelerators automatically.","Experimental results show that POM achieves a $6.46\\times$ average speedup on typical benchmark suites and a $6.06\\times$ average speedup on real-world applications compared to the state-of-the-art."],"url":"http://arxiv.org/abs/2401.05154v1"}
{"created":"2024-01-10 13:32:47","title":"CrossDiff: Exploring Self-Supervised Representation of Pansharpening via Cross-Predictive Diffusion Model","abstract":"Fusion of a panchromatic (PAN) image and corresponding multispectral (MS) image is also known as pansharpening, which aims to combine abundant spatial details of PAN and spectral information of MS. Due to the absence of high-resolution MS images, available deep-learning-based methods usually follow the paradigm of training at reduced resolution and testing at both reduced and full resolution. When taking original MS and PAN images as inputs, they always obtain sub-optimal results due to the scale variation. In this paper, we propose to explore the self-supervised representation of pansharpening by designing a cross-predictive diffusion model, named CrossDiff. It has two-stage training. In the first stage, we introduce a cross-predictive pretext task to pre-train the UNet structure based on conditional DDPM, while in the second stage, the encoders of the UNets are frozen to directly extract spatial and spectral features from PAN and MS, and only the fusion head is trained to adapt for pansharpening task. Extensive experiments show the effectiveness and superiority of the proposed model compared with state-of-the-art supervised and unsupervised methods. Besides, the cross-sensor experiments also verify the generalization ability of proposed self-supervised representation learners for other satellite's datasets. We will release our code for reproducibility.","sentences":["Fusion of a panchromatic (PAN) image and corresponding multispectral (MS) image is also known as pansharpening, which aims to combine abundant spatial details of PAN and spectral information of MS.","Due to the absence of high-resolution MS images, available deep-learning-based methods usually follow the paradigm of training at reduced resolution and testing at both reduced and full resolution.","When taking original MS and PAN images as inputs, they always obtain sub-optimal results due to the scale variation.","In this paper, we propose to explore the self-supervised representation of pansharpening by designing a cross-predictive diffusion model, named CrossDiff.","It has two-stage training.","In the first stage, we introduce a cross-predictive pretext task to pre-train the UNet structure based on conditional DDPM, while in the second stage, the encoders of the UNets are frozen to directly extract spatial and spectral features from PAN and MS, and only the fusion head is trained to adapt for pansharpening task.","Extensive experiments show the effectiveness and superiority of the proposed model compared with state-of-the-art supervised and unsupervised methods.","Besides, the cross-sensor experiments also verify the generalization ability of proposed self-supervised representation learners for other satellite's datasets.","We will release our code for reproducibility."],"url":"http://arxiv.org/abs/2401.05153v1"}
{"created":"2024-01-10 13:32:01","title":"Multi S-Graphs: an Efficient Real-time Distributed Semantic-Relational Collaborative SLAM","abstract":"Collaborative Simultaneous Localization and Mapping (CSLAM) is critical to enable multiple robots to operate in complex environments. Most CSLAM techniques rely on raw sensor measurement or low-level features such as keyframe descriptors, which can lead to wrong loop closures due to the lack of deep understanding of the environment. Moreover, the exchange of these measurements and low-level features among the robots requires the transmission of a significant amount of data, which limits the scalability of the system. To overcome these limitations, we present Multi S-Graphs, a decentralized CSLAM system that utilizes high-level semantic-relational information embedded in the four-layered hierarchical and optimizable situational graphs for cooperative map generation and localization while minimizing the information exchanged between the robots. To support this, we present a novel room-based descriptor which, along with its connected walls, is used to perform inter-robot loop closures, addressing the challenges of multi-robot kidnapped problem initialization. Multiple experiments in simulated and real environments validate the improvement in accuracy and robustness of the proposed approach while reducing the amount of data exchanged between robots compared to other state-of-the-art approaches.   Software available within a docker image: https://github.com/snt-arg/multi_s_graphs_docker","sentences":["Collaborative Simultaneous Localization and Mapping (CSLAM) is critical to enable multiple robots to operate in complex environments.","Most CSLAM techniques rely on raw sensor measurement or low-level features such as keyframe descriptors, which can lead to wrong loop closures due to the lack of deep understanding of the environment.","Moreover, the exchange of these measurements and low-level features among the robots requires the transmission of a significant amount of data, which limits the scalability of the system.","To overcome these limitations, we present Multi S-Graphs, a decentralized CSLAM system that utilizes high-level semantic-relational information embedded in the four-layered hierarchical and optimizable situational graphs for cooperative map generation and localization while minimizing the information exchanged between the robots.","To support this, we present a novel room-based descriptor which, along with its connected walls, is used to perform inter-robot loop closures, addressing the challenges of multi-robot kidnapped problem initialization.","Multiple experiments in simulated and real environments validate the improvement in accuracy and robustness of the proposed approach while reducing the amount of data exchanged between robots compared to other state-of-the-art approaches.   ","Software available within a docker image: https://github.com/snt-arg/multi_s_graphs_docker"],"url":"http://arxiv.org/abs/2401.05152v1"}
{"created":"2024-01-10 13:28:37","title":"On the Influence of Reading Sequences on Knowledge Gain during Web Search","abstract":"Nowadays, learning increasingly involves the usage of search engines and web resources. The related interdisciplinary research field search as learning aims to understand how people learn on the web. Previous work has investigated several feature classes to predict, for instance, the expected knowledge gain during web search. Therein, eye-tracking features have not been extensively studied so far. In this paper, we extend a previously used reading model from a line-based one to one that can detect reading sequences across multiple lines. We use publicly available study data from a web-based learning task to examine the relationship between our feature set and the participants' test scores. Our findings demonstrate that learners with higher knowledge gain spent significantly more time reading, and processing more words in total. We also find evidence that faster reading at the expense of more backward regressions may be an indicator of better web-based learning. We make our code publicly available at https://github.com/TIBHannover/reading_web_search.","sentences":["Nowadays, learning increasingly involves the usage of search engines and web resources.","The related interdisciplinary research field search as learning aims to understand how people learn on the web.","Previous work has investigated several feature classes to predict, for instance, the expected knowledge gain during web search.","Therein, eye-tracking features have not been extensively studied so far.","In this paper, we extend a previously used reading model from a line-based one to one that can detect reading sequences across multiple lines.","We use publicly available study data from a web-based learning task to examine the relationship between our feature set and the participants' test scores.","Our findings demonstrate that learners with higher knowledge gain spent significantly more time reading, and processing more words in total.","We also find evidence that faster reading at the expense of more backward regressions may be an indicator of better web-based learning.","We make our code publicly available at https://github.com/TIBHannover/reading_web_search."],"url":"http://arxiv.org/abs/2401.05148v1"}
{"created":"2024-01-10 13:26:19","title":"Federated Unlearning: A Survey on Methods, Design Guidelines, and Evaluation Metrics","abstract":"Federated Learning (FL) enables collaborative training of a Machine Learning (ML) model across multiple parties, facilitating the preservation of users' and institutions' privacy by keeping data stored locally. Instead of centralizing raw data, FL exchanges locally refined model parameters to build a global model incrementally. While FL is more compliant with emerging regulations such as the European General Data Protection Regulation (GDPR), ensuring the right to be forgotten in this context - allowing FL participants to remove their data contributions from the learned model - remains unclear. In addition, it is recognized that malicious clients may inject backdoors into the global model through updates, e.g. to generate mispredictions on specially crafted data examples. Consequently, there is the need for mechanisms that can guarantee individuals the possibility to remove their data and erase malicious contributions even after aggregation, without compromising the already acquired \"good\" knowledge. This highlights the necessity for novel Federated Unlearning (FU) algorithms, which can efficiently remove specific clients' contributions without full model retraining. This survey provides background concepts, empirical evidence, and practical guidelines to design/implement efficient FU schemes. Our study includes a detailed analysis of the metrics for evaluating unlearning in FL and presents an in-depth literature review categorizing state-of-the-art FU contributions under a novel taxonomy. Finally, we outline the most relevant and still open technical challenges, by identifying the most promising research directions in the field.","sentences":["Federated Learning (FL) enables collaborative training of a Machine Learning (ML) model across multiple parties, facilitating the preservation of users' and institutions' privacy by keeping data stored locally.","Instead of centralizing raw data, FL exchanges locally refined model parameters to build a global model incrementally.","While FL is more compliant with emerging regulations such as the European General Data Protection Regulation (GDPR), ensuring the right to be forgotten in this context - allowing FL participants to remove their data contributions from the learned model - remains unclear.","In addition, it is recognized that malicious clients may inject backdoors into the global model through updates, e.g. to generate mispredictions on specially crafted data examples.","Consequently, there is the need for mechanisms that can guarantee individuals the possibility to remove their data and erase malicious contributions even after aggregation, without compromising the already acquired \"good\" knowledge.","This highlights the necessity for novel Federated Unlearning (FU) algorithms, which can efficiently remove specific clients' contributions without full model retraining.","This survey provides background concepts, empirical evidence, and practical guidelines to design/implement efficient FU schemes.","Our study includes a detailed analysis of the metrics for evaluating unlearning in FL and presents an in-depth literature review categorizing state-of-the-art FU contributions under a novel taxonomy.","Finally, we outline the most relevant and still open technical challenges, by identifying the most promising research directions in the field."],"url":"http://arxiv.org/abs/2401.05146v1"}
{"created":"2024-01-10 13:25:49","title":"Machine Learning to Promote Translational Research: Predicting Patent and Clinical Trial Inclusion in Dementia Research","abstract":"Projected to impact 1.6 million people in the UK by 2040 and costing {\\pounds}25 billion annually, dementia presents a growing challenge to society. This study, a pioneering effort to predict the translational potential of dementia research using machine learning, hopes to address the slow translation of fundamental discoveries into practical applications despite dementia's significant societal and economic impact. We used the Dimensions database to extract data from 43,091 UK dementia research publications between the years 1990-2023, specifically metadata (authors, publication year etc.), concepts mentioned in the paper, and the paper abstract. To prepare the data for machine learning we applied methods such as one hot encoding and/or word embeddings. We trained a CatBoost Classifier to predict if a publication will be cited in a future patent or clinical trial. We trained several model variations. The model combining metadata, concept, and abstract embeddings yielded the highest performance: for patent predictions, an Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.84 and 77.17% accuracy; for clinical trial predictions, an AUROC of 0.81 and 75.11% accuracy. The results demonstrate that integrating machine learning within current research methodologies can uncover overlooked publications, expediting the identification of promising research and potentially transforming dementia research by predicting real-world impact and guiding translational strategies.","sentences":["Projected to impact 1.6 million people in the UK by 2040 and costing {\\pounds}25 billion annually, dementia presents a growing challenge to society.","This study, a pioneering effort to predict the translational potential of dementia research using machine learning, hopes to address the slow translation of fundamental discoveries into practical applications despite dementia's significant societal and economic impact.","We used the Dimensions database to extract data from 43,091 UK dementia research publications between the years 1990-2023, specifically metadata (authors, publication year etc.), concepts mentioned in the paper, and the paper abstract.","To prepare the data for machine learning we applied methods such as one hot encoding and/or word embeddings.","We trained a CatBoost Classifier to predict if a publication will be cited in a future patent or clinical trial.","We trained several model variations.","The model combining metadata, concept, and abstract embeddings yielded the highest performance: for patent predictions, an Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.84 and 77.17% accuracy; for clinical trial predictions, an AUROC of 0.81 and 75.11% accuracy.","The results demonstrate that integrating machine learning within current research methodologies can uncover overlooked publications, expediting the identification of promising research and potentially transforming dementia research by predicting real-world impact and guiding translational strategies."],"url":"http://arxiv.org/abs/2401.05145v1"}
{"created":"2024-01-10 13:22:13","title":"SARA: A Collection of Sensitivity-Aware Relevance Assessments","abstract":"Large archival collections, such as email or government documents, must be manually reviewed to identify any sensitive information before the collection can be released publicly. Sensitivity classification has received a lot of attention in the literature. However, more recently, there has been increasing interest in developing sensitivity-aware search engines that can provide users with relevant search results, while ensuring that no sensitive documents are returned to the user. Sensitivity-aware search would mitigate the need for a manual sensitivity review prior to collections being made available publicly. To develop such systems, there is a need for test collections that contain relevance assessments for a set of information needs as well as ground-truth labels for a variety of sensitivity categories. The well-known Enron email collection contains a classification ground-truth that can be used to represent sensitive information, e.g., the Purely Personal and Personal but in Professional Context categories can be used to represent sensitive personal information. However, the existing Enron collection does not contain a set of information needs and relevance assessments. In this work, we present a collection of fifty information needs (topics) with crowdsourced query formulations (3 per topic) and relevance assessments (11,471 in total) for the Enron collection (mean number of relevant documents per topic = 11, variance = 34.7). The developed information needs, queries and relevance judgements are available on GitHub and will be available along with the existing Enron collection through the popular ir_datasets library. Our proposed collection results in the first freely available test collection for developing sensitivity-aware search systems.","sentences":["Large archival collections, such as email or government documents, must be manually reviewed to identify any sensitive information before the collection can be released publicly.","Sensitivity classification has received a lot of attention in the literature.","However, more recently, there has been increasing interest in developing sensitivity-aware search engines that can provide users with relevant search results, while ensuring that no sensitive documents are returned to the user.","Sensitivity-aware search would mitigate the need for a manual sensitivity review prior to collections being made available publicly.","To develop such systems, there is a need for test collections that contain relevance assessments for a set of information needs as well as ground-truth labels for a variety of sensitivity categories.","The well-known Enron email collection contains a classification ground-truth that can be used to represent sensitive information, e.g., the Purely Personal and Personal but in Professional Context categories can be used to represent sensitive personal information.","However, the existing Enron collection does not contain a set of information needs and relevance assessments.","In this work, we present a collection of fifty information needs (topics) with crowdsourced query formulations (3 per topic) and relevance assessments (11,471 in total) for the Enron collection (mean number of relevant documents per topic = 11, variance = 34.7).","The developed information needs, queries and relevance judgements are available on GitHub and will be available along with the existing Enron collection through the popular ir_datasets library.","Our proposed collection results in the first freely available test collection for developing sensitivity-aware search systems."],"url":"http://arxiv.org/abs/2401.05144v1"}
{"created":"2024-01-10 13:00:18","title":"Code Review Automation: Strengths and Weaknesses of the State of the Art","abstract":"The automation of code review has been tackled by several researchers with the goal of reducing its cost. The adoption of deep learning in software engineering pushed the automation to new boundaries, with techniques imitating developers in generative tasks, such as commenting on a code change as a reviewer would do or addressing a reviewer's comment by modifying code. The performance of these techniques is usually assessed through quantitative metrics, e.g., the percentage of instances in the test set for which correct predictions are generated, leaving many open questions on the techniques' capabilities. For example, knowing that an approach is able to correctly address a reviewer's comment in 10% of cases is of little value without knowing what was asked by the reviewer: What if in all successful cases the code change required to address the comment was just the removal of an empty line? In this paper we aim at characterizing the cases in which three code review automation techniques tend to succeed or fail in the two above-described tasks. The study has a strong qualitative focus, with ~105 man-hours of manual inspection invested in manually analyzing correct and wrong predictions generated by the three techniques, for a total of 2,291 inspected predictions. The output of this analysis are two taxonomies reporting, for each of the two tasks, the types of code changes on which the experimented techniques tend to succeed or to fail, pointing to areas for future work. A result of our manual analysis was also the identification of several issues in the datasets used to train and test the experimented techniques. Finally, we assess the importance of researching in techniques specialized for code review automation by comparing their performance with ChatGPT, a general purpose large language model, finding that ChatGPT struggles in commenting code as a human reviewer would do.","sentences":["The automation of code review has been tackled by several researchers with the goal of reducing its cost.","The adoption of deep learning in software engineering pushed the automation to new boundaries, with techniques imitating developers in generative tasks, such as commenting on a code change as a reviewer would do or addressing a reviewer's comment by modifying code.","The performance of these techniques is usually assessed through quantitative metrics, e.g., the percentage of instances in the test set for which correct predictions are generated, leaving many open questions on the techniques' capabilities.","For example, knowing that an approach is able to correctly address a reviewer's comment in 10% of cases is of little value without knowing what was asked by the reviewer:","What if in all successful cases the code change required to address the comment was just the removal of an empty line?","In this paper we aim at characterizing the cases in which three code review automation techniques tend to succeed or fail in the two above-described tasks.","The study has a strong qualitative focus, with ~105 man-hours of manual inspection invested in manually analyzing correct and wrong predictions generated by the three techniques, for a total of 2,291 inspected predictions.","The output of this analysis are two taxonomies reporting, for each of the two tasks, the types of code changes on which the experimented techniques tend to succeed or to fail, pointing to areas for future work.","A result of our manual analysis was also the identification of several issues in the datasets used to train and test the experimented techniques.","Finally, we assess the importance of researching in techniques specialized for code review automation by comparing their performance with ChatGPT, a general purpose large language model, finding that ChatGPT struggles in commenting code as a human reviewer would do."],"url":"http://arxiv.org/abs/2401.05136v1"}
{"created":"2024-01-10 12:56:47","title":"Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation","abstract":"Over the past few years, the use of the Internet for healthcare-related tasks has grown by leaps and bounds, posing a challenge in effectively managing and processing information to ensure its efficient utilization. During moments of emotional turmoil and psychological challenges, we frequently turn to the internet as our initial source of support, choosing this over discussing our feelings with others due to the associated social stigma. In this paper, we propose a new task of multi-modal medical concern summary (MMCS) generation, which provides a short and precise summary of patients' major concerns brought up during the consultation. Nonverbal cues, such as patients' gestures and facial expressions, aid in accurately identifying patients' concerns. Doctors also consider patients' personal information, such as age and gender, in order to describe the medical condition appropriately. Motivated by the potential efficacy of patients' personal context and visual gestures, we propose a transformer-based multi-task, multi-modal intent-recognition, and medical concern summary generation (IR-MMCSG) system. Furthermore, we propose a multitasking framework for intent recognition and medical concern summary generation for doctor-patient consultations. We construct the first multi-modal medical concern summary generation (MM-MediConSummation) corpus, which includes patient-doctor consultations annotated with medical concern summaries, intents, patient personal information, doctor's recommendations, and keywords. Our experiments and analysis demonstrate (a) the significant role of patients' expressions/gestures and their personal information in intent identification and medical concern summary generation, and (b) the strong correlation between intent recognition and patients' medical concern summary generation   The dataset and source code are available at https://github.com/NLP-RL/MMCSG.","sentences":["Over the past few years, the use of the Internet for healthcare-related tasks has grown by leaps and bounds, posing a challenge in effectively managing and processing information to ensure its efficient utilization.","During moments of emotional turmoil and psychological challenges, we frequently turn to the internet as our initial source of support, choosing this over discussing our feelings with others due to the associated social stigma.","In this paper, we propose a new task of multi-modal medical concern summary (MMCS) generation, which provides a short and precise summary of patients' major concerns brought up during the consultation.","Nonverbal cues, such as patients' gestures and facial expressions, aid in accurately identifying patients' concerns.","Doctors also consider patients' personal information, such as age and gender, in order to describe the medical condition appropriately.","Motivated by the potential efficacy of patients' personal context and visual gestures, we propose a transformer-based multi-task, multi-modal intent-recognition, and medical concern summary generation (IR-MMCSG) system.","Furthermore, we propose a multitasking framework for intent recognition and medical concern summary generation for doctor-patient consultations.","We construct the first multi-modal medical concern summary generation (MM-MediConSummation) corpus, which includes patient-doctor consultations annotated with medical concern summaries, intents, patient personal information, doctor's recommendations, and keywords.","Our experiments and analysis demonstrate (a) the significant role of patients' expressions/gestures and their personal information in intent identification and medical concern summary generation, and (b) the strong correlation between intent recognition and patients' medical concern summary generation   The dataset and source code are available at https://github.com/NLP-RL/MMCSG."],"url":"http://arxiv.org/abs/2401.05134v1"}
{"created":"2024-01-10 12:56:24","title":"Neural Population Learning beyond Symmetric Zero-sum Games","abstract":"We study computationally efficient methods for finding equilibria in n-player general-sum games, specifically ones that afford complex visuomotor skills. We show how existing methods would struggle in this setting, either computationally or in theory. We then introduce NeuPL-JPSRO, a neural population learning algorithm that benefits from transfer learning of skills and converges to a Coarse Correlated Equilibrium (CCE) of the game. We show empirical convergence in a suite of OpenSpiel games, validated rigorously by exact game solvers. We then deploy NeuPL-JPSRO to complex domains, where our approach enables adaptive coordination in a MuJoCo control domain and skill transfer in capture-the-flag. Our work shows that equilibrium convergent population learning can be implemented at scale and in generality, paving the way towards solving real-world games between heterogeneous players with mixed motives.","sentences":["We study computationally efficient methods for finding equilibria in n-player general-sum games, specifically ones that afford complex visuomotor skills.","We show how existing methods would struggle in this setting, either computationally or in theory.","We then introduce NeuPL-JPSRO, a neural population learning algorithm that benefits from transfer learning of skills and converges to a Coarse Correlated Equilibrium (CCE) of the game.","We show empirical convergence in a suite of OpenSpiel games, validated rigorously by exact game solvers.","We then deploy NeuPL-JPSRO to complex domains, where our approach enables adaptive coordination in a MuJoCo control domain and skill transfer in capture-the-flag.","Our work shows that equilibrium convergent population learning can be implemented at scale and in generality, paving the way towards solving real-world games between heterogeneous players with mixed motives."],"url":"http://arxiv.org/abs/2401.05133v1"}
