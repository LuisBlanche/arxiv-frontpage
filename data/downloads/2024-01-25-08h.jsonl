{"created":"2024-01-24 18:58:35","title":"Predicting the Impact of Crashes Across Release Channels","abstract":"Software maintenance faces a persistent challenge with crash bugs, especially across diverse release channels catering to distinct user bases. Nightly builds, favoured by enthusiasts, often reveal crashes that are cheaper to fix but may differ significantly from those in stable releases. In this paper, we emphasize the need for a data-driven solution to predict the impact of crashes happening on nightly channels once they are released to stable channels. We also list the challenges that need to be considered when approaching this problem.","sentences":["Software maintenance faces a persistent challenge with crash bugs, especially across diverse release channels catering to distinct user bases.","Nightly builds, favoured by enthusiasts, often reveal crashes that are cheaper to fix but may differ significantly from those in stable releases.","In this paper, we emphasize the need for a data-driven solution to predict the impact of crashes happening on nightly channels once they are released to stable channels.","We also list the challenges that need to be considered when approaching this problem."],"url":"http://arxiv.org/abs/2401.13667v1"}
{"created":"2024-01-24 18:58:21","title":"Algebraic methods for solving recognition problems with non-crossing classes","abstract":"In this paper, we propose to consider various models of pattern recognition. At the same time, it is proposed to consider models in the form of two operators: a recognizing operator and a decision rule. Algebraic operations are introduced on recognizing operators, and based on the application of these operators, a family of recognizing algorithms is created. An upper estimate is constructed for the model, which guarantees the completeness of the extension.","sentences":["In this paper, we propose to consider various models of pattern recognition.","At the same time, it is proposed to consider models in the form of two operators: a recognizing operator and a decision rule.","Algebraic operations are introduced on recognizing operators, and based on the application of these operators, a family of recognizing algorithms is created.","An upper estimate is constructed for the model, which guarantees the completeness of the extension."],"url":"http://arxiv.org/abs/2401.13666v1"}
{"created":"2024-01-24 18:56:53","title":"The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations","abstract":"In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning. While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms. We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations. In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms. We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization. All code is available at https://github.com/Matt00n/PolicyGradientsJax.","sentences":["In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning.","While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms.","We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations.","In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms.","We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization.","All code is available at https://github.com/Matt00n/PolicyGradientsJax."],"url":"http://arxiv.org/abs/2401.13662v1"}
{"created":"2024-01-24 18:53:53","title":"MambaByte: Token-free Selective State Space Model","abstract":"Token-free language models learn directly from raw bytes and remove the bias of subword tokenization. Operating on bytes, however, results in significantly longer sequences, and standard autoregressive Transformers scale poorly in such settings. We experiment with MambaByte, a token-free adaptation of the Mamba state space model, trained autoregressively on byte sequences. Our experiments indicate the computational efficiency of MambaByte compared to other byte-level models. We also find MambaByte to be competitive with and even outperform state-of-the-art subword Transformers. Furthermore, owing to linear scaling in length, MambaByte benefits from fast inference compared to Transformers. Our findings establish the viability of MambaByte in enabling token-free language modeling.","sentences":["Token-free language models learn directly from raw bytes and remove the bias of subword tokenization.","Operating on bytes, however, results in significantly longer sequences, and standard autoregressive Transformers scale poorly in such settings.","We experiment with MambaByte, a token-free adaptation of the Mamba state space model, trained autoregressively on byte sequences.","Our experiments indicate the computational efficiency of MambaByte compared to other byte-level models.","We also find MambaByte to be competitive with and even outperform state-of-the-art subword Transformers.","Furthermore, owing to linear scaling in length, MambaByte benefits from fast inference compared to Transformers.","Our findings establish the viability of MambaByte in enabling token-free language modeling."],"url":"http://arxiv.org/abs/2401.13660v1"}
{"created":"2024-01-24 18:49:30","title":"Inadequacy of common stochastic neural networks for reliable clinical decision support","abstract":"Widespread adoption of AI for medical decision making is still hindered due to ethical and safety-related concerns. For AI-based decision support systems in healthcare settings it is paramount to be reliable and trustworthy. Common deep learning approaches, however, have the tendency towards overconfidence under data shift. Such inappropriate extrapolation beyond evidence-based scenarios may have dire consequences. This highlights the importance of reliable estimation of local uncertainty and its communication to the end user. While stochastic neural networks have been heralded as a potential solution to these issues, this study investigates their actual reliability in clinical applications. We centered our analysis on the exemplary use case of mortality prediction for ICU hospitalizations using EHR from MIMIC3 study. For predictions on the EHR time series, Encoder-Only Transformer models were employed. Stochasticity of model functions was achieved by incorporating common methods such as Bayesian neural network layers and model ensembles. Our models achieve state of the art performance in terms of discrimination performance (AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality prediction benchmark. However, epistemic uncertainty is critically underestimated by the selected stochastic deep learning methods. A heuristic proof for the responsible collapse of the posterior distribution is provided. Our findings reveal the inadequacy of commonly used stochastic deep learning approaches to reliably recognize OoD samples. In both methods, unsubstantiated model confidence is not prevented due to strongly biased functional posteriors, rendering them inappropriate for reliable clinical decision support. This highlights the need for approaches with more strictly enforced or inherent distance-awareness to known data points, e.g., using kernel-based techniques.","sentences":["Widespread adoption of AI for medical decision making is still hindered due to ethical and safety-related concerns.","For AI-based decision support systems in healthcare settings it is paramount to be reliable and trustworthy.","Common deep learning approaches, however, have the tendency towards overconfidence under data shift.","Such inappropriate extrapolation beyond evidence-based scenarios may have dire consequences.","This highlights the importance of reliable estimation of local uncertainty and its communication to the end user.","While stochastic neural networks have been heralded as a potential solution to these issues, this study investigates their actual reliability in clinical applications.","We centered our analysis on the exemplary use case of mortality prediction for ICU hospitalizations using EHR from MIMIC3 study.","For predictions on the EHR time series, Encoder-Only Transformer models were employed.","Stochasticity of model functions was achieved by incorporating common methods such as Bayesian neural network layers and model ensembles.","Our models achieve state of the art performance in terms of discrimination performance (AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality prediction benchmark.","However, epistemic uncertainty is critically underestimated by the selected stochastic deep learning methods.","A heuristic proof for the responsible collapse of the posterior distribution is provided.","Our findings reveal the inadequacy of commonly used stochastic deep learning approaches to reliably recognize OoD samples.","In both methods, unsubstantiated model confidence is not prevented due to strongly biased functional posteriors, rendering them inappropriate for reliable clinical decision support.","This highlights the need for approaches with more strictly enforced or inherent distance-awareness to known data points, e.g., using kernel-based techniques."],"url":"http://arxiv.org/abs/2401.13657v1"}
{"created":"2024-01-24 18:49:19","title":"Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity","abstract":"The prevalent perspective in quantitative research on opinion dynamics flattens the landscape of the online political discourse into a traditional left--right dichotomy. While this approach helps simplify the analysis and modeling effort, it also neglects the intrinsic multidimensional richness of ideologies. In this study, we analyze social interactions on Reddit, under the lens of a multi-dimensional ideological framework: the political compass. We examine over 8 million comments posted on the subreddits /r/PoliticalCompass and /r/PoliticalCompassMemes during 2020--2022. By leveraging their self-declarations, we disentangle the ideological dimensions of users into economic (left--right) and social (libertarian--authoritarian) axes. In addition, we characterize users by their demographic attributes (age, gender, and affluence).   We find significant homophily for interactions along the social axis of the political compass and demographic attributes. Compared to a null model, interactions among individuals of similar ideology surpass expectations by 6%. In contrast, we uncover a significant heterophily along the economic axis: left/right interactions exceed expectations by 10%. Furthermore, heterophilic interactions are characterized by a higher language toxicity than homophilic interactions, which hints at a conflictual discourse between every opposite ideology. Our results help reconcile apparent contradictions in recent literature, which found a superposition of homophilic and heterophilic interactions in online political discussions. By disentangling such interactions into the economic and social axes we pave the way for a deeper understanding of opinion dynamics on social media.","sentences":["The prevalent perspective in quantitative research on opinion dynamics flattens the landscape of the online political discourse into a traditional left--right dichotomy.","While this approach helps simplify the analysis and modeling effort, it also neglects the intrinsic multidimensional richness of ideologies.","In this study, we analyze social interactions on Reddit, under the lens of a multi-dimensional ideological framework: the political compass.","We examine over 8 million comments posted on the subreddits /r/PoliticalCompass and /r/PoliticalCompassMemes during 2020--2022.","By leveraging their self-declarations, we disentangle the ideological dimensions of users into economic (left--right) and social (libertarian--authoritarian) axes.","In addition, we characterize users by their demographic attributes (age, gender, and affluence).   ","We find significant homophily for interactions along the social axis of the political compass and demographic attributes.","Compared to a null model, interactions among individuals of similar ideology surpass expectations by 6%.","In contrast, we uncover a significant heterophily along the economic axis: left/right interactions exceed expectations by 10%.","Furthermore, heterophilic interactions are characterized by a higher language toxicity than homophilic interactions, which hints at a conflictual discourse between every opposite ideology.","Our results help reconcile apparent contradictions in recent literature, which found a superposition of homophilic and heterophilic interactions in online political discussions.","By disentangling such interactions into the economic and social axes we pave the way for a deeper understanding of opinion dynamics on social media."],"url":"http://arxiv.org/abs/2401.13656v1"}
{"created":"2024-01-24 18:48:28","title":"HetDAPAC: Distributed Attribute-Based Private Access Control with Heterogeneous Attributes","abstract":"Verifying user attributes to provide fine-grained access control to databases is fundamental to an attribute-based authentication system. In such systems, either a single (central) authority verifies all attributes, or multiple independent authorities verify individual attributes distributedly to allow a user to access records stored on the servers. While a \\emph{central} setup is more communication cost efficient, it causes privacy breach of \\emph{all} user attributes to a central authority. Recently, Jafarpisheh et al. studied an information theoretic formulation of the \\emph{distributed} multi-authority setup with $N$ non-colluding authorities, $N$ attributes and $K$ possible values for each attribute, called an $(N,K)$ distributed attribute-based private access control (DAPAC) system, where each server learns only one attribute value that it verifies, and remains oblivious to the remaining $N-1$ attributes. We show that off-loading a subset of attributes to a central server for verification improves the achievable rate from $\\frac{1}{2K}$ in Jafarpisheh et al. to $\\frac{1}{K+1}$ in this paper, thus \\emph{almost doubling the rate} for relatively large $K$, while sacrificing the privacy of a few possibly non-sensitive attributes.","sentences":["Verifying user attributes to provide fine-grained access control to databases is fundamental to an attribute-based authentication system.","In such systems, either a single (central) authority verifies all attributes, or multiple independent authorities verify individual attributes distributedly to allow a user to access records stored on the servers.","While a \\emph{central} setup is more communication cost efficient, it causes privacy breach of \\emph{all} user attributes to a central authority.","Recently, Jafarpisheh et al. studied an information theoretic formulation of the \\emph{distributed} multi-authority setup with $N$ non-colluding authorities, $N$ attributes and $K$ possible values for each attribute, called an $(N,K)$ distributed attribute-based private access control (DAPAC) system, where each server learns only one attribute value that it verifies, and remains oblivious to the remaining $N-1$ attributes.","We show that off-loading a subset of attributes to a central server for verification improves the achievable rate from $\\frac{1}{2K}$ in Jafarpisheh et al. to $\\frac{1}{K+1}$ in this paper, thus \\emph{almost doubling the rate} for relatively large $K$, while sacrificing the privacy of a few possibly non-sensitive attributes."],"url":"http://arxiv.org/abs/2401.13653v1"}
{"created":"2024-01-24 18:44:14","title":"Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity Detectors","abstract":"In this paper, we present a novel approach for detecting the discontinuity interfaces of a discontinuous function. This approach leverages Graph-Informed Neural Networks (GINNs) and sparse grids to address discontinuity detection also in domains of dimension larger than 3. GINNs, trained to identify troubled points on sparse grids, exploit graph structures built on the grids to achieve efficient and accurate discontinuity detection performances. We also introduce a recursive algorithm for general sparse grid-based detectors, characterized by convergence properties and easy applicability. Numerical experiments on functions with dimensions n = 2 and n = 4 demonstrate the efficiency and robust generalization of GINNs in detecting discontinuity interfaces. Notably, the trained GINNs offer portability and versatility, allowing integration into various algorithms and sharing among users.","sentences":["In this paper, we present a novel approach for detecting the discontinuity interfaces of a discontinuous function.","This approach leverages Graph-Informed Neural Networks (GINNs) and sparse grids to address discontinuity detection also in domains of dimension larger than 3. GINNs, trained to identify troubled points on sparse grids, exploit graph structures built on the grids to achieve efficient and accurate discontinuity detection performances.","We also introduce a recursive algorithm for general sparse grid-based detectors, characterized by convergence properties and easy applicability.","Numerical experiments on functions with dimensions n = 2 and n = 4 demonstrate the efficiency and robust generalization of GINNs in detecting discontinuity interfaces.","Notably, the trained GINNs offer portability and versatility, allowing integration into various algorithms and sharing among users."],"url":"http://arxiv.org/abs/2401.13652v1"}
{"created":"2024-01-24 18:35:21","title":"VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks","abstract":"Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve. Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively. To bridge this gap, we introduce VisualWebArena, a benchmark designed to assess the performance of multimodal web agents on realistic \\textit{visually grounded tasks}. VisualWebArena comprises of a set of diverse and complex web-based tasks that evaluate various capabilities of autonomous multimodal agents. To perform on this benchmark, agents need to accurately process image-text inputs, interpret natural language instructions, and execute actions on websites to accomplish user-defined objectives. We conduct an extensive evaluation of state-of-the-art LLM-based autonomous agents, including several multimodal models. Through extensive quantitative and qualitative analysis, we identify several limitations of text-only LLM agents, and reveal gaps in the capabilities of state-of-the-art multimodal language agents. VisualWebArena provides a framework for evaluating multimodal autonomous language agents, and offers insights towards building stronger autonomous agents for the web. Our code, baseline models, and data is publicly available at https://jykoh.com/vwa.","sentences":["Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks.","However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve.","Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively.","To bridge this gap, we introduce VisualWebArena, a benchmark designed to assess the performance of multimodal web agents on realistic \\textit{visually grounded tasks}.","VisualWebArena comprises of a set of diverse and complex web-based tasks that evaluate various capabilities of autonomous multimodal agents.","To perform on this benchmark, agents need to accurately process image-text inputs, interpret natural language instructions, and execute actions on websites to accomplish user-defined objectives.","We conduct an extensive evaluation of state-of-the-art LLM-based autonomous agents, including several multimodal models.","Through extensive quantitative and qualitative analysis, we identify several limitations of text-only LLM agents, and reveal gaps in the capabilities of state-of-the-art multimodal language agents.","VisualWebArena provides a framework for evaluating multimodal autonomous language agents, and offers insights towards building stronger autonomous agents for the web.","Our code, baseline models, and data is publicly available at https://jykoh.com/vwa."],"url":"http://arxiv.org/abs/2401.13649v1"}
{"created":"2024-01-24 18:28:52","title":"Employing polyhedral methods to optimize stencils on FPGAs with stencil-specific caches, data reuse, and wide data bursts","abstract":"It is well known that to accelerate stencil codes on CPUs or GPUs and to exploit hardware caches and their lines optimizers must find spatial and temporal locality of array accesses to harvest data-reuse opportunities. On FPGAs there is the burden that there are no built-in caches (or only pre-built hardware descriptions for cache blocks that are inefficient for stencil codes). But this paper demonstrates that this lack is also a chance as polyhedral methods can be used to generate stencil-specific cache-structures of the right sizes on the FPGA and to fill and flush them efficiently with wide bursts during stencil execution. The paper shows how to derive the appropriate directives and code restructurings from stencil codes so that the FPGA compiler generates fast stencil hardware. Switching on our optimization improves the runtime of a set of 10 stencils by between 43x and 156x.","sentences":["It is well known that to accelerate stencil codes on CPUs or GPUs and to exploit hardware caches and their lines optimizers must find spatial and temporal locality of array accesses to harvest data-reuse opportunities.","On FPGAs there is the burden that there are no built-in caches (or only pre-built hardware descriptions for cache blocks that are inefficient for stencil codes).","But this paper demonstrates that this lack is also a chance as polyhedral methods can be used to generate stencil-specific cache-structures of the right sizes on the FPGA and to fill and flush them efficiently with wide bursts during stencil execution.","The paper shows how to derive the appropriate directives and code restructurings from stencil codes so that the FPGA compiler generates fast stencil hardware.","Switching on our optimization improves the runtime of a set of 10 stencils by between 43x and 156x."],"url":"http://arxiv.org/abs/2401.13645v1"}
{"created":"2024-01-24 18:21:13","title":"Design, Development, and Deployment of Context-Adaptive AI Systems for Enhanced End-User Adoption","abstract":"My research centers on the development of context-adaptive AI systems to improve end-user adoption through the integration of technical methods. I deploy these AI systems across various interaction modalities, including user interfaces and embodied agents like robots, to expand their practical applicability. My research unfolds in three key stages: design, development, and deployment. In the design phase, user-centered approaches were used to understand user experiences with AI systems and create design tools for user participation in crafting AI explanations. In the ongoing development stage, a safety-guaranteed AI system for a robot agent was created to automatically provide adaptive solutions and explanations for unforeseen scenarios. The next steps will involve the implementation and evaluation of context-adaptive AI systems in various interaction forms. I seek to prioritize human needs in technology development, creating AI systems that tangibly benefit end-users in real-world applications and enhance interaction experiences.","sentences":["My research centers on the development of context-adaptive AI systems to improve end-user adoption through the integration of technical methods.","I deploy these AI systems across various interaction modalities, including user interfaces and embodied agents like robots, to expand their practical applicability.","My research unfolds in three key stages: design, development, and deployment.","In the design phase, user-centered approaches were used to understand user experiences with AI systems and create design tools for user participation in crafting AI explanations.","In the ongoing development stage, a safety-guaranteed AI system for a robot agent was created to automatically provide adaptive solutions and explanations for unforeseen scenarios.","The next steps will involve the implementation and evaluation of context-adaptive AI systems in various interaction forms.","I seek to prioritize human needs in technology development, creating AI systems that tangibly benefit end-users in real-world applications and enhance interaction experiences."],"url":"http://arxiv.org/abs/2401.13643v1"}
{"created":"2024-01-24 18:10:39","title":"How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability","abstract":"Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning).   The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of the automatic decisions in human scenarios. Experiments are carried out in order to evaluate the performance and robustness of ChatGPT, using popular public benchmarks and comparing the results with state-of-the-art methods in the field. The results achieved in this study show the potential of LLMs such as ChatGPT for face biometrics, especially to enhance explainability. For reproducibility reasons, we release all the code in GitHub.","sentences":["Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society.","This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed.","As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning).   ","The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics.","In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results.","ChatGPT could be very valuable to further increase the explainability and transparency of the automatic decisions in human scenarios.","Experiments are carried out in order to evaluate the performance and robustness of ChatGPT, using popular public benchmarks and comparing the results with state-of-the-art methods in the field.","The results achieved in this study show the potential of LLMs such as ChatGPT for face biometrics, especially to enhance explainability.","For reproducibility reasons, we release all the code in GitHub."],"url":"http://arxiv.org/abs/2401.13641v1"}
{"created":"2024-01-24 18:09:16","title":"Winding Clearness for Differentiable Point Cloud Optimization","abstract":"We propose to explore the properties of raw point clouds through the \\emph{winding clearness}, a concept we first introduce for assessing the clarity of the interior/exterior relationships represented by the winding number field of the point cloud. In geometric modeling, the winding number is a powerful tool for distinguishing the interior and exterior of a given surface $\\partial \\Omega$, and it has been previously used for point normal orientation and surface reconstruction. In this work, we introduce a novel approach to assess and optimize the quality of point clouds based on the winding clearness. We observe that point clouds with reduced noise tend to exhibit improved winding clearness. Accordingly, we propose an objective function that quantifies the error in winding clearness, solely utilizing the positions of the point clouds. Moreover, we demonstrate that the winding clearness error is differentiable and can serve as a loss function in optimization-based and learning-based point cloud processing. In the optimization-based method, the loss function is directly back-propagated to update the point positions, resulting in an overall improvement of the point cloud. In the learning-based method, we incorporate the winding clearness as a geometric constraint in the diffusion-based 3D generative model. Experimental results demonstrate the effectiveness of optimizing the winding clearness in enhancing the quality of the point clouds. Our method exhibits superior performance in handling noisy point clouds with thin structures, highlighting the benefits of the global perspective enabled by the winding number.","sentences":["We propose to explore the properties of raw point clouds through the \\emph{winding clearness}, a concept we first introduce for assessing the clarity of the interior/exterior relationships represented by the winding number field of the point cloud.","In geometric modeling, the winding number is a powerful tool for distinguishing the interior and exterior of a given surface $\\partial \\Omega$, and it has been previously used for point normal orientation and surface reconstruction.","In this work, we introduce a novel approach to assess and optimize the quality of point clouds based on the winding clearness.","We observe that point clouds with reduced noise tend to exhibit improved winding clearness.","Accordingly, we propose an objective function that quantifies the error in winding clearness, solely utilizing the positions of the point clouds.","Moreover, we demonstrate that the winding clearness error is differentiable and can serve as a loss function in optimization-based and learning-based point cloud processing.","In the optimization-based method, the loss function is directly back-propagated to update the point positions, resulting in an overall improvement of the point cloud.","In the learning-based method, we incorporate the winding clearness as a geometric constraint in the diffusion-based 3D generative model.","Experimental results demonstrate the effectiveness of optimizing the winding clearness in enhancing the quality of the point clouds.","Our method exhibits superior performance in handling noisy point clouds with thin structures, highlighting the benefits of the global perspective enabled by the winding number."],"url":"http://arxiv.org/abs/2401.13639v1"}
{"created":"2024-01-24 18:00:11","title":"Quantifying the Impact of Frame Preemption on Combined TSN Shapers","abstract":"Different scheduling mechanisms in Time Sensitive Networking (TSN) can be integrated together to design and support complex architectures with enhanced capabilities for mixed critical networks. Integrating Frame Preemption (FP) with Credit-Based Shaper (CBS) and Gate Control List (GCL) opens up different modes and configuration choices resulting in a complex evaluation of several possibilities and their impact on the Quality of Service (QoS). In this paper, we implement and quantify the integration of preemptive CBS with GCL by incorporating FP into the architecture. Our experiments show that the end-to-end delay of Audio Video Bridging (AVB) flows shaped by CBS reduces significantly (up to 40\\%) when AVB flows are set to preemptable class. We further show that the jitter of Time Triggered (TT) traffic remains unaffected in \"with Hold/Release\" mode. Furthermore, we propose to introduce Guardband (GB) in the \"without Hold/Release\" to reduce the jitter of the TT flow. We compare all the different integration modes, starting with CBS with GCL, extending it further to FP. We evaluate all feasible combinations in both synthetic and realistic scenarios and offer recommendations for practical configuration methods.","sentences":["Different scheduling mechanisms in Time Sensitive Networking (TSN) can be integrated together to design and support complex architectures with enhanced capabilities for mixed critical networks.","Integrating Frame Preemption (FP) with Credit-Based Shaper (CBS) and Gate Control List (GCL) opens up different modes and configuration choices resulting in a complex evaluation of several possibilities and their impact on the Quality of Service (QoS).","In this paper, we implement and quantify the integration of preemptive CBS with GCL by incorporating FP into the architecture.","Our experiments show that the end-to-end delay of Audio Video Bridging (AVB) flows shaped by CBS reduces significantly (up to 40\\%) when AVB flows are set to preemptable class.","We further show that the jitter of Time Triggered (TT) traffic remains unaffected in \"with Hold/Release\" mode.","Furthermore, we propose to introduce Guardband (GB) in the \"without Hold/Release\" to reduce the jitter of the TT flow.","We compare all the different integration modes, starting with CBS with GCL, extending it further to FP.","We evaluate all feasible combinations in both synthetic and realistic scenarios and offer recommendations for practical configuration methods."],"url":"http://arxiv.org/abs/2401.13631v1"}
{"created":"2024-01-24 17:59:00","title":"Enabling Seamless Data Security, Consensus, and Trading in Vehicular Networks","abstract":"Cooperative driving is an emerging paradigm to enhance the safety and efficiency of autonomous vehicles. To ensure successful cooperation, road users must reach a consensus for making collective decisions, while recording vehicular data to analyze and address failures related to such agreements. This data has the potential to provide valuable insights into various vehicular events, while also potentially improving accountability measures. Furthermore, vehicles may benefit from the ability to negotiate and trade services among themselves, adding value to the cooperative driving framework. However, the majority of proposed systems aiming to ensure data security, consensus, or service trading, lack efficient and thoroughly validated mechanisms that consider the distinctive characteristics of vehicular networks. These limitations are amplified by a dependency on the centralized support provided by the infrastructure. Furthermore, corresponding mechanisms must diligently address security concerns, especially regarding potential malicious or misbehaving nodes, while also considering inherent constraints of the wireless medium. We introduce the Verifiable Event Extension (VEE), an applicational extension designed for Intelligent Transportation System (ITS) messages. The VEE operates seamlessly with any existing standardized vehicular communications protocol, addressing crucial aspects of data security, consensus, and trading with minimal overhead. To achieve this, we employ blockchain techniques, Byzantine fault tolerance (BFT) consensus protocols, and cryptocurrency-based mechanics. To assess our proposal's feasibility and lightweight nature, we employed a hardware-in-the-loop setup for analysis. Experimental results demonstrate the viability and efficiency of the VEE extension in overcoming the challenges posed by the distributed and opportunistic nature of wireless vehicular communications.","sentences":["Cooperative driving is an emerging paradigm to enhance the safety and efficiency of autonomous vehicles.","To ensure successful cooperation, road users must reach a consensus for making collective decisions, while recording vehicular data to analyze and address failures related to such agreements.","This data has the potential to provide valuable insights into various vehicular events, while also potentially improving accountability measures.","Furthermore, vehicles may benefit from the ability to negotiate and trade services among themselves, adding value to the cooperative driving framework.","However, the majority of proposed systems aiming to ensure data security, consensus, or service trading, lack efficient and thoroughly validated mechanisms that consider the distinctive characteristics of vehicular networks.","These limitations are amplified by a dependency on the centralized support provided by the infrastructure.","Furthermore, corresponding mechanisms must diligently address security concerns, especially regarding potential malicious or misbehaving nodes, while also considering inherent constraints of the wireless medium.","We introduce the Verifiable Event Extension (VEE), an applicational extension designed for Intelligent Transportation System (ITS) messages.","The VEE operates seamlessly with any existing standardized vehicular communications protocol, addressing crucial aspects of data security, consensus, and trading with minimal overhead.","To achieve this, we employ blockchain techniques, Byzantine fault tolerance (BFT) consensus protocols, and cryptocurrency-based mechanics.","To assess our proposal's feasibility and lightweight nature, we employed a hardware-in-the-loop setup for analysis.","Experimental results demonstrate the viability and efficiency of the VEE extension in overcoming the challenges posed by the distributed and opportunistic nature of wireless vehicular communications."],"url":"http://arxiv.org/abs/2401.13630v1"}
{"created":"2024-01-24 17:58:07","title":"Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild","abstract":"We introduce SUPIR (Scaling-UP Image Restoration), a groundbreaking image restoration method that harnesses generative prior and the power of model scaling up. Leveraging multi-modal techniques and advanced generative prior, SUPIR marks a significant advance in intelligent and realistic image restoration. As a pivotal catalyst within SUPIR, model scaling dramatically enhances its capabilities and demonstrates new potential for image restoration. We collect a dataset comprising 20 million high-resolution, high-quality images for model training, each enriched with descriptive text annotations. SUPIR provides the capability to restore images guided by textual prompts, broadening its application scope and potential. Moreover, we introduce negative-quality prompts to further improve perceptual quality. We also develop a restoration-guided sampling method to suppress the fidelity issue encountered in generative-based restoration. Experiments demonstrate SUPIR's exceptional restoration effects and its novel capacity to manipulate restoration through textual prompts.","sentences":["We introduce SUPIR (Scaling-UP Image Restoration), a groundbreaking image restoration method that harnesses generative prior and the power of model scaling up.","Leveraging multi-modal techniques and advanced generative prior, SUPIR marks a significant advance in intelligent and realistic image restoration.","As a pivotal catalyst within SUPIR, model scaling dramatically enhances its capabilities and demonstrates new potential for image restoration.","We collect a dataset comprising 20 million high-resolution, high-quality images for model training, each enriched with descriptive text annotations.","SUPIR provides the capability to restore images guided by textual prompts, broadening its application scope and potential.","Moreover, we introduce negative-quality prompts to further improve perceptual quality.","We also develop a restoration-guided sampling method to suppress the fidelity issue encountered in generative-based restoration.","Experiments demonstrate SUPIR's exceptional restoration effects and its novel capacity to manipulate restoration through textual prompts."],"url":"http://arxiv.org/abs/2401.13627v1"}
{"created":"2024-01-24 17:52:24","title":"What Makes a Great Software Quality Assurance Engineer?","abstract":"Software Quality Assurance (SQA) Engineers are responsible for assessing a product during every phase of the software development process to ensure that the outcomes of each phase and the final product possess the desired qualities. In general, a great SQA engineer needs to have a different set of abilities from development engineers to effectively oversee the entire product development process from beginning to end. Recent empirical studies identified important attributes of software engineers and managers, but the quality assurance role is overlooked. As software quality aspects have become more of a priority in the life cycle of software development, employers seek professionals that best suit the company's objectives and new graduates desire to make a valuable contribution through their job as an SQA engineer, but what makes them great? We addressed this knowledge gap by conducting 25 semi-structured interviews and 363 survey respondents with software quality assurance engineers from different companies around the world. We use the data collected from these activities to derive a comprehensive set of attributes that are considered important. As a result of the interviews, twenty-five attributes were identified and grouped into five main categories: personal, social, technical, management, and decision-making attributes. Through a rating survey, we confirmed that the distinguishing characteristics of great SQA engineers are curiosity, the ability to communicate effectively, and critical thinking skills. This work will guide further studies with SQA practitioners, by considering contextual factors and providing some implications for research and practice.","sentences":["Software Quality Assurance (SQA) Engineers are responsible for assessing a product during every phase of the software development process to ensure that the outcomes of each phase and the final product possess the desired qualities.","In general, a great SQA engineer needs to have a different set of abilities from development engineers to effectively oversee the entire product development process from beginning to end.","Recent empirical studies identified important attributes of software engineers and managers, but the quality assurance role is overlooked.","As software quality aspects have become more of a priority in the life cycle of software development, employers seek professionals that best suit the company's objectives and new graduates desire to make a valuable contribution through their job as an SQA engineer, but what makes them great?","We addressed this knowledge gap by conducting 25 semi-structured interviews and 363 survey respondents with software quality assurance engineers from different companies around the world.","We use the data collected from these activities to derive a comprehensive set of attributes that are considered important.","As a result of the interviews, twenty-five attributes were identified and grouped into five main categories: personal, social, technical, management, and decision-making attributes.","Through a rating survey, we confirmed that the distinguishing characteristics of great SQA engineers are curiosity, the ability to communicate effectively, and critical thinking skills.","This work will guide further studies with SQA practitioners, by considering contextual factors and providing some implications for research and practice."],"url":"http://arxiv.org/abs/2401.13623v1"}
{"created":"2024-01-24 17:51:06","title":"Cooperative Periodic Coverage With Collision Avoidance","abstract":"In this paper we propose a periodic solution to the problem of persistently covering a finite set of interest points with a group of autonomous mobile agents. These agents visit periodically the points and spend some time carrying out the coverage task, which we call coverage time. Since this periodic persistent coverage problem is NP-hard, we split it into three subproblems to counteract its complexity. In the first place, we plan individual closed paths for the agents to cover all the points. Second, we formulate a quadratically constrained linear program to find the optimal coverage times and actions that satisfy the coverage objective. Finally, we join together the individual plans of the agents in a periodic team plan by obtaining a schedule that guarantees collision avoidance. To this end, we solve a mixed integer linear program that minimizes the time in which two or more agents move at the same time. Eventually, we apply the proposed solution to an induction hob with mobile inductors for a domestic heating application and show its performance with experiments on a real prototype.","sentences":["In this paper we propose a periodic solution to the problem of persistently covering a finite set of interest points with a group of autonomous mobile agents.","These agents visit periodically the points and spend some time carrying out the coverage task, which we call coverage time.","Since this periodic persistent coverage problem is NP-hard, we split it into three subproblems to counteract its complexity.","In the first place, we plan individual closed paths for the agents to cover all the points.","Second, we formulate a quadratically constrained linear program to find the optimal coverage times and actions that satisfy the coverage objective.","Finally, we join together the individual plans of the agents in a periodic team plan by obtaining a schedule that guarantees collision avoidance.","To this end, we solve a mixed integer linear program that minimizes the time in which two or more agents move at the same time.","Eventually, we apply the proposed solution to an induction hob with mobile inductors for a domestic heating application and show its performance with experiments on a real prototype."],"url":"http://arxiv.org/abs/2401.13622v1"}
{"created":"2024-01-24 17:48:45","title":"DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning","abstract":"Contrastive-learning-based methods have dominated sentence representation learning. These methods regularize the representation space by pulling similar sentence representations closer and pushing away the dissimilar ones and have been proven effective in various NLP tasks, e.g., semantic textual similarity (STS) tasks. However, it is challenging for these methods to learn fine-grained semantics as they only learn from the inter-sentence perspective, i.e., their supervision signal comes from the relationship between data samples. In this work, we propose a novel denoising objective that inherits from another perspective, i.e., the intra-sentence perspective. By introducing both discrete and continuous noise, we generate noisy sentences and then train our model to restore them to their original form. Our empirical evaluations demonstrate that this approach delivers competitive results on both semantic textual similarity (STS) and a wide range of transfer tasks, standing up well in comparison to contrastive-learning-based methods. Notably, the proposed intra-sentence denoising objective complements existing inter-sentence contrastive methodologies and can be integrated with them to further enhance performance. Our code is available at https://github.com/xinghaow99/DenoSent.","sentences":["Contrastive-learning-based methods have dominated sentence representation learning.","These methods regularize the representation space by pulling similar sentence representations closer and pushing away the dissimilar ones and have been proven effective in various NLP tasks, e.g., semantic textual similarity (STS) tasks.","However, it is challenging for these methods to learn fine-grained semantics as they only learn from the inter-sentence perspective, i.e., their supervision signal comes from the relationship between data samples.","In this work, we propose a novel denoising objective that inherits from another perspective, i.e., the intra-sentence perspective.","By introducing both discrete and continuous noise, we generate noisy sentences and then train our model to restore them to their original form.","Our empirical evaluations demonstrate that this approach delivers competitive results on both semantic textual similarity (STS) and a wide range of transfer tasks, standing up well in comparison to contrastive-learning-based methods.","Notably, the proposed intra-sentence denoising objective complements existing inter-sentence contrastive methodologies and can be integrated with them to further enhance performance.","Our code is available at https://github.com/xinghaow99/DenoSent."],"url":"http://arxiv.org/abs/2401.13621v1"}
{"created":"2024-01-24 17:41:00","title":"Equitable Persistent Coverage of Non-Convex Environments with Graph-Based Planning","abstract":"In this paper we tackle the problem of persistently covering a complex non-convex environment with a team of robots. We consider scenarios where the coverage quality of the environment deteriorates with time, requiring to constantly revisit every point. As a first step, our solution finds a partition of the environment where the amount of work for each robot, weighted by the importance of each point, is equal. This is achieved using a power diagram and finding an equitable partition through a provably correct distributed control law on the power weights. Compared to other existing partitioning methods, our solution considers a continuous environment formulation with non-convex obstacles. In the second step, each robot computes a graph that gathers sweep-like paths and covers its entire partition. At each planning time, the coverage error at the graph vertices is assigned as weights of the corresponding edges. Then, our solution is capable of efficiently finding the optimal open coverage path through the graph with respect to the coverage error per distance traversed. Simulation and experimental results are presented to support our proposal.","sentences":["In this paper we tackle the problem of persistently covering a complex non-convex environment with a team of robots.","We consider scenarios where the coverage quality of the environment deteriorates with time, requiring to constantly revisit every point.","As a first step, our solution finds a partition of the environment where the amount of work for each robot, weighted by the importance of each point, is equal.","This is achieved using a power diagram and finding an equitable partition through a provably correct distributed control law on the power weights.","Compared to other existing partitioning methods, our solution considers a continuous environment formulation with non-convex obstacles.","In the second step, each robot computes a graph that gathers sweep-like paths and covers its entire partition.","At each planning time, the coverage error at the graph vertices is assigned as weights of the corresponding edges.","Then, our solution is capable of efficiently finding the optimal open coverage path through the graph with respect to the coverage error per distance traversed.","Simulation and experimental results are presented to support our proposal."],"url":"http://arxiv.org/abs/2401.13614v1"}
{"created":"2024-01-24 17:35:38","title":"Enhancing Image Retrieval : A Comprehensive Study on Photo Search using the CLIP Mode","abstract":"Photo search, the task of retrieving images based on textual queries, has witnessed significant advancements with the introduction of CLIP (Contrastive Language-Image Pretraining) model. CLIP leverages a vision-language pre training approach, wherein it learns a shared representation space for images and text, enabling cross-modal understanding. This model demonstrates the capability to understand the semantic relationships between diverse image and text pairs, allowing for efficient and accurate retrieval of images based on natural language queries. By training on a large-scale dataset containing images and their associated textual descriptions, CLIP achieves remarkable generalization, providing a powerful tool for tasks such as zero-shot learning and few-shot classification. This abstract summarizes the foundational principles of CLIP and highlights its potential impact on advancing the field of photo search, fostering a seamless integration of natural language understanding and computer vision for improved information retrieval in multimedia applications","sentences":["Photo search, the task of retrieving images based on textual queries, has witnessed significant advancements with the introduction of CLIP (Contrastive Language-Image Pretraining) model.","CLIP leverages a vision-language pre training approach, wherein it learns a shared representation space for images and text, enabling cross-modal understanding.","This model demonstrates the capability to understand the semantic relationships between diverse image and text pairs, allowing for efficient and accurate retrieval of images based on natural language queries.","By training on a large-scale dataset containing images and their associated textual descriptions, CLIP achieves remarkable generalization, providing a powerful tool for tasks such as zero-shot learning and few-shot classification.","This abstract summarizes the foundational principles of CLIP and highlights its potential impact on advancing the field of photo search, fostering a seamless integration of natural language understanding and computer vision for improved information retrieval in multimedia applications"],"url":"http://arxiv.org/abs/2401.13613v1"}
{"created":"2024-01-24 17:35:11","title":"Intermittent Connectivity Maintenance With Heterogeneous Robots","abstract":"We consider a scenario of cooperative task servicing, with a team of heterogeneous robots with different maximum speeds and communication radii, in charge of keeping the network intermittently connected. We abstract the task locations into a $1D$ cycle graph that is traversed by the communicating robots, and we discuss intermittent communication strategies so that each task location is periodically visited, with a worst--case revisiting time. Robots move forward and backward along the cycle graph, exchanging data with their previous and next neighbors when they meet, and updating their region boundaries. Asymptotically, each robot is in charge of a region of the cycle graph, depending on its capabilities. The method is distributed, and robots only exchange data when they meet.","sentences":["We consider a scenario of cooperative task servicing, with a team of heterogeneous robots with different maximum speeds and communication radii, in charge of keeping the network intermittently connected.","We abstract the task locations into a $1D$ cycle graph that is traversed by the communicating robots, and we discuss intermittent communication strategies so that each task location is periodically visited, with a worst--case revisiting time.","Robots move forward and backward along the cycle graph, exchanging data with their previous and next neighbors when they meet, and updating their region boundaries.","Asymptotically, each robot is in charge of a region of the cycle graph, depending on its capabilities.","The method is distributed, and robots only exchange data when they meet."],"url":"http://arxiv.org/abs/2401.13612v1"}
{"created":"2024-01-24 17:31:07","title":"Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users using Intermediate ASR Features and Human Memory Models","abstract":"Neural networks have been successfully used for non-intrusive speech intelligibility prediction. Recently, the use of feature representations sourced from intermediate layers of pre-trained self-supervised and weakly-supervised models has been found to be particularly useful for this task. This work combines the use of Whisper ASR decoder layer representations as neural network input features with an exemplar-based, psychologically motivated model of human memory to predict human intelligibility ratings for hearing-aid users. Substantial performance improvement over an established intrusive HASPI baseline system is found, including on enhancement systems and listeners unseen in the training data, with a root mean squared error of 25.3 compared with the baseline of 28.7.","sentences":["Neural networks have been successfully used for non-intrusive speech intelligibility prediction.","Recently, the use of feature representations sourced from intermediate layers of pre-trained self-supervised and weakly-supervised models has been found to be particularly useful for this task.","This work combines the use of Whisper ASR decoder layer representations as neural network input features with an exemplar-based, psychologically motivated model of human memory to predict human intelligibility ratings for hearing-aid users.","Substantial performance improvement over an established intrusive HASPI baseline system is found, including on enhancement systems and listeners unseen in the training data, with a root mean squared error of 25.3 compared with the baseline of 28.7."],"url":"http://arxiv.org/abs/2401.13611v1"}
{"created":"2024-01-24 17:29:25","title":"Scale-free vision-based aerial control of a ground formation with hybrid topology","abstract":"We present a novel vision-based control method to make a group of ground mobile robots achieve a specified formation shape with unspecified size. Our approach uses multiple aerial control units equipped with downward-facing cameras, each observing a partial subset of the multirobot team. The units compute the control commands from the ground robots' image projections, using neither calibration nor scene scale information, and transmit them to the robots. The control strategy relies on the calculation of image similarity transformations, and we show it to be asymptotically stable if the overlaps between the subsets of controlled robots satisfy certain conditions. The presence of the supervisory units, which coordinate their motions to guarantee a correct control performance, gives rise to a hybrid system topology. All in all, the proposed system provides relevant practical advantages in simplicity and flexibility. Within the problem of controlling a team shape, our contribution lies in addressing several simultaneous challenges: the controller needs only partial information of the robotic group, does not use distance measurements or global reference frames, is designed for unicycle agents, and can accommodate topology changes. We present illustrative simulation results.","sentences":["We present a novel vision-based control method to make a group of ground mobile robots achieve a specified formation shape with unspecified size.","Our approach uses multiple aerial control units equipped with downward-facing cameras, each observing a partial subset of the multirobot team.","The units compute the control commands from the ground robots' image projections, using neither calibration nor scene scale information, and transmit them to the robots.","The control strategy relies on the calculation of image similarity transformations, and we show it to be asymptotically stable if the overlaps between the subsets of controlled robots satisfy certain conditions.","The presence of the supervisory units, which coordinate their motions to guarantee a correct control performance, gives rise to a hybrid system topology.","All in all, the proposed system provides relevant practical advantages in simplicity and flexibility.","Within the problem of controlling a team shape, our contribution lies in addressing several simultaneous challenges: the controller needs only partial information of the robotic group, does not use distance measurements or global reference frames, is designed for unicycle agents, and can accommodate topology changes.","We present illustrative simulation results."],"url":"http://arxiv.org/abs/2401.13610v1"}
{"created":"2024-01-24 17:27:08","title":"Building Contextual Knowledge Graphs for Personalized Learning Recommendations using Text Mining and Semantic Graph Completion","abstract":"Modelling learning objects (LO) within their context enables the learner to advance from a basic, remembering-level, learning objective to a higher-order one, i.e., a level with an application- and analysis objective. While hierarchical data models are commonly used in digital learning platforms, using graph-based models enables representing the context of LOs in those platforms. This leads to a foundation for personalized recommendations of learning paths. In this paper, the transformation of hierarchical data models into knowledge graph (KG) models of LOs using text mining is introduced and evaluated. We utilize custom text mining pipelines to mine semantic relations between elements of an expert-curated hierarchical model. We evaluate the KG structure and relation extraction using graph quality-control metrics and the comparison of algorithmic semantic-similarities to expert-defined ones. The results show that the relations in the KG are semantically comparable to those defined by domain experts, and that the proposed KG improves representing and linking the contexts of LOs through increasing graph communities and betweenness centrality.","sentences":["Modelling learning objects (LO) within their context enables the learner to advance from a basic, remembering-level, learning objective to a higher-order one, i.e., a level with an application- and analysis objective.","While hierarchical data models are commonly used in digital learning platforms, using graph-based models enables representing the context of LOs in those platforms.","This leads to a foundation for personalized recommendations of learning paths.","In this paper, the transformation of hierarchical data models into knowledge graph (KG) models of LOs using text mining is introduced and evaluated.","We utilize custom text mining pipelines to mine semantic relations between elements of an expert-curated hierarchical model.","We evaluate the KG structure and relation extraction using graph quality-control metrics and the comparison of algorithmic semantic-similarities to expert-defined ones.","The results show that the relations in the KG are semantically comparable to those defined by domain experts, and that the proposed KG improves representing and linking the contexts of LOs through increasing graph communities and betweenness centrality."],"url":"http://arxiv.org/abs/2401.13609v1"}
{"created":"2024-01-24 17:22:33","title":"Regulating AI-Based Remote Biometric Identification. Investigating the Public Demand for Bans, Audits, and Public Database Registrations","abstract":"AI is increasingly being used in the public sector, including public security. In this context, the use of AI-powered remote biometric identification (RBI) systems is a much-discussed technology. RBI systems are used to identify criminal activity in public spaces, but are criticised for inheriting biases and violating fundamental human rights. It is therefore important to ensure that such systems are developed in the public interest, which means that any technology that is deployed for public use needs to be scrutinised. While there is a consensus among business leaders, policymakers and scientists that AI must be developed in an ethical and trustworthy manner, scholars have argued that ethical guidelines do not guarantee ethical AI, but rather prevent stronger regulation of AI. As a possible counterweight, public opinion can have a decisive influence on policymakers to establish boundaries and conditions under which AI systems should be used -- if at all. However, we know little about the conditions that lead to regulatory demand for AI systems. In this study, we focus on the role of trust in AI as well as trust in law enforcement as potential factors that may lead to demands for regulation of AI technology. In addition, we explore the mediating effects of discrimination perceptions regarding RBI. We test the effects on four different use cases of RBI varying the temporal aspect (real-time vs. post hoc analysis) and purpose of use (persecution of criminals vs. safeguarding public events) in a survey among German citizens. We found that German citizens do not differentiate between the different modes of application in terms of their demand for RBI regulation. Furthermore, we show that perceptions of discrimination lead to a demand for stronger regulation, while trust in AI and trust in law enforcement lead to opposite effects in terms of demand for a ban on RBI systems.","sentences":["AI is increasingly being used in the public sector, including public security.","In this context, the use of AI-powered remote biometric identification (RBI) systems is a much-discussed technology.","RBI systems are used to identify criminal activity in public spaces, but are criticised for inheriting biases and violating fundamental human rights.","It is therefore important to ensure that such systems are developed in the public interest, which means that any technology that is deployed for public use needs to be scrutinised.","While there is a consensus among business leaders, policymakers and scientists that AI must be developed in an ethical and trustworthy manner, scholars have argued that ethical guidelines do not guarantee ethical AI, but rather prevent stronger regulation of AI.","As a possible counterweight, public opinion can have a decisive influence on policymakers to establish boundaries and conditions under which AI systems should be used -- if at all.","However, we know little about the conditions that lead to regulatory demand for AI systems.","In this study, we focus on the role of trust in AI as well as trust in law enforcement as potential factors that may lead to demands for regulation of AI technology.","In addition, we explore the mediating effects of discrimination perceptions regarding RBI.","We test the effects on four different use cases of RBI varying the temporal aspect (real-time vs. post hoc analysis) and purpose of use (persecution of criminals vs. safeguarding public events) in a survey among German citizens.","We found that German citizens do not differentiate between the different modes of application in terms of their demand for RBI regulation.","Furthermore, we show that perceptions of discrimination lead to a demand for stronger regulation, while trust in AI and trust in law enforcement lead to opposite effects in terms of demand for a ban on RBI systems."],"url":"http://arxiv.org/abs/2401.13605v1"}
{"created":"2024-01-24 17:14:50","title":"Stream-based perception for cognitive agents in mobile ecosystems","abstract":"Cognitive agent abstractions can help to engineer intelligent systems across mobile devices. On smartphones, the data obtained from onboard sensors can give valuable insights into the user's current situation. Unfortunately, today's cognitive agent frameworks cannot cope well with the challenging characteristics of sensor data. Sensor data is located on a low abstraction level and the individual data elements are not meaningful when observed in isolation. In contrast, cognitive agents operate on high-level percepts and lack the means to effectively detect complex spatio-temporal patterns in sequences of multiple percepts. In this paper, we present a stream-based perception approach that enables the agents to perceive meaningful situations in low-level sensor data streams. We present a crowdshipping case study where autonomous, self-interested agents collaborate to deliver parcels to their destinations. We show how situations derived from smartphone sensor data can trigger and guide auctions, which the agents use to reach agreements. Experiments with real smartphone data demonstrate the benefits of stream-based agent perception.","sentences":["Cognitive agent abstractions can help to engineer intelligent systems across mobile devices.","On smartphones, the data obtained from onboard sensors can give valuable insights into the user's current situation.","Unfortunately, today's cognitive agent frameworks cannot cope well with the challenging characteristics of sensor data.","Sensor data is located on a low abstraction level and the individual data elements are not meaningful when observed in isolation.","In contrast, cognitive agents operate on high-level percepts and lack the means to effectively detect complex spatio-temporal patterns in sequences of multiple percepts.","In this paper, we present a stream-based perception approach that enables the agents to perceive meaningful situations in low-level sensor data streams.","We present a crowdshipping case study where autonomous, self-interested agents collaborate to deliver parcels to their destinations.","We show how situations derived from smartphone sensor data can trigger and guide auctions, which the agents use to reach agreements.","Experiments with real smartphone data demonstrate the benefits of stream-based agent perception."],"url":"http://arxiv.org/abs/2401.13604v1"}
{"created":"2024-01-24 17:10:45","title":"MM-LLMs: Recent Advances in MultiModal Large Language Models","abstract":"In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Specifically, we first outline general design formulations for model architecture and training pipeline. Subsequently, we provide brief introductions of $26$ existing MM-LLMs, each characterized by its specific formulations. Additionally, we review the performance of MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field. We hope that this survey contributes to the ongoing advancement of the MM-LLMs domain.","sentences":["In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies.","The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks.","In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs.","Specifically, we first outline general design formulations for model architecture and training pipeline.","Subsequently, we provide brief introductions of $26$ existing MM-LLMs, each characterized by its specific formulations.","Additionally, we review the performance of MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs.","Lastly, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field.","We hope that this survey contributes to the ongoing advancement of the MM-LLMs domain."],"url":"http://arxiv.org/abs/2401.13601v1"}
{"created":"2024-01-24 17:04:28","title":"Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction","abstract":"Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document. Existing methods heavily rely on a substantial amount of fully labeled data. However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive. Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations. In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which generates labeled data by retrieval and denoising knowledge from LLMs, called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step. To improve the quality of synthetic data, we propose a denoising strategy based on the consistency of cross-document knowledge. Leveraging our denoised synthetic data, we proceed to fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets. We perform experiments for both zero-shot document-level relation and triplet extraction on two public datasets. The experimental results illustrate that our GenRDK framework outperforms strong baselines.","sentences":["Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document.","Existing methods heavily rely on a substantial amount of fully labeled data.","However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive.","Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations.","In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which generates labeled data by retrieval and denoising knowledge from LLMs, called GenRDK.","Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step.","To improve the quality of synthetic data, we propose a denoising strategy based on the consistency of cross-document knowledge.","Leveraging our denoised synthetic data, we proceed to fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets.","We perform experiments for both zero-shot document-level relation and triplet extraction on two public datasets.","The experimental results illustrate that our GenRDK framework outperforms strong baselines."],"url":"http://arxiv.org/abs/2401.13598v1"}
{"created":"2024-01-24 17:01:42","title":"Graph Guided Question Answer Generation for Procedural Question-Answering","abstract":"In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller. 2) semantic coverage is the key indicator for downstream QA performance. Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model. In contrast, the higher semantic coverage provided by our method is critical for QA performance.","sentences":["In this paper, we focus on task-specific question answering (QA).","To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants.","The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data.","While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model.","In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs.","We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner.","Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller.","2) semantic coverage is the key indicator for downstream QA performance.","Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model.","In contrast, the higher semantic coverage provided by our method is critical for QA performance."],"url":"http://arxiv.org/abs/2401.13594v1"}
{"created":"2024-01-24 16:52:37","title":"Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes","abstract":"The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance. However, their performance in actual clinical applications has been underexplored. Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts. This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings. Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes. Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an in-depth analysis. Results: GPT-4 showed overall superior performance compared to other LLMs. In contrast, both GPT-3.5 and text-davinci-003 exhibit enhanced performance when the appropriate prompting strategies are employed. The GPT family models have demonstrated considerable efficiency, evidenced by their cost-effectiveness and time-saving capabilities. Conclusion: A comprehensive qualitative performance evaluation framework for LLMs is developed and operationalized. This framework goes beyond singular performance aspects. With expert annotations, this methodology not only validates LLMs' capabilities in processing complex medical data but also establishes a benchmark for future LLM evaluations across specialized domains.","sentences":["The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance.","However, their performance in actual clinical applications has been underexplored.","Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts.","This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings.","Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication.","Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes.","Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians.","Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an in-depth analysis.","Results:","GPT-4 showed overall superior performance compared to other LLMs.","In contrast, both GPT-3.5 and text-davinci-003 exhibit enhanced performance when the appropriate prompting strategies are employed.","The GPT family models have demonstrated considerable efficiency, evidenced by their cost-effectiveness and time-saving capabilities.","Conclusion: A comprehensive qualitative performance evaluation framework for LLMs is developed and operationalized.","This framework goes beyond singular performance aspects.","With expert annotations, this methodology not only validates LLMs' capabilities in processing complex medical data but also establishes a benchmark for future LLM evaluations across specialized domains."],"url":"http://arxiv.org/abs/2401.13588v1"}
{"created":"2024-01-24 16:51:42","title":"Deep Learning Based Adaptive Joint mmWave Beam Alignment","abstract":"The challenging propagation environment, combined with the hardware limitations of mmWave systems, gives rise to the need for accurate initial access beam alignment strategies with low latency and high achievable beamforming gain. Much of the recent work in this area either focuses on one-sided beam alignment, or, joint beam alignment methods where both sides of the link perform a sequence of fixed channel probing steps. Codebook-based non-adaptive beam alignment schemes have the potential to allow multiple user equipment (UE) to perform initial access beam alignment in parallel whereas adaptive schemes are favourable in achievable beamforming gain. This work introduces a novel deep learning based joint beam alignment scheme that aims to combine the benefits of adaptive, codebook-free beam alignment at the UE side with the advantages of a codebook-sweep based scheme at the base station. The proposed end-to-end trainable scheme is compatible with current cellular standard signaling and can be readily integrated into the standard without requiring significant changes to it. Extensive simulations demonstrate superior performance of the proposed approach over purely codebook-based ones.","sentences":["The challenging propagation environment, combined with the hardware limitations of mmWave systems, gives rise to the need for accurate initial access beam alignment strategies with low latency and high achievable beamforming gain.","Much of the recent work in this area either focuses on one-sided beam alignment, or, joint beam alignment methods where both sides of the link perform a sequence of fixed channel probing steps.","Codebook-based non-adaptive beam alignment schemes have the potential to allow multiple user equipment (UE) to perform initial access beam alignment in parallel whereas adaptive schemes are favourable in achievable beamforming gain.","This work introduces a novel deep learning based joint beam alignment scheme that aims to combine the benefits of adaptive, codebook-free beam alignment at the UE side with the advantages of a codebook-sweep based scheme at the base station.","The proposed end-to-end trainable scheme is compatible with current cellular standard signaling and can be readily integrated into the standard without requiring significant changes to it.","Extensive simulations demonstrate superior performance of the proposed approach over purely codebook-based ones."],"url":"http://arxiv.org/abs/2401.13587v1"}
{"created":"2024-01-24 16:51:23","title":"Prompt Weight Experiments for LLM Instruction Fine-Tuning","abstract":"We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets. We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW.","sentences":["We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks.","We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets.","We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW."],"url":"http://arxiv.org/abs/2401.13586v1"}
{"created":"2024-01-24 16:50:54","title":"Securing the Invisible Thread: A Comprehensive Analysis of BLE Tracker Security in Apple AirTags and Samsung SmartTags","abstract":"This study presents an in-depth analysis of the security landscape in Bluetooth Low Energy (BLE) tracking systems, with a particular emphasis on Apple AirTags and Samsung SmartTags, including their cryptographic frameworks. Our investigation traverses a wide spectrum of attack vectors such as physical tampering, firmware exploitation, signal spoofing, eavesdropping, jamming, app security flaws, Bluetooth security weaknesses, location spoofing, threats to owner devices, and cloud-related vulnerabilities. Moreover, we delve into the security implications of the cryptographic methods utilized in these systems. Our findings reveal that while BLE trackers like AirTags and SmartTags offer substantial utility, they also pose significant security risks. Notably, Apple's approach, which prioritizes user privacy by removing intermediaries, inadvertently leads to device authentication challenges, evidenced by successful AirTag spoofing instances. Conversely, Samsung SmartTags, designed to thwart beacon spoofing, raise critical concerns about cloud security and user privacy. Our analysis also highlights the constraints faced by these devices due to their design focus on battery life conservation, particularly the absence of secure boot processes, which leaves them susceptible to OS modification and a range of potential attacks. The paper concludes with insights into the anticipated evolution of these tracking systems. We predict that future enhancements will likely focus on bolstering security features, especially as these devices become increasingly integrated into the broader IoT ecosystem and face evolving privacy regulations. This shift is imperative to address the intricate balance between functionality and security in next-generation BLE tracking systems.","sentences":["This study presents an in-depth analysis of the security landscape in Bluetooth Low Energy (BLE) tracking systems, with a particular emphasis on Apple AirTags and Samsung SmartTags, including their cryptographic frameworks.","Our investigation traverses a wide spectrum of attack vectors such as physical tampering, firmware exploitation, signal spoofing, eavesdropping, jamming, app security flaws, Bluetooth security weaknesses, location spoofing, threats to owner devices, and cloud-related vulnerabilities.","Moreover, we delve into the security implications of the cryptographic methods utilized in these systems.","Our findings reveal that while BLE trackers like AirTags and SmartTags offer substantial utility, they also pose significant security risks.","Notably, Apple's approach, which prioritizes user privacy by removing intermediaries, inadvertently leads to device authentication challenges, evidenced by successful AirTag spoofing instances.","Conversely, Samsung SmartTags, designed to thwart beacon spoofing, raise critical concerns about cloud security and user privacy.","Our analysis also highlights the constraints faced by these devices due to their design focus on battery life conservation, particularly the absence of secure boot processes, which leaves them susceptible to OS modification and a range of potential attacks.","The paper concludes with insights into the anticipated evolution of these tracking systems.","We predict that future enhancements will likely focus on bolstering security features, especially as these devices become increasingly integrated into the broader IoT ecosystem and face evolving privacy regulations.","This shift is imperative to address the intricate balance between functionality and security in next-generation BLE tracking systems."],"url":"http://arxiv.org/abs/2401.13584v1"}
{"created":"2024-01-24 16:45:42","title":"Towards Efficient and Effective Deep Clustering with Dynamic Grouping and Prototype Aggregation","abstract":"Previous contrastive deep clustering methods mostly focus on instance-level information while overlooking the member relationship within groups/clusters, which may significantly undermine their representation learning and clustering capability. Recently, some group-contrastive methods have been developed, which, however, typically rely on the samples of the entire dataset to obtain pseudo labels and lack the ability to efficiently update the group assignments in a batch-wise manner. To tackle these critical issues, we present a novel end-to-end deep clustering framework with dynamic grouping and prototype aggregation, termed as DigPro. Specifically, the proposed dynamic grouping extends contrastive learning from instance-level to group-level, which is effective and efficient for timely updating groups. Meanwhile, we perform contrastive learning on prototypes in a spherical feature space, termed as prototype aggregation, which aims to maximize the inter-cluster distance. Notably, with an expectation-maximization framework, DigPro simultaneously takes advantage of compact intra-cluster connections, well-separated clusters, and efficient group updating during the self-supervised training. Extensive experiments on six image benchmarks demonstrate the superior performance of our approach over the state-of-the-art. Code is available at https://github.com/Regan-Zhang/DigPro.","sentences":["Previous contrastive deep clustering methods mostly focus on instance-level information while overlooking the member relationship within groups/clusters, which may significantly undermine their representation learning and clustering capability.","Recently, some group-contrastive methods have been developed, which, however, typically rely on the samples of the entire dataset to obtain pseudo labels and lack the ability to efficiently update the group assignments in a batch-wise manner.","To tackle these critical issues, we present a novel end-to-end deep clustering framework with dynamic grouping and prototype aggregation, termed as DigPro.","Specifically, the proposed dynamic grouping extends contrastive learning from instance-level to group-level, which is effective and efficient for timely updating groups.","Meanwhile, we perform contrastive learning on prototypes in a spherical feature space, termed as prototype aggregation, which aims to maximize the inter-cluster distance.","Notably, with an expectation-maximization framework, DigPro simultaneously takes advantage of compact intra-cluster connections, well-separated clusters, and efficient group updating during the self-supervised training.","Extensive experiments on six image benchmarks demonstrate the superior performance of our approach over the state-of-the-art.","Code is available at https://github.com/Regan-Zhang/DigPro."],"url":"http://arxiv.org/abs/2401.13581v1"}
{"created":"2024-01-24 16:43:35","title":"WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition","abstract":"This work explores an emerging security threat against deep neural networks (DNNs) based image classification, i.e., backdoor attack. In this scenario, the attacker aims to inject a backdoor into the model by manipulating training data, such that the backdoor could be activated by a particular trigger and bootstraps the model to make a target prediction at inference. Currently, most existing data poisoning-based attacks struggle to achieve success at low poisoning ratios, increasing the risk of being defended by defense methods. In this paper, we propose a novel frequency-based backdoor attack via Wavelet Packet Decomposition (WPD), WPD decomposes the original image signal to a spectrogram that contains frequency information with different semantic meanings. We leverage WPD to statistically analyze the frequency distribution of the dataset to infer the key frequency regions the DNNs would focus on, and the trigger information is only injected into the key frequency regions. Our method mainly includes three parts: 1) the selection of the poisoning frequency regions in spectrogram; 2) trigger generation; 3) the generation of the poisoned dataset. Our method is stealthy and precise, evidenced by the 98.12% Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio 0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can bypass most existing defense methods. Besides, we also provide visualization analyses to explain why our method works.","sentences":["This work explores an emerging security threat against deep neural networks (DNNs) based image classification, i.e., backdoor attack.","In this scenario, the attacker aims to inject a backdoor into the model by manipulating training data, such that the backdoor could be activated by a particular trigger and bootstraps the model to make a target prediction at inference.","Currently, most existing data poisoning-based attacks struggle to achieve success at low poisoning ratios, increasing the risk of being defended by defense methods.","In this paper, we propose a novel frequency-based backdoor attack via Wavelet Packet Decomposition (WPD), WPD decomposes the original image signal to a spectrogram that contains frequency information with different semantic meanings.","We leverage WPD to statistically analyze the frequency distribution of the dataset to infer the key frequency regions the DNNs would focus on, and the trigger information is only injected into the key frequency regions.","Our method mainly includes three parts: 1) the selection of the poisoning frequency regions in spectrogram; 2) trigger generation; 3) the generation of the poisoned dataset.","Our method is stealthy and precise, evidenced by the 98.12% Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio 0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can bypass most existing defense methods.","Besides, we also provide visualization analyses to explain why our method works."],"url":"http://arxiv.org/abs/2401.13578v1"}
{"created":"2024-01-24 16:40:30","title":"CNN architecture extraction on edge GPU","abstract":"Neural networks have become popular due to their versatility and state-of-the-art results in many applications, such as image classification, natural language processing, speech recognition, forecasting, etc. These applications are also used in resource-constrained environments such as embedded devices. In this work, the susceptibility of neural network implementations to reverse engineering is explored on the NVIDIA Jetson Nano microcomputer via side-channel analysis. To this end, an architecture extraction attack is presented. In the attack, 15 popular convolutional neural network architectures (EfficientNets, MobileNets, NasNet, etc.) are implemented on the GPU of Jetson Nano and the electromagnetic radiation of the GPU is analyzed during the inference operation of the neural networks. The results of the analysis show that neural network architectures are easily distinguishable using deep learning-based side-channel analysis.","sentences":["Neural networks have become popular due to their versatility and state-of-the-art results in many applications, such as image classification, natural language processing, speech recognition, forecasting, etc.","These applications are also used in resource-constrained environments such as embedded devices.","In this work, the susceptibility of neural network implementations to reverse engineering is explored on the NVIDIA Jetson Nano microcomputer via side-channel analysis.","To this end, an architecture extraction attack is presented.","In the attack, 15 popular convolutional neural network architectures (EfficientNets, MobileNets, NasNet, etc.) are implemented on the GPU of Jetson Nano and the electromagnetic radiation of the GPU is analyzed during the inference operation of the neural networks.","The results of the analysis show that neural network architectures are easily distinguishable using deep learning-based side-channel analysis."],"url":"http://arxiv.org/abs/2401.13575v1"}
{"created":"2024-01-24 16:34:27","title":"Distributed matrix multiplication with straggler tolerance using algebraic function fields","abstract":"The problem of straggler mitigation in distributed matrix multiplication (DMM) is considered for a large number of worker nodes and a fixed small finite field. Polynomial codes and matdot codes are generalized by making use of algebraic function fields (i.e., algebraic functions over an algebraic curve) over a finite field. The construction of optimal solutions is translated to a combinatorial problem on the Weierstrass semigroups of the corresponding algebraic curves. Optimal or almost optimal solutions are provided. These have the same computational complexity per worker as classical polynomial and matdot codes, and their recovery thresholds are almost optimal in the asymptotic regime (growing number of workers and a fixed finite field).","sentences":["The problem of straggler mitigation in distributed matrix multiplication (DMM) is considered for a large number of worker nodes and a fixed small finite field.","Polynomial codes and matdot codes are generalized by making use of algebraic function fields (i.e., algebraic functions over an algebraic curve) over a finite field.","The construction of optimal solutions is translated to a combinatorial problem on the Weierstrass semigroups of the corresponding algebraic curves.","Optimal or almost optimal solutions are provided.","These have the same computational complexity per worker as classical polynomial and matdot codes, and their recovery thresholds are almost optimal in the asymptotic regime (growing number of workers and a fixed finite field)."],"url":"http://arxiv.org/abs/2401.13573v1"}
{"created":"2024-01-24 16:31:50","title":"Guided Diffusion for Fast Inverse Design of Density-based Mechanical Metamaterials","abstract":"Mechanical metamaterial is a synthetic material that can possess extraordinary physical characteristics, such as abnormal elasticity, stiffness, and stability, by carefully designing its internal structure. To make metamaterials contain delicate local structures with unique mechanical properties, it is a potential method to represent them through high-resolution voxels. However, it brings a substantial computational burden. To this end, this paper proposes a fast inverse design method, whose core is an advanced deep generative AI algorithm, to generate voxel-based mechanical metamaterials. Specifically, we use the self-conditioned diffusion model, capable of generating a microstructure with a resolution of $128^3$ to approach the specified homogenized tensor matrix in just 3 seconds. Accordingly, this rapid reverse design tool facilitates the exploration of extreme metamaterials, the sequence interpolation in metamaterials, and the generation of diverse microstructures for multi-scale design. This flexible and adaptive generative tool is of great value in structural engineering or other mechanical systems and can stimulate more subsequent research.","sentences":["Mechanical metamaterial is a synthetic material that can possess extraordinary physical characteristics, such as abnormal elasticity, stiffness, and stability, by carefully designing its internal structure.","To make metamaterials contain delicate local structures with unique mechanical properties, it is a potential method to represent them through high-resolution voxels.","However, it brings a substantial computational burden.","To this end, this paper proposes a fast inverse design method, whose core is an advanced deep generative AI algorithm, to generate voxel-based mechanical metamaterials.","Specifically, we use the self-conditioned diffusion model, capable of generating a microstructure with a resolution of $128^3$ to approach the specified homogenized tensor matrix in just 3 seconds.","Accordingly, this rapid reverse design tool facilitates the exploration of extreme metamaterials, the sequence interpolation in metamaterials, and the generation of diverse microstructures for multi-scale design.","This flexible and adaptive generative tool is of great value in structural engineering or other mechanical systems and can stimulate more subsequent research."],"url":"http://arxiv.org/abs/2401.13570v1"}
{"created":"2024-01-24 16:30:21","title":"SPARC-LoRa: A Scalable, Power-efficient, Affordable, Reliable, and Cloud Service-enabled LoRa Networking System for Agriculture Applications","abstract":"With the rapid development of cloud and edge computing, Internet of Things (IoT) applications have been deployed in various aspects of human life. In this paper, we design and implement a holistic LoRa-based IoT system with LoRa communication capabilities, named SPARC-LoRa, which consists of field sensor nodes and a gateway connected to the Internet. SPARC-LoRa has the following important features. First, the proposed wireless network of SPARC-LoRa is even-driven and using off-the-shelf microcontroller and LoRa communication modules with a customized PCB design to integrate all the hardware. This enables SPARC-LoRa to achieve low power consumption, long range communication, and low cost. With a new connection-based upper layer protocol design, the scalability and communication reliability of SPARC-loRa can be achieved. Second, an open source software including sensor nodes and servers is designed based on Docker container with cloud storage, computing, and LTE functionalities. In order to achieve reliable wireless communication under extreme conditions, a relay module is designed and applied to SPARC-LoRa to forward the data from sensor nodes to the gateway node. The system design and implementation is completely open source and hosted on the DigitalOcean Droplet Cloud. Hence, the proposed system enables further research and applications in both academia and industry. The proposed system has been tested in real fields under different and extreme environmental conditions in Salt Lake City, Utah and the University of Nebraska-Lincoln. The experimental results validate the features of SPARC-LoRa including low power, reliability, and cloud services provided by SPARC-LoRa.","sentences":["With the rapid development of cloud and edge computing, Internet of Things (IoT) applications have been deployed in various aspects of human life.","In this paper, we design and implement a holistic LoRa-based IoT system with LoRa communication capabilities, named SPARC-LoRa, which consists of field sensor nodes and a gateway connected to the Internet.","SPARC-LoRa has the following important features.","First, the proposed wireless network of SPARC-LoRa is even-driven and using off-the-shelf microcontroller and LoRa communication modules with a customized PCB design to integrate all the hardware.","This enables SPARC-LoRa to achieve low power consumption, long range communication, and low cost.","With a new connection-based upper layer protocol design, the scalability and communication reliability of SPARC-loRa can be achieved.","Second, an open source software including sensor nodes and servers is designed based on Docker container with cloud storage, computing, and LTE functionalities.","In order to achieve reliable wireless communication under extreme conditions, a relay module is designed and applied to SPARC-LoRa to forward the data from sensor nodes to the gateway node.","The system design and implementation is completely open source and hosted on the DigitalOcean Droplet Cloud.","Hence, the proposed system enables further research and applications in both academia and industry.","The proposed system has been tested in real fields under different and extreme environmental conditions in Salt Lake City, Utah and the University of Nebraska-Lincoln.","The experimental results validate the features of SPARC-LoRa including low power, reliability, and cloud services provided by SPARC-LoRa."],"url":"http://arxiv.org/abs/2401.13569v1"}
{"created":"2024-01-24 16:29:42","title":"Investigating the Performance of Soft Robotic Adaptive Feet with Longitudinal and Transverse Arches","abstract":"Biped robots usually adopt feet with a rigid structure that simplifies walking on flat grounds and yet hinders ground adaptation in unstructured environments, thus jeopardizing stability. We recently explored in the SoftFoot the idea of adapting a robotic foot to ground irregularities along the sagittal plane. Building on the previous results, we propose in this paper a novel robotic foot able to adapt both in the sagittal and frontal planes, similarly to the human foot. It features five parallel modules with intrinsic longitudinal adaptability that can be combined in many possible designs through optional rigid or elastic connections. By following a methodological design approach, we narrow down the design space to five candidate foot designs and implement them on a modular system. Prototypes are tested experimentally via controlled application of force, through a robotic arm, onto a sensorized plate endowed with different obstacles. Their performance is compared, using also a rigid foot and the previous SoftFoot as a baseline. Analysis of footprint stability shows that the introduction of the transverse arch, by elastically connecting the five parallel modules, is advantageous for obstacle negotiation, especially when obstacles are located under the forefoot. In addition to biped robots' locomotion, this finding might also benefit lower-limb prostheses design.","sentences":["Biped robots usually adopt feet with a rigid structure that simplifies walking on flat grounds and yet hinders ground adaptation in unstructured environments, thus jeopardizing stability.","We recently explored in the SoftFoot the idea of adapting a robotic foot to ground irregularities along the sagittal plane.","Building on the previous results, we propose in this paper a novel robotic foot able to adapt both in the sagittal and frontal planes, similarly to the human foot.","It features five parallel modules with intrinsic longitudinal adaptability that can be combined in many possible designs through optional rigid or elastic connections.","By following a methodological design approach, we narrow down the design space to five candidate foot designs and implement them on a modular system.","Prototypes are tested experimentally via controlled application of force, through a robotic arm, onto a sensorized plate endowed with different obstacles.","Their performance is compared, using also a rigid foot and the previous SoftFoot as a baseline.","Analysis of footprint stability shows that the introduction of the transverse arch, by elastically connecting the five parallel modules, is advantageous for obstacle negotiation, especially when obstacles are located under the forefoot.","In addition to biped robots' locomotion, this finding might also benefit lower-limb prostheses design."],"url":"http://arxiv.org/abs/2401.13568v1"}
{"created":"2024-01-24 16:23:14","title":"A Cost-Sensitive Meta-Learning Strategy for Fair Provider Exposure in Recommendation","abstract":"When devising recommendation services, it is important to account for the interests of all content providers, encompassing not only newcomers but also minority demographic groups. In various instances, certain provider groups find themselves underrepresented in the item catalog, a situation that can influence recommendation results. Hence, platform owners often seek to regulate the exposure of these provider groups in the recommended lists. In this paper, we propose a novel cost-sensitive approach designed to guarantee these target exposure levels in pairwise recommendation models. This approach quantifies, and consequently mitigate, the discrepancies between the volume of recommendations allocated to groups and their contribution in the item catalog, under the principle of equity. Our results show that this approach, while aligning groups exposure with their assigned levels, does not compromise to the original recommendation utility. Source code and pre-processed data can be retrieved at https://github.com/alessandraperniciano/meta-learning-strategy-fair-provider-exposure.","sentences":["When devising recommendation services, it is important to account for the interests of all content providers, encompassing not only newcomers but also minority demographic groups.","In various instances, certain provider groups find themselves underrepresented in the item catalog, a situation that can influence recommendation results.","Hence, platform owners often seek to regulate the exposure of these provider groups in the recommended lists.","In this paper, we propose a novel cost-sensitive approach designed to guarantee these target exposure levels in pairwise recommendation models.","This approach quantifies, and consequently mitigate, the discrepancies between the volume of recommendations allocated to groups and their contribution in the item catalog, under the principle of equity.","Our results show that this approach, while aligning groups exposure with their assigned levels, does not compromise to the original recommendation utility.","Source code and pre-processed data can be retrieved at https://github.com/alessandraperniciano/meta-learning-strategy-fair-provider-exposure."],"url":"http://arxiv.org/abs/2401.13566v1"}
{"created":"2024-01-24 16:21:28","title":"Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding","abstract":"In this paper, we present significant advancements in the pretraining of Mistral 7B, a large-scale language model, using a dataset of 32.6 GB, equivalent to 1.1 billion tokens. We explore the impact of extending the context length, releasing models with context lengths of 4096 and 32768 tokens, and further refining performance with a specialized 16384 context length instruction-tuned model, we called it Malaysian Mistral.   Our experiments demonstrate the efficacy of continue pretraining and the influence of extended context lengths on Mistral 7B's language understanding capabilities. Additionally, we release a model specifically tuned with a 16384 context length instruction, showcasing its potential for capturing nuanced language intricacies.   Furthermore, our research contributes to the benchmarking of Malaysian Mistral against prominent language models, including ChatGPT3.5 and Claude 2. We present compelling results indicating Malaysian Mistral's superior performance on Tatabahasa (Malay grammar) test set, particularly when fine-tuned with instructions.   All models released at https://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c","sentences":["In this paper, we present significant advancements in the pretraining of Mistral 7B, a large-scale language model, using a dataset of 32.6 GB, equivalent to 1.1 billion tokens.","We explore the impact of extending the context length, releasing models with context lengths of 4096 and 32768 tokens, and further refining performance with a specialized 16384 context length instruction-tuned model, we called it Malaysian Mistral.   ","Our experiments demonstrate the efficacy of continue pretraining and the influence of extended context lengths on Mistral 7B's language understanding capabilities.","Additionally, we release a model specifically tuned with a 16384 context length instruction, showcasing its potential for capturing nuanced language intricacies.   ","Furthermore, our research contributes to the benchmarking of Malaysian Mistral against prominent language models, including ChatGPT3.5 and Claude 2.","We present compelling results indicating Malaysian Mistral's superior performance on Tatabahasa (Malay grammar) test set, particularly when fine-tuned with instructions.   ","All models released at https://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c"],"url":"http://arxiv.org/abs/2401.13565v1"}
{"created":"2024-01-24 16:21:14","title":"RIS Empowered Near-Field Covert Communications","abstract":"This paper studies an extremely large-scale reconfigurable intelligent surface (XL-RIS) empowered covert communication system in the near-field region. Alice covertly transmits messages to Bob with the assistance of the XL-RIS, while evading detection by Willie. To enhance the covert communication performance, we maximize the achievable covert rate by jointly optimizing the hybrid analog and digital beamformers at Alice, as well as the reflection coefficient matrix at the XL-RIS. An alternating optimization algorithm is proposed to solve the joint beamforming design problem. For the hybrid beamformer design, a semi-closed-form solution for fully digital beamformer is first obtained by a weighted minimum mean-square error based algorithm, then the baseband digital and analog beamformers at Alice are designed by approximating the fully digital beamformer via manifold optimization. For the XL-RIS's reflection coefficient matrix design, a low-complexity alternating direction method of multipliers based algorithm is proposed to address the challenge of large-scale variables and unit-modulus constraints. Numerical results unveil that i) the near-field communications can achieve a higher covert rate than the far-field covert communications in general, and still realize covert transmission even if Willie is located at the same direction as Bob and closer to the XL-RIS; ii) the proposed algorithm can enhance the covert rate significantly compared to the benchmark schemes; iii) the proposed algorithm leads to a beam diffraction pattern that can bypass Willie and achieve high-rate covert transmission to Bob.","sentences":["This paper studies an extremely large-scale reconfigurable intelligent surface (XL-RIS) empowered covert communication system in the near-field region.","Alice covertly transmits messages to Bob with the assistance of the XL-RIS, while evading detection by Willie.","To enhance the covert communication performance, we maximize the achievable covert rate by jointly optimizing the hybrid analog and digital beamformers at Alice, as well as the reflection coefficient matrix at the XL-RIS.","An alternating optimization algorithm is proposed to solve the joint beamforming design problem.","For the hybrid beamformer design, a semi-closed-form solution for fully digital beamformer is first obtained by a weighted minimum mean-square error based algorithm, then the baseband digital and analog beamformers at Alice are designed by approximating the fully digital beamformer via manifold optimization.","For the XL-RIS's reflection coefficient matrix design, a low-complexity alternating direction method of multipliers based algorithm is proposed to address the challenge of large-scale variables and unit-modulus constraints.","Numerical results unveil that i) the near-field communications can achieve a higher covert rate than the far-field covert communications in general, and still realize covert transmission even if Willie is located at the same direction as Bob and closer to the XL-RIS; ii) the proposed algorithm can enhance the covert rate significantly compared to the benchmark schemes; iii) the proposed algorithm leads to a beam diffraction pattern that can bypass Willie and achieve high-rate covert transmission to Bob."],"url":"http://arxiv.org/abs/2401.13564v1"}
{"created":"2024-01-24 16:17:23","title":"SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation","abstract":"The Transformer architecture has shown a remarkable ability in modeling global relationships. However, it poses a significant computational challenge when processing high-dimensional medical images. This hinders its development and widespread adoption in this task. Mamba, as a State Space Model (SSM), recently emerged as a notable manner for long-range dependencies in sequential modeling, excelling in natural language processing filed with its remarkable memory efficiency and computational speed. Inspired by its success, we introduce SegMamba, a novel 3D medical image \\textbf{Seg}mentation \\textbf{Mamba} model, designed to effectively capture long-range dependencies within whole volume features at every scale. Our SegMamba, in contrast to Transformer-based methods, excels in whole volume feature modeling from a state space model standpoint, maintaining superior processing speed, even with volume features at a resolution of {$64\\times 64\\times 64$}. Comprehensive experiments on the BraTS2023 dataset demonstrate the effectiveness and efficiency of our SegMamba. The code for SegMamba is available at: https://github.com/ge-xing/SegMamba","sentences":["The Transformer architecture has shown a remarkable ability in modeling global relationships.","However, it poses a significant computational challenge when processing high-dimensional medical images.","This hinders its development and widespread adoption in this task.","Mamba, as a State Space Model (SSM), recently emerged as a notable manner for long-range dependencies in sequential modeling, excelling in natural language processing filed with its remarkable memory efficiency and computational speed.","Inspired by its success, we introduce SegMamba, a novel 3D medical image \\textbf{Seg}mentation \\textbf{Mamba} model, designed to effectively capture long-range dependencies within whole volume features at every scale.","Our SegMamba, in contrast to Transformer-based methods, excels in whole volume feature modeling from a state space model standpoint, maintaining superior processing speed, even with volume features at a resolution of {$64\\times 64\\times 64$}.","Comprehensive experiments on the BraTS2023 dataset demonstrate the effectiveness and efficiency of our SegMamba.","The code for SegMamba is available at: https://github.com/ge-xing/SegMamba"],"url":"http://arxiv.org/abs/2401.13560v1"}
{"created":"2024-01-24 16:14:38","title":"Task structure and nonlinearity jointly determine learned representational geometry","abstract":"The utility of a learned neural representation depends on how well its geometry supports performance in downstream tasks. This geometry depends on the structure of the inputs, the structure of the target outputs, and the architecture of the network. By studying the learning dynamics of networks with one hidden layer, we discovered that the network's activation function has an unexpectedly strong impact on the representational geometry: Tanh networks tend to learn representations that reflect the structure of the target outputs, while ReLU networks retain more information about the structure of the raw inputs. This difference is consistently observed across a broad class of parameterized tasks in which we modulated the degree of alignment between the geometry of the task inputs and that of the task labels. We analyzed the learning dynamics in weight space and show how the differences between the networks with Tanh and ReLU nonlinearities arise from the asymmetric asymptotic behavior of ReLU, which leads feature neurons to specialize for different regions of input space. By contrast, feature neurons in Tanh networks tend to inherit the task label structure. Consequently, when the target outputs are low dimensional, Tanh networks generate neural representations that are more disentangled than those obtained with a ReLU nonlinearity. Our findings shed light on the interplay between input-output geometry, nonlinearity, and learned representations in neural networks.","sentences":["The utility of a learned neural representation depends on how well its geometry supports performance in downstream tasks.","This geometry depends on the structure of the inputs, the structure of the target outputs, and the architecture of the network.","By studying the learning dynamics of networks with one hidden layer, we discovered that the network's activation function has an unexpectedly strong impact on the representational geometry: Tanh networks tend to learn representations that reflect the structure of the target outputs, while ReLU networks retain more information about the structure of the raw inputs.","This difference is consistently observed across a broad class of parameterized tasks in which we modulated the degree of alignment between the geometry of the task inputs and that of the task labels.","We analyzed the learning dynamics in weight space and show how the differences between the networks with Tanh and ReLU nonlinearities arise from the asymmetric asymptotic behavior of ReLU, which leads feature neurons to specialize for different regions of input space.","By contrast, feature neurons in Tanh networks tend to inherit the task label structure.","Consequently, when the target outputs are low dimensional, Tanh networks generate neural representations that are more disentangled than those obtained with a ReLU nonlinearity.","Our findings shed light on the interplay between input-output geometry, nonlinearity, and learned representations in neural networks."],"url":"http://arxiv.org/abs/2401.13558v1"}
{"created":"2024-01-24 16:13:26","title":"Benchmarking the Fairness of Image Upsampling Methods","abstract":"Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\\unicode{x2013}$inspired by their supervised fairness counterparts$\\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to dataset imbalances. Alarmingly, we find that none of the considered methods produces statistically fair and diverse results.","sentences":["Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos.","While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness.","In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models.","We develop a set of metrics$\\unicode{x2013}$inspired by their supervised fairness counterparts$\\unicode{x2013}$to evaluate the models on their fairness and diversity.","Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods.","As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets.","Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to dataset imbalances.","Alarmingly, we find that none of the considered methods produces statistically fair and diverse results."],"url":"http://arxiv.org/abs/2401.13555v1"}
{"created":"2024-01-24 16:13:24","title":"PanAf20K: A Large Video Dataset for Wild Ape Detection and Behaviour Recognition","abstract":"We present the PanAf20K dataset, the largest and most diverse open-access annotated video dataset of great apes in their natural environment. It comprises more than 7 million frames across ~20,000 camera trap videos of chimpanzees and gorillas collected at 18 field sites in tropical Africa as part of the Pan African Programme: The Cultured Chimpanzee. The footage is accompanied by a rich set of annotations and benchmarks making it suitable for training and testing a variety of challenging and ecologically important computer vision tasks including ape detection and behaviour recognition. Furthering AI analysis of camera trap information is critical given the International Union for Conservation of Nature now lists all species in the great ape family as either Endangered or Critically Endangered. We hope the dataset can form a solid basis for engagement of the AI community to improve performance, efficiency, and result interpretation in order to support assessments of great ape presence, abundance, distribution, and behaviour and thereby aid conservation efforts.","sentences":["We present the PanAf20K dataset, the largest and most diverse open-access annotated video dataset of great apes in their natural environment.","It comprises more than 7 million frames across ~20,000 camera trap videos of chimpanzees and gorillas collected at 18 field sites in tropical Africa as part of the Pan African Programme: The Cultured Chimpanzee.","The footage is accompanied by a rich set of annotations and benchmarks making it suitable for training and testing a variety of challenging and ecologically important computer vision tasks including ape detection and behaviour recognition.","Furthering AI analysis of camera trap information is critical given the International Union for Conservation of Nature now lists all species in the great ape family as either Endangered or Critically Endangered.","We hope the dataset can form a solid basis for engagement of the AI community to improve performance, efficiency, and result interpretation in order to support assessments of great ape presence, abundance, distribution, and behaviour and thereby aid conservation efforts."],"url":"http://arxiv.org/abs/2401.13554v1"}
{"created":"2024-01-24 16:11:42","title":"Interleaving One-Class and Weakly-Supervised Models with Adaptive Thresholding for Unsupervised Video Anomaly Detection","abstract":"Without human annotations, a typical Unsupervised Video Anomaly Detection (UVAD) method needs to train two models that generate pseudo labels for each other. In previous work, the two models are closely entangled with each other, and it is not known how to upgrade their method without modifying their training framework significantly. Second, previous work usually adopts fixed thresholding to obtain pseudo labels, however the user-specified threshold is not reliable which inevitably introduces errors into the training process. To alleviate these two problems, we propose a novel interleaved framework that alternately trains a One-Class Classification (OCC) model and a Weakly-Supervised (WS) model for UVAD. The OCC or WS models in our method can be easily replaced with other OCC or WS models, which facilitates our method to upgrade with the most recent developments in both fields. For handling the fixed thresholding problem, we break through the conventional cognitive boundary and propose a weighted OCC model that can be trained on both normal and abnormal data. We also propose an adaptive mechanism for automatically finding the optimal threshold for the WS model in a loose to strict manner. Experiments demonstrate that the proposed UVAD method outperforms previous approaches.","sentences":["Without human annotations, a typical Unsupervised Video Anomaly Detection (UVAD) method needs to train two models that generate pseudo labels for each other.","In previous work, the two models are closely entangled with each other, and it is not known how to upgrade their method without modifying their training framework significantly.","Second, previous work usually adopts fixed thresholding to obtain pseudo labels, however the user-specified threshold is not reliable which inevitably introduces errors into the training process.","To alleviate these two problems, we propose a novel interleaved framework that alternately trains a One-Class Classification (OCC) model and a Weakly-Supervised (WS) model for UVAD.","The OCC or WS models in our method can be easily replaced with other OCC or WS models, which facilitates our method to upgrade with the most recent developments in both fields.","For handling the fixed thresholding problem, we break through the conventional cognitive boundary and propose a weighted OCC model that can be trained on both normal and abnormal data.","We also propose an adaptive mechanism for automatically finding the optimal threshold for the WS model in a loose to strict manner.","Experiments demonstrate that the proposed UVAD method outperforms previous approaches."],"url":"http://arxiv.org/abs/2401.13551v1"}
{"created":"2024-01-24 16:08:21","title":"A Phoneme-Scale Assessment of Multichannel Speech Enhancement Algorithms","abstract":"In the intricate acoustic landscapes where speech intelligibility is challenged by noise and reverberation, multichannel speech enhancement emerges as a promising solution for individuals with hearing loss. Such algorithms are commonly evaluated at the utterance level. However, this approach overlooks the granular acoustic nuances revealed by phoneme-specific analysis, potentially obscuring key insights into their performance. This paper presents an in-depth phoneme-scale evaluation of 3 state-of-the-art multichannel speech enhancement algorithms. These algorithms -- FasNet, MVDR, and Tango -- are extensively evaluated across different noise conditions and spatial setups, employing realistic acoustic simulations with measured room impulse responses, and leveraging diversity offered by multiple microphones in a binaural hearing setup. The study emphasizes the fine-grained phoneme-level analysis, revealing that while some phonemes like plosives are heavily impacted by environmental acoustics and challenging to deal with by the algorithms, others like nasals and sibilants see substantial improvements after enhancement. These investigations demonstrate important improvements in phoneme clarity in noisy conditions, with insights that could drive the development of more personalized and phoneme-aware hearing aid technologies.","sentences":["In the intricate acoustic landscapes where speech intelligibility is challenged by noise and reverberation, multichannel speech enhancement emerges as a promising solution for individuals with hearing loss.","Such algorithms are commonly evaluated at the utterance level.","However, this approach overlooks the granular acoustic nuances revealed by phoneme-specific analysis, potentially obscuring key insights into their performance.","This paper presents an in-depth phoneme-scale evaluation of 3 state-of-the-art multichannel speech enhancement algorithms.","These algorithms -- FasNet, MVDR, and Tango -- are extensively evaluated across different noise conditions and spatial setups, employing realistic acoustic simulations with measured room impulse responses, and leveraging diversity offered by multiple microphones in a binaural hearing setup.","The study emphasizes the fine-grained phoneme-level analysis, revealing that while some phonemes like plosives are heavily impacted by environmental acoustics and challenging to deal with by the algorithms, others like nasals and sibilants see substantial improvements after enhancement.","These investigations demonstrate important improvements in phoneme clarity in noisy conditions, with insights that could drive the development of more personalized and phoneme-aware hearing aid technologies."],"url":"http://arxiv.org/abs/2401.13548v1"}
{"created":"2024-01-24 16:05:03","title":"Fine-grained Contract NER using instruction based model","abstract":"Lately, instruction-based techniques have made significant strides in improving performance in few-shot learning scenarios. They achieve this by bridging the gap between pre-trained language models and fine-tuning for specific downstream tasks. Despite these advancements, the performance of Large Language Models (LLMs) in information extraction tasks like Named Entity Recognition (NER), using prompts or instructions, still falls short of supervised baselines. The reason for this performance gap can be attributed to the fundamental disparity between NER and LLMs. NER is inherently a sequence labeling task, where the model must assign entity-type labels to individual tokens within a sentence. In contrast, LLMs are designed as a text generation task. This distinction between semantic labeling and text generation leads to subpar performance. In this paper, we transform the NER task into a text-generation task that can be readily adapted by LLMs. This involves enhancing source sentences with task-specific instructions and answer choices, allowing for the identification of entities and their types within natural language. We harness the strength of LLMs by integrating supervised learning within them. The goal of this combined strategy is to boost the performance of LLMs in extraction tasks like NER while simultaneously addressing hallucination issues often observed in LLM-generated content. A novel corpus Contract NER comprising seven frequently observed contract categories, encompassing named entities associated with 18 distinct legal entity types is released along with our baseline models. Our models and dataset are available to the community for future research * .","sentences":["Lately, instruction-based techniques have made significant strides in improving performance in few-shot learning scenarios.","They achieve this by bridging the gap between pre-trained language models and fine-tuning for specific downstream tasks.","Despite these advancements, the performance of Large Language Models (LLMs) in information extraction tasks like Named Entity Recognition (NER), using prompts or instructions, still falls short of supervised baselines.","The reason for this performance gap can be attributed to the fundamental disparity between NER and LLMs.","NER is inherently a sequence labeling task, where the model must assign entity-type labels to individual tokens within a sentence.","In contrast, LLMs are designed as a text generation task.","This distinction between semantic labeling and text generation leads to subpar performance.","In this paper, we transform the NER task into a text-generation task that can be readily adapted by LLMs.","This involves enhancing source sentences with task-specific instructions and answer choices, allowing for the identification of entities and their types within natural language.","We harness the strength of LLMs by integrating supervised learning within them.","The goal of this combined strategy is to boost the performance of LLMs in extraction tasks like NER while simultaneously addressing hallucination issues often observed in LLM-generated content.","A novel corpus Contract NER comprising seven frequently observed contract categories, encompassing named entities associated with 18 distinct legal entity types is released along with our baseline models.","Our models and dataset are available to the community for future research * ."],"url":"http://arxiv.org/abs/2401.13545v1"}
{"created":"2024-01-24 16:02:14","title":"Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?","abstract":"Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts. A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output. In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set. Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the practical utility of the proposed techniques, we apply them to deep chest X-ray classifiers and show that fine-tuned black boxes can be as intervenable and more performant than CBMs.","sentences":["Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts.","A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output.","In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set.","Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models.","Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks.","We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions.","To showcase the practical utility of the proposed techniques, we apply them to deep chest X-ray classifiers and show that fine-tuned black boxes can be as intervenable and more performant than CBMs."],"url":"http://arxiv.org/abs/2401.13544v1"}
{"created":"2024-01-24 15:56:13","title":"State Estimation for Continuum Multi-Robot Systems on SE(3)","abstract":"In contrast to conventional robots, accurately modeling the kinematics and statics of continuum robots is challenging due to partially unknown material properties, parasitic effects, or unknown forces acting on the continuous body. Consequentially, state estimation approaches that utilize additional sensor information to predict the shape of continuum robots have garnered significant interest. This paper presents a novel approach to state estimation for systems with multiple coupled continuum robots, which allows estimating the shape and strain variables of multiple continuum robots in an arbitrary coupled topology. Simulations and experiments demonstrate the capabilities and versatility of the proposed method, while achieving accurate and continuous estimates for the state of such systems, resulting in average end-effector errors of 3.3 mm and 5.02{\\deg} depending on the sensor setup. It is further shown, that the approach offers fast computation times of below 10 ms, enabling its utilization in quasi-static real-time scenarios with average update rates of 100-200 Hz. An open-source C++ implementation of the proposed state estimation method is made publicly available to the community.","sentences":["In contrast to conventional robots, accurately modeling the kinematics and statics of continuum robots is challenging due to partially unknown material properties, parasitic effects, or unknown forces acting on the continuous body.","Consequentially, state estimation approaches that utilize additional sensor information to predict the shape of continuum robots have garnered significant interest.","This paper presents a novel approach to state estimation for systems with multiple coupled continuum robots, which allows estimating the shape and strain variables of multiple continuum robots in an arbitrary coupled topology.","Simulations and experiments demonstrate the capabilities and versatility of the proposed method, while achieving accurate and continuous estimates for the state of such systems, resulting in average end-effector errors of 3.3 mm and 5.02{\\deg} depending on the sensor setup.","It is further shown, that the approach offers fast computation times of below 10 ms, enabling its utilization in quasi-static real-time scenarios with average update rates of 100-200 Hz.","An open-source C++ implementation of the proposed state estimation method is made publicly available to the community."],"url":"http://arxiv.org/abs/2401.13540v1"}
{"created":"2024-01-24 15:50:32","title":"Dynamic Risk Management in Cyber Physical Systems","abstract":"Cyber Physical Systems (CPS) enable new kinds of applications as well as significant improvements of existing ones in numerous different application domains. A major trait of upcoming CPS is an increasing degree of automation up to the point of autonomy, as there is a huge potential for economic success as well as for ecologic and societal improvements. However, to unlock the full potential of such (cooperative and automated) CPS, we first need to overcome several significant engineering challenges, where safety assurance is a particularly important one. Unfortunately, established safety assurance methods and standards do not live up to this task, as they have been designed with closed and less complex systems in mind. This paper structures safety assurance challenges of cooperative automated CPS, provides an overview on our vision of dynamic risk management and describes already existing building blocks.","sentences":["Cyber Physical Systems (CPS) enable new kinds of applications as well as significant improvements of existing ones in numerous different application domains.","A major trait of upcoming CPS is an increasing degree of automation up to the point of autonomy, as there is a huge potential for economic success as well as for ecologic and societal improvements.","However, to unlock the full potential of such (cooperative and automated) CPS, we first need to overcome several significant engineering challenges, where safety assurance is a particularly important one.","Unfortunately, established safety assurance methods and standards do not live up to this task, as they have been designed with closed and less complex systems in mind.","This paper structures safety assurance challenges of cooperative automated CPS, provides an overview on our vision of dynamic risk management and describes already existing building blocks."],"url":"http://arxiv.org/abs/2401.13539v1"}
{"created":"2024-01-24 15:43:38","title":"On the Approximate Core and Nucleon of Flow Games","abstract":"The flow game with public arcs is a cooperative revenue game derived from a flow network. In this game, each player possesses an arc, while certain arcs, known as public arcs, are not owned by any specific player and are accessible to any coalition. The aim of this game is to maximize the flow that can be routed in the network through strategic coalition formation. By exploring its connection to the maximum partially disjoint path problem, we investigate the approximate core and nucleon of the flow game with public arcs. The approximate core is an extension of the core that allows for some deviation in group rationality, while the nucleon is a multiplicative analogue of the nucleolus. In this paper, we provide two complete characterizations for the optimal approximate core and show that the nucleon can be computed in polynomial time.","sentences":["The flow game with public arcs is a cooperative revenue game derived from a flow network.","In this game, each player possesses an arc, while certain arcs, known as public arcs, are not owned by any specific player and are accessible to any coalition.","The aim of this game is to maximize the flow that can be routed in the network through strategic coalition formation.","By exploring its connection to the maximum partially disjoint path problem, we investigate the approximate core and nucleon of the flow game with public arcs.","The approximate core is an extension of the core that allows for some deviation in group rationality, while the nucleon is a multiplicative analogue of the nucleolus.","In this paper, we provide two complete characterizations for the optimal approximate core and show that the nucleon can be computed in polynomial time."],"url":"http://arxiv.org/abs/2401.13535v1"}
{"created":"2024-01-24 15:37:31","title":"QAGait: Revisit Gait Recognition from a Quality Perspective","abstract":"Gait recognition is a promising biometric method that aims to identify pedestrians from their unique walking patterns. Silhouette modality, renowned for its easy acquisition, simple structure, sparse representation, and convenient modeling, has been widely employed in controlled in-the-lab research. However, as gait recognition rapidly advances from in-the-lab to in-the-wild scenarios, various conditions raise significant challenges for silhouette modality, including 1) unidentifiable low-quality silhouettes (abnormal segmentation, severe occlusion, or even non-human shape), and 2) identifiable but challenging silhouettes (background noise, non-standard posture, slight occlusion). To address these challenges, we revisit gait recognition pipeline and approach gait recognition from a quality perspective, namely QAGait. Specifically, we propose a series of cost-effective quality assessment strategies, including Maxmial Connect Area and Template Match to eliminate background noises and unidentifiable silhouettes, Alignment strategy to handle non-standard postures. We also propose two quality-aware loss functions to integrate silhouette quality into optimization within the embedding space. Extensive experiments demonstrate our QAGait can guarantee both gait reliability and performance enhancement. Furthermore, our quality assessment strategies can seamlessly integrate with existing gait datasets, showcasing our superiority. Code is available at https://github.com/wzb-bupt/QAGait.","sentences":["Gait recognition is a promising biometric method that aims to identify pedestrians from their unique walking patterns.","Silhouette modality, renowned for its easy acquisition, simple structure, sparse representation, and convenient modeling, has been widely employed in controlled in-the-lab research.","However, as gait recognition rapidly advances from in-the-lab to in-the-wild scenarios, various conditions raise significant challenges for silhouette modality, including 1) unidentifiable low-quality silhouettes (abnormal segmentation, severe occlusion, or even non-human shape), and 2) identifiable but challenging silhouettes (background noise, non-standard posture, slight occlusion).","To address these challenges, we revisit gait recognition pipeline and approach gait recognition from a quality perspective, namely QAGait.","Specifically, we propose a series of cost-effective quality assessment strategies, including Maxmial Connect Area and Template Match to eliminate background noises and unidentifiable silhouettes, Alignment strategy to handle non-standard postures.","We also propose two quality-aware loss functions to integrate silhouette quality into optimization within the embedding space.","Extensive experiments demonstrate our QAGait can guarantee both gait reliability and performance enhancement.","Furthermore, our quality assessment strategies can seamlessly integrate with existing gait datasets, showcasing our superiority.","Code is available at https://github.com/wzb-bupt/QAGait."],"url":"http://arxiv.org/abs/2401.13531v1"}
{"created":"2024-01-24 15:35:44","title":"Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space","abstract":"Recently, optimization on the Riemannian manifold has provided new insights to the optimization community. In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes. In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence). In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow. The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet. By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamics of desired stochastic methods in the corresponded random vector space. Then, the flows of probability measures are naturally obtained by applying Fokker-Planck equation to such SDE. Furthermore, the convergence rates of the proposed Riemannian stochastic flows are proven, and they match the results in Euclidean space.","sentences":["Recently, optimization on the Riemannian manifold has provided new insights to the optimization community.","In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes.","In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence).","In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow.","The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet.","By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamics of desired stochastic methods in the corresponded random vector space.","Then, the flows of probability measures are naturally obtained by applying Fokker-Planck equation to such SDE.","Furthermore, the convergence rates of the proposed Riemannian stochastic flows are proven, and they match the results in Euclidean space."],"url":"http://arxiv.org/abs/2401.13530v1"}
{"created":"2024-01-24 15:25:01","title":"SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation","abstract":"Benefiting from effective speech modeling, current Speech Large Language Models (SLLMs) have demonstrated exceptional capabilities in in-context speech generation and efficient generalization to unseen speakers. However, the prevailing information modeling process is encumbered by certain redundancies, leading to inefficiencies in speech generation. We propose Chain-of-Information Generation (CoIG), a method for decoupling semantic and perceptual information in large-scale speech generation. Building on this, we develop SpeechGPT-Gen, an 8-billion-parameter SLLM efficient in semantic and perceptual information modeling. It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling. Additionally, we introduce the novel approach of infusing semantic information into the prior distribution to enhance the efficiency of flow matching. Extensive experimental results demonstrate that SpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice conversion, and speech-to-speech dialogue, underscoring CoIG's remarkable proficiency in capturing and modeling speech's semantic and perceptual dimensions. Code and models are available at https://github.com/0nutation/SpeechGPT.","sentences":["Benefiting from effective speech modeling, current Speech Large Language Models (SLLMs) have demonstrated exceptional capabilities in in-context speech generation and efficient generalization to unseen speakers.","However, the prevailing information modeling process is encumbered by certain redundancies, leading to inefficiencies in speech generation.","We propose Chain-of-Information Generation (CoIG), a method for decoupling semantic and perceptual information in large-scale speech generation.","Building on this, we develop SpeechGPT-Gen, an 8-billion-parameter SLLM efficient in semantic and perceptual information modeling.","It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling.","Additionally, we introduce the novel approach of infusing semantic information into the prior distribution to enhance the efficiency of flow matching.","Extensive experimental results demonstrate that SpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice conversion, and speech-to-speech dialogue, underscoring CoIG's remarkable proficiency in capturing and modeling speech's semantic and perceptual dimensions.","Code and models are available at https://github.com/0nutation/SpeechGPT."],"url":"http://arxiv.org/abs/2401.13527v1"}
{"created":"2024-01-24 15:15:03","title":"Addressing Data Quality Challenges in Observational Ambulatory Studies: Analysis, Methodologies and Practical Solutions for Wrist-worn Wearable Monitoring","abstract":"Chronic disease management and follow-up are vital for realizing sustained patient well-being and optimal health outcomes. Recent advancements in wearable sensing technologies, particularly wrist-worn devices, offer promising solutions for longitudinal patient follow-up by shifting from subjective, intermittent self-reporting to objective, continuous monitoring. However, collecting and analyzing wearable data presents unique challenges, such as data entry errors, non-wear periods, missing wearable data, and wearable artifacts. We therefore present an in-depth exploration of data analysis challenges tied to wrist-worn wearables and ambulatory label acquisition, using two real-world datasets (i.e., mBrain21 and ETRI lifelog2020). We introduce novel practical countermeasures, including participant compliance visualizations, interaction-triggered questionnaires to assess personal bias, and an optimized wearable non-wear detection pipeline. Further, we propose a visual analytics approach to validate processing pipelines using scalable tools such as tsflex and Plotly-Resampler. Lastly, we investigate the impact of missing wearable data on \"window-of-interest\" analysis methodologies. Prioritizing transparency and reproducibility, we offer open access to our detailed code examples, facilitating adaptation in future wearable research. In conclusion, our contributions provide actionable approaches for wearable data collection and analysis in chronic disease management.","sentences":["Chronic disease management and follow-up are vital for realizing sustained patient well-being and optimal health outcomes.","Recent advancements in wearable sensing technologies, particularly wrist-worn devices, offer promising solutions for longitudinal patient follow-up by shifting from subjective, intermittent self-reporting to objective, continuous monitoring.","However, collecting and analyzing wearable data presents unique challenges, such as data entry errors, non-wear periods, missing wearable data, and wearable artifacts.","We therefore present an in-depth exploration of data analysis challenges tied to wrist-worn wearables and ambulatory label acquisition, using two real-world datasets (i.e., mBrain21 and ETRI lifelog2020).","We introduce novel practical countermeasures, including participant compliance visualizations, interaction-triggered questionnaires to assess personal bias, and an optimized wearable non-wear detection pipeline.","Further, we propose a visual analytics approach to validate processing pipelines using scalable tools such as tsflex and Plotly-Resampler.","Lastly, we investigate the impact of missing wearable data on \"window-of-interest\" analysis methodologies.","Prioritizing transparency and reproducibility, we offer open access to our detailed code examples, facilitating adaptation in future wearable research.","In conclusion, our contributions provide actionable approaches for wearable data collection and analysis in chronic disease management."],"url":"http://arxiv.org/abs/2401.13518v1"}
{"created":"2024-01-24 15:14:05","title":"Delocate: Detection and Localization for Deepfake Videos with Randomly-Located Tampered Traces","abstract":"Deepfake videos are becoming increasingly realistic, showing subtle tampering traces on facial areasthat vary between frames. Consequently, many existing Deepfake detection methods struggle to detect unknown domain Deepfake videos while accurately locating the tampered region. To address thislimitation, we propose Delocate, a novel Deepfake detection model that can both recognize andlocalize unknown domain Deepfake videos. Ourmethod consists of two stages named recoveringand localization. In the recovering stage, the modelrandomly masks regions of interest (ROIs) and reconstructs real faces without tampering traces, resulting in a relatively good recovery effect for realfaces and a poor recovery effect for fake faces. Inthe localization stage, the output of the recoveryphase and the forgery ground truth mask serve assupervision to guide the forgery localization process. This process strategically emphasizes the recovery phase of fake faces with poor recovery, facilitating the localization of tampered regions. Ourextensive experiments on four widely used benchmark datasets demonstrate that Delocate not onlyexcels in localizing tampered areas but also enhances cross-domain detection performance.","sentences":["Deepfake videos are becoming increasingly realistic, showing subtle tampering traces on facial areasthat vary between frames.","Consequently, many existing Deepfake detection methods struggle to detect unknown domain Deepfake videos while accurately locating the tampered region.","To address thislimitation, we propose Delocate, a novel Deepfake detection model that can both recognize andlocalize unknown domain Deepfake videos.","Ourmethod consists of two stages named recoveringand localization.","In the recovering stage, the modelrandomly masks regions of interest (ROIs) and reconstructs real faces without tampering traces, resulting in a relatively good recovery effect for realfaces and a poor recovery effect for fake faces.","Inthe localization stage, the output of the recoveryphase and the forgery ground truth mask serve assupervision to guide the forgery localization process.","This process strategically emphasizes the recovery phase of fake faces with poor recovery, facilitating the localization of tampered regions.","Ourextensive experiments on four widely used benchmark datasets demonstrate that Delocate not onlyexcels in localizing tampered areas but also enhances cross-domain detection performance."],"url":"http://arxiv.org/abs/2401.13516v1"}
{"created":"2024-01-24 15:10:13","title":"Can GPT-3.5 Generate and Code Discharge Summaries?","abstract":"Objective: To investigate GPT-3.5 in generating and coding medical documents with ICD-10 codes for data augmentation on low-resources labels.   Materials and Methods: Employing GPT-3.5 we generated and coded 9,606 discharge summaries based on lists of ICD-10 code descriptions of patients with infrequent (generation) codes within the MIMIC-IV dataset. Combined with the baseline training set, this formed an augmented training set. Neural coding models were trained on baseline and augmented data and evaluated on a MIMIC-IV test set. We report micro- and macro-F1 scores on the full codeset, generation codes, and their families. Weak Hierarchical Confusion Matrices were employed to determine within-family and outside-of-family coding errors in the latter codesets. The coding performance of GPT-3.5 was evaluated both on prompt-guided self-generated data and real MIMIC-IV data. Clinical professionals evaluated the clinical acceptability of the generated documents.   Results: Augmentation slightly hinders the overall performance of the models but improves performance for the generation candidate codes and their families, including one unseen in the baseline training data. Augmented models display lower out-of-family error rates. GPT-3.5 can identify ICD-10 codes by the prompted descriptions, but performs poorly on real data. Evaluators note the correctness of generated concepts while suffering in variety, supporting information, and narrative.   Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding. Augmentation positively affects generation code families but mainly benefits codes with existing examples. Augmentation reduces out-of-family errors. Discharge summaries generated by GPT-3.5 state prompted concepts correctly but lack variety, and authenticity in narratives. They are unsuitable for clinical practice.","sentences":["Objective: To investigate GPT-3.5 in generating and coding medical documents with ICD-10 codes for data augmentation on low-resources labels.   ","Materials and Methods: Employing GPT-3.5 we generated and coded 9,606 discharge summaries based on lists of ICD-10 code descriptions of patients with infrequent (generation) codes within the MIMIC-IV dataset.","Combined with the baseline training set, this formed an augmented training set.","Neural coding models were trained on baseline and augmented data and evaluated on a MIMIC-IV test set.","We report micro- and macro-F1 scores on the full codeset, generation codes, and their families.","Weak Hierarchical Confusion Matrices were employed to determine within-family and outside-of-family coding errors in the latter codesets.","The coding performance of GPT-3.5 was evaluated both on prompt-guided self-generated data and real MIMIC-IV data.","Clinical professionals evaluated the clinical acceptability of the generated documents.   ","Results:","Augmentation slightly hinders the overall performance of the models but improves performance for the generation candidate codes and their families, including one unseen in the baseline training data.","Augmented models display lower out-of-family error rates.","GPT-3.5 can identify ICD-10 codes by the prompted descriptions, but performs poorly on real data.","Evaluators note the correctness of generated concepts while suffering in variety, supporting information, and narrative.   ","Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding.","Augmentation positively affects generation code families but mainly benefits codes with existing examples.","Augmentation reduces out-of-family errors.","Discharge summaries generated by GPT-3.5 state prompted concepts correctly but lack variety, and authenticity in narratives.","They are unsuitable for clinical practice."],"url":"http://arxiv.org/abs/2401.13512v1"}
{"created":"2024-01-24 15:06:44","title":"TPRF: A Transformer-based Pseudo-Relevance Feedback Model for Efficient and Effective Retrieval","abstract":"This paper considers Pseudo-Relevance Feedback (PRF) methods for dense retrievers in a resource constrained environment such as that of cheap cloud instances or embedded systems (e.g., smartphones and smartwatches), where memory and CPU are limited and GPUs are not present. For this, we propose a transformer-based PRF method (TPRF), which has a much smaller memory footprint and faster inference time compared to other deep language models that employ PRF mechanisms, with a marginal effectiveness loss. TPRF learns how to effectively combine the relevance feedback signals from dense passage representations. Specifically, TPRF provides a mechanism for modelling relationships and weights between the query and the relevance feedback signals. The method is agnostic to the specific dense representation used and thus can be generally applied to any dense retriever.","sentences":["This paper considers Pseudo-Relevance Feedback (PRF) methods for dense retrievers in a resource constrained environment such as that of cheap cloud instances or embedded systems (e.g., smartphones and smartwatches), where memory and CPU are limited and GPUs are not present.","For this, we propose a transformer-based PRF method (TPRF), which has a much smaller memory footprint and faster inference time compared to other deep language models that employ PRF mechanisms, with a marginal effectiveness loss.","TPRF learns how to effectively combine the relevance feedback signals from dense passage representations.","Specifically, TPRF provides a mechanism for modelling relationships and weights between the query and the relevance feedback signals.","The method is agnostic to the specific dense representation used and thus can be generally applied to any dense retriever."],"url":"http://arxiv.org/abs/2401.13509v1"}
{"created":"2024-01-24 14:53:13","title":"Generative Human Motion Stylization in Latent Space","abstract":"Human motion stylization aims to revise the style of an input motion while keeping its content unaltered. Unlike existing works that operate directly in pose space, we leverage the latent space of pretrained autoencoders as a more expressive and robust representation for motion extraction and infusion. Building upon this, we present a novel generative model that produces diverse stylization results of a single motion (latent) code. During training, a motion code is decomposed into two coding components: a deterministic content code, and a probabilistic style code adhering to a prior distribution; then a generator massages the random combination of content and style codes to reconstruct the corresponding motion codes. Our approach is versatile, allowing the learning of probabilistic style space from either style labeled or unlabeled motions, providing notable flexibility in stylization as well. In inference, users can opt to stylize a motion using style cues from a reference motion or a label. Even in the absence of explicit style input, our model facilitates novel re-stylization by sampling from the unconditional style prior distribution. Experimental results show that our proposed stylization models, despite their lightweight design, outperform the state-of-the-arts in style reeanactment, content preservation, and generalization across various applications and settings. Project Page: https://yxmu.foo/GenMoStyle","sentences":["Human motion stylization aims to revise the style of an input motion while keeping its content unaltered.","Unlike existing works that operate directly in pose space, we leverage the latent space of pretrained autoencoders as a more expressive and robust representation for motion extraction and infusion.","Building upon this, we present a novel generative model that produces diverse stylization results of a single motion (latent) code.","During training, a motion code is decomposed into two coding components: a deterministic content code, and a probabilistic style code adhering to a prior distribution; then a generator massages the random combination of content and style codes to reconstruct the corresponding motion codes.","Our approach is versatile, allowing the learning of probabilistic style space from either style labeled or unlabeled motions, providing notable flexibility in stylization as well.","In inference, users can opt to stylize a motion using style cues from a reference motion or a label.","Even in the absence of explicit style input, our model facilitates novel re-stylization by sampling from the unconditional style prior distribution.","Experimental results show that our proposed stylization models, despite their lightweight design, outperform the state-of-the-arts in style reeanactment, content preservation, and generalization across various applications and settings.","Project Page: https://yxmu.foo/GenMoStyle"],"url":"http://arxiv.org/abs/2401.13505v1"}
{"created":"2024-01-24 14:53:06","title":"Research about the Ability of LLM in the Tamper-Detection Area","abstract":"In recent years, particularly since the early 2020s, Large Language Models (LLMs) have emerged as the most powerful AI tools in addressing a diverse range of challenges, from natural language processing to complex problem-solving in various domains. In the field of tamper detection, LLMs are capable of identifying basic tampering activities.To assess the capabilities of LLMs in more specialized domains, we have collected five different LLMs developed by various companies: GPT-4, LLaMA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen. This diverse range of models allows for a comprehensive evaluation of their performance in detecting sophisticated tampering instances.We devised two domains of detection: AI-Generated Content (AIGC) detection and manipulation detection. AIGC detection aims to test the ability to distinguish whether an image is real or AI-generated. Manipulation detection, on the other hand, focuses on identifying tampered images. According to our experiments, most LLMs can identify composite pictures that are inconsistent with logic, and only more powerful LLMs can distinguish logical, but visible signs of tampering to the human eye. All of the LLMs can't identify carefully forged images and very realistic images generated by AI. In the area of tamper detection, LLMs still have a long way to go, particularly in reliably identifying highly sophisticated forgeries and AI-generated images that closely mimic reality.","sentences":["In recent years, particularly since the early 2020s, Large Language Models (LLMs) have emerged as the most powerful AI tools in addressing a diverse range of challenges, from natural language processing to complex problem-solving in various domains.","In the field of tamper detection, LLMs are capable of identifying basic tampering activities.","To assess the capabilities of LLMs in more specialized domains, we have collected five different LLMs developed by various companies: GPT-4, LLaMA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen.","This diverse range of models allows for a comprehensive evaluation of their performance in detecting sophisticated tampering instances.","We devised two domains of detection: AI-Generated Content (AIGC) detection and manipulation detection.","AIGC detection aims to test the ability to distinguish whether an image is real or AI-generated.","Manipulation detection, on the other hand, focuses on identifying tampered images.","According to our experiments, most LLMs can identify composite pictures that are inconsistent with logic, and only more powerful LLMs can distinguish logical, but visible signs of tampering to the human eye.","All of the LLMs can't identify carefully forged images and very realistic images generated by AI.","In the area of tamper detection, LLMs still have a long way to go, particularly in reliably identifying highly sophisticated forgeries and AI-generated images that closely mimic reality."],"url":"http://arxiv.org/abs/2401.13504v1"}
{"created":"2024-01-24 14:51:33","title":"Learning Representations for Clustering via Partial Information Discrimination and Cross-Level Interaction","abstract":"In this paper, we present a novel deep image clustering approach termed PICI, which enforces the partial information discrimination and the cross-level interaction in a joint learning framework. In particular, we leverage a Transformer encoder as the backbone, through which the masked image modeling with two paralleled augmented views is formulated. After deriving the class tokens from the masked images by the Transformer encoder, three partial information learning modules are further incorporated, including the PISD module for training the auto-encoder via masked image reconstruction, the PICD module for employing two levels of contrastive learning, and the CLI module for mutual interaction between the instance-level and cluster-level subspaces. Extensive experiments have been conducted on six real-world image datasets, which demononstrate the superior clustering performance of the proposed PICI approach over the state-of-the-art deep clustering approaches. The source code is available at https://github.com/Regan-Zhang/PICI.","sentences":["In this paper, we present a novel deep image clustering approach termed PICI, which enforces the partial information discrimination and the cross-level interaction in a joint learning framework.","In particular, we leverage a Transformer encoder as the backbone, through which the masked image modeling with two paralleled augmented views is formulated.","After deriving the class tokens from the masked images by the Transformer encoder, three partial information learning modules are further incorporated, including the PISD module for training the auto-encoder via masked image reconstruction, the PICD module for employing two levels of contrastive learning, and the CLI module for mutual interaction between the instance-level and cluster-level subspaces.","Extensive experiments have been conducted on six real-world image datasets, which demononstrate the superior clustering performance of the proposed PICI approach over the state-of-the-art deep clustering approaches.","The source code is available at https://github.com/Regan-Zhang/PICI."],"url":"http://arxiv.org/abs/2401.13503v1"}
{"created":"2024-01-24 14:51:17","title":"Faster Combinatorial k-Clique Algorithms","abstract":"Detecting if a graph contains a $k$-Clique is one of the most fundamental problems in computer science. The asymptotically fastest algorithm runs in time $O(n^{\\omega k/3})$, where $\\omega$ is the exponent of Boolean matrix multiplication. To date, this is the only technique capable of beating the trivial $O(n^k)$ bound by a polynomial factor. Due to this technique's various limitations, much effort has gone into designing \"combinatorial\" algorithms that improve over exhaustive search via other techniques.   The first contribution of this work is a faster combinatorial algorithm for $k$-Clique, improving Vassilevska's bound of $O(n^{k}/\\log^{k-1}{n})$ by two log factors. Technically, our main result is a new reduction from $k$-Clique to Triangle detection that exploits the same divide-and-conquer at the core of recent combinatorial algorithms by Chan (SODA'15) and Yu (ICALP'15).   Our second contribution is exploiting combinatorial techniques to improve the state-of-the-art (even of non-combinatorial algorithms) for generalizations of the $k$-Clique problem. In particular, we give the first $o(n^k)$ algorithm for $k$-clique in hypergraphs and an $O(n^3/\\log^{2.25}{n} + t)$ algorithm for listing $t$ triangles in a graph.","sentences":["Detecting if a graph contains a $k$-Clique is one of the most fundamental problems in computer science.","The asymptotically fastest algorithm runs in time $O(n^{\\omega k/3})$, where $\\omega$ is the exponent of Boolean matrix multiplication.","To date, this is the only technique capable of beating the trivial $O(n^k)$ bound by a polynomial factor.","Due to this technique's various limitations, much effort has gone into designing \"combinatorial\" algorithms that improve over exhaustive search via other techniques.   ","The first contribution of this work is a faster combinatorial algorithm for $k$-Clique, improving Vassilevska's bound of $O(n^{k}/\\log^{k-1}{n})$ by two log factors.","Technically, our main result is a new reduction from $k$-Clique to Triangle detection that exploits the same divide-and-conquer at the core of recent combinatorial algorithms by Chan (SODA'15) and Yu (ICALP'15).   ","Our second contribution is exploiting combinatorial techniques to improve the state-of-the-art (even of non-combinatorial algorithms) for generalizations of the $k$-Clique problem.","In particular, we give the first $o(n^k)$ algorithm for $k$-clique in hypergraphs and an $O(n^3/\\log^{2.25}{n} + t)$ algorithm for listing $t$ triangles in a graph."],"url":"http://arxiv.org/abs/2401.13502v1"}
{"created":"2024-01-24 14:44:48","title":"LDCA: Local Descriptors with Contextual Augmentation for Few-Shot Learning","abstract":"Few-shot image classification has emerged as a key challenge in the field of computer vision, highlighting the capability to rapidly adapt to new tasks with minimal labeled data. Existing methods predominantly rely on image-level features or local descriptors, often overlooking the holistic context surrounding these descriptors. In this work, we introduce a novel approach termed \"Local Descriptor with Contextual Augmentation (LDCA)\". Specifically, this method bridges the gap between local and global understanding uniquely by leveraging an adaptive global contextual enhancement module. This module incorporates a visual transformer, endowing local descriptors with contextual awareness capabilities, ranging from broad global perspectives to intricate surrounding nuances. By doing so, LDCA transcends traditional descriptor-based approaches, ensuring each local feature is interpreted within its larger visual narrative. Extensive experiments underscore the efficacy of our method, showing a maximal absolute improvement of 20\\% over the next-best on fine-grained classification datasets, thus demonstrating significant advancements in few-shot classification tasks.","sentences":["Few-shot image classification has emerged as a key challenge in the field of computer vision, highlighting the capability to rapidly adapt to new tasks with minimal labeled data.","Existing methods predominantly rely on image-level features or local descriptors, often overlooking the holistic context surrounding these descriptors.","In this work, we introduce a novel approach termed \"Local Descriptor with Contextual Augmentation (LDCA)\".","Specifically, this method bridges the gap between local and global understanding uniquely by leveraging an adaptive global contextual enhancement module.","This module incorporates a visual transformer, endowing local descriptors with contextual awareness capabilities, ranging from broad global perspectives to intricate surrounding nuances.","By doing so, LDCA transcends traditional descriptor-based approaches, ensuring each local feature is interpreted within its larger visual narrative.","Extensive experiments underscore the efficacy of our method, showing a maximal absolute improvement of 20\\% over the next-best on fine-grained classification datasets, thus demonstrating significant advancements in few-shot classification tasks."],"url":"http://arxiv.org/abs/2401.13499v1"}
{"created":"2024-01-24 14:44:01","title":"Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting","abstract":"Synthesizing performing guitar sound is a highly challenging task due to the polyphony and high variability in expression. Recently, deep generative models have shown promising results in synthesizing expressive polyphonic instrument sounds from music scores, often using a generic MIDI input. In this work, we propose an expressive acoustic guitar sound synthesis model with a customized input representation to the instrument, which we call guitarroll. We implement the proposed approach using diffusion-based outpainting which can generate audio with long-term consistency. To overcome the lack of MIDI/audio-paired datasets, we used not only an existing guitar dataset but also collected data from a high quality sample-based guitar synthesizer. Through quantitative and qualitative evaluations, we show that our proposed model has higher audio quality than the baseline model and generates more realistic timbre sounds than the previous leading work.","sentences":["Synthesizing performing guitar sound is a highly challenging task due to the polyphony and high variability in expression.","Recently, deep generative models have shown promising results in synthesizing expressive polyphonic instrument sounds from music scores, often using a generic MIDI input.","In this work, we propose an expressive acoustic guitar sound synthesis model with a customized input representation to the instrument, which we call guitarroll.","We implement the proposed approach using diffusion-based outpainting which can generate audio with long-term consistency.","To overcome the lack of MIDI/audio-paired datasets, we used not only an existing guitar dataset but also collected data from a high quality sample-based guitar synthesizer.","Through quantitative and qualitative evaluations, we show that our proposed model has higher audio quality than the baseline model and generates more realistic timbre sounds than the previous leading work."],"url":"http://arxiv.org/abs/2401.13498v1"}
{"created":"2024-01-24 14:42:05","title":"Towards an Autonomous Compost Turner: Current State of Research","abstract":"This preprint presents the current status of research into the development and application of an autonomous, self-driving compost turner. The aim is to overcome challenges in the composting industry, such as adverse working conditions, by automating the composting process. The preprint provides a comprehensive overview of the overall concept of the self-driving compost turner, including the hardware architecture with sensors, navigation module and control module. In addition, the methodical development of the architecture of concepts, models and their subsequent software integration in ROS using model-based systems engineering is described. The validation and verification of the overall system is carried out in an industrial environment using three scenarios. The capabilities of the compost turner are demonstrated by autonomously following predefined trajectories in the composting plant and performing the required composting tasks. The results show that the autonomous compost turner is capable of performing the required activities. In addition, the compost turner has intelligent processing capabilities for compost data as well as its transmission, visualization and storage in a cloud server. It is important to note that this work is a preprint that represents the current state of research. The authors aim to publish the full paper in a peer-reviewed journal in the near future.","sentences":["This preprint presents the current status of research into the development and application of an autonomous, self-driving compost turner.","The aim is to overcome challenges in the composting industry, such as adverse working conditions, by automating the composting process.","The preprint provides a comprehensive overview of the overall concept of the self-driving compost turner, including the hardware architecture with sensors, navigation module and control module.","In addition, the methodical development of the architecture of concepts, models and their subsequent software integration in ROS using model-based systems engineering is described.","The validation and verification of the overall system is carried out in an industrial environment using three scenarios.","The capabilities of the compost turner are demonstrated by autonomously following predefined trajectories in the composting plant and performing the required composting tasks.","The results show that the autonomous compost turner is capable of performing the required activities.","In addition, the compost turner has intelligent processing capabilities for compost data as well as its transmission, visualization and storage in a cloud server.","It is important to note that this work is a preprint that represents the current state of research.","The authors aim to publish the full paper in a peer-reviewed journal in the near future."],"url":"http://arxiv.org/abs/2401.13493v1"}
{"created":"2024-01-24 14:37:44","title":"Visualization of rank-citation curves for fast detection of h-index anomalies in university metrics","abstract":"University rankings, despite facing criticism, continue to maintain their popularity. In the 2023 Scopus Ranking of Ukrainian Universities, certain institutions stood out due to their high h-index, despite modest publication and citation numbers. This phenomenon can be attributed to influential research topics or involvement in international collaborative research. However, these results may also be due to the authors' own efforts to increase the number of citations of their publications in order to improve their h-index. To investigate this, the publications from the top 30 universities in the ranking were analysed, revealing humpback rank-citation curves for two universities. These humpbacks indicate unusual trends in the citation data, especially considering the high percentage of self-citations and FWCI of analysed papers. While quantitative analysis has limitations, the combination of humped rank-citation curves, self-citations, FWCI, and previous research findings raises concerns about the possible causes of these anomalies in the citation data of the analysed universities. The method presented in this paper can aid ranking compilers and citation databases managers in identifying potential instances of citation data anomalies, emphasizing the importance of expert assessment for accurate conclusions.","sentences":["University rankings, despite facing criticism, continue to maintain their popularity.","In the 2023 Scopus Ranking of Ukrainian Universities, certain institutions stood out due to their high h-index, despite modest publication and citation numbers.","This phenomenon can be attributed to influential research topics or involvement in international collaborative research.","However, these results may also be due to the authors' own efforts to increase the number of citations of their publications in order to improve their h-index.","To investigate this, the publications from the top 30 universities in the ranking were analysed, revealing humpback rank-citation curves for two universities.","These humpbacks indicate unusual trends in the citation data, especially considering the high percentage of self-citations and FWCI of analysed papers.","While quantitative analysis has limitations, the combination of humped rank-citation curves, self-citations, FWCI, and previous research findings raises concerns about the possible causes of these anomalies in the citation data of the analysed universities.","The method presented in this paper can aid ranking compilers and citation databases managers in identifying potential instances of citation data anomalies, emphasizing the importance of expert assessment for accurate conclusions."],"url":"http://arxiv.org/abs/2401.13490v1"}
{"created":"2024-01-24 14:36:08","title":"Fast Inverse Model Transformation: Algebraic Framework for Fast Data Plane Verification","abstract":"Data plane verification (DPV) analyzes routing tables and detects routing abnormalities and policy violations during network operation and planning. Thus, it has become an important tool to harden the networking infrastructure and the computing systems building on top. Substantial advancements have been made in the last decade and state-of-the-art DPV systems can achieve sub-us verification for an update of a single forwarding rule.   In this paper, we introduce fast inverse model transformation (FIMT), the first theoretical framework to systematically model and analyze centralized DPV systems. FIMT reveals the algebraic structure in the model update process, a key step in fast DPV systems. Thus, it can systematically analyze the correctness of several DPV systems, using algebraic properties. The theory also guides the design and implementation of NeoFlash, a refactored version of Flash with new optimization techniques. Evaluations show that NeoFlash outperforms existing state-of-the-art centralized DPV systems in various datasets and reveal insights to key techniques towards fast DPV.","sentences":["Data plane verification (DPV) analyzes routing tables and detects routing abnormalities and policy violations during network operation and planning.","Thus, it has become an important tool to harden the networking infrastructure and the computing systems building on top.","Substantial advancements have been made in the last decade and state-of-the-art DPV systems can achieve sub-us verification for an update of a single forwarding rule.   ","In this paper, we introduce fast inverse model transformation (FIMT), the first theoretical framework to systematically model and analyze centralized DPV systems.","FIMT reveals the algebraic structure in the model update process, a key step in fast DPV systems.","Thus, it can systematically analyze the correctness of several DPV systems, using algebraic properties.","The theory also guides the design and implementation of NeoFlash, a refactored version of Flash with new optimization techniques.","Evaluations show that NeoFlash outperforms existing state-of-the-art centralized DPV systems in various datasets and reveal insights to key techniques towards fast DPV."],"url":"http://arxiv.org/abs/2401.13488v1"}
{"created":"2024-01-24 14:29:39","title":"How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment","abstract":"Exposure to large language model output is rapidly increasing. How will seeing AI-generated ideas affect human ideas? We conducted an experiment (800+ participants, 40+ countries) where participants viewed creative ideas that were from ChatGPT or prior experimental participants and then brainstormed their own idea. We varied the number of AI-generated examples (none, low, or high exposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic experiment design -- ideas from prior participants in an experimental condition are used as stimuli for future participants in the same experimental condition -- mimics the interdependent process of cultural creation: creative ideas are built upon prior ideas. Hence, we capture the compounding effects of having LLMs 'in the culture loop'. We find that high AI exposure (but not low AI exposure) did not affect the creativity of individual ideas but did increase the average amount and rate of change of collective idea diversity. AI made ideas different, not better. There were no main effects of disclosure. We also found that self-reported creative people were less influenced by knowing an idea was from AI, and that participants were more likely to knowingly adopt AI ideas when the task was difficult. Our findings suggest that introducing AI ideas into society may increase collective diversity but not individual creativity.","sentences":["Exposure to large language model output is rapidly increasing.","How will seeing AI-generated ideas affect human ideas?","We conducted an experiment (800+ participants, 40+ countries) where participants viewed creative ideas that were from ChatGPT or prior experimental participants and then brainstormed their own idea.","We varied the number of AI-generated examples (none, low, or high exposure) and if the examples were labeled as 'AI' (disclosure).","Our dynamic experiment design -- ideas from prior participants in an experimental condition are used as stimuli for future participants in the same experimental condition -- mimics the interdependent process of cultural creation: creative ideas are built upon prior ideas.","Hence, we capture the compounding effects of having LLMs 'in the culture loop'.","We find that high AI exposure (but not low AI exposure) did not affect the creativity of individual ideas but did increase the average amount and rate of change of collective idea diversity.","AI made ideas different, not better.","There were no main effects of disclosure.","We also found that self-reported creative people were less influenced by knowing an idea was from AI, and that participants were more likely to knowingly adopt AI ideas when the task was difficult.","Our findings suggest that introducing AI ideas into society may increase collective diversity but not individual creativity."],"url":"http://arxiv.org/abs/2401.13481v1"}
{"created":"2024-01-24 14:28:55","title":"The Dynamics of (Not) Unfollowing Misinformation Spreaders","abstract":"Many studies explore how people 'come into' misinformation exposure. But much less is known about how people 'come out of' misinformation exposure. Do people organically sever ties to misinformation spreaders? And what predicts doing so? Over six months, we tracked the frequency and predictors of ~1M followers unfollowing ~5K health misinformation spreaders on Twitter. We found that misinformation ties are persistent. Monthly unfollowing rates are just 0.52%. Users are also 31% more likely to unfollow non-misinformation spreaders than they are to unfollow misinformation spreaders. Although generally infrequent, the factors most associated with unfollowing misinformation spreaders are (1) redundancy and (2) ideology. First, users initially following many spreaders, or who follow spreaders that tweet often, are most likely to unfollow later. Second, liberals are more likely to unfollow than conservatives. Overall, we observe strong persistence of misinformation ties. The fact that users rarely unfollow misinformation spreaders suggests a need for external nudges and the importance of preventing exposure from arising in the first place.","sentences":["Many studies explore how people 'come into' misinformation exposure.","But much less is known about how people 'come out of' misinformation exposure.","Do people organically sever ties to misinformation spreaders?","And what predicts doing so?","Over six months, we tracked the frequency and predictors of ~1M followers unfollowing ~5K health misinformation spreaders on Twitter.","We found that misinformation ties are persistent.","Monthly unfollowing rates are just 0.52%.","Users are also 31% more likely to unfollow non-misinformation spreaders than they are to unfollow misinformation spreaders.","Although generally infrequent, the factors most associated with unfollowing misinformation spreaders are (1) redundancy and (2) ideology.","First, users initially following many spreaders, or who follow spreaders that tweet often, are most likely to unfollow later.","Second, liberals are more likely to unfollow than conservatives.","Overall, we observe strong persistence of misinformation ties.","The fact that users rarely unfollow misinformation spreaders suggests a need for external nudges and the importance of preventing exposure from arising in the first place."],"url":"http://arxiv.org/abs/2401.13480v1"}
{"created":"2024-01-24 14:23:12","title":"SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval","abstract":"Multi-modal information retrieval (MMIR) is a rapidly evolving field, where significant progress, particularly in image-text pairing, has been made through advanced representation learning and cross-modality alignment research. However, current benchmarks for evaluating MMIR performance in image-text pairing within the scientific domain show a notable gap, where chart and table images described in scholarly language usually do not play a significant role. To bridge this gap, we develop a specialised scientific MMIR (SciMMIR) benchmark by leveraging open-access paper collections to extract data relevant to the scientific domain. This benchmark comprises 530K meticulously curated image-text pairs, extracted from figures and tables with detailed captions in scientific documents. We further annotate the image-text pairs with two-level subset-subcategory hierarchy annotations to facilitate a more comprehensive evaluation of the baselines. We conducted zero-shot and fine-tuning evaluations on prominent multi-modal image-captioning and visual language models, such as CLIP and BLIP. Our analysis offers critical insights for MMIR in the scientific domain, including the impact of pre-training and fine-tuning settings and the influence of the visual and textual encoders. All our data and checkpoints are publicly available at https://github.com/Wusiwei0410/SciMMIR.","sentences":["Multi-modal information retrieval (MMIR) is a rapidly evolving field, where significant progress, particularly in image-text pairing, has been made through advanced representation learning and cross-modality alignment research.","However, current benchmarks for evaluating MMIR performance in image-text pairing within the scientific domain show a notable gap, where chart and table images described in scholarly language usually do not play a significant role.","To bridge this gap, we develop a specialised scientific MMIR (SciMMIR) benchmark by leveraging open-access paper collections to extract data relevant to the scientific domain.","This benchmark comprises 530K meticulously curated image-text pairs, extracted from figures and tables with detailed captions in scientific documents.","We further annotate the image-text pairs with two-level subset-subcategory hierarchy annotations to facilitate a more comprehensive evaluation of the baselines.","We conducted zero-shot and fine-tuning evaluations on prominent multi-modal image-captioning and visual language models, such as CLIP and BLIP.","Our analysis offers critical insights for MMIR in the scientific domain, including the impact of pre-training and fine-tuning settings and the influence of the visual and textual encoders.","All our data and checkpoints are publicly available at https://github.com/Wusiwei0410/SciMMIR."],"url":"http://arxiv.org/abs/2401.13478v1"}
