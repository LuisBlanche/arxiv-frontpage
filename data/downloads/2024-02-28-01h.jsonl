{"created":"2024-02-26 07:19:23","title":"Language-guided Skill Learning with Temporal Variational Inference","abstract":"We present an algorithm for skill discovery from expert demonstrations. The algorithm first utilizes Large Language Models (LLMs) to propose an initial segmentation of the trajectories. Following that, a hierarchical variational inference framework incorporates the LLM-generated segmentation information to discover reusable skills by merging trajectory segments. To further control the trade-off between compression and reusability, we introduce a novel auxiliary objective based on the Minimum Description Length principle that helps guide this skill discovery process. Our results demonstrate that agents equipped with our method are able to discover skills that help accelerate learning and outperform baseline skill learning approaches on new long-horizon tasks in BabyAI, a grid world navigation environment, as well as ALFRED, a household simulation environment.","sentences":["We present an algorithm for skill discovery from expert demonstrations.","The algorithm first utilizes Large Language Models (LLMs) to propose an initial segmentation of the trajectories.","Following that, a hierarchical variational inference framework incorporates the LLM-generated segmentation information to discover reusable skills by merging trajectory segments.","To further control the trade-off between compression and reusability, we introduce a novel auxiliary objective based on the Minimum Description Length principle that helps guide this skill discovery process.","Our results demonstrate that agents equipped with our method are able to discover skills that help accelerate learning and outperform baseline skill learning approaches on new long-horizon tasks in BabyAI, a grid world navigation environment, as well as ALFRED, a household simulation environment."],"url":"http://arxiv.org/abs/2402.16354v1"}
{"created":"2024-02-26 07:17:25","title":"MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs","abstract":"Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems from a small-scale problem-solution dataset (denoted as seed data). We augment the ground-truth solutions of our seed data and train a back-translation model to translate the augmented solutions back into new questions. Subsequently, we generate code-integrated solutions for the new questions. To ensure the correctness of the code-integrated solutions, we employ rationale-based strategy for solution verification. Various pretrained models, ranging from 7B to 70B, are trained on the newly curated data to test the effectiveness of the proposed augmentation technique, resulting in a family of models known as MathGenieLM. These models consistently outperform previous open-source models across five representative mathematical reasoning datasets, achieving state-of-the-art performance. In particular, MathGenieLM-InternLM2 achieves an accuracy of 87.7% on GSM8K and 55.7% on MATH, securing the best overall score among open-source language models.","sentences":["Large language models (LLMs) have exhibited great potential in mathematical reasoning.","However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4.","In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems from a small-scale problem-solution dataset (denoted as seed data).","We augment the ground-truth solutions of our seed data and train a back-translation model to translate the augmented solutions back into new questions.","Subsequently, we generate code-integrated solutions for the new questions.","To ensure the correctness of the code-integrated solutions, we employ rationale-based strategy for solution verification.","Various pretrained models, ranging from 7B to 70B, are trained on the newly curated data to test the effectiveness of the proposed augmentation technique, resulting in a family of models known as MathGenieLM.","These models consistently outperform previous open-source models across five representative mathematical reasoning datasets, achieving state-of-the-art performance.","In particular, MathGenieLM-InternLM2 achieves an accuracy of 87.7% on GSM8K and 55.7% on MATH, securing the best overall score among open-source language models."],"url":"http://arxiv.org/abs/2402.16352v1"}
{"created":"2024-02-26 07:07:18","title":"Impression-CLIP: Contrastive Shape-Impression Embedding for Fonts","abstract":"Fonts convey different impressions to readers. These impressions often come from the font shapes. However, the correlation between fonts and their impression is weak and unstable because impressions are subjective. To capture such weak and unstable cross-modal correlation between font shapes and their impressions, we propose Impression-CLIP, which is a novel machine-learning model based on CLIP (Contrastive Language-Image Pre-training). By using the CLIP-based model, font image features and their impression features are pulled closer, and font image features and unrelated impression features are pushed apart. This procedure realizes co-embedding between font image and their impressions. In our experiment, we perform cross-modal retrieval between fonts and impressions through co-embedding. The results indicate that Impression-CLIP achieves better retrieval accuracy than the state-of-the-art method. Additionally, our model shows the robustness to noise and missing tags.","sentences":["Fonts convey different impressions to readers.","These impressions often come from the font shapes.","However, the correlation between fonts and their impression is weak and unstable because impressions are subjective.","To capture such weak and unstable cross-modal correlation between font shapes and their impressions, we propose Impression-CLIP, which is a novel machine-learning model based on CLIP (Contrastive Language-Image Pre-training).","By using the CLIP-based model, font image features and their impression features are pulled closer, and font image features and unrelated impression features are pushed apart.","This procedure realizes co-embedding between font image and their impressions.","In our experiment, we perform cross-modal retrieval between fonts and impressions through co-embedding.","The results indicate that Impression-CLIP achieves better retrieval accuracy than the state-of-the-art method.","Additionally, our model shows the robustness to noise and missing tags."],"url":"http://arxiv.org/abs/2402.16350v1"}
{"created":"2024-02-26 07:07:00","title":"C-GAIL: Stabilizing Generative Adversarial Imitation Learning with Control Theory","abstract":"Generative Adversarial Imitation Learning (GAIL) trains a generative policy to mimic a demonstrator. It uses on-policy Reinforcement Learning (RL) to optimize a reward signal derived from a GAN-like discriminator. A major drawback of GAIL is its training instability - it inherits the complex training dynamics of GANs, and the distribution shift introduced by RL. This can cause oscillations during training, harming its sample efficiency and final policy performance. Recent work has shown that control theory can help with the convergence of a GAN's training. This paper extends this line of work, conducting a control-theoretic analysis of GAIL and deriving a novel controller that not only pushes GAIL to the desired equilibrium but also achieves asymptotic stability in a 'one-step' setting. Based on this, we propose a practical algorithm 'Controlled-GAIL' (C-GAIL). On MuJoCo tasks, our controlled variant is able to speed up the rate of convergence, reduce the range of oscillation and match the expert's distribution more closely both for vanilla GAIL and GAIL-DAC.","sentences":["Generative Adversarial Imitation Learning (GAIL) trains a generative policy to mimic a demonstrator.","It uses on-policy Reinforcement Learning (RL) to optimize a reward signal derived from a GAN-like discriminator.","A major drawback of GAIL is its training instability - it inherits the complex training dynamics of GANs, and the distribution shift introduced by RL.","This can cause oscillations during training, harming its sample efficiency and final policy performance.","Recent work has shown that control theory can help with the convergence of a GAN's training.","This paper extends this line of work, conducting a control-theoretic analysis of GAIL and deriving a novel controller that not only pushes GAIL to the desired equilibrium but also achieves asymptotic stability in a 'one-step' setting.","Based on this, we propose a practical algorithm 'Controlled-GAIL' (C-GAIL).","On MuJoCo tasks, our controlled variant is able to speed up the rate of convergence, reduce the range of oscillation and match the expert's distribution more closely both for vanilla GAIL and GAIL-DAC."],"url":"http://arxiv.org/abs/2402.16349v1"}
{"created":"2024-02-26 07:02:05","title":"Star-Searcher: A Complete and Efficient Aerial System for Autonomous Target Search in Complex Unknown Environments","abstract":"This paper tackles the challenge of autonomous target search using unmanned aerial vehicles (UAVs) in complex unknown environments. To fill the gap in systematic approaches for this task, we introduce Star-Searcher, an aerial system featuring specialized sensor suites, mapping, and planning modules to optimize searching. Path planning challenges due to increased inspection requirements are addressed through a hierarchical planner with a visibility-based viewpoint clustering method. This simplifies planning by breaking it into global and local sub-problems, ensuring efficient global and local path coverage in real-time. Furthermore, our global path planning employs a history-aware mechanism to reduce motion inconsistency from frequent map changes, significantly enhancing search efficiency. We conduct comparisons with state-of-the-art methods in both simulation and the real world, demonstrating shorter flight paths, reduced time, and higher target search completeness. Our approach will be open-sourced for community benefit at https://github.com/SYSU-STAR/STAR-Searcher.","sentences":["This paper tackles the challenge of autonomous target search using unmanned aerial vehicles (UAVs) in complex unknown environments.","To fill the gap in systematic approaches for this task, we introduce Star-Searcher, an aerial system featuring specialized sensor suites, mapping, and planning modules to optimize searching.","Path planning challenges due to increased inspection requirements are addressed through a hierarchical planner with a visibility-based viewpoint clustering method.","This simplifies planning by breaking it into global and local sub-problems, ensuring efficient global and local path coverage in real-time.","Furthermore, our global path planning employs a history-aware mechanism to reduce motion inconsistency from frequent map changes, significantly enhancing search efficiency.","We conduct comparisons with state-of-the-art methods in both simulation and the real world, demonstrating shorter flight paths, reduced time, and higher target search completeness.","Our approach will be open-sourced for community benefit at https://github.com/SYSU-STAR/STAR-Searcher."],"url":"http://arxiv.org/abs/2402.16348v1"}
{"created":"2024-02-26 07:00:58","title":"CodeS: Towards Building Open-source Language Models for Text-to-SQL","abstract":"Language models have shown promising performance on the task of translating natural language questions into SQL queries (Text-to-SQL). However, most of the state-of-the-art (SOTA) approaches rely on powerful yet closed-source large language models (LLMs), such as ChatGPT and GPT-4, which may have the limitations of unclear model architectures, data privacy risks, and expensive inference overheads. To address the limitations, we introduce CodeS, a series of pre-trained language models with parameters ranging from 1B to 15B, specifically designed for the text-to-SQL task. CodeS is a fully open-source language model, which achieves superior accuracy with much smaller parameter sizes. This paper studies the research challenges in building CodeS. To enhance the SQL generation abilities of CodeS, we adopt an incremental pre-training approach using a specifically curated SQL-centric corpus. Based on this, we address the challenges of schema linking and rapid domain adaptation through strategic prompt construction and a bi-directional data augmentation technique. We conduct comprehensive evaluations on multiple datasets, including the widely used Spider benchmark, the newly released BIRD benchmark, robustness-diagnostic benchmarks such as Spider-DK, Spider-Syn, Spider-Realistic, and Dr.Spider, as well as two real-world datasets created for financial and academic applications. The experimental results show that our CodeS achieves new SOTA accuracy and robustness on nearly all challenging text-to-SQL benchmarks.","sentences":["Language models have shown promising performance on the task of translating natural language questions into SQL queries (Text-to-SQL).","However, most of the state-of-the-art (SOTA) approaches rely on powerful yet closed-source large language models (LLMs), such as ChatGPT and GPT-4, which may have the limitations of unclear model architectures, data privacy risks, and expensive inference overheads.","To address the limitations, we introduce CodeS, a series of pre-trained language models with parameters ranging from 1B to 15B, specifically designed for the text-to-SQL task.","CodeS is a fully open-source language model, which achieves superior accuracy with much smaller parameter sizes.","This paper studies the research challenges in building CodeS.","To enhance the SQL generation abilities of CodeS, we adopt an incremental pre-training approach using a specifically curated SQL-centric corpus.","Based on this, we address the challenges of schema linking and rapid domain adaptation through strategic prompt construction and a bi-directional data augmentation technique.","We conduct comprehensive evaluations on multiple datasets, including the widely used Spider benchmark, the newly released BIRD benchmark, robustness-diagnostic benchmarks such as Spider-DK, Spider-Syn, Spider-Realistic, and Dr.Spider, as well as two real-world datasets created for financial and academic applications.","The experimental results show that our CodeS achieves new SOTA accuracy and robustness on nearly all challenging text-to-SQL benchmarks."],"url":"http://arxiv.org/abs/2402.16347v1"}
{"created":"2024-02-26 07:00:24","title":"Boosting Graph Pooling with Persistent Homology","abstract":"Recently, there has been an emerging trend to integrate persistent homology (PH) into graph neural networks (GNNs) to enrich expressive power. However, naively plugging PH features into GNN layers always results in marginal improvement with low interpretability. In this paper, we investigate a novel mechanism for injecting global topological invariance into pooling layers using PH, motivated by the observation that filtration operation in PH naturally aligns graph pooling in a cut-off manner. In this fashion, message passing in the coarsened graph acts along persistent pooled topology, leading to improved performance. Experimentally, we apply our mechanism to a collection of graph pooling methods and observe consistent and substantial performance gain over several popular datasets, demonstrating its wide applicability and flexibility.","sentences":["Recently, there has been an emerging trend to integrate persistent homology (PH) into graph neural networks (GNNs) to enrich expressive power.","However, naively plugging PH features into GNN layers always results in marginal improvement with low interpretability.","In this paper, we investigate a novel mechanism for injecting global topological invariance into pooling layers using PH, motivated by the observation that filtration operation in PH naturally aligns graph pooling in a cut-off manner.","In this fashion, message passing in the coarsened graph acts along persistent pooled topology, leading to improved performance.","Experimentally, we apply our mechanism to a collection of graph pooling methods and observe consistent and substantial performance gain over several popular datasets, demonstrating its wide applicability and flexibility."],"url":"http://arxiv.org/abs/2402.16346v1"}
{"created":"2024-02-26 06:55:36","title":"Trimma: Trimming Metadata Storage and Latency for Hybrid Memory Systems","abstract":"Hybrid main memory systems combine both performance and capacity advantages from heterogeneous memory technologies. With larger capacities, higher associativities, and finer granularities, hybrid memory systems currently exhibit significant metadata storage and lookup overheads for flexibly remapping data blocks between the two memory tiers. To alleviate the inefficiencies of existing designs, we propose Trimma, the combination of a multi-level metadata structure and an efficient metadata cache design. Trimma uses a multi-level metadata table to only track truly necessary address remap entries. The saved memory space is effectively utilized as extra DRAM cache capacity to improve performance. Trimma also uses separate formats to store the entries with non-identity and identity mappings. This improves the overall remap cache hit rate, further boosting the performance. Trimma is transparent to software and compatible with various types of hybrid memory systems. When evaluated on a representative DDR4 + NVM hybrid memory system, Trimma achieves up to 2.4$\\times$ and on average 58.1\\% speedup benefits, compared with a state-of-the-art design that only leverages the unallocated fast memory space for caching. Trimma addresses metadata management overheads and targets future scalable large-scale hybrid memory architectures.","sentences":["Hybrid main memory systems combine both performance and capacity advantages from heterogeneous memory technologies.","With larger capacities, higher associativities, and finer granularities, hybrid memory systems currently exhibit significant metadata storage and lookup overheads for flexibly remapping data blocks between the two memory tiers.","To alleviate the inefficiencies of existing designs, we propose Trimma, the combination of a multi-level metadata structure and an efficient metadata cache design.","Trimma uses a multi-level metadata table to only track truly necessary address remap entries.","The saved memory space is effectively utilized as extra DRAM cache capacity to improve performance.","Trimma also uses separate formats to store the entries with non-identity and identity mappings.","This improves the overall remap cache hit rate, further boosting the performance.","Trimma is transparent to software and compatible with various types of hybrid memory systems.","When evaluated on a representative DDR4 + NVM hybrid memory system, Trimma achieves up to 2.4$\\times$ and on average 58.1\\% speedup benefits, compared with a state-of-the-art design that only leverages the unallocated fast memory space for caching.","Trimma addresses metadata management overheads and targets future scalable large-scale hybrid memory architectures."],"url":"http://arxiv.org/abs/2402.16343v1"}
{"created":"2024-02-26 06:42:30","title":"Contingency Planning Using Bi-level Markov Decision Processes for Space Missions","abstract":"This work focuses on autonomous contingency planning for scientific missions by enabling rapid policy computation from any off-nominal point in the state space in the event of a delay or deviation from the nominal mission plan. Successful contingency planning involves managing risks and rewards, often probabilistically associated with actions, in stochastic scenarios. Markov Decision Processes (MDPs) are used to mathematically model decision-making in such scenarios. However, in the specific case of planetary rover traverse planning, the vast action space and long planning time horizon pose computational challenges. A bi-level MDP framework is proposed to improve computational tractability, while also aligning with existing mission planning practices and enhancing explainability and trustworthiness of AI-driven solutions. We discuss the conversion of a mission planning MDP into a bi-level MDP, and test the framework on RoverGridWorld, a modified GridWorld environment for rover mission planning. We demonstrate the computational tractability and near-optimal policies achievable with the bi-level MDP approach, highlighting the trade-offs between compute time and policy optimality as the problem's complexity grows. This work facilitates more efficient and flexible contingency planning in the context of scientific missions.","sentences":["This work focuses on autonomous contingency planning for scientific missions by enabling rapid policy computation from any off-nominal point in the state space in the event of a delay or deviation from the nominal mission plan.","Successful contingency planning involves managing risks and rewards, often probabilistically associated with actions, in stochastic scenarios.","Markov Decision Processes (MDPs) are used to mathematically model decision-making in such scenarios.","However, in the specific case of planetary rover traverse planning, the vast action space and long planning time horizon pose computational challenges.","A bi-level MDP framework is proposed to improve computational tractability, while also aligning with existing mission planning practices and enhancing explainability and trustworthiness of AI-driven solutions.","We discuss the conversion of a mission planning MDP into a bi-level MDP, and test the framework on RoverGridWorld, a modified GridWorld environment for rover mission planning.","We demonstrate the computational tractability and near-optimal policies achievable with the bi-level MDP approach, highlighting the trade-offs between compute time and policy optimality as the problem's complexity grows.","This work facilitates more efficient and flexible contingency planning in the context of scientific missions."],"url":"http://arxiv.org/abs/2402.16342v1"}
{"created":"2024-02-26 06:36:32","title":"BLO-SAM: Bi-level Optimization Based Overfitting-Preventing Finetuning of SAM","abstract":"The Segment Anything Model (SAM), a foundation model pretrained on millions of images and segmentation masks, has significantly advanced semantic segmentation, a fundamental task in computer vision. Despite its strengths, SAM encounters two major challenges. Firstly, it struggles with segmenting specific objects autonomously, as it relies on users to manually input prompts like points or bounding boxes to identify targeted objects. Secondly, SAM faces challenges in excelling at specific downstream tasks, like medical imaging, due to a disparity between the distribution of its pretraining data, which predominantly consists of general-domain images, and the data used in downstream tasks. Current solutions to these problems, which involve finetuning SAM, often lead to overfitting, a notable issue in scenarios with very limited data, like in medical imaging. To overcome these limitations, we introduce BLO-SAM, which finetunes SAM based on bi-level optimization (BLO). Our approach allows for automatic image segmentation without the need for manual prompts, by optimizing a learnable prompt embedding. Furthermore, it significantly reduces the risk of overfitting by training the model's weight parameters and the prompt embedding on two separate subsets of the training dataset, each at a different level of optimization. We apply BLO-SAM to diverse semantic segmentation tasks in general and medical domains. The results demonstrate BLO-SAM's superior performance over various state-of-the-art image semantic segmentation methods.","sentences":["The Segment Anything Model (SAM), a foundation model pretrained on millions of images and segmentation masks, has significantly advanced semantic segmentation, a fundamental task in computer vision.","Despite its strengths, SAM encounters two major challenges.","Firstly, it struggles with segmenting specific objects autonomously, as it relies on users to manually input prompts like points or bounding boxes to identify targeted objects.","Secondly, SAM faces challenges in excelling at specific downstream tasks, like medical imaging, due to a disparity between the distribution of its pretraining data, which predominantly consists of general-domain images, and the data used in downstream tasks.","Current solutions to these problems, which involve finetuning SAM, often lead to overfitting, a notable issue in scenarios with very limited data, like in medical imaging.","To overcome these limitations, we introduce BLO-SAM, which finetunes SAM based on bi-level optimization (BLO).","Our approach allows for automatic image segmentation without the need for manual prompts, by optimizing a learnable prompt embedding.","Furthermore, it significantly reduces the risk of overfitting by training the model's weight parameters and the prompt embedding on two separate subsets of the training dataset, each at a different level of optimization.","We apply BLO-SAM to diverse semantic segmentation tasks in general and medical domains.","The results demonstrate BLO-SAM's superior performance over various state-of-the-art image semantic segmentation methods."],"url":"http://arxiv.org/abs/2402.16338v1"}
{"created":"2024-02-26 06:28:54","title":"Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation","abstract":"Social media has emerged as a cornerstone of social movements, wielding significant influence in driving societal change. Simulating the response of the public and forecasting the potential impact has become increasingly important. However, existing methods for simulating such phenomena encounter challenges concerning their efficacy and efficiency in capturing the behaviors of social movement participants. In this paper, we introduce a hybrid framework for social media user simulation, wherein users are categorized into two types. Core users are driven by Large Language Models, while numerous ordinary users are modeled by deductive agent-based models. We further construct a Twitter-like environment to replicate their response dynamics following trigger events. Subsequently, we develop a multi-faceted benchmark SoMoSiMu-Bench for evaluation and conduct comprehensive experiments across real-world datasets. Experimental results demonstrate the effectiveness and flexibility of our method.","sentences":["Social media has emerged as a cornerstone of social movements, wielding significant influence in driving societal change.","Simulating the response of the public and forecasting the potential impact has become increasingly important.","However, existing methods for simulating such phenomena encounter challenges concerning their efficacy and efficiency in capturing the behaviors of social movement participants.","In this paper, we introduce a hybrid framework for social media user simulation, wherein users are categorized into two types.","Core users are driven by Large Language Models, while numerous ordinary users are modeled by deductive agent-based models.","We further construct a Twitter-like environment to replicate their response dynamics following trigger events.","Subsequently, we develop a multi-faceted benchmark SoMoSiMu-Bench for evaluation and conduct comprehensive experiments across real-world datasets.","Experimental results demonstrate the effectiveness and flexibility of our method."],"url":"http://arxiv.org/abs/2402.16333v1"}
{"created":"2024-02-26 06:22:41","title":"A Joint Communication and Computation Design for Probabilistic Semantic Communications","abstract":"In this paper, the problem of joint transmission and computation resource allocation for a multi-user probabilistic semantic communication (PSC) network is investigated. In the considered model, users employ semantic information extraction techniques to compress their large-sized data before transmitting them to a multi-antenna base station (BS). Our model represents large-sized data through substantial knowledge graphs, utilizing shared probability graphs between the users and the BS for efficient semantic compression. The resource allocation problem is formulated as an optimization problem with the objective of maximizing the sum of equivalent rate of all users, considering total power budget and semantic resource limit constraints. The computation load considered in the PSC network is formulated as a non-smooth piecewise function with respect to the semantic compression ratio. To tackle this non-convex non-smooth optimization challenge, a three-stage algorithm is proposed where the solutions for the receive beamforming matrix of the BS, transmit power of each user, and semantic compression ratio of each user are obtained stage by stage. Numerical results validate the effectiveness of our proposed scheme.","sentences":["In this paper, the problem of joint transmission and computation resource allocation for a multi-user probabilistic semantic communication (PSC) network is investigated.","In the considered model, users employ semantic information extraction techniques to compress their large-sized data before transmitting them to a multi-antenna base station (BS).","Our model represents large-sized data through substantial knowledge graphs, utilizing shared probability graphs between the users and the BS for efficient semantic compression.","The resource allocation problem is formulated as an optimization problem with the objective of maximizing the sum of equivalent rate of all users, considering total power budget and semantic resource limit constraints.","The computation load considered in the PSC network is formulated as a non-smooth piecewise function with respect to the semantic compression ratio.","To tackle this non-convex non-smooth optimization challenge, a three-stage algorithm is proposed where the solutions for the receive beamforming matrix of the BS, transmit power of each user, and semantic compression ratio of each user are obtained stage by stage.","Numerical results validate the effectiveness of our proposed scheme."],"url":"http://arxiv.org/abs/2402.16328v1"}
{"created":"2024-02-26 06:21:01","title":"Deep Rating Elicitation for New Users in Collaborative Filtering","abstract":"Recent recommender systems started to use rating elicitation, which asks new users to rate a small seed itemset for inferring their preferences, to improve the quality of initial recommendations. The key challenge of the rating elicitation is to choose the seed items which can best infer the new users' preference. This paper proposes a novel end-to-end Deep learning framework for Rating Elicitation (DRE), that chooses all the seed items at a time with consideration of the non-linear interactions. To this end, it first defines categorical distributions to sample seed items from the entire itemset, then it trains both the categorical distributions and a neural reconstruction network to infer users' preferences on the remaining items from CF information of the sampled seed items. Through the end-to-end training, the categorical distributions are learned to select the most representative seed items while reflecting the complex non-linear interactions. Experimental results show that DRE outperforms the state-of-the-art approaches in the recommendation quality by accurately inferring the new users' preferences and its seed itemset better represents the latent space than the seed itemset obtained by the other methods.","sentences":["Recent recommender systems started to use rating elicitation, which asks new users to rate a small seed itemset for inferring their preferences, to improve the quality of initial recommendations.","The key challenge of the rating elicitation is to choose the seed items which can best infer the new users' preference.","This paper proposes a novel end-to-end Deep learning framework for Rating Elicitation (DRE), that chooses all the seed items at a time with consideration of the non-linear interactions.","To this end, it first defines categorical distributions to sample seed items from the entire itemset, then it trains both the categorical distributions and a neural reconstruction network to infer users' preferences on the remaining items from CF information of the sampled seed items.","Through the end-to-end training, the categorical distributions are learned to select the most representative seed items while reflecting the complex non-linear interactions.","Experimental results show that DRE outperforms the state-of-the-art approaches in the recommendation quality by accurately inferring the new users' preferences and its seed itemset better represents the latent space than the seed itemset obtained by the other methods."],"url":"http://arxiv.org/abs/2402.16327v1"}
{"created":"2024-02-26 06:13:24","title":"Confidence Calibration for Recommender Systems and Its Applications","abstract":"Despite the importance of having a measure of confidence in recommendation results, it has been surprisingly overlooked in the literature compared to the accuracy of the recommendation. In this dissertation, I propose a model calibration framework for recommender systems for estimating accurate confidence in recommendation results based on the learned ranking scores. Moreover, I subsequently introduce two real-world applications of confidence on recommendations: (1) Training a small student model by treating the confidence of a big teacher model as additional learning guidance, (2) Adjusting the number of presented items based on the expected user utility estimated with calibrated probability.","sentences":["Despite the importance of having a measure of confidence in recommendation results, it has been surprisingly overlooked in the literature compared to the accuracy of the recommendation.","In this dissertation, I propose a model calibration framework for recommender systems for estimating accurate confidence in recommendation results based on the learned ranking scores.","Moreover, I subsequently introduce two real-world applications of confidence on recommendations: (1) Training a small student model by treating the confidence of a big teacher model as additional learning guidance, (2) Adjusting the number of presented items based on the expected user utility estimated with calibrated probability."],"url":"http://arxiv.org/abs/2402.16325v1"}
{"created":"2024-02-26 06:08:25","title":"Achieving $\\tilde{O}(1/\u03b5)$ Sample Complexity for Constrained Markov Decision Process","abstract":"We consider the reinforcement learning problem for the constrained Markov decision process (CMDP), which plays a central role in satisfying safety or resource constraints in sequential learning and decision-making. In this problem, we are given finite resources and a MDP with unknown transition probabilities. At each stage, we take an action, collecting a reward and consuming some resources, all assumed to be unknown and need to be learned over time. In this work, we take the first step towards deriving optimal problem-dependent guarantees for the CMDP problems. We derive a logarithmic regret bound, which translates into a $O(\\frac{\\kappa}{\\epsilon}\\cdot\\log^2(1/\\epsilon))$ sample complexity bound, with $\\kappa$ being a problem-dependent parameter, yet independent of $\\epsilon$. Our sample complexity bound improves upon the state-of-art $O(1/\\epsilon^2)$ sample complexity for CMDP problems established in the previous literature, in terms of the dependency on $\\epsilon$. To achieve this advance, we develop a new framework for analyzing CMDP problems. To be specific, our algorithm operates in the primal space and we resolve the primal LP for the CMDP problem at each period in an online manner, with \\textit{adaptive} remaining resource capacities. The key elements of our algorithm are: i). an eliminating procedure that characterizes one optimal basis of the primal LP, and; ii) a resolving procedure that is adaptive to the remaining resources and sticks to the characterized optimal basis.","sentences":["We consider the reinforcement learning problem for the constrained Markov decision process (CMDP), which plays a central role in satisfying safety or resource constraints in sequential learning and decision-making.","In this problem, we are given finite resources and a MDP with unknown transition probabilities.","At each stage, we take an action, collecting a reward and consuming some resources, all assumed to be unknown and need to be learned over time.","In this work, we take the first step towards deriving optimal problem-dependent guarantees for the CMDP problems.","We derive a logarithmic regret bound, which translates into a $O(\\frac{\\kappa}{\\epsilon}\\cdot\\log^2(1/\\epsilon))$ sample complexity bound, with $\\kappa$ being a problem-dependent parameter, yet independent of $\\epsilon$. Our sample complexity bound improves upon the state-of-art $O(1/\\epsilon^2)$ sample complexity for CMDP problems established in the previous literature, in terms of the dependency on $\\epsilon$. To achieve this advance, we develop a new framework for analyzing CMDP problems.","To be specific, our algorithm operates in the primal space and we resolve the primal LP for the CMDP problem at each period in an online manner, with \\textit{adaptive} remaining resource capacities.","The key elements of our algorithm are: i).","an eliminating procedure that characterizes one optimal basis of the primal LP, and; ii) a resolving procedure that is adaptive to the remaining resources and sticks to the characterized optimal basis."],"url":"http://arxiv.org/abs/2402.16324v1"}
{"created":"2024-02-26 06:08:11","title":"Algorithms for Halfplane Coverage and Related Problems","abstract":"Given in the plane a set of points and a set of halfplanes, we consider the problem of computing a smallest subset of halfplanes whose union covers all points. In this paper, we present an $O(n^{4/3}\\log^{5/3}n\\log^{O(1)}\\log n)$-time algorithm for the problem, where $n$ is the total number of all points and halfplanes. This improves the previously best algorithm of $n^{10/3}2^{O(\\log^*n)}$ time by roughly a quadratic factor. For the special case where all halfplanes are lower ones, our algorithm runs in $O(n\\log n)$ time, which improves the previously best algorithm of $n^{4/3}2^{O(\\log^*n)}$ time and matches an $\\Omega(n\\log n)$ lower bound. Further, our techniques can be extended to solve a star-shaped polygon coverage problem in $O(n\\log n)$ time, which in turn leads to an $O(n\\log n)$-time algorithm for computing an instance-optimal $\\epsilon$-kernel of a set of $n$ points in the plane. Agarwal and Har-Peled presented an $O(nk\\log n)$-time algorithm for this problem in SoCG 2023, where $k$ is the size of the $\\epsilon$-kernel; they also raised an open question whether the problem can be solved in $O(n\\log n)$ time. Our result thus answers the open question affirmatively.","sentences":["Given in the plane a set of points and a set of halfplanes, we consider the problem of computing a smallest subset of halfplanes whose union covers all points.","In this paper, we present an $O(n^{4/3}\\log^{5/3}n\\log^{O(1)}\\log n)$-time algorithm for the problem, where $n$ is the total number of all points and halfplanes.","This improves the previously best algorithm of $n^{10/3}2^{O(\\log^*n)}$ time by roughly a quadratic factor.","For the special case where all halfplanes are lower ones, our algorithm runs in $O(n\\log n)$ time, which improves the previously best algorithm of $n^{4/3}2^{O(\\log^*n)}$ time and matches an $\\Omega(n\\log n)$ lower bound.","Further, our techniques can be extended to solve a star-shaped polygon coverage problem in $O(n\\log n)$ time, which in turn leads to an $O(n\\log n)$-time algorithm for computing an instance-optimal $\\epsilon$-kernel of a set of $n$ points in the plane.","Agarwal and Har-Peled presented an $O(nk\\log n)$-time algorithm for this problem in SoCG 2023, where $k$ is the size of the $\\epsilon$-kernel; they also raised an open question whether the problem can be solved in $O(n\\log n)$ time.","Our result thus answers the open question affirmatively."],"url":"http://arxiv.org/abs/2402.16323v1"}
{"created":"2024-02-26 06:01:38","title":"Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech","abstract":"Speech quality estimation has recently undergone a paradigm shift from human-hearing expert designs to machine-learning models. However, current models rely mainly on supervised learning, which is time-consuming and expensive for label collection. To solve this problem, we propose VQScore, a self-supervised metric for evaluating speech based on the quantization error of a vector-quantized-variational autoencoder (VQ-VAE). The training of VQ-VAE relies on clean speech; hence, large quantization errors can be expected when the speech is distorted. To further improve correlation with real quality scores, domain knowledge of speech processing is incorporated into the model design. We found that the vector quantization mechanism could also be used for self-supervised speech enhancement (SE) model training. To improve the robustness of the encoder for SE, a novel self-distillation mechanism combined with adversarial training is introduced. In summary, the proposed speech quality estimation method and enhancement models require only clean speech for training without any label requirements. Experimental results show that the proposed VQScore and enhancement model are competitive with supervised baselines. The code will be released after publication.","sentences":["Speech quality estimation has recently undergone a paradigm shift from human-hearing expert designs to machine-learning models.","However, current models rely mainly on supervised learning, which is time-consuming and expensive for label collection.","To solve this problem, we propose VQScore, a self-supervised metric for evaluating speech based on the quantization error of a vector-quantized-variational autoencoder (VQ-VAE).","The training of VQ-VAE relies on clean speech; hence, large quantization errors can be expected when the speech is distorted.","To further improve correlation with real quality scores, domain knowledge of speech processing is incorporated into the model design.","We found that the vector quantization mechanism could also be used for self-supervised speech enhancement (SE) model training.","To improve the robustness of the encoder for SE, a novel self-distillation mechanism combined with adversarial training is introduced.","In summary, the proposed speech quality estimation method and enhancement models require only clean speech for training without any label requirements.","Experimental results show that the proposed VQScore and enhancement model are competitive with supervised baselines.","The code will be released after publication."],"url":"http://arxiv.org/abs/2402.16321v1"}
{"created":"2024-02-26 05:51:47","title":"Data-freeWeight Compress and Denoise for Large Language Models","abstract":"Large Language Models (LLMs) are reshaping the research landscape in artificial intelligence, particularly as model parameters scale up significantly, unlocking remarkable capabilities across various domains. Nevertheless, the scalability of model parameters faces constraints due to limitations in GPU memory and computational speed. To address these constraints, various weight compression methods have emerged, such as Pruning and Quantization. Given the low-rank nature of weight matrices in language models, the reduction of weights through matrix decomposition undoubtedly holds significant potential and promise. In this paper, drawing upon the intrinsic structure of LLMs, we propose a novel approach termed Data-free Joint Rank-k Approximation for compressing the parameter matrices. Significantly, our method is characterized by without necessitating additional involvement of any corpus, while simultaneously preserving orthogonality in conjunction with pruning and quantization methods. We achieve a model pruning of 80% parameters while retaining 93.43% of the original performance without any calibration data. Additionally, we explore the fundamental properties of the weight matrix of LLMs undergone Rank-k Approximation and conduct comprehensive experiments to elucidate our hypothesis.","sentences":["Large Language Models (LLMs) are reshaping the research landscape in artificial intelligence, particularly as model parameters scale up significantly, unlocking remarkable capabilities across various domains.","Nevertheless, the scalability of model parameters faces constraints due to limitations in GPU memory and computational speed.","To address these constraints, various weight compression methods have emerged, such as Pruning and Quantization.","Given the low-rank nature of weight matrices in language models, the reduction of weights through matrix decomposition undoubtedly holds significant potential and promise.","In this paper, drawing upon the intrinsic structure of LLMs, we propose a novel approach termed Data-free Joint Rank-k Approximation for compressing the parameter matrices.","Significantly, our method is characterized by without necessitating additional involvement of any corpus, while simultaneously preserving orthogonality in conjunction with pruning and quantization methods.","We achieve a model pruning of 80% parameters while retaining 93.43% of the original performance without any calibration data.","Additionally, we explore the fundamental properties of the weight matrix of LLMs undergone Rank-k Approximation and conduct comprehensive experiments to elucidate our hypothesis."],"url":"http://arxiv.org/abs/2402.16319v1"}
{"created":"2024-02-26 05:50:43","title":"Gradient-Guided Modality Decoupling for Missing-Modality Robustness","abstract":"Multimodal learning with incomplete input data (missing modality) is practical and challenging. In this work, we conduct an in-depth analysis of this challenge and find that modality dominance has a significant negative impact on the model training, greatly degrading the missing modality performance. Motivated by Grad-CAM, we introduce a novel indicator, gradients, to monitor and reduce modality dominance which widely exists in the missing-modality scenario. In aid of this indicator, we present a novel Gradient-guided Modality Decoupling (GMD) method to decouple the dependency on dominating modalities. Specifically, GMD removes the conflicted gradient components from different modalities to achieve this decoupling, significantly improving the performance. In addition, to flexibly handle modal-incomplete data, we design a parameter-efficient Dynamic Sharing (DS) framework which can adaptively switch on/off the network parameters based on whether one modality is available. We conduct extensive experiments on three popular multimodal benchmarks, including BraTS 2018 for medical segmentation, CMU-MOSI, and CMU-MOSEI for sentiment analysis. The results show that our method can significantly outperform the competitors, showing the effectiveness of the proposed solutions. Our code is released here: https://github.com/HaoWang420/Gradient-guided-Modality-Decoupling.","sentences":["Multimodal learning with incomplete input data (missing modality) is practical and challenging.","In this work, we conduct an in-depth analysis of this challenge and find that modality dominance has a significant negative impact on the model training, greatly degrading the missing modality performance.","Motivated by Grad-CAM, we introduce a novel indicator, gradients, to monitor and reduce modality dominance which widely exists in the missing-modality scenario.","In aid of this indicator, we present a novel Gradient-guided Modality Decoupling (GMD) method to decouple the dependency on dominating modalities.","Specifically, GMD removes the conflicted gradient components from different modalities to achieve this decoupling, significantly improving the performance.","In addition, to flexibly handle modal-incomplete data, we design a parameter-efficient Dynamic Sharing (DS) framework which can adaptively switch on/off the network parameters based on whether one modality is available.","We conduct extensive experiments on three popular multimodal benchmarks, including BraTS 2018 for medical segmentation, CMU-MOSI, and CMU-MOSEI for sentiment analysis.","The results show that our method can significantly outperform the competitors, showing the effectiveness of the proposed solutions.","Our code is released here: https://github.com/HaoWang420/Gradient-guided-Modality-Decoupling."],"url":"http://arxiv.org/abs/2402.16318v1"}
{"created":"2024-02-26 05:44:24","title":"Polynomial-Time Computation of Exact $\u03a6$-Equilibria in Polyhedral Games","abstract":"It is a well-known fact that correlated equilibria can be computed in polynomial time in a large class of concisely represented games using the celebrated Ellipsoid Against Hope algorithm (Papadimitriou and Roughgarden, 2008; Jiang and Leyton-Brown, 2015). However, the landscape of efficiently computable equilibria in sequential (extensive-form) games remains unknown. The Ellipsoid Against Hope does not apply directly to these games, because they do not have the required \"polynomial type\" property. Despite this barrier, Huang and von Stengel (2008) altered the algorithm to compute exact extensive-form correlated equilibria.   In this paper, we generalize the Ellipsoid Against Hope and develop a simple algorithmic framework for efficiently computing saddle-points in bilinear zero-sum games, even when one of the dimensions is exponentially large. Moreover, the framework only requires a \"good-enough-response\" oracle, which is a weakened notion of a best-response oracle.   Using this machinery, we develop a general algorithmic framework for computing exact linear $\\Phi$-equilibria in any polyhedral game (under mild assumptions), including correlated equilibria in normal-form games, and extensive-form correlated equilibria in extensive-form games. This enables us to give the first polynomial-time algorithm for computing exact linear-deviation correlated equilibria in extensive-form games, thus resolving an open question by Farina and Pipis (2023). Furthermore, even for the cases for which a polynomial time algorithm for exact equilibria was already known, our framework provides a conceptually simpler solution.","sentences":["It is a well-known fact that correlated equilibria can be computed in polynomial time in a large class of concisely represented games using the celebrated Ellipsoid Against Hope algorithm (Papadimitriou and Roughgarden, 2008; Jiang and Leyton-Brown, 2015).","However, the landscape of efficiently computable equilibria in sequential (extensive-form) games remains unknown.","The Ellipsoid Against Hope does not apply directly to these games, because they do not have the required \"polynomial type\" property.","Despite this barrier, Huang and von Stengel (2008) altered the algorithm to compute exact extensive-form correlated equilibria.   ","In this paper, we generalize the Ellipsoid Against Hope and develop a simple algorithmic framework for efficiently computing saddle-points in bilinear zero-sum games, even when one of the dimensions is exponentially large.","Moreover, the framework only requires a \"good-enough-response\" oracle, which is a weakened notion of a best-response oracle.   ","Using this machinery, we develop a general algorithmic framework for computing exact linear $\\Phi$-equilibria in any polyhedral game (under mild assumptions), including correlated equilibria in normal-form games, and extensive-form correlated equilibria in extensive-form games.","This enables us to give the first polynomial-time algorithm for computing exact linear-deviation correlated equilibria in extensive-form games, thus resolving an open question by Farina and Pipis (2023).","Furthermore, even for the cases for which a polynomial time algorithm for exact equilibria was already known, our framework provides a conceptually simpler solution."],"url":"http://arxiv.org/abs/2402.16316v1"}
{"created":"2024-02-26 05:43:51","title":"Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models","abstract":"Recent advances in instruction-tuned Large Vision-Language Models (LVLMs) have imbued the models with the ability to generate high-level, image-grounded explanations with ease. While such capability is largely attributed to the rich world knowledge contained within the Large Language Models (LLMs), our work reveals their shortcomings in fine-grained visual categorization (FGVC) across six different benchmark settings. Most recent state-of-the-art LVLMs like LLaVa-1.5, InstructBLIP and GPT-4V not only severely deteriorate in terms of classification performance, e.g., average drop of 65.58 in EM for Stanford Dogs for LLaVA-1.5, but also struggle to generate an accurate explanation with detailed attributes based on the concept that appears within an input image despite their capability to generate holistic image-level descriptions. In-depth analyses show that instruction-tuned LVLMs exhibit modality gap, showing discrepancy when given textual and visual inputs that correspond to the same concept, preventing the image modality from leveraging the rich parametric knowledge within the LLMs. In an effort to further the community's endeavor in this direction, we propose a multiple granularity attribute-centric evaluation benchmark, Finer, which aims to establish a ground to evaluate LVLMs' fine-grained visual comprehension ability and provide significantly improved explainability.","sentences":["Recent advances in instruction-tuned Large Vision-Language Models (LVLMs) have imbued the models with the ability to generate high-level, image-grounded explanations with ease.","While such capability is largely attributed to the rich world knowledge contained within the Large Language Models (LLMs), our work reveals their shortcomings in fine-grained visual categorization (FGVC) across six different benchmark settings.","Most recent state-of-the-art LVLMs like LLaVa-1.5, InstructBLIP and GPT-4V","not only severely deteriorate in terms of classification performance, e.g., average drop of 65.58 in EM for Stanford Dogs for LLaVA-1.5, but also struggle to generate an accurate explanation with detailed attributes based on the concept that appears within an input image despite their capability to generate holistic image-level descriptions.","In-depth analyses show that instruction-tuned LVLMs exhibit modality gap, showing discrepancy when given textual and visual inputs that correspond to the same concept, preventing the image modality from leveraging the rich parametric knowledge within the LLMs.","In an effort to further the community's endeavor in this direction, we propose a multiple granularity attribute-centric evaluation benchmark, Finer, which aims to establish a ground to evaluate LVLMs' fine-grained visual comprehension ability and provide significantly improved explainability."],"url":"http://arxiv.org/abs/2402.16315v1"}
{"created":"2024-02-26 05:43:48","title":"Equational Bit-Vector Solving via Strong Gr\u00f6bner Bases","abstract":"Bit-vectors, which are integers in a finite number of bits, are ubiquitous in software and hardware systems. In this work, we consider the satisfiability modulo theories (SMT) of bit-vectors. Unlike normal integers, the arithmetics of bit-vectors are modular upon integer overflow. Therefore, the SMT solving of bit-vectors needs to resolve the underlying modular arithmetics. In the literature, two prominent approaches for SMT solving are bit-blasting (that transforms the SMT problem into boolean satisfiability) and integer solving (that transforms the SMT problem into integer properties). Both approaches ignore the algebraic properties of the modular arithmetics and hence could not utilize these properties to improve the efficiency of SMT solving.   In this work, we consider the equational theory of bit-vectors and capture the algebraic properties behind them via strong Gr\\\"obner bases. First, we apply strong Gr\\\"obner bases to the quantifier-free equational theory of bit-vectors and propose a novel algorithmic improvement in the key computation of multiplicative inverse modulo a power of two. Second, we resolve the important case of invariant generation in quantified equational bit-vector properties via strong Gr\\\"obner bases and linear congruence solving. Experimental results over an extensive range of benchmarks show that our approach outperforms existing methods in both time efficiency and memory consumption.","sentences":["Bit-vectors, which are integers in a finite number of bits, are ubiquitous in software and hardware systems.","In this work, we consider the satisfiability modulo theories (SMT) of bit-vectors.","Unlike normal integers, the arithmetics of bit-vectors are modular upon integer overflow.","Therefore, the SMT solving of bit-vectors needs to resolve the underlying modular arithmetics.","In the literature, two prominent approaches for SMT solving are bit-blasting (that transforms the SMT problem into boolean satisfiability) and integer solving (that transforms the SMT problem into integer properties).","Both approaches ignore the algebraic properties of the modular arithmetics and hence could not utilize these properties to improve the efficiency of SMT solving.   ","In this work, we consider the equational theory of bit-vectors and capture the algebraic properties behind them via strong Gr\\\"obner bases.","First, we apply strong Gr\\\"obner bases to the quantifier-free equational theory of bit-vectors and propose a novel algorithmic improvement in the key computation of multiplicative inverse modulo a power of two.","Second, we resolve the important case of invariant generation in quantified equational bit-vector properties via strong Gr\\\"obner bases and linear congruence solving.","Experimental results over an extensive range of benchmarks show that our approach outperforms existing methods in both time efficiency and memory consumption."],"url":"http://arxiv.org/abs/2402.16314v1"}
{"created":"2024-02-26 05:31:34","title":"Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering","abstract":"Open-ended question answering requires models to find appropriate evidence to form well-reasoned, comprehensive and helpful answers. In practical applications, models also need to engage in extended discussions on potential scenarios closely relevant to the question. With augmentation of retrieval module, open-source Large Language Models (LLMs) can produce coherent answers often with different focuses, but are still sub-optimal in terms of reliable evidence selection and in-depth question analysis. In this paper, we propose a novel Chain-of-Discussion framework to leverage the synergy among multiple open-source LLMs aiming to provide \\textbf{more correct} and \\textbf{more comprehensive} answers for open-ended QA, although they are not strong enough individually. Our experiments show that discussions among multiple LLMs play a vital role in enhancing the quality of answers. We release our data and code at \\url{https://github.com/kobayashikanna01/Chain-of-Discussion}.","sentences":["Open-ended question answering requires models to find appropriate evidence to form well-reasoned, comprehensive and helpful answers.","In practical applications, models also need to engage in extended discussions on potential scenarios closely relevant to the question.","With augmentation of retrieval module, open-source Large Language Models (LLMs) can produce coherent answers often with different focuses, but are still sub-optimal in terms of reliable evidence selection and in-depth question analysis.","In this paper, we propose a novel Chain-of-Discussion framework to leverage the synergy among multiple open-source LLMs aiming to provide \\textbf{more correct} and \\textbf{more comprehensive} answers for open-ended QA, although they are not strong enough individually.","Our experiments show that discussions among multiple LLMs play a vital role in enhancing the quality of answers.","We release our data and code at \\url{https://github.com/kobayashikanna01/Chain-of-Discussion}."],"url":"http://arxiv.org/abs/2402.16313v1"}
{"created":"2024-02-26 05:31:14","title":"Federated Contextual Cascading Bandits with Asynchronous Communication and Heterogeneous Users","abstract":"We study the problem of federated contextual combinatorial cascading bandits, where $|\\mathcal{U}|$ agents collaborate under the coordination of a central server to provide tailored recommendations to the $|\\mathcal{U}|$ corresponding users. Existing works consider either a synchronous framework, necessitating full agent participation and global synchronization, or assume user homogeneity with identical behaviors. We overcome these limitations by considering (1) federated agents operating in an asynchronous communication paradigm, where no mandatory synchronization is required and all agents communicate independently with the server, (2) heterogeneous user behaviors, where users can be stratified into $J \\le |\\mathcal{U}|$ latent user clusters, each exhibiting distinct preferences. For this setting, we propose a UCB-type algorithm with delicate communication protocols. Through theoretical analysis, we give sub-linear regret bounds on par with those achieved in the synchronous framework, while incurring only logarithmic communication costs. Empirical evaluation on synthetic and real-world datasets validates our algorithm's superior performance in terms of regrets and communication costs.","sentences":["We study the problem of federated contextual combinatorial cascading bandits, where $|\\mathcal{U}|$ agents collaborate under the coordination of a central server to provide tailored recommendations to the $|\\mathcal{U}|$ corresponding users.","Existing works consider either a synchronous framework, necessitating full agent participation and global synchronization, or assume user homogeneity with identical behaviors.","We overcome these limitations by considering (1) federated agents operating in an asynchronous communication paradigm, where no mandatory synchronization is required and all agents communicate independently with the server, (2) heterogeneous user behaviors, where users can be stratified into $J \\le |\\mathcal{U}|$ latent user clusters, each exhibiting distinct preferences.","For this setting, we propose a UCB-type algorithm with delicate communication protocols.","Through theoretical analysis, we give sub-linear regret bounds on par with those achieved in the synchronous framework, while incurring only logarithmic communication costs.","Empirical evaluation on synthetic and real-world datasets validates our algorithm's superior performance in terms of regrets and communication costs."],"url":"http://arxiv.org/abs/2402.16312v1"}
{"created":"2024-02-26 05:30:48","title":"Cross-domain Chinese Sentence Pattern Parsing","abstract":"Sentence Pattern Structure (SPS) parsing is a syntactic analysis method primarily employed in language teaching.Existing SPS parsers rely heavily on textbook corpora for training, lacking cross-domain capability.To overcome this constraint, this paper proposes an innovative approach leveraging large language models (LLMs) within a self-training framework. Partial syntactic rules from a source domain are combined with target domain sentences to dynamically generate training data, enhancing the adaptability of the parser to diverse domains.Experiments conducted on textbook and news domains demonstrate the effectiveness of the proposed method, outperforming rule-based baselines by 1.68 points on F1 metrics.","sentences":["Sentence Pattern Structure (SPS) parsing is a syntactic analysis method primarily employed in language teaching.","Existing SPS parsers rely heavily on textbook corpora for training, lacking cross-domain capability.","To overcome this constraint, this paper proposes an innovative approach leveraging large language models (LLMs) within a self-training framework.","Partial syntactic rules from a source domain are combined with target domain sentences to dynamically generate training data, enhancing the adaptability of the parser to diverse domains.","Experiments conducted on textbook and news domains demonstrate the effectiveness of the proposed method, outperforming rule-based baselines by 1.68 points on F1 metrics."],"url":"http://arxiv.org/abs/2402.16311v1"}
{"created":"2024-02-26 05:28:36","title":"REPLAY: Modeling Time-Varying Temporal Regularities of Human Mobility for Location Prediction over Sparse Trajectories","abstract":"Location prediction forecasts a user's location based on historical user mobility traces. To tackle the intrinsic sparsity issue of real-world user mobility traces, spatiotemporal contexts have been shown as significantly useful. Existing solutions mostly incorporate spatiotemporal distances between locations in mobility traces, either by feeding them as additional inputs to Recurrent Neural Networks (RNNs) or by using them to search for informative past hidden states for prediction. However, such distance-based methods fail to capture the time-varying temporal regularities of human mobility, where human mobility is often more regular in the morning than in other periods, for example; this suggests the usefulness of the actual timestamps besides the temporal distances. Against this background, we propose REPLAY, a general RNN architecture learning to capture the time-varying temporal regularities for location prediction. Specifically, REPLAY not only resorts to the spatiotemporal distances in sparse trajectories to search for the informative past hidden states, but also accommodates the time-varying temporal regularities by incorporating smoothed timestamp embeddings using Gaussian weighted averaging with timestamp-specific learnable bandwidths, which can flexibly adapt to the temporal regularities of different strengths across different timestamps. Our extensive evaluation compares REPLAY against a sizable collection of state-of-the-art techniques on two real-world datasets. Results show that REPLAY consistently and significantly outperforms state-of-the-art methods by 7.7\\%-10.9\\% in the location prediction task, and the bandwidths reveal interesting patterns of the time-varying temporal regularities.","sentences":["Location prediction forecasts a user's location based on historical user mobility traces.","To tackle the intrinsic sparsity issue of real-world user mobility traces, spatiotemporal contexts have been shown as significantly useful.","Existing solutions mostly incorporate spatiotemporal distances between locations in mobility traces, either by feeding them as additional inputs to Recurrent Neural Networks (RNNs) or by using them to search for informative past hidden states for prediction.","However, such distance-based methods fail to capture the time-varying temporal regularities of human mobility, where human mobility is often more regular in the morning than in other periods, for example; this suggests the usefulness of the actual timestamps besides the temporal distances.","Against this background, we propose REPLAY, a general RNN architecture learning to capture the time-varying temporal regularities for location prediction.","Specifically, REPLAY not only resorts to the spatiotemporal distances in sparse trajectories to search for the informative past hidden states, but also accommodates the time-varying temporal regularities by incorporating smoothed timestamp embeddings using Gaussian weighted averaging with timestamp-specific learnable bandwidths, which can flexibly adapt to the temporal regularities of different strengths across different timestamps.","Our extensive evaluation compares REPLAY against a sizable collection of state-of-the-art techniques on two real-world datasets.","Results show that REPLAY consistently and significantly outperforms state-of-the-art methods by 7.7\\%-10.9\\% in the location prediction task, and the bandwidths reveal interesting patterns of the time-varying temporal regularities."],"url":"http://arxiv.org/abs/2402.16310v1"}
{"created":"2024-02-26 05:17:06","title":"DreamUp3D: Object-Centric Generative Models for Single-View 3D Scene Understanding and Real-to-Sim Transfer","abstract":"3D scene understanding for robotic applications exhibits a unique set of requirements including real-time inference, object-centric latent representation learning, accurate 6D pose estimation and 3D reconstruction of objects. Current methods for scene understanding typically rely on a combination of trained models paired with either an explicit or learnt volumetric representation, all of which have their own drawbacks and limitations. We introduce DreamUp3D, a novel Object-Centric Generative Model (OCGM) designed explicitly to perform inference on a 3D scene informed only by a single RGB-D image. DreamUp3D is a self-supervised model, trained end-to-end, and is capable of segmenting objects, providing 3D object reconstructions, generating object-centric latent representations and accurate per-object 6D pose estimates. We compare DreamUp3D to baselines including NeRFs, pre-trained CLIP-features, ObSurf, and ObPose, in a range of tasks including 3D scene reconstruction, object matching and object pose estimation. Our experiments show that our model outperforms all baselines by a significant margin in real-world scenarios displaying its applicability for 3D scene understanding tasks while meeting the strict demands exhibited in robotics applications.","sentences":["3D scene understanding for robotic applications exhibits a unique set of requirements including real-time inference, object-centric latent representation learning, accurate 6D pose estimation and 3D reconstruction of objects.","Current methods for scene understanding typically rely on a combination of trained models paired with either an explicit or learnt volumetric representation, all of which have their own drawbacks and limitations.","We introduce DreamUp3D, a novel Object-Centric Generative Model (OCGM) designed explicitly to perform inference on a 3D scene informed only by a single RGB-D image.","DreamUp3D is a self-supervised model, trained end-to-end, and is capable of segmenting objects, providing 3D object reconstructions, generating object-centric latent representations and accurate per-object 6D pose estimates.","We compare DreamUp3D to baselines including NeRFs, pre-trained CLIP-features, ObSurf, and ObPose, in a range of tasks including 3D scene reconstruction, object matching and object pose estimation.","Our experiments show that our model outperforms all baselines by a significant margin in real-world scenarios displaying its applicability for 3D scene understanding tasks while meeting the strict demands exhibited in robotics applications."],"url":"http://arxiv.org/abs/2402.16308v1"}
{"created":"2024-02-26 05:08:40","title":"Referee Can Play: An Alternative Approach to Conditional Generation via Model Inversion","abstract":"As a dominant force in text-to-image generation tasks, Diffusion Probabilistic Models (DPMs) face a critical challenge in controllability, struggling to adhere strictly to complex, multi-faceted instructions. In this work, we aim to address this alignment challenge for conditional generation tasks. First, we provide an alternative view of state-of-the-art DPMs as a way of inverting advanced Vision-Language Models (VLMs). With this formulation, we naturally propose a training-free approach that bypasses the conventional sampling process associated with DPMs. By directly optimizing images with the supervision of discriminative VLMs, the proposed method can potentially achieve a better text-image alignment. As proof of concept, we demonstrate the pipeline with the pre-trained BLIP-2 model and identify several key designs for improved image generation. To further enhance the image fidelity, a Score Distillation Sampling module of Stable Diffusion is incorporated. By carefully balancing the two components during optimization, our method can produce high-quality images with near state-of-the-art performance on T2I-Compbench.","sentences":["As a dominant force in text-to-image generation tasks, Diffusion Probabilistic Models (DPMs) face a critical challenge in controllability, struggling to adhere strictly to complex, multi-faceted instructions.","In this work, we aim to address this alignment challenge for conditional generation tasks.","First, we provide an alternative view of state-of-the-art DPMs as a way of inverting advanced Vision-Language Models (VLMs).","With this formulation, we naturally propose a training-free approach that bypasses the conventional sampling process associated with DPMs.","By directly optimizing images with the supervision of discriminative VLMs, the proposed method can potentially achieve a better text-image alignment.","As proof of concept, we demonstrate the pipeline with the pre-trained BLIP-2 model and identify several key designs for improved image generation.","To further enhance the image fidelity, a Score Distillation Sampling module of Stable Diffusion is incorporated.","By carefully balancing the two components during optimization, our method can produce high-quality images with near state-of-the-art performance on T2I-Compbench."],"url":"http://arxiv.org/abs/2402.16305v1"}
