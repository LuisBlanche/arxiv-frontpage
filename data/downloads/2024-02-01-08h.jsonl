{"created":"2024-01-31 18:59:59","title":"Motion Guidance: Diffusion-Based Image Editing with Differentiable Motion Estimators","abstract":"Diffusion models are capable of generating impressive images conditioned on text descriptions, and extensions of these models allow users to edit images at a relatively coarse scale. However, the ability to precisely edit the layout, position, pose, and shape of objects in images with diffusion models is still difficult. To this end, we propose motion guidance, a zero-shot technique that allows a user to specify dense, complex motion fields that indicate where each pixel in an image should move. Motion guidance works by steering the diffusion sampling process with the gradients through an off-the-shelf optical flow network. Specifically, we design a guidance loss that encourages the sample to have the desired motion, as estimated by a flow network, while also being visually similar to the source image. By simultaneously sampling from a diffusion model and guiding the sample to have low guidance loss, we can obtain a motion-edited image. We demonstrate that our technique works on complex motions and produces high quality edits of real and generated images.","sentences":["Diffusion models are capable of generating impressive images conditioned on text descriptions, and extensions of these models allow users to edit images at a relatively coarse scale.","However, the ability to precisely edit the layout, position, pose, and shape of objects in images with diffusion models is still difficult.","To this end, we propose motion guidance, a zero-shot technique that allows a user to specify dense, complex motion fields that indicate where each pixel in an image should move.","Motion guidance works by steering the diffusion sampling process with the gradients through an off-the-shelf optical flow network.","Specifically, we design a guidance loss that encourages the sample to have the desired motion, as estimated by a flow network, while also being visually similar to the source image.","By simultaneously sampling from a diffusion model and guiding the sample to have low guidance loss, we can obtain a motion-edited image.","We demonstrate that our technique works on complex motions and produces high quality edits of real and generated images."],"url":"http://arxiv.org/abs/2401.18085v1"}
{"created":"2024-01-31 18:59:57","title":"Binding Touch to Everything: Learning Unified Multimodal Tactile Representations","abstract":"The ability to associate touch with other modalities has huge implications for humans and computational systems. However, multimodal learning with touch remains challenging due to the expensive data collection process and non-standardized sensor outputs. We introduce UniTouch, a unified tactile model for vision-based touch sensors connected to multiple modalities, including vision, language, and sound. We achieve this by aligning our UniTouch embeddings to pretrained image embeddings already associated with a variety of other modalities. We further propose learnable sensor-specific tokens, allowing the model to learn from a set of heterogeneous tactile sensors, all at the same time. UniTouch is capable of conducting various touch sensing tasks in the zero-shot setting, from robot grasping prediction to touch image question answering. To the best of our knowledge, UniTouch is the first to demonstrate such capabilities. Project page: https://cfeng16.github.io/UniTouch/","sentences":["The ability to associate touch with other modalities has huge implications for humans and computational systems.","However, multimodal learning with touch remains challenging due to the expensive data collection process and non-standardized sensor outputs.","We introduce UniTouch, a unified tactile model for vision-based touch sensors connected to multiple modalities, including vision, language, and sound.","We achieve this by aligning our UniTouch embeddings to pretrained image embeddings already associated with a variety of other modalities.","We further propose learnable sensor-specific tokens, allowing the model to learn from a set of heterogeneous tactile sensors, all at the same time.","UniTouch is capable of conducting various touch sensing tasks in the zero-shot setting, from robot grasping prediction to touch image question answering.","To the best of our knowledge, UniTouch is the first to demonstrate such capabilities.","Project page: https://cfeng16.github.io/UniTouch/"],"url":"http://arxiv.org/abs/2401.18084v1"}
{"created":"2024-01-31 18:59:12","title":"Improved Scene Landmark Detection for Camera Localization","abstract":"Camera localization methods based on retrieval, local feature matching, and 3D structure-based pose estimation are accurate but require high storage, are slow, and are not privacy-preserving. A method based on scene landmark detection (SLD) was recently proposed to address these limitations. It involves training a convolutional neural network (CNN) to detect a few predetermined, salient, scene-specific 3D points or landmarks and computing camera pose from the associated 2D-3D correspondences. Although SLD outperformed existing learning-based approaches, it was notably less accurate than 3D structure-based methods. In this paper, we show that the accuracy gap was due to insufficient model capacity and noisy labels during training. To mitigate the capacity issue, we propose to split the landmarks into subgroups and train a separate network for each subgroup. To generate better training labels, we propose using dense reconstructions to estimate visibility of scene landmarks. Finally, we present a compact architecture to improve memory efficiency. Accuracy wise, our approach is on par with state of the art structure based methods on the INDOOR-6 dataset but runs significantly faster and uses less storage. Code and models can be found at https://github.com/microsoft/SceneLandmarkLocalization.","sentences":["Camera localization methods based on retrieval, local feature matching, and 3D structure-based pose estimation are accurate but require high storage, are slow, and are not privacy-preserving.","A method based on scene landmark detection (SLD) was recently proposed to address these limitations.","It involves training a convolutional neural network (CNN) to detect a few predetermined, salient, scene-specific 3D points or landmarks and computing camera pose from the associated 2D-3D correspondences.","Although SLD outperformed existing learning-based approaches, it was notably less accurate than 3D structure-based methods.","In this paper, we show that the accuracy gap was due to insufficient model capacity and noisy labels during training.","To mitigate the capacity issue, we propose to split the landmarks into subgroups and train a separate network for each subgroup.","To generate better training labels, we propose using dense reconstructions to estimate visibility of scene landmarks.","Finally, we present a compact architecture to improve memory efficiency.","Accuracy wise, our approach is on par with state of the art structure based methods on the INDOOR-6 dataset but runs significantly faster and uses less storage.","Code and models can be found at https://github.com/microsoft/SceneLandmarkLocalization."],"url":"http://arxiv.org/abs/2401.18083v1"}
{"created":"2024-01-31 18:58:14","title":"KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization","abstract":"LLMs are seeing growing use for applications such as document analysis and summarization which require large context windows, and with these large context windows KV cache activations surface as the dominant contributor to memory consumption during inference. Quantization is a promising approach for compressing KV cache activations; however, existing solutions fail to represent activations accurately in ultra-low precisions, such as sub-4-bit. In this work, we present KVQuant, which addresses this problem by incorporating novel methods for quantizing cached KV activations, including: (i) Per-Channel Key Quantization, where we adjust the dimension along which we quantize the Key activations to better match the distribution; (ii) Pre-RoPE Key Quantization, where we quantize Key activations before the rotary positional embedding to mitigate its impact on quantization; (iii) Non-Uniform KV Cache Quantization, where we derive per-layer sensitivity-weighted non-uniform datatypes that better represent the distributions; (iv) Per-Vector Dense-and-Sparse Quantization, where we isolate outliers separately for each vector to minimize skews in quantization ranges; and (v) Q-Norm, where we normalize quantization centroids in order to mitigate distribution shift, providing additional benefits for 2-bit quantization. By applying our method to the LLaMA, LLaMA-2, and Mistral models, we achieve $<0.1$ perplexity degradation with 3-bit quantization on both Wikitext-2 and C4, outperforming existing approaches. Our method enables serving the LLaMA-7B model with a context length of up to 1 million on a single A100-80GB GPU and up to 10 million on an 8-GPU system.","sentences":["LLMs are seeing growing use for applications such as document analysis and summarization which require large context windows, and with these large context windows KV cache activations surface as the dominant contributor to memory consumption during inference.","Quantization is a promising approach for compressing KV cache activations; however, existing solutions fail to represent activations accurately in ultra-low precisions, such as sub-4-bit.","In this work, we present KVQuant, which addresses this problem by incorporating novel methods for quantizing cached KV activations, including: (i) Per-Channel Key Quantization, where we adjust the dimension along which we quantize the Key activations to better match the distribution; (ii) Pre-RoPE Key Quantization, where we quantize Key activations before the rotary positional embedding to mitigate its impact on quantization; (iii) Non-Uniform KV Cache Quantization, where we derive per-layer sensitivity-weighted non-uniform datatypes that better represent the distributions; (iv) Per-Vector Dense-and-Sparse Quantization, where we isolate outliers separately for each vector to minimize skews in quantization ranges; and (v) Q-Norm, where we normalize quantization centroids in order to mitigate distribution shift, providing additional benefits for 2-bit quantization.","By applying our method to the LLaMA, LLaMA-2, and Mistral models, we achieve $<0.1$ perplexity degradation with 3-bit quantization on both Wikitext-2 and C4, outperforming existing approaches.","Our method enables serving the LLaMA-7B model with a context length of up to 1 million on a single A100-80GB GPU and up to 10 million on an 8-GPU system."],"url":"http://arxiv.org/abs/2401.18079v1"}
{"created":"2024-01-31 18:56:09","title":"CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting","abstract":"We propose CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting, a method for predicting future 3D scenes given past observations, such as 2D ego-centric images. Our method maps an image to a distribution over plausible 3D latent scene configurations using a probabilistic encoder, and predicts the evolution of the hypothesized scenes through time. Our latent scene representation conditions a global Neural Radiance Field (NeRF) to represent a 3D scene model, which enables explainable predictions and straightforward downstream applications. This approach extends beyond previous neural rendering work by considering complex scenarios of uncertainty in environmental states and dynamics. We employ a two-stage training of Pose-Conditional-VAE and NeRF to learn 3D representations. Additionally, we auto-regressively predict latent scene representations as a partially observable Markov decision process, utilizing a mixture density network. We demonstrate the utility of our method in realistic scenarios using the CARLA driving simulator, where CARFF can be used to enable efficient trajectory and contingency planning in complex multi-agent autonomous driving scenarios involving visual occlusions.","sentences":["We propose CARFF:","Conditional Auto-encoded Radiance Field for 3D Scene Forecasting, a method for predicting future 3D scenes given past observations, such as 2D ego-centric images.","Our method maps an image to a distribution over plausible 3D latent scene configurations using a probabilistic encoder, and predicts the evolution of the hypothesized scenes through time.","Our latent scene representation conditions a global Neural Radiance Field (NeRF) to represent a 3D scene model, which enables explainable predictions and straightforward downstream applications.","This approach extends beyond previous neural rendering work by considering complex scenarios of uncertainty in environmental states and dynamics.","We employ a two-stage training of Pose-Conditional-VAE and NeRF to learn 3D representations.","Additionally, we auto-regressively predict latent scene representations as a partially observable Markov decision process, utilizing a mixture density network.","We demonstrate the utility of our method in realistic scenarios using the CARLA driving simulator, where CARFF can be used to enable efficient trajectory and contingency planning in complex multi-agent autonomous driving scenarios involving visual occlusions."],"url":"http://arxiv.org/abs/2401.18075v1"}
{"created":"2024-01-31 18:48:20","title":"Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?","abstract":"There is increasing interest in employing large language models (LLMs) as cognitive models. For such purposes, it is central to understand which cognitive properties are well-modeled by LLMs, and which are not. In this work, we study the biases of LLMs in relation to those known in children when solving arithmetic word problems. Surveying the learning science literature, we posit that the problem-solving process can be split into three distinct steps: text comprehension, solution planning and solution execution. We construct tests for each one in order to understand which parts of this process can be faithfully modeled by current state-of-the-art LLMs. We generate a novel set of word problems for each of these tests, using a neuro-symbolic method that enables fine-grained control over the problem features. We find evidence that LLMs, with and without instruction-tuning, exhibit human-like biases in both the text-comprehension and the solution-planning steps of the solving process, but not during the final step which relies on the problem's arithmetic expressions (solution execution).","sentences":["There is increasing interest in employing large language models (LLMs) as cognitive models.","For such purposes, it is central to understand which cognitive properties are well-modeled by LLMs, and which are not.","In this work, we study the biases of LLMs in relation to those known in children when solving arithmetic word problems.","Surveying the learning science literature, we posit that the problem-solving process can be split into three distinct steps: text comprehension, solution planning and solution execution.","We construct tests for each one in order to understand which parts of this process can be faithfully modeled by current state-of-the-art LLMs.","We generate a novel set of word problems for each of these tests, using a neuro-symbolic method that enables fine-grained control over the problem features.","We find evidence that LLMs, with and without instruction-tuning, exhibit human-like biases in both the text-comprehension and the solution-planning steps of the solving process, but not during the final step which relies on the problem's arithmetic expressions (solution execution)."],"url":"http://arxiv.org/abs/2401.18070v1"}
{"created":"2024-01-31 18:47:44","title":"Classification-Oriented Semantic Wireless Communications","abstract":"We propose semantic communication over wireless channels for various modalities, e.g., text and images, in a task-oriented communications setup where the task is classification. We present two approaches based on memory and learning. Both approaches rely on a pre-trained neural network to extract semantic information but differ in codebook construction. In the memory-based approach, we use semantic quantization and compression models, leveraging past source realizations as a codebook to eliminate the need for further training. In the learning-based approach, we use a semantic vector quantized autoencoder model that learns a codebook from scratch. Both are followed by a channel coder in order to reliably convey semantic information to the receiver (classifier) through the wireless medium. In addition to classification accuracy, we define system time efficiency as a new performance metric. Our results demonstrate that the proposed memory-based approach outperforms its learning-based counterpart with respect to system time efficiency while offering comparable accuracy to semantic agnostic conventional baselines.","sentences":["We propose semantic communication over wireless channels for various modalities, e.g., text and images, in a task-oriented communications setup where the task is classification.","We present two approaches based on memory and learning.","Both approaches rely on a pre-trained neural network to extract semantic information but differ in codebook construction.","In the memory-based approach, we use semantic quantization and compression models, leveraging past source realizations as a codebook to eliminate the need for further training.","In the learning-based approach, we use a semantic vector quantized autoencoder model that learns a codebook from scratch.","Both are followed by a channel coder in order to reliably convey semantic information to the receiver (classifier) through the wireless medium.","In addition to classification accuracy, we define system time efficiency as a new performance metric.","Our results demonstrate that the proposed memory-based approach outperforms its learning-based counterpart with respect to system time efficiency while offering comparable accuracy to semantic agnostic conventional baselines."],"url":"http://arxiv.org/abs/2401.18069v1"}
{"created":"2024-01-31 18:41:08","title":"Neural Locality Sensitive Hashing for Entity Blocking","abstract":"Locality-sensitive hashing (LSH) is a fundamental algorithmic technique widely employed in large-scale data processing applications, such as nearest-neighbor search, entity resolution, and clustering. However, its applicability in some real-world scenarios is limited due to the need for careful design of hashing functions that align with specific metrics. Existing LSH-based Entity Blocking solutions primarily rely on generic similarity metrics such as Jaccard similarity, whereas practical use cases often demand complex and customized similarity rules surpassing the capabilities of generic similarity metrics. Consequently, designing LSH functions for these customized similarity rules presents considerable challenges. In this research, we propose a neuralization approach to enhance locality-sensitive hashing by training deep neural networks to serve as hashing functions for complex metrics. We assess the effectiveness of this approach within the context of the entity resolution problem, which frequently involves the use of task-specific metrics in real-world applications. Specifically, we introduce NLSHBlock (Neural-LSH Block), a novel blocking methodology that leverages pre-trained language models, fine-tuned with a novel LSH-based loss function. Through extensive evaluations conducted on a diverse range of real-world datasets, we demonstrate the superiority of NLSHBlock over existing methods, exhibiting significant performance improvements. Furthermore, we showcase the efficacy of NLSHBlock in enhancing the performance of the entity matching phase, particularly within the semi-supervised setting.","sentences":["Locality-sensitive hashing (LSH) is a fundamental algorithmic technique widely employed in large-scale data processing applications, such as nearest-neighbor search, entity resolution, and clustering.","However, its applicability in some real-world scenarios is limited due to the need for careful design of hashing functions that align with specific metrics.","Existing LSH-based Entity Blocking solutions primarily rely on generic similarity metrics such as Jaccard similarity, whereas practical use cases often demand complex and customized similarity rules surpassing the capabilities of generic similarity metrics.","Consequently, designing LSH functions for these customized similarity rules presents considerable challenges.","In this research, we propose a neuralization approach to enhance locality-sensitive hashing by training deep neural networks to serve as hashing functions for complex metrics.","We assess the effectiveness of this approach within the context of the entity resolution problem, which frequently involves the use of task-specific metrics in real-world applications.","Specifically, we introduce NLSHBlock (Neural-LSH Block), a novel blocking methodology that leverages pre-trained language models, fine-tuned with a novel LSH-based loss function.","Through extensive evaluations conducted on a diverse range of real-world datasets, we demonstrate the superiority of NLSHBlock over existing methods, exhibiting significant performance improvements.","Furthermore, we showcase the efficacy of NLSHBlock in enhancing the performance of the entity matching phase, particularly within the semi-supervised setting."],"url":"http://arxiv.org/abs/2401.18064v1"}
{"created":"2024-01-31 18:37:39","title":"AoII-Optimum Sampling of CTMC Information Sources Under Sampling Rate Constraints","abstract":"We consider a sensor that samples an $N$-state continuous-time Markov chain (CTMC)-based information source process, and transmits the observed state of the source, to a remote monitor tasked with timely tracking of the source process. The mismatch between the source and monitor processes is quantified by age of incorrect information (AoII), which penalizes the mismatch as it stays longer, and our objective is to minimize the average AoII under an average sampling rate constraint. We assume a perfect reverse channel and hence the sensor has information of the estimate while initiating a transmission or preempting an ongoing transmission. First, by modeling the problem as an average cost constrained semi-Markov decision process (CSMDP), we show that the structure of the problem gives rise to an optimum threshold policy for which the sensor initiates a transmission once the AoII exceeds a threshold depending on the instantaneous values of both the source and monitor processes. However, due to the high complexity of obtaining the optimum policy in this general setting, we consider a relaxed problem where the thresholds are allowed to be dependent only on the estimate. We show that this relaxed problem can be solved with a novel CSMDP formulation based on the theory of absorbing MCs, with a computational complexity of $\\mathcal{O}(N^4)$, allowing one to obtain optimum policies for general CTMCs with over a hundred states.","sentences":["We consider a sensor that samples an $N$-state continuous-time Markov chain (CTMC)-based information source process, and transmits the observed state of the source, to a remote monitor tasked with timely tracking of the source process.","The mismatch between the source and monitor processes is quantified by age of incorrect information (AoII), which penalizes the mismatch as it stays longer, and our objective is to minimize the average AoII under an average sampling rate constraint.","We assume a perfect reverse channel and hence the sensor has information of the estimate while initiating a transmission or preempting an ongoing transmission.","First, by modeling the problem as an average cost constrained semi-Markov decision process (CSMDP), we show that the structure of the problem gives rise to an optimum threshold policy for which the sensor initiates a transmission once the AoII exceeds a threshold depending on the instantaneous values of both the source and monitor processes.","However, due to the high complexity of obtaining the optimum policy in this general setting, we consider a relaxed problem where the thresholds are allowed to be dependent only on the estimate.","We show that this relaxed problem can be solved with a novel CSMDP formulation based on the theory of absorbing MCs, with a computational complexity of $\\mathcal{O}(N^4)$, allowing one to obtain optimum policies for general CTMCs with over a hundred states."],"url":"http://arxiv.org/abs/2401.18063v1"}
{"created":"2024-01-31 18:30:21","title":"RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval","abstract":"Retrieval-augmented language models can better adapt to changes in world state and incorporate long-tail knowledge. However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, limiting holistic understanding of the overall document context. We introduce the novel approach of recursively embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization from the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across lengthy documents at different levels of abstraction. Controlled experiments show that retrieval with recursive summaries offers significant improvements over traditional retrieval-augmented LMs on several tasks. On question-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example, by coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by 20% in absolute accuracy.","sentences":["Retrieval-augmented language models can better adapt to changes in world state and incorporate long-tail knowledge.","However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, limiting holistic understanding of the overall document context.","We introduce the novel approach of recursively embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization from the bottom up.","At inference time, our RAPTOR model retrieves from this tree, integrating information across lengthy documents at different levels of abstraction.","Controlled experiments show that retrieval with recursive summaries offers significant improvements over traditional retrieval-augmented LMs on several tasks.","On question-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example, by coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by 20% in absolute accuracy."],"url":"http://arxiv.org/abs/2401.18059v1"}
{"created":"2024-01-31 18:29:39","title":"LongAlign: A Recipe for Long Context Alignment of Large Language Models","abstract":"Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length. To address this, we present LongAlign -- a recipe of the instruction data, training, and evaluation for long context alignment. First, we construct a long instruction-following dataset using Self-Instruct. To ensure the data diversity, it covers a broad range of tasks from various long context sources. Second, we adopt the packing and sorted batching strategies to speed up supervised fine-tuning on data with varied length distributions. Additionally, we develop a loss weighting method to balance the contribution to the loss across different sequences during packing training. Third, we introduce the LongBench-Chat benchmark for evaluating instruction-following capabilities on queries of 10k-100k in length. Experiments show that LongAlign outperforms existing recipes for LLMs in long context tasks by up to 30\\%, while also maintaining their proficiency in handling short, generic tasks. The code, data, and long-aligned models are open-sourced at https://github.com/THUDM/LongAlign.","sentences":["Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length.","To address this, we present LongAlign -- a recipe of the instruction data, training, and evaluation for long context alignment.","First, we construct a long instruction-following dataset using Self-Instruct.","To ensure the data diversity, it covers a broad range of tasks from various long context sources.","Second, we adopt the packing and sorted batching strategies to speed up supervised fine-tuning on data with varied length distributions.","Additionally, we develop a loss weighting method to balance the contribution to the loss across different sequences during packing training.","Third, we introduce the LongBench-Chat benchmark for evaluating instruction-following capabilities on queries of 10k-100k in length.","Experiments show that LongAlign outperforms existing recipes for LLMs in long context tasks by up to 30\\%, while also maintaining their proficiency in handling short, generic tasks.","The code, data, and long-aligned models are open-sourced at https://github.com/THUDM/LongAlign."],"url":"http://arxiv.org/abs/2401.18058v1"}
{"created":"2024-01-31 18:29:10","title":"Rank Supervised Contrastive Learning for Time Series Classification","abstract":"Recently, various contrastive learning techniques have been developed to categorize time series data and exhibit promising performance. A general paradigm is to utilize appropriate augmentations and construct feasible positive samples such that the encoder can yield robust and discriminative representations by mapping similar data points closer together in the feature space while pushing dissimilar data points farther apart. Despite its efficacy, the fine-grained relative similarity (e.g., rank) information of positive samples is largely ignored, especially when labeled samples are limited. To this end, we present Rank Supervised Contrastive Learning (RankSCL) to perform time series classification. Different from conventional contrastive learning frameworks, RankSCL augments raw data in a targeted way in the embedding space and adopts certain filtering rules to select more informative positive and negative pairs of samples. Moreover, a novel rank loss is developed to assign different weights for different levels of positive samples, enable the encoder to extract the fine-grained information of the same class, and produce a clear boundary among different classes. Thoroughly empirical studies on 128 UCR datasets and 30 UEA datasets demonstrate that the proposed RankSCL can achieve state-of-the-art performance compared to existing baseline methods.","sentences":["Recently, various contrastive learning techniques have been developed to categorize time series data and exhibit promising performance.","A general paradigm is to utilize appropriate augmentations and construct feasible positive samples such that the encoder can yield robust and discriminative representations by mapping similar data points closer together in the feature space while pushing dissimilar data points farther apart.","Despite its efficacy, the fine-grained relative similarity (e.g., rank) information of positive samples is largely ignored, especially when labeled samples are limited.","To this end, we present Rank Supervised Contrastive Learning (RankSCL) to perform time series classification.","Different from conventional contrastive learning frameworks, RankSCL augments raw data in a targeted way in the embedding space and adopts certain filtering rules to select more informative positive and negative pairs of samples.","Moreover, a novel rank loss is developed to assign different weights for different levels of positive samples, enable the encoder to extract the fine-grained information of the same class, and produce a clear boundary among different classes.","Thoroughly empirical studies on 128 UCR datasets and 30 UEA datasets demonstrate that the proposed RankSCL can achieve state-of-the-art performance compared to existing baseline methods."],"url":"http://arxiv.org/abs/2401.18057v1"}
{"created":"2024-01-31 18:20:42","title":"Benchmarking Sensitivity of Continual Graph Learning for Skeleton-Based Action Recognition","abstract":"Continual learning (CL) is the research field that aims to build machine learning models that can accumulate knowledge continuously over different tasks without retraining from scratch. Previous studies have shown that pre-training graph neural networks (GNN) may lead to negative transfer (Hu et al., 2020) after fine-tuning, a setting which is closely related to CL. Thus, we focus on studying GNN in the continual graph learning (CGL) setting. We propose the first continual graph learning benchmark for spatio-temporal graphs and use it to benchmark well-known CGL methods in this novel setting. The benchmark is based on the N-UCLA and NTU-RGB+D datasets for skeleton-based action recognition. Beyond benchmarking for standard performance metrics, we study the class and task-order sensitivity of CGL methods, i.e., the impact of learning order on each class/task's performance, and the architectural sensitivity of CGL methods with backbone GNN at various widths and depths. We reveal that task-order robust methods can still be class-order sensitive and observe results that contradict previous empirical observations on architectural sensitivity in CL.","sentences":["Continual learning (CL) is the research field that aims to build machine learning models that can accumulate knowledge continuously over different tasks without retraining from scratch.","Previous studies have shown that pre-training graph neural networks (GNN) may lead to negative transfer (Hu et al., 2020) after fine-tuning, a setting which is closely related to CL.","Thus, we focus on studying GNN in the continual graph learning (CGL) setting.","We propose the first continual graph learning benchmark for spatio-temporal graphs and use it to benchmark well-known CGL methods in this novel setting.","The benchmark is based on the N-UCLA and NTU-RGB+D datasets for skeleton-based action recognition.","Beyond benchmarking for standard performance metrics, we study the class and task-order sensitivity of CGL methods, i.e., the impact of learning order on each class/task's performance, and the architectural sensitivity of CGL methods with backbone GNN at various widths and depths.","We reveal that task-order robust methods can still be class-order sensitive and observe results that contradict previous empirical observations on architectural sensitivity in CL."],"url":"http://arxiv.org/abs/2401.18054v1"}
{"created":"2024-01-31 18:20:36","title":"How to Measure TLS, X.509 Certificates, and Web PKI: A Tutorial and Brief Survey","abstract":"Transport Layer Security (TLS) is the base for many Internet applications and services to achieve end-to-end security. In this paper, we provide guidance on how to measure TLS deployments, including X.509 certificates and Web PKI. We introduce common data sources and tools, and systematically describe necessary steps to conduct sound measurements and data analysis. By surveying prior TLS measurement studies we find that diverging results are rather rooted in different setups instead of different deployments. To improve the situation, we identify common pitfalls and introduce a framework to describe TLS and Web PKI measurements. Where necessary, our insights are bolstered by a data-driven approach, in which we complement arguments by additional measurements.","sentences":["Transport Layer Security (TLS) is the base for many Internet applications and services to achieve end-to-end security.","In this paper, we provide guidance on how to measure TLS deployments, including X.509 certificates and Web PKI.","We introduce common data sources and tools, and systematically describe necessary steps to conduct sound measurements and data analysis.","By surveying prior TLS measurement studies we find that diverging results are rather rooted in different setups instead of different deployments.","To improve the situation, we identify common pitfalls and introduce a framework to describe TLS and Web PKI measurements.","Where necessary, our insights are bolstered by a data-driven approach, in which we complement arguments by additional measurements."],"url":"http://arxiv.org/abs/2401.18053v1"}
{"created":"2024-01-31 18:14:13","title":"Hypermultiplexed Integrated Tensor Optical Processor","abstract":"Optical processors hold great potential to accelerate deep learning tasks with their high clock-rates and low-loss data transmission. However, existing integrated systems are hindered by low scalability due to the quadratic scaling of device counts, energy costs with high-speed analog-to-digital converters, and lack of inline nonlinearity. Here, we overcome these challenges with a wavelength-space-time multiplexed optical tensor processor. Hyperdimensional parallelism allows matrix-matrix multiplications ($N^{3}$ operations) using $O(N)$ devices. We incorporated wavelength-multiplexed III/V-based micron-scale lasers (spanning ~1 THz) for input activation with inline rectifier (ReLU) nonlinearities and thin-film Lithium-Niobate electro-optic modulators ($V_{\\pi}\\approx1.3 V$) for dynamic weighting. With each device encoding 10-billion activations per second, we demonstrated a machine-learning model with 405,000 parameters. High-clock-rate (10 GS/s), low-energy (500 fJ/OP) parallel computing with real-time programmability unlocks the full potential of light for next-generation scalable AI accelerators.","sentences":["Optical processors hold great potential to accelerate deep learning tasks with their high clock-rates and low-loss data transmission.","However, existing integrated systems are hindered by low scalability due to the quadratic scaling of device counts, energy costs with high-speed analog-to-digital converters, and lack of inline nonlinearity.","Here, we overcome these challenges with a wavelength-space-time multiplexed optical tensor processor.","Hyperdimensional parallelism allows matrix-matrix multiplications ($N^{3}$ operations) using $O(N)$ devices.","We incorporated wavelength-multiplexed III/V-based micron-scale lasers (spanning ~1 THz) for input activation with inline rectifier (ReLU) nonlinearities and thin-film Lithium-Niobate electro-optic modulators ($V_{\\pi}\\approx1.3 V$) for dynamic weighting.","With each device encoding 10-billion activations per second, we demonstrated a machine-learning model with 405,000 parameters.","High-clock-rate (10 GS/s), low-energy (500 fJ/OP) parallel computing with real-time programmability unlocks the full potential of light for next-generation scalable AI accelerators."],"url":"http://arxiv.org/abs/2401.18050v1"}
{"created":"2024-01-31 18:08:06","title":"Epidemic Modeling using Hybrid of Time-varying SIRD, Particle Swarm Optimization, and Deep Learning","abstract":"Epidemiological models are best suitable to model an epidemic if the spread pattern is stationary. To deal with non-stationary patterns and multiple waves of an epidemic, we develop a hybrid model encompassing epidemic modeling, particle swarm optimization, and deep learning. The model mainly caters to three objectives for better prediction: 1. Periodic estimation of the model parameters. 2. Incorporating impact of all the aspects using data fitting and parameter optimization 3. Deep learning based prediction of the model parameters. In our model, we use a system of ordinary differential equations (ODEs) for Susceptible-Infected-Recovered-Dead (SIRD) epidemic modeling, Particle Swarm Optimization (PSO) for model parameter optimization, and stacked-LSTM for forecasting the model parameters. Initial or one time estimation of model parameters is not able to model multiple waves of an epidemic. So, we estimate the model parameters periodically (weekly). We use PSO to identify the optimum values of the model parameters. We next train the stacked-LSTM on the optimized parameters, and perform forecasting of the model parameters for upcoming four weeks. Further, we fed the LSTM forecasted parameters into the SIRD model to forecast the number of COVID-19 cases. We evaluate the model for highly affected three countries namely; the USA, India, and the UK. The proposed hybrid model is able to deal with multiple waves, and has outperformed existing methods on all the three datasets.","sentences":["Epidemiological models are best suitable to model an epidemic if the spread pattern is stationary.","To deal with non-stationary patterns and multiple waves of an epidemic, we develop a hybrid model encompassing epidemic modeling, particle swarm optimization, and deep learning.","The model mainly caters to three objectives for better prediction:","1.","Periodic estimation of the model parameters.","2. Incorporating impact of all the aspects using data fitting and parameter optimization 3.","Deep learning based prediction of the model parameters.","In our model, we use a system of ordinary differential equations (ODEs) for Susceptible-Infected-Recovered-Dead (SIRD) epidemic modeling, Particle Swarm Optimization (PSO) for model parameter optimization, and stacked-LSTM for forecasting the model parameters.","Initial or one time estimation of model parameters is not able to model multiple waves of an epidemic.","So, we estimate the model parameters periodically (weekly).","We use PSO to identify the optimum values of the model parameters.","We next train the stacked-LSTM on the optimized parameters, and perform forecasting of the model parameters for upcoming four weeks.","Further, we fed the LSTM forecasted parameters into the SIRD model to forecast the number of COVID-19 cases.","We evaluate the model for highly affected three countries namely; the USA, India, and the UK.","The proposed hybrid model is able to deal with multiple waves, and has outperformed existing methods on all the three datasets."],"url":"http://arxiv.org/abs/2401.18047v1"}
{"created":"2024-01-31 18:07:12","title":"Multipath parsing in the brain","abstract":"Humans understand sentences word-by-word, in the order that they hear them. This incrementality entails resolving temporary ambiguities about syntactic relationships. We investigate how humans process these syntactic ambiguities by correlating predictions from incremental generative dependency parsers with timecourse data from people undergoing functional neuroimaging while listening to an audiobook. In particular, we compare competing hypotheses regarding the number of developing syntactic analyses in play during word-by-word comprehension: one vs more than one. This comparison involves evaluating syntactic surprisal from a state-of-the-art dependency parser with LLM-adapted encodings against an existing fMRI dataset. In both English and Chinese data, we find evidence for multipath parsing. Brain regions associated with this multipath effect include bilateral superior temporal gyrus.","sentences":["Humans understand sentences word-by-word, in the order that they hear them.","This incrementality entails resolving temporary ambiguities about syntactic relationships.","We investigate how humans process these syntactic ambiguities by correlating predictions from incremental generative dependency parsers with timecourse data from people undergoing functional neuroimaging while listening to an audiobook.","In particular, we compare competing hypotheses regarding the number of developing syntactic analyses in play during word-by-word comprehension: one vs more than one.","This comparison involves evaluating syntactic surprisal from a state-of-the-art dependency parser with LLM-adapted encodings against an existing fMRI dataset.","In both English and Chinese data, we find evidence for multipath parsing.","Brain regions associated with this multipath effect include bilateral superior temporal gyrus."],"url":"http://arxiv.org/abs/2401.18046v1"}
{"created":"2024-01-31 18:06:29","title":"SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition","abstract":"Recent advancements in language models have significantly enhanced performance in multiple speech-related tasks. Existing speech language models typically utilize task-dependent prompt tokens to unify various speech tasks in a single model. However, this design omits the intrinsic connections between different speech tasks, which can potentially boost the performance of each task. In this work, we propose a novel decoder-only speech language model, SpeechComposer, that can unify common speech tasks by composing a fixed set of prompt tokens. Built upon four primary tasks -- speech synthesis, speech recognition, speech language modeling, and text language modeling -- SpeechComposer can easily extend to more speech tasks via compositions of well-designed prompt tokens, like voice conversion and speech enhancement. The unification of prompt tokens also makes it possible for knowledge sharing among different speech tasks in a more structured manner. Experimental results demonstrate that our proposed SpeechComposer can improve the performance of both primary tasks and composite tasks, showing the effectiveness of the shared prompt tokens. Remarkably, the unified decoder-only model achieves a comparable and even better performance than the baselines which are expert models designed for single tasks.","sentences":["Recent advancements in language models have significantly enhanced performance in multiple speech-related tasks.","Existing speech language models typically utilize task-dependent prompt tokens to unify various speech tasks in a single model.","However, this design omits the intrinsic connections between different speech tasks, which can potentially boost the performance of each task.","In this work, we propose a novel decoder-only speech language model, SpeechComposer, that can unify common speech tasks by composing a fixed set of prompt tokens.","Built upon four primary tasks -- speech synthesis, speech recognition, speech language modeling, and text language modeling -- SpeechComposer can easily extend to more speech tasks via compositions of well-designed prompt tokens, like voice conversion and speech enhancement.","The unification of prompt tokens also makes it possible for knowledge sharing among different speech tasks in a more structured manner.","Experimental results demonstrate that our proposed SpeechComposer can improve the performance of both primary tasks and composite tasks, showing the effectiveness of the shared prompt tokens.","Remarkably, the unified decoder-only model achieves a comparable and even better performance than the baselines which are expert models designed for single tasks."],"url":"http://arxiv.org/abs/2401.18045v1"}
{"created":"2024-01-31 18:03:39","title":"Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability","abstract":"End-to-end multi-task dialogue systems are usually designed with separate modules for the dialogue pipeline. Among these, the policy module is essential for deciding what to do in response to user input. This policy is trained by reinforcement learning algorithms by taking advantage of an environment in which an agent receives feedback in the form of a reward signal. The current dialogue systems, however, only provide meagre and simplistic rewards. Investigating intrinsic motivation reinforcement learning algorithms is the goal of this study. Through this, the agent can quickly accelerate training and improve its capacity to judge the quality of its actions by teaching it an internal incentive system. In particular, we adapt techniques for random network distillation and curiosity-driven reinforcement learning to measure the frequency of state visits and encourage exploration by using semantic similarity between utterances. Experimental results on MultiWOZ, a heterogeneous dataset, show that intrinsic motivation-based debate systems outperform policies that depend on extrinsic incentives. By adopting random network distillation, for example, which is trained using semantic similarity between user-system dialogues, an astounding average success rate of 73% is achieved. This is a significant improvement over the baseline Proximal Policy Optimization (PPO), which has an average success rate of 60%. In addition, performance indicators such as booking rates and completion rates show a 10% rise over the baseline. Furthermore, these intrinsic incentive models help improve the system's policy's resilience in an increasing amount of domains. This implies that they could be useful in scaling up to settings that cover a wider range of domains.","sentences":["End-to-end multi-task dialogue systems are usually designed with separate modules for the dialogue pipeline.","Among these, the policy module is essential for deciding what to do in response to user input.","This policy is trained by reinforcement learning algorithms by taking advantage of an environment in which an agent receives feedback in the form of a reward signal.","The current dialogue systems, however, only provide meagre and simplistic rewards.","Investigating intrinsic motivation reinforcement learning algorithms is the goal of this study.","Through this, the agent can quickly accelerate training and improve its capacity to judge the quality of its actions by teaching it an internal incentive system.","In particular, we adapt techniques for random network distillation and curiosity-driven reinforcement learning to measure the frequency of state visits and encourage exploration by using semantic similarity between utterances.","Experimental results on MultiWOZ, a heterogeneous dataset, show that intrinsic motivation-based debate systems outperform policies that depend on extrinsic incentives.","By adopting random network distillation, for example, which is trained using semantic similarity between user-system dialogues, an astounding average success rate of 73% is achieved.","This is a significant improvement over the baseline Proximal Policy Optimization (PPO), which has an average success rate of 60%.","In addition, performance indicators such as booking rates and completion rates show a 10% rise over the baseline.","Furthermore, these intrinsic incentive models help improve the system's policy's resilience in an increasing amount of domains.","This implies that they could be useful in scaling up to settings that cover a wider range of domains."],"url":"http://arxiv.org/abs/2401.18040v1"}
{"created":"2024-01-31 17:59:57","title":"Optimizing contrastive learning for cortical folding pattern detection","abstract":"The human cerebral cortex has many bumps and grooves called gyri and sulci. Even though there is a high inter-individual consistency for the main cortical folds, this is not the case when we examine the exact shapes and details of the folding patterns. Because of this complexity, characterizing the cortical folding variability and relating them to subjects' behavioral characteristics or pathologies is still an open scientific problem. Classical approaches include labeling a few specific patterns, either manually or semi-automatically, based on geometric distances, but the recent availability of MRI image datasets of tens of thousands of subjects makes modern deep-learning techniques particularly attractive. Here, we build a self-supervised deep-learning model to detect folding patterns in the cingulate region. We train a contrastive self-supervised model (SimCLR) on both Human Connectome Project (1101 subjects) and UKBioBank (21070 subjects) datasets with topological-based augmentations on the cortical skeletons, which are topological objects that capture the shape of the folds. We explore several backbone architectures (convolutional network, DenseNet, and PointNet) for the SimCLR. For evaluation and testing, we perform a linear classification task on a database manually labeled for the presence of the \"double-parallel\" folding pattern in the cingulate region, which is related to schizophrenia characteristics. The best model, giving a test AUC of 0.76, is a convolutional network with 6 layers, a 10-dimensional latent space, a linear projection head, and using the branch-clipping augmentation. This is the first time that a self-supervised deep learning model has been applied to cortical skeletons on such a large dataset and quantitatively evaluated. We can now envisage the next step: applying it to other brain regions to detect other biomarkers.","sentences":["The human cerebral cortex has many bumps and grooves called gyri and sulci.","Even though there is a high inter-individual consistency for the main cortical folds, this is not the case when we examine the exact shapes and details of the folding patterns.","Because of this complexity, characterizing the cortical folding variability and relating them to subjects' behavioral characteristics or pathologies is still an open scientific problem.","Classical approaches include labeling a few specific patterns, either manually or semi-automatically, based on geometric distances, but the recent availability of MRI image datasets of tens of thousands of subjects makes modern deep-learning techniques particularly attractive.","Here, we build a self-supervised deep-learning model to detect folding patterns in the cingulate region.","We train a contrastive self-supervised model (SimCLR) on both Human Connectome Project (1101 subjects) and UKBioBank (21070 subjects) datasets with topological-based augmentations on the cortical skeletons, which are topological objects that capture the shape of the folds.","We explore several backbone architectures (convolutional network, DenseNet, and PointNet) for the SimCLR.","For evaluation and testing, we perform a linear classification task on a database manually labeled for the presence of the \"double-parallel\" folding pattern in the cingulate region, which is related to schizophrenia characteristics.","The best model, giving a test AUC of 0.76, is a convolutional network with 6 layers, a 10-dimensional latent space, a linear projection head, and using the branch-clipping augmentation.","This is the first time that a self-supervised deep learning model has been applied to cortical skeletons on such a large dataset and quantitatively evaluated.","We can now envisage the next step: applying it to other brain regions to detect other biomarkers."],"url":"http://arxiv.org/abs/2401.18035v1"}
{"created":"2024-01-31 17:58:10","title":"Paramanu: A Family of Novel Efficient Indic Generative Foundation Language Models","abstract":"We present Gyan AI Paramanu (\"atom\"), a family of novel language models for Indian languages. It is a collection of auto-regressive monolingual, bilingual, and multilingual Indic language models pretrained from scratch on a single GPU for 10 Indian languages (Assamese, Bangla, Hindi, Konkani, Maithili, Marathi, Odia, Sanskrit, Tamil, Telugu) across 5 scripts (Bangla, Devanagari, Odia, Tamil, Telugu) of varying sizes ranging from 13.29M to 367.5M.The models are pretrained with a context size of 1024 on a single GPU. The models are very efficient, small, fast, and powerful. We have also developed an efficient most advanced Indic tokenizer that can even tokenize unseen languages. In order to avoid the \"curse of multi-linguality\" in our multilingual mParamanu model, we pretrained on comparable corpora by typological grouping using the same script. We performed human evaluation of our pretrained models for open end text generation on grammar, coherence, creativity, and factuality metrics for Bangla, Hindi, and Sanskrit. Our Bangla, Hindi, and Sanskrit models outperformed GPT-3.5-Turbo (ChatGPT), Bloom 7B, LLaMa-2 7B, OPT 6.7B, GPT-J 6B, GPTNeo 1.3B, GPT2-XL large language models (LLMs) by a large margin despite being smaller in size by 66 to 20 times compared to standard 7B LLMs. To run inference on our pretrained models, CPU is enough, and GPU is not needed. We also instruction-tuned our pretrained Bangla, Hindi, Marathi, Tamil, and Telugu models on 23k instructions in respective languages. Our pretrained and instruction-tuned models which are first of its kind, most powerful efficient small generative language models ever developed for Indic languages, and the various results lead to the conclusion that high quality generative language models are possible without high amount of compute power and humongous number of parameters. We plan to release our models at https://www.bharatgpts.com.","sentences":["We present Gyan AI Paramanu (\"atom\"), a family of novel language models for Indian languages.","It is a collection of auto-regressive monolingual, bilingual, and multilingual Indic language models pretrained from scratch on a single GPU for 10 Indian languages (Assamese, Bangla, Hindi, Konkani, Maithili, Marathi, Odia, Sanskrit, Tamil, Telugu) across 5 scripts (Bangla, Devanagari, Odia, Tamil, Telugu) of varying sizes ranging from 13.29M to 367.5M.The models are pretrained with a context size of 1024 on a single GPU.","The models are very efficient, small, fast, and powerful.","We have also developed an efficient most advanced Indic tokenizer that can even tokenize unseen languages.","In order to avoid the \"curse of multi-linguality\" in our multilingual mParamanu model, we pretrained on comparable corpora by typological grouping using the same script.","We performed human evaluation of our pretrained models for open end text generation on grammar, coherence, creativity, and factuality metrics for Bangla, Hindi, and Sanskrit.","Our Bangla, Hindi, and Sanskrit models outperformed GPT-3.5-Turbo (ChatGPT), Bloom 7B, LLaMa-2 7B, OPT 6.7B, GPT-J 6B, GPTNeo 1.3B, GPT2-XL large language models (LLMs) by a large margin despite being smaller in size by 66 to 20 times compared to standard 7B LLMs.","To run inference on our pretrained models, CPU is enough, and GPU is not needed.","We also instruction-tuned our pretrained Bangla, Hindi, Marathi, Tamil, and Telugu models on 23k instructions in respective languages.","Our pretrained and instruction-tuned models which are first of its kind, most powerful efficient small generative language models ever developed for Indic languages, and the various results lead to the conclusion that high quality generative language models are possible without high amount of compute power and humongous number of parameters.","We plan to release our models at https://www.bharatgpts.com."],"url":"http://arxiv.org/abs/2401.18034v1"}
{"created":"2024-01-31 17:54:43","title":"DROP: Decouple Re-Identification and Human Parsing with Task-specific Features for Occluded Person Re-identification","abstract":"The paper introduces the Decouple Re-identificatiOn and human Parsing (DROP) method for occluded person re-identification (ReID). Unlike mainstream approaches using global features for simultaneous multi-task learning of ReID and human parsing, or relying on semantic information for attention guidance, DROP argues that the inferior performance of the former is due to distinct granularity requirements for ReID and human parsing features. ReID focuses on instance part-level differences between pedestrian parts, while human parsing centers on semantic spatial context, reflecting the internal structure of the human body. To address this, DROP decouples features for ReID and human parsing, proposing detail-preserving upsampling to combine varying resolution feature maps. Parsing-specific features for human parsing are decoupled, and human position information is exclusively added to the human parsing branch. In the ReID branch, a part-aware compactness loss is introduced to enhance instance-level part differences. Experimental results highlight the efficacy of DROP, especially achieving a Rank-1 accuracy of 76.8% on Occluded-Duke, surpassing two mainstream methods. The codebase is accessible at https://github.com/shuguang-52/DROP.","sentences":["The paper introduces the Decouple Re-identificatiOn and human Parsing (DROP) method for occluded person re-identification (ReID).","Unlike mainstream approaches using global features for simultaneous multi-task learning of ReID and human parsing, or relying on semantic information for attention guidance, DROP argues that the inferior performance of the former is due to distinct granularity requirements for ReID and human parsing features.","ReID focuses on instance part-level differences between pedestrian parts, while human parsing centers on semantic spatial context, reflecting the internal structure of the human body.","To address this, DROP decouples features for ReID and human parsing, proposing detail-preserving upsampling to combine varying resolution feature maps.","Parsing-specific features for human parsing are decoupled, and human position information is exclusively added to the human parsing branch.","In the ReID branch, a part-aware compactness loss is introduced to enhance instance-level part differences.","Experimental results highlight the efficacy of DROP, especially achieving a Rank-1 accuracy of 76.8% on Occluded-Duke, surpassing two mainstream methods.","The codebase is accessible at https://github.com/shuguang-52/DROP."],"url":"http://arxiv.org/abs/2401.18032v1"}
{"created":"2024-01-31 17:45:05","title":"Context-Sensitive Abstract Interpretation of Dynamic Languages","abstract":"There is a vast gap in the quality of IDE tooling between static languages like Java and dynamic languages like Python or JavaScript. Modern frameworks and libraries in these languages heavily use their dynamic capabilities to achieve the best ergonomics and readability. This has a side effect of making the current generation of IDEs blind to control flow and data flow, which often breaks navigation, autocompletion and refactoring. In this thesis we propose an algorithm that can bridge this gap between tooling for dynamic and static languages by statically analyzing dynamic metaprogramming and runtime reflection in programs. We use a technique called abstract interpretation to partially execute programs and extract information that is usually only available at runtime. Our algorithm has been implemented in a prototype analyzer that can analyze programs written in a subset of JavaScript.","sentences":["There is a vast gap in the quality of IDE tooling between static languages like Java and dynamic languages like Python or JavaScript.","Modern frameworks and libraries in these languages heavily use their dynamic capabilities to achieve the best ergonomics and readability.","This has a side effect of making the current generation of IDEs blind to control flow and data flow, which often breaks navigation, autocompletion and refactoring.","In this thesis we propose an algorithm that can bridge this gap between tooling for dynamic and static languages by statically analyzing dynamic metaprogramming and runtime reflection in programs.","We use a technique called abstract interpretation to partially execute programs and extract information that is usually only available at runtime.","Our algorithm has been implemented in a prototype analyzer that can analyze programs written in a subset of JavaScript."],"url":"http://arxiv.org/abs/2401.18029v1"}
{"created":"2024-01-31 17:43:04","title":"Supporting Anticipatory Governance using LLMs: Evaluating and Aligning Large Language Models with the News Media to Anticipate the Negative Impacts of AI","abstract":"Anticipating the negative impacts of emerging AI technologies is a challenge, especially in the early stages of development. An understudied approach to such anticipation is the use of LLMs to enhance and guide this process. Despite advancements in LLMs and evaluation metrics to account for biases in generated text, it is unclear how well these models perform in anticipatory tasks. Specifically, the use of LLMs to anticipate AI impacts raises questions about the quality and range of categories of negative impacts these models are capable of generating. In this paper we leverage news media, a diverse data source that is rich with normative assessments of emerging technologies, to formulate a taxonomy of impacts to act as a baseline for comparing against. By computationally analyzing thousands of news articles published by hundreds of online news domains around the world, we develop a taxonomy consisting of ten categories of AI impacts. We then evaluate both instruction-based (GPT-4 and Mistral-7B-Instruct) and fine-tuned completion models (Mistral-7B and GPT-3) using a sample from this baseline. We find that the generated impacts using Mistral-7B, fine-tuned on impacts from the news media, tend to be qualitatively on par with impacts generated using a larger scale model such as GPT-4. Moreover, we find that these LLMs generate impacts that largely reflect the taxonomy of negative impacts identified in the news media, however the impacts produced by instruction-based models had gaps in the production of certain categories of impacts in comparison to fine-tuned models. This research highlights a potential bias in state-of-the-art LLMs when used for anticipating impacts and demonstrates the advantages of aligning smaller LLMs with a diverse range of impacts, such as those reflected in the news media, to better reflect such impacts during anticipatory exercises.","sentences":["Anticipating the negative impacts of emerging AI technologies is a challenge, especially in the early stages of development.","An understudied approach to such anticipation is the use of LLMs to enhance and guide this process.","Despite advancements in LLMs and evaluation metrics to account for biases in generated text, it is unclear how well these models perform in anticipatory tasks.","Specifically, the use of LLMs to anticipate AI impacts raises questions about the quality and range of categories of negative impacts these models are capable of generating.","In this paper we leverage news media, a diverse data source that is rich with normative assessments of emerging technologies, to formulate a taxonomy of impacts to act as a baseline for comparing against.","By computationally analyzing thousands of news articles published by hundreds of online news domains around the world, we develop a taxonomy consisting of ten categories of AI impacts.","We then evaluate both instruction-based (GPT-4 and Mistral-7B-Instruct) and fine-tuned completion models (Mistral-7B and GPT-3) using a sample from this baseline.","We find that the generated impacts using Mistral-7B, fine-tuned on impacts from the news media, tend to be qualitatively on par with impacts generated using a larger scale model such as GPT-4.","Moreover, we find that these LLMs generate impacts that largely reflect the taxonomy of negative impacts identified in the news media, however the impacts produced by instruction-based models had gaps in the production of certain categories of impacts in comparison to fine-tuned models.","This research highlights a potential bias in state-of-the-art LLMs when used for anticipating impacts and demonstrates the advantages of aligning smaller LLMs with a diverse range of impacts, such as those reflected in the news media, to better reflect such impacts during anticipatory exercises."],"url":"http://arxiv.org/abs/2401.18028v1"}
{"created":"2024-01-31 17:38:34","title":"Benchmarking Private Population Data Release Mechanisms: Synthetic Data vs. TopDown","abstract":"Differential privacy (DP) is increasingly used to protect the release of hierarchical, tabular population data, such as census data. A common approach for implementing DP in this setting is to release noisy responses to a predefined set of queries. For example, this is the approach of the TopDown algorithm used by the US Census Bureau. Such methods have an important shortcoming: they cannot answer queries for which they were not optimized. An appealing alternative is to generate DP synthetic data, which is drawn from some generating distribution. Like the TopDown method, synthetic data can also be optimized to answer specific queries, while also allowing the data user to later submit arbitrary queries over the synthetic population data. To our knowledge, there has not been a head-to-head empirical comparison of these approaches. This study conducts such a comparison between the TopDown algorithm and private synthetic data generation to determine how accuracy is affected by query complexity, in-distribution vs. out-of-distribution queries, and privacy guarantees. Our results show that for in-distribution queries, the TopDown algorithm achieves significantly better privacy-fidelity tradeoffs than any of the synthetic data methods we evaluated; for instance, in our experiments, TopDown achieved at least $20\\times$ lower error on counting queries than the leading synthetic data method at the same privacy budget. Our findings suggest guidelines for practitioners and the synthetic data research community.","sentences":["Differential privacy (DP) is increasingly used to protect the release of hierarchical, tabular population data, such as census data.","A common approach for implementing DP in this setting is to release noisy responses to a predefined set of queries.","For example, this is the approach of the TopDown algorithm used by the US Census Bureau.","Such methods have an important shortcoming: they cannot answer queries for which they were not optimized.","An appealing alternative is to generate DP synthetic data, which is drawn from some generating distribution.","Like the TopDown method, synthetic data can also be optimized to answer specific queries, while also allowing the data user to later submit arbitrary queries over the synthetic population data.","To our knowledge, there has not been a head-to-head empirical comparison of these approaches.","This study conducts such a comparison between the TopDown algorithm and private synthetic data generation to determine how accuracy is affected by query complexity, in-distribution vs. out-of-distribution queries, and privacy guarantees.","Our results show that for in-distribution queries, the TopDown algorithm achieves significantly better privacy-fidelity tradeoffs than any of the synthetic data methods we evaluated; for instance, in our experiments, TopDown achieved at least $20\\times$ lower error on counting queries than the leading synthetic data method at the same privacy budget.","Our findings suggest guidelines for practitioners and the synthetic data research community."],"url":"http://arxiv.org/abs/2401.18024v1"}
{"created":"2024-01-31 17:29:16","title":"Joining Entities Across Relation and Graph with a Unified Model","abstract":"This paper introduces RG (Relational Genetic) model, a revised relational model to represent graph-structured data in RDBMS while preserving its topology, for efficiently and effectively extracting data in different formats from disparate sources. Along with: (a) SQL$_\\delta$, an SQL dialect augmented with graph pattern queries and tuple-vertex joins, such that one can extract graph properties via graph pattern matching, and \"semantically\" match entities across relations and graphs; (b) a logical representation of graphs in RDBMS, which introduces an exploration operator for efficient pattern querying, supports also browsing and updating graph-structured data; and (c) a strategy to uniformly evaluate SQL, pattern and hybrid queries that join tuples and vertices, all inside an RDBMS by leveraging its optimizer without performance degradation on switching different execution engines. A lightweight system, WhiteDB, is developed as an implementation to evaluate the benefits it can actually bring on real-life data. We empirically verified that the RG model enables the graph pattern queries to be answered as efficiently as in native graph engines; can consider the access on graph and relation in any order for optimal plan; and supports effective data enrichment.","sentences":["This paper introduces RG (Relational Genetic) model, a revised relational model to represent graph-structured data in RDBMS while preserving its topology, for efficiently and effectively extracting data in different formats from disparate sources.","Along with: (a) SQL$_\\delta$, an SQL dialect augmented with graph pattern queries and tuple-vertex joins, such that one can extract graph properties via graph pattern matching, and \"semantically\" match entities across relations and graphs; (b) a logical representation of graphs in RDBMS, which introduces an exploration operator for efficient pattern querying, supports also browsing and updating graph-structured data; and (c) a strategy to uniformly evaluate SQL, pattern and hybrid queries that join tuples and vertices, all inside an RDBMS by leveraging its optimizer without performance degradation on switching different execution engines.","A lightweight system, WhiteDB, is developed as an implementation to evaluate the benefits it can actually bring on real-life data.","We empirically verified that the RG model enables the graph pattern queries to be answered as efficiently as in native graph engines; can consider the access on graph and relation in any order for optimal plan; and supports effective data enrichment."],"url":"http://arxiv.org/abs/2401.18019v1"}
{"created":"2024-01-31 17:28:24","title":"Prompt-Driven LLM Safeguarding via Directed Representation Optimization","abstract":"Prepending model inputs with safety prompts is a common practice of safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not yet been fully understood, which hinders the potential for automatically optimizing them for improved LLM safety. Motivated by this problem, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by different safety prompts in similar directions, where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. DRO treats safety prompts as continuous, trainable embeddings and learns to move the representations of harmful/harmless queries along/opposite the direction in which the model's refusal probability increases. We demonstrate that DRO remarkably improves the safeguarding performance of human-crafted safety prompts and outperforms strong baselines, as evaluated on out-of-domain benchmarks, without compromising the general model capability.","sentences":["Prepending model inputs with safety prompts is a common practice of safeguarding large language models (LLMs) from complying with queries that contain harmful intents.","However, the working mechanisms of safety prompts have not yet been fully understood, which hinders the potential for automatically optimizing them for improved LLM safety.","Motivated by this problem, we investigate the impact of safety prompts from the perspective of model representations.","We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts.","Instead, the queries' representations are moved by different safety prompts in similar directions, where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless.","Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization.","DRO treats safety prompts as continuous, trainable embeddings and learns to move the representations of harmful/harmless queries along/opposite the direction in which the model's refusal probability increases.","We demonstrate that DRO remarkably improves the safeguarding performance of human-crafted safety prompts and outperforms strong baselines, as evaluated on out-of-domain benchmarks, without compromising the general model capability."],"url":"http://arxiv.org/abs/2401.18018v1"}
{"created":"2024-01-31 17:20:36","title":"On The Power of Subtle Expressive Cues in the Perception of Human Affects","abstract":"In this study, we introduce a sketch-based method for testing how subtle expressive cues influence the perception of affect in illustrations of human figures. We specifically study the impact of human posture and gaze direction, implicitly specified through nose orientation, on perceived emotions and mood. Through a series of user studies using sketchy illustrations of a running figure, where a professional illustrator manipulated gaze direction through adjustments on the nose orientation, we found that this simple change resulted in a diverse range of perceived affects, spanning from fear to concern and wonder. These findings shed light on the importance of fine details in defining context for context-aware system designs and underscore the importance of recognizing and expressing affect. Understanding minor expressive cues is crucial to developing emotionally intelligent systems capable of expressing affect.","sentences":["In this study, we introduce a sketch-based method for testing how subtle expressive cues influence the perception of affect in illustrations of human figures.","We specifically study the impact of human posture and gaze direction, implicitly specified through nose orientation, on perceived emotions and mood.","Through a series of user studies using sketchy illustrations of a running figure, where a professional illustrator manipulated gaze direction through adjustments on the nose orientation, we found that this simple change resulted in a diverse range of perceived affects, spanning from fear to concern and wonder.","These findings shed light on the importance of fine details in defining context for context-aware system designs and underscore the importance of recognizing and expressing affect.","Understanding minor expressive cues is crucial to developing emotionally intelligent systems capable of expressing affect."],"url":"http://arxiv.org/abs/2401.18013v1"}
{"created":"2024-01-31 17:02:31","title":"Desiderata for the Context Use of Question Answering Systems","abstract":"Prior work has uncovered a set of common problems in state-of-the-art context-based question answering (QA) systems: a lack of attention to the context when the latter conflicts with a model's parametric knowledge, little robustness to noise, and a lack of consistency with their answers. However, most prior work focus on one or two of those problems in isolation, which makes it difficult to see trends across them. We aim to close this gap, by first outlining a set of -- previously discussed as well as novel -- desiderata for QA models. We then survey relevant analysis and methods papers to provide an overview of the state of the field. The second part of our work presents experiments where we evaluate 15 QA systems on 5 datasets according to all desiderata at once. We find many novel trends, including (1) systems that are less susceptible to noise are not necessarily more consistent with their answers when given irrelevant context; (2) most systems that are more susceptible to noise are more likely to correctly answer according to a context that conflicts with their parametric knowledge; and (3) the combination of conflicting knowledge and noise can reduce system performance by up to 96%. As such, our desiderata help increase our understanding of how these models work and reveal potential avenues for improvements.","sentences":["Prior work has uncovered a set of common problems in state-of-the-art context-based question answering (QA) systems: a lack of attention to the context when the latter conflicts with a model's parametric knowledge, little robustness to noise, and a lack of consistency with their answers.","However, most prior work focus on one or two of those problems in isolation, which makes it difficult to see trends across them.","We aim to close this gap, by first outlining a set of -- previously discussed as well as novel -- desiderata for QA models.","We then survey relevant analysis and methods papers to provide an overview of the state of the field.","The second part of our work presents experiments where we evaluate 15 QA systems on 5 datasets according to all desiderata at once.","We find many novel trends, including (1) systems that are less susceptible to noise are not necessarily more consistent with their answers when given irrelevant context; (2) most systems that are more susceptible to noise are more likely to correctly answer according to a context that conflicts with their parametric knowledge; and (3) the combination of conflicting knowledge and noise can reduce system performance by up to 96%.","As such, our desiderata help increase our understanding of how these models work and reveal potential avenues for improvements."],"url":"http://arxiv.org/abs/2401.18001v1"}
{"created":"2024-01-31 16:55:44","title":"Development and Adaptation of Robotic Vision in the Real-World: the Challenge of Door Detection","abstract":"Mobile service robots are increasingly prevalent in human-centric, real-world domains, operating autonomously in unconstrained indoor environments. In such a context, robotic vision plays a central role in enabling service robots to perceive high-level environmental features from visual observations. Despite the data-driven approaches based on deep learning push the boundaries of vision systems, applying these techniques to real-world robotic scenarios presents unique methodological challenges. Traditional models fail to represent the challenging perception constraints typical of service robots and must be adapted for the specific environment where robots finally operate. We propose a method leveraging photorealistic simulations that balances data quality and acquisition costs for synthesizing visual datasets from the robot perspective used to train deep architectures. Then, we show the benefits in qualifying a general detector for the target domain in which the robot is deployed, showing also the trade-off between the effort for obtaining new examples from such a setting and the performance gain. In our extensive experimental campaign, we focus on the door detection task (namely recognizing the presence and the traversability of doorways) that, in dynamic settings, is useful to infer the topology of the map. Our findings are validated in a real-world robot deployment, comparing prominent deep-learning models and demonstrating the effectiveness of our approach in practical settings.","sentences":["Mobile service robots are increasingly prevalent in human-centric, real-world domains, operating autonomously in unconstrained indoor environments.","In such a context, robotic vision plays a central role in enabling service robots to perceive high-level environmental features from visual observations.","Despite the data-driven approaches based on deep learning push the boundaries of vision systems, applying these techniques to real-world robotic scenarios presents unique methodological challenges.","Traditional models fail to represent the challenging perception constraints typical of service robots and must be adapted for the specific environment where robots finally operate.","We propose a method leveraging photorealistic simulations that balances data quality and acquisition costs for synthesizing visual datasets from the robot perspective used to train deep architectures.","Then, we show the benefits in qualifying a general detector for the target domain in which the robot is deployed, showing also the trade-off between the effort for obtaining new examples from such a setting and the performance gain.","In our extensive experimental campaign, we focus on the door detection task (namely recognizing the presence and the traversability of doorways) that, in dynamic settings, is useful to infer the topology of the map.","Our findings are validated in a real-world robot deployment, comparing prominent deep-learning models and demonstrating the effectiveness of our approach in practical settings."],"url":"http://arxiv.org/abs/2401.17996v1"}
{"created":"2024-01-31 16:52:19","title":"Multilinear Operator Networks","abstract":"Despite the remarkable capabilities of deep neural networks in image recognition, the dependence on activation functions remains a largely unexplored area and has yet to be eliminated. On the other hand, Polynomial Networks is a class of models that does not require activation functions, but have yet to perform on par with modern architectures. In this work, we aim close this gap and propose MONet, which relies solely on multilinear operators. The core layer of MONet, called Mu-Layer, captures multiplicative interactions of the elements of the input token. MONet captures high-degree interactions of the input elements and we demonstrate the efficacy of our approach on a series of image recognition and scientific computing benchmarks. The proposed model outperforms prior polynomial networks and performs on par with modern architectures. We believe that MONet can inspire further research on models that use entirely multilinear operations.","sentences":["Despite the remarkable capabilities of deep neural networks in image recognition, the dependence on activation functions remains a largely unexplored area and has yet to be eliminated.","On the other hand, Polynomial Networks is a class of models that does not require activation functions, but have yet to perform on par with modern architectures.","In this work, we aim close this gap and propose MONet, which relies solely on multilinear operators.","The core layer of MONet, called Mu-Layer, captures multiplicative interactions of the elements of the input token.","MONet captures high-degree interactions of the input elements and we demonstrate the efficacy of our approach on a series of image recognition and scientific computing benchmarks.","The proposed model outperforms prior polynomial networks and performs on par with modern architectures.","We believe that MONet can inspire further research on models that use entirely multilinear operations."],"url":"http://arxiv.org/abs/2401.17992v1"}
{"created":"2024-01-31 16:51:23","title":"Evaluating the Effectiveness of GPT-4 Turbo in Creating Defeaters for Assurance Cases","abstract":"Assurance cases (ACs) are structured arguments that support the verification of the correct implementation of systems' non-functional requirements, such as safety and security, thereby preventing system failures which could lead to catastrophic outcomes, including loss of lives. ACs facilitate the certification of systems in accordance with industrial standards, for example, DO-178C and ISO 26262. Identifying defeaters arguments that refute these ACs is essential for improving the robustness and confidence in ACs. To automate this task, we introduce a novel method that leverages the capabilities of GPT-4 Turbo, an advanced Large Language Model (LLM) developed by OpenAI, to identify defeaters within ACs formalized using the Eliminative Argumentation (EA) notation. Our initial evaluation gauges the model's proficiency in understanding and generating arguments within this framework. The findings indicate that GPT-4 Turbo excels in EA notation and is capable of generating various types of defeaters.","sentences":["Assurance cases (ACs) are structured arguments that support the verification of the correct implementation of systems' non-functional requirements, such as safety and security, thereby preventing system failures which could lead to catastrophic outcomes, including loss of lives.","ACs facilitate the certification of systems in accordance with industrial standards, for example, DO-178C and ISO 26262.","Identifying defeaters arguments that refute these ACs is essential for improving the robustness and confidence in ACs.","To automate this task, we introduce a novel method that leverages the capabilities of GPT-4 Turbo, an advanced Large Language Model (LLM) developed by OpenAI, to identify defeaters within ACs formalized using the Eliminative Argumentation (EA) notation.","Our initial evaluation gauges the model's proficiency in understanding and generating arguments within this framework.","The findings indicate that GPT-4 Turbo excels in EA notation and is capable of generating various types of defeaters."],"url":"http://arxiv.org/abs/2401.17991v1"}
{"created":"2024-01-31 16:44:20","title":"Shrub of a thousand faces: an individual segmentation from satellite images using deep learning","abstract":"Monitoring the distribution and size structure of long-living shrubs, such as Juniperus communis, can be used to estimate the long-term effects of climate change on high-mountain and high latitude ecosystems. Historical aerial very-high resolution imagery offers a retrospective tool to monitor shrub growth and distribution at high precision. Currently, deep learning models provide impressive results for detecting and delineating the contour of objects with defined shapes. However, adapting these models to detect natural objects that express complex growth patterns, such as junipers, is still a challenging task.   This research presents a novel approach that leverages remotely sensed RGB imagery in conjunction with Mask R-CNN-based instance segmentation models to individually delineate Juniperus shrubs above the treeline in Sierra Nevada (Spain). In this study, we propose a new data construction design that consists in using photo interpreted (PI) and field work (FW) data to respectively develop and externally validate the model. We also propose a new shrub-tailored evaluation algorithm based on a new metric called Multiple Intersections over Ground Truth Area (MIoGTA) to assess and optimize the model shrub delineation performance. Finally, we deploy the developed model for the first time to generate a wall-to-wall map of Juniperus individuals.   The experimental results demonstrate the efficiency of our dual data construction approach in overcoming the limitations associated with traditional field survey methods. They also highlight the robustness of MIoGTA metric in evaluating instance segmentation models on species with complex growth patterns showing more resilience against data annotation uncertainty. Furthermore, they show the effectiveness of employing Mask R-CNN with ResNet101-C4 backbone in delineating PI and FW shrubs, achieving an F1-score of 87,87% and 76.86%, respectively.","sentences":["Monitoring the distribution and size structure of long-living shrubs, such as Juniperus communis, can be used to estimate the long-term effects of climate change on high-mountain and high latitude ecosystems.","Historical aerial very-high resolution imagery offers a retrospective tool to monitor shrub growth and distribution at high precision.","Currently, deep learning models provide impressive results for detecting and delineating the contour of objects with defined shapes.","However, adapting these models to detect natural objects that express complex growth patterns, such as junipers, is still a challenging task.   ","This research presents a novel approach that leverages remotely sensed RGB imagery in conjunction with Mask R-CNN-based instance segmentation models to individually delineate Juniperus shrubs above the treeline in Sierra Nevada (Spain).","In this study, we propose a new data construction design that consists in using photo interpreted (PI) and field work (FW) data to respectively develop and externally validate the model.","We also propose a new shrub-tailored evaluation algorithm based on a new metric called Multiple Intersections over Ground Truth Area (MIoGTA) to assess and optimize the model shrub delineation performance.","Finally, we deploy the developed model for the first time to generate a wall-to-wall map of Juniperus individuals.   ","The experimental results demonstrate the efficiency of our dual data construction approach in overcoming the limitations associated with traditional field survey methods.","They also highlight the robustness of MIoGTA metric in evaluating instance segmentation models on species with complex growth patterns showing more resilience against data annotation uncertainty.","Furthermore, they show the effectiveness of employing Mask R-CNN with ResNet101-C4 backbone in delineating PI and FW shrubs, achieving an F1-score of 87,87% and 76.86%, respectively."],"url":"http://arxiv.org/abs/2401.17985v1"}
{"created":"2024-01-31 16:44:11","title":"Makinote: An FPGA-Based HW/SW Platform for Pre-Silicon Emulation of RISC-V Designs","abstract":"Emulating chip functionality before silicon production is crucial, especially with the increasing prevalence of RISC-V-based designs. FPGAs are promising candidates for such purposes due to their high-speed and reconfigurable architecture. In this paper, we introduce our Makinote, an FPGA-based Cluster platform, hosted at Barcelona Supercomputing Center (BSC-CNS), which is composed of a large number of FPGAs (in total 96 AMD/Xilinx Alveo U55c) to emulate massive size RTL designs (up to 750M ASIC cells). In addition, we introduce our FPGA shell as a powerful tool to facilitate the utilization of such a large FPGA cluster with minimal effort needed by the designers. The proposed FPGA shell provides an easy-to-use interface for the RTL developers to rapidly port such design into several FPGAs by automatically connecting to the necessary ports, e.g., PCIe Gen4, DRAM (DDR4 and HBM), ETH10g/100g. Moreover, specific drivers for exploiting RISC-V based architectures are provided within the set of tools associated with the FPGA shell. We release the tool online for further extensions.   We validate the efficiency of our hardware platform (i.e., FPGA cluster) and the software tool (i.e., FPGA Shell) by emulating a RISC-V processor and experimenting HPC Challenge application running on 32 FPGAs. Our results demonstrate that the performance improves by 8 times over the single-FPGA case.","sentences":["Emulating chip functionality before silicon production is crucial, especially with the increasing prevalence of RISC-V-based designs.","FPGAs are promising candidates for such purposes due to their high-speed and reconfigurable architecture.","In this paper, we introduce our Makinote, an FPGA-based Cluster platform, hosted at Barcelona Supercomputing Center (BSC-CNS), which is composed of a large number of FPGAs (in total 96 AMD/Xilinx Alveo U55c) to emulate massive size RTL designs (up to 750M ASIC cells).","In addition, we introduce our FPGA shell as a powerful tool to facilitate the utilization of such a large FPGA cluster with minimal effort needed by the designers.","The proposed FPGA shell provides an easy-to-use interface for the RTL developers to rapidly port such design into several FPGAs by automatically connecting to the necessary ports, e.g., PCIe Gen4, DRAM (DDR4 and HBM), ETH10g/100g.","Moreover, specific drivers for exploiting RISC-V based architectures are provided within the set of tools associated with the FPGA shell.","We release the tool online for further extensions.   ","We validate the efficiency of our hardware platform (i.e., FPGA cluster) and the software tool (i.e., FPGA Shell) by emulating a RISC-V processor and experimenting HPC Challenge application running on 32 FPGAs.","Our results demonstrate that the performance improves by 8 times over the single-FPGA case."],"url":"http://arxiv.org/abs/2401.17984v1"}
{"created":"2024-01-31 16:38:32","title":"Enhancing Multimodal Large Language Models with Vision Detection Models: An Empirical Study","abstract":"Despite the impressive capabilities of Multimodal Large Language Models (MLLMs) in integrating text and image modalities, challenges remain in accurately interpreting detailed visual elements. This paper presents an empirical study on enhancing MLLMs with state-of-the-art (SOTA) object detection and Optical Character Recognition models to improve fine-grained image understanding and reduce hallucination in responses. Our research investigates the embedding-based infusion of detection information, the impact of such infusion on the MLLMs' original abilities, and the interchangeability of detection models. We conduct systematic experiments with models such as LLaVA-1.5, DINO, and PaddleOCRv2, revealing that our approach not only refines MLLMs' performance in specific visual tasks but also maintains their original strengths. The resulting enhanced MLLMs outperform SOTA models on 9 out of 10 benchmarks, achieving an improvement of up to 12.99% on the normalized average score, marking a notable advancement in multimodal understanding. We release our codes to facilitate further exploration into the fine-grained multimodal dialogue capabilities of MLLMs.","sentences":["Despite the impressive capabilities of Multimodal Large Language Models (MLLMs) in integrating text and image modalities, challenges remain in accurately interpreting detailed visual elements.","This paper presents an empirical study on enhancing MLLMs with state-of-the-art (SOTA) object detection and Optical Character Recognition models to improve fine-grained image understanding and reduce hallucination in responses.","Our research investigates the embedding-based infusion of detection information, the impact of such infusion on the MLLMs' original abilities, and the interchangeability of detection models.","We conduct systematic experiments with models such as LLaVA-1.5, DINO, and PaddleOCRv2, revealing that our approach not only refines MLLMs' performance in specific visual tasks but also maintains their original strengths.","The resulting enhanced MLLMs outperform SOTA models on 9 out of 10 benchmarks, achieving an improvement of up to 12.99% on the normalized average score, marking a notable advancement in multimodal understanding.","We release our codes to facilitate further exploration into the fine-grained multimodal dialogue capabilities of MLLMs."],"url":"http://arxiv.org/abs/2401.17981v1"}
{"created":"2024-01-31 16:34:10","title":"Entity Linking in the Job Market Domain","abstract":"In Natural Language Processing, entity linking (EL) has centered around Wikipedia, but yet remains underexplored for the job market domain. Disambiguating skill mentions can help us get insight into the current labor market demands. In this work, we are the first to explore EL in this domain, specifically targeting the linkage of occupational skills to the ESCO taxonomy (le Vrang et al., 2014). Previous efforts linked coarse-grained (full) sentences to a corresponding ESCO skill. In this work, we link more fine-grained span-level mentions of skills. We tune two high-performing neural EL models, a bi-encoder (Wu et al., 2020) and an autoregressive model (Cao et al., 2021), on a synthetically generated mention--skill pair dataset and evaluate them on a human-annotated skill-linking benchmark. Our findings reveal that both models are capable of linking implicit mentions of skills to their correct taxonomy counterparts. Empirically, BLINK outperforms GENRE in strict evaluation, but GENRE performs better in loose evaluation (accuracy@$k$).","sentences":["In Natural Language Processing, entity linking (EL) has centered around Wikipedia, but yet remains underexplored for the job market domain.","Disambiguating skill mentions can help us get insight into the current labor market demands.","In this work, we are the first to explore EL in this domain, specifically targeting the linkage of occupational skills to the ESCO taxonomy (le Vrang et al., 2014).","Previous efforts linked coarse-grained (full) sentences to a corresponding ESCO skill.","In this work, we link more fine-grained span-level mentions of skills.","We tune two high-performing neural EL models, a bi-encoder (Wu et al., 2020) and an autoregressive model (Cao et al., 2021), on a synthetically generated mention--skill pair dataset and evaluate them on a human-annotated skill-linking benchmark.","Our findings reveal that both models are capable of linking implicit mentions of skills to their correct taxonomy counterparts.","Empirically, BLINK outperforms GENRE in strict evaluation, but GENRE performs better in loose evaluation (accuracy@$k$)."],"url":"http://arxiv.org/abs/2401.17979v1"}
{"created":"2024-01-31 16:31:54","title":"Understanding polysemanticity in neural networks through coding theory","abstract":"Despite substantial efforts, neural network interpretability remains an elusive goal, with previous research failing to provide succinct explanations of most single neurons' impact on the network output. This limitation is due to the polysemantic nature of most neurons, whereby a given neuron is involved in multiple unrelated network states, complicating the interpretation of that neuron. In this paper, we apply tools developed in neuroscience and information theory to propose both a novel practical approach to network interpretability and theoretical insights into polysemanticity and the density of codes. We infer levels of redundancy in the network's code by inspecting the eigenspectrum of the activation's covariance matrix. Furthermore, we show how random projections can reveal whether a network exhibits a smooth or non-differentiable code and hence how interpretable the code is. This same framework explains the advantages of polysemantic neurons to learning performance and explains trends found in recent results by Elhage et al.~(2022). Our approach advances the pursuit of interpretability in neural networks, providing insights into their underlying structure and suggesting new avenues for circuit-level interpretability.","sentences":["Despite substantial efforts, neural network interpretability remains an elusive goal, with previous research failing to provide succinct explanations of most single neurons' impact on the network output.","This limitation is due to the polysemantic nature of most neurons, whereby a given neuron is involved in multiple unrelated network states, complicating the interpretation of that neuron.","In this paper, we apply tools developed in neuroscience and information theory to propose both a novel practical approach to network interpretability and theoretical insights into polysemanticity and the density of codes.","We infer levels of redundancy in the network's code by inspecting the eigenspectrum of the activation's covariance matrix.","Furthermore, we show how random projections can reveal whether a network exhibits a smooth or non-differentiable code and hence how interpretable the code is.","This same framework explains the advantages of polysemantic neurons to learning performance and explains trends found in recent results by Elhage et al.~(2022).","Our approach advances the pursuit of interpretability in neural networks, providing insights into their underlying structure and suggesting new avenues for circuit-level interpretability."],"url":"http://arxiv.org/abs/2401.17975v1"}
{"created":"2024-01-31 16:30:50","title":"GUMsley: Evaluating Entity Salience in Summarization for 12 English Genres","abstract":"As NLP models become increasingly capable of understanding documents in terms of coherent entities rather than strings, obtaining the most salient entities for each document is not only an important end task in itself but also vital for Information Retrieval (IR) and other downstream applications such as controllable summarization. In this paper, we present and evaluate GUMsley, the first entity salience dataset covering all named and non-named salient entities for 12 genres of English text, aligned with entity types, Wikification links and full coreference resolution annotations. We promote a strict definition of salience using human summaries and demonstrate high inter-annotator agreement for salience based on whether a source entity is mentioned in the summary. Our evaluation shows poor performance by pre-trained SOTA summarization models and zero-shot LLM prompting in capturing salient entities in generated summaries. We also show that predicting or providing salient entities to several model architectures enhances performance and helps derive higher-quality summaries by alleviating the entity hallucination problem in existing abstractive summarization.","sentences":["As NLP models become increasingly capable of understanding documents in terms of coherent entities rather than strings, obtaining the most salient entities for each document is not only an important end task in itself but also vital for Information Retrieval (IR) and other downstream applications such as controllable summarization.","In this paper, we present and evaluate GUMsley, the first entity salience dataset covering all named and non-named salient entities for 12 genres of English text, aligned with entity types, Wikification links and full coreference resolution annotations.","We promote a strict definition of salience using human summaries and demonstrate high inter-annotator agreement for salience based on whether a source entity is mentioned in the summary.","Our evaluation shows poor performance by pre-trained SOTA summarization models and zero-shot LLM prompting in capturing salient entities in generated summaries.","We also show that predicting or providing salient entities to several model architectures enhances performance and helps derive higher-quality summaries by alleviating the entity hallucination problem in existing abstractive summarization."],"url":"http://arxiv.org/abs/2401.17974v1"}
{"created":"2024-01-31 16:27:47","title":"MelNet: A Real-Time Deep Learning Algorithm for Object Detection","abstract":"In this study, a novel deep learning algorithm for object detection, named MelNet, was introduced. MelNet underwent training utilizing the KITTI dataset for object detection. Following 300 training epochs, MelNet attained an mAP (mean average precision) score of 0.732. Additionally, three alternative models -YOLOv5, EfficientDet, and Faster-RCNN-MobileNetv3- were trained on the KITTI dataset and juxtaposed with MelNet for object detection.   The outcomes underscore the efficacy of employing transfer learning in certain instances. Notably, preexisting models trained on prominent datasets (e.g., ImageNet, COCO, and Pascal VOC) yield superior results. Another finding underscores the viability of creating a new model tailored to a specific scenario and training it on a specific dataset. This investigation demonstrates that training MelNet exclusively on the KITTI dataset also surpasses EfficientDet after 150 epochs. Consequently, post-training, MelNet's performance closely aligns with that of other pre-trained models.","sentences":["In this study, a novel deep learning algorithm for object detection, named MelNet, was introduced.","MelNet underwent training utilizing the KITTI dataset for object detection.","Following 300 training epochs, MelNet attained an mAP (mean average precision) score of 0.732.","Additionally, three alternative models -YOLOv5, EfficientDet, and Faster-RCNN-MobileNetv3- were trained on the KITTI dataset and juxtaposed with MelNet for object detection.   ","The outcomes underscore the efficacy of employing transfer learning in certain instances.","Notably, preexisting models trained on prominent datasets (e.g., ImageNet, COCO, and Pascal VOC) yield superior results.","Another finding underscores the viability of creating a new model tailored to a specific scenario and training it on a specific dataset.","This investigation demonstrates that training MelNet exclusively on the KITTI dataset also surpasses EfficientDet after 150 epochs.","Consequently, post-training, MelNet's performance closely aligns with that of other pre-trained models."],"url":"http://arxiv.org/abs/2401.17972v1"}
{"created":"2024-01-31 16:16:48","title":"CONCORD: Towards a DSL for Configurable Graph Code Representation","abstract":"Deep learning is widely used to uncover hidden patterns in large code corpora. To achieve this, constructing a format that captures the relevant characteristics and features of source code is essential. Graph-based representations have gained attention for their ability to model structural and semantic information. However, existing tools lack flexibility in constructing graphs across different programming languages, limiting their use. Additionally, the output of these tools often lacks interoperability and results in excessively large graphs, making graph-based neural networks training slower and less scalable.   We introduce CONCORD, a domain-specific language to build customizable graph representations. It implements reduction heuristics to reduce graphs' size complexity. We demonstrate its effectiveness in code smell detection as an illustrative use case and show that: first, CONCORD can produce code representations automatically per the specified configuration, and second, our heuristics can achieve comparable performance with significantly reduced size. CONCORD will help researchers a) create and experiment with customizable graph-based code representations for different software engineering tasks involving DL, b) reduce the engineering work to generate graph representations, c) address the issue of scalability in GNN models, and d) enhance the reproducibility of experiments in research through a standardized approach to code representation and analysis.","sentences":["Deep learning is widely used to uncover hidden patterns in large code corpora.","To achieve this, constructing a format that captures the relevant characteristics and features of source code is essential.","Graph-based representations have gained attention for their ability to model structural and semantic information.","However, existing tools lack flexibility in constructing graphs across different programming languages, limiting their use.","Additionally, the output of these tools often lacks interoperability and results in excessively large graphs, making graph-based neural networks training slower and less scalable.   ","We introduce CONCORD, a domain-specific language to build customizable graph representations.","It implements reduction heuristics to reduce graphs' size complexity.","We demonstrate its effectiveness in code smell detection as an illustrative use case and show that: first, CONCORD can produce code representations automatically per the specified configuration, and second, our heuristics can achieve comparable performance with significantly reduced size.","CONCORD will help researchers a) create and experiment with customizable graph-based code representations for different software engineering tasks involving DL, b) reduce the engineering work to generate graph representations, c) address the issue of scalability in GNN models, and d) enhance the reproducibility of experiments in research through a standardized approach to code representation and analysis."],"url":"http://arxiv.org/abs/2401.17967v1"}
{"created":"2024-01-31 16:08:01","title":"University Students Motives and Challenges in Utilising Institutional Repository Resources","abstract":"One of the core functions of an academic institution is to generate knowledge, disseminate it to the intended audiences, and preserve it for future use. Academic institutions are now establishing Institutional Repositories (IRs) to collect produced resources to facilitate accessibility, dissemination, utilization, and management of intellectual materials produced within an institution. This study aimed to assess postgraduate students motives for utilizing IR resources and the challenges they encounter when utilizing IR resources at the University of Dar es Salaam. This study was conducted using a descriptive study design whereby it used both qualitative and quantitative research approaches. The population of this study comprised postgraduate students, librarians, and ICT personnel from the University of Dar es Salaam. A sample of 102 respondents was drawn conveniently and purposively for this study. Data were collected through questionnaires, interviews, as well as a review of documentary sources. Quantitative data were analyzed through a Version 16 Statistics Package for Social Science and qualitative data were analyzed using content analysis. The findings indicate that access to fulltext documents, the relevance of IR resources, and easy searching of the materials in the repository system motivate the utilization of IR resources. However, several challenges impede the utilization of these resources including unreliable internet access, inaccessibility of full-text and lack of guiding policy have been revealed as the major challenges toward utilization of IR resources. The study recommends training postgraduate students on the general use of IRs. Also, the University management should develop an IR policy that will guide the utilization of IR resources","sentences":["One of the core functions of an academic institution is to generate knowledge, disseminate it to the intended audiences, and preserve it for future use.","Academic institutions are now establishing Institutional Repositories (IRs) to collect produced resources to facilitate accessibility, dissemination, utilization, and management of intellectual materials produced within an institution.","This study aimed to assess postgraduate students motives for utilizing IR resources and the challenges they encounter when utilizing IR resources at the University of Dar es Salaam.","This study was conducted using a descriptive study design whereby it used both qualitative and quantitative research approaches.","The population of this study comprised postgraduate students, librarians, and ICT personnel from the University of Dar es Salaam.","A sample of 102 respondents was drawn conveniently and purposively for this study.","Data were collected through questionnaires, interviews, as well as a review of documentary sources.","Quantitative data were analyzed through a Version 16 Statistics Package for Social Science and qualitative data were analyzed using content analysis.","The findings indicate that access to fulltext documents, the relevance of IR resources, and easy searching of the materials in the repository system motivate the utilization of IR resources.","However, several challenges impede the utilization of these resources including unreliable internet access, inaccessibility of full-text and lack of guiding policy have been revealed as the major challenges toward utilization of IR resources.","The study recommends training postgraduate students on the general use of IRs.","Also, the University management should develop an IR policy that will guide the utilization of IR resources"],"url":"http://arxiv.org/abs/2401.17959v1"}
{"created":"2024-01-31 15:59:16","title":"Error-Tolerant E-Discovery Protocols","abstract":"We consider the multi-party classification problem introduced by Dong, Hartline, and Vijayaraghavan (2022) in the context of electronic discovery (e-discovery). Based on a request for production from the requesting party, the responding party is required to provide documents that are responsive to the request except for those that are legally privileged. Our goal is to find a protocol that verifies that the responding party sends almost all responsive documents while minimizing the disclosure of non-responsive documents. We provide protocols in the challenging non-realizable setting, where the instance may not be perfectly separated by a linear classifier. We demonstrate empirically that our protocol successfully manages to find almost all relevant documents, while incurring only a small disclosure of non-responsive documents. We complement this with a theoretical analysis of our protocol in the single-dimensional setting, and other experiments on simulated data which suggest that the non-responsive disclosure incurred by our protocol may be unavoidable.","sentences":["We consider the multi-party classification problem introduced by Dong, Hartline, and Vijayaraghavan (2022) in the context of electronic discovery (e-discovery).","Based on a request for production from the requesting party, the responding party is required to provide documents that are responsive to the request except for those that are legally privileged.","Our goal is to find a protocol that verifies that the responding party sends almost all responsive documents while minimizing the disclosure of non-responsive documents.","We provide protocols in the challenging non-realizable setting, where the instance may not be perfectly separated by a linear classifier.","We demonstrate empirically that our protocol successfully manages to find almost all relevant documents, while incurring only a small disclosure of non-responsive documents.","We complement this with a theoretical analysis of our protocol in the single-dimensional setting, and other experiments on simulated data which suggest that the non-responsive disclosure incurred by our protocol may be unavoidable."],"url":"http://arxiv.org/abs/2401.17952v1"}
{"created":"2024-01-31 15:57:21","title":"HyperZ$\\cdot$Z$\\cdot$W Operator Connects Slow-Fast Networks for Full Context Interaction","abstract":"The self-attention mechanism utilizes large implicit weight matrices, programmed through dot product-based activations with very few trainable parameters, to enable long sequence modeling. In this paper, we investigate the possibility of discarding residual learning by employing large implicit kernels to achieve full context interaction at each layer of the network. To accomplish it, we introduce coordinate-based implicit MLPs as a slow network to generate hyper-kernels for another fast convolutional network. To get context-varying weights for fast dynamic encoding, we propose a $\\mathrm{Hyper}\\mathcal{Z{\\cdot}Z{\\cdot}W}$ operator that connects hyper-kernels ($\\mathcal{W}$) and hidden activations ($\\mathcal{Z}$) through simple elementwise multiplication, followed by convolution of $\\mathcal{Z}$ using the context-dependent $\\mathcal{W}$. Based on this design, we present a novel Terminator architecture that integrates hyper-kernels of different sizes to produce multi-branch hidden representations for enhancing the feature extraction capability of each layer. Additionally, a bottleneck layer is employed to compress the concatenated channels, allowing only valuable information to propagate to the subsequent layers. Notably, our model incorporates several innovative components and exhibits excellent properties, such as introducing local feedback error for updating the slow network, stable zero-mean features, faster training convergence, and fewer model parameters. Extensive experimental results on pixel-level 1D and 2D image classification benchmarks demonstrate the superior performance of our architecture.","sentences":["The self-attention mechanism utilizes large implicit weight matrices, programmed through dot product-based activations with very few trainable parameters, to enable long sequence modeling.","In this paper, we investigate the possibility of discarding residual learning by employing large implicit kernels to achieve full context interaction at each layer of the network.","To accomplish it, we introduce coordinate-based implicit MLPs as a slow network to generate hyper-kernels for another fast convolutional network.","To get context-varying weights for fast dynamic encoding, we propose a $\\mathrm{Hyper}\\mathcal{Z{\\cdot}Z{\\cdot}W}$ operator that connects hyper-kernels ($\\mathcal{W}$) and hidden activations ($\\mathcal{Z}$) through simple elementwise multiplication, followed by convolution of $\\mathcal{Z}$ using the context-dependent $\\mathcal{W}$. Based on this design, we present a novel Terminator architecture that integrates hyper-kernels of different sizes to produce multi-branch hidden representations for enhancing the feature extraction capability of each layer.","Additionally, a bottleneck layer is employed to compress the concatenated channels, allowing only valuable information to propagate to the subsequent layers.","Notably, our model incorporates several innovative components and exhibits excellent properties, such as introducing local feedback error for updating the slow network, stable zero-mean features, faster training convergence, and fewer model parameters.","Extensive experimental results on pixel-level 1D and 2D image classification benchmarks demonstrate the superior performance of our architecture."],"url":"http://arxiv.org/abs/2401.17948v1"}
{"created":"2024-01-31 15:35:21","title":"[Lions: 1] and [Tigers: 2] and [Bears: 3], Oh My! Literary Coreference Annotation with LLMs","abstract":"Coreference annotation and resolution is a vital component of computational literary studies. However, it has previously been difficult to build high quality systems for fiction. Coreference requires complicated structured outputs, and literary text involves subtle inferences and highly varied language. New language-model-based seq2seq systems present the opportunity to solve both these problems by learning to directly generate a copy of an input sentence with markdown-like annotations. We create, evaluate, and release several trained models for coreference, as well as a workflow for training new models.","sentences":["Coreference annotation and resolution is a vital component of computational literary studies.","However, it has previously been difficult to build high quality systems for fiction.","Coreference requires complicated structured outputs, and literary text involves subtle inferences and highly varied language.","New language-model-based seq2seq systems present the opportunity to solve both these problems by learning to directly generate a copy of an input sentence with markdown-like annotations.","We create, evaluate, and release several trained models for coreference, as well as a workflow for training new models."],"url":"http://arxiv.org/abs/2401.17922v1"}
{"created":"2024-01-31 15:33:37","title":"LOCOST: State-Space Models for Long Document Abstractive Summarization","abstract":"State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies. We propose LOCOST: an encoder-decoder architecture based on state-space models for conditional text generation with long context inputs. With a computational complexity of $O(L \\log L)$, this architecture can handle significantly longer sequences than state-of-the-art models that are based on sparse attention patterns. We evaluate our model on a series of long document abstractive summarization tasks. The model reaches a performance level that is 93-96% comparable to the top-performing sparse transformers of the same size while saving up to 50% memory during training and up to 87% during inference. Additionally, LOCOST effectively handles input texts exceeding 600K tokens at inference time, setting new state-of-the-art results on full-book summarization and opening new perspectives for long input processing.","sentences":["State-space models are a low-complexity alternative to transformers for encoding long sequences and capturing long-term dependencies.","We propose LOCOST: an encoder-decoder architecture based on state-space models for conditional text generation with long context inputs.","With a computational complexity of $O(L \\log L)$, this architecture can handle significantly longer sequences than state-of-the-art models that are based on sparse attention patterns.","We evaluate our model on a series of long document abstractive summarization tasks.","The model reaches a performance level that is 93-96% comparable to the top-performing sparse transformers of the same size while saving up to 50% memory during training and up to 87% during inference.","Additionally, LOCOST effectively handles input texts exceeding 600K tokens at inference time, setting new state-of-the-art results on full-book summarization and opening new perspectives for long input processing."],"url":"http://arxiv.org/abs/2401.17919v1"}
{"created":"2024-01-31 15:33:29","title":"GuardFS: a File System for Integrated Detection and Mitigation of Linux-based Ransomware","abstract":"Although ransomware has received broad attention in media and research, this evolving threat vector still poses a systematic threat. Related literature has explored their detection using various approaches leveraging Machine and Deep Learning. While these approaches are effective in detecting malware, they do not answer how to use this intelligence to protect against threats, raising concerns about their applicability in a hostile environment. Solutions that focus on mitigation rarely explore how to prevent and not just alert or halt its execution, especially when considering Linux-based samples. This paper presents GuardFS, a file system-based approach to investigate the integration of detection and mitigation of ransomware. Using a bespoke overlay file system, data is extracted before files are accessed. Models trained on this data are used by three novel defense configurations that obfuscate, delay, or track access to the file system. The experiments on GuardFS test the configurations in a reactive setting. The results demonstrate that although data loss cannot be completely prevented, it can be significantly reduced. Usability and performance analysis demonstrate that the defense effectiveness of the configurations relates to their impact on resource consumption and usability.","sentences":["Although ransomware has received broad attention in media and research, this evolving threat vector still poses a systematic threat.","Related literature has explored their detection using various approaches leveraging Machine and Deep Learning.","While these approaches are effective in detecting malware, they do not answer how to use this intelligence to protect against threats, raising concerns about their applicability in a hostile environment.","Solutions that focus on mitigation rarely explore how to prevent and not just alert or halt its execution, especially when considering Linux-based samples.","This paper presents GuardFS, a file system-based approach to investigate the integration of detection and mitigation of ransomware.","Using a bespoke overlay file system, data is extracted before files are accessed.","Models trained on this data are used by three novel defense configurations that obfuscate, delay, or track access to the file system.","The experiments on GuardFS test the configurations in a reactive setting.","The results demonstrate that although data loss cannot be completely prevented, it can be significantly reduced.","Usability and performance analysis demonstrate that the defense effectiveness of the configurations relates to their impact on resource consumption and usability."],"url":"http://arxiv.org/abs/2401.17917v1"}
{"created":"2024-01-31 15:32:44","title":"Source-free Domain Adaptive Object Detection in Remote Sensing Images","abstract":"Recent studies have used unsupervised domain adaptive object detection (UDAOD) methods to bridge the domain gap in remote sensing (RS) images. However, UDAOD methods typically assume that the source domain data can be accessed during the domain adaptation process. This setting is often impractical in the real world due to RS data privacy and transmission difficulty. To address this challenge, we propose a practical source-free object detection (SFOD) setting for RS images, which aims to perform target domain adaptation using only the source pre-trained model. We propose a new SFOD method for RS images consisting of two parts: perturbed domain generation and alignment. The proposed multilevel perturbation constructs the perturbed domain in a simple yet efficient form by perturbing the domain-variant features at the image level and feature level according to the color and style bias. The proposed multilevel alignment calculates feature and label consistency between the perturbed domain and the target domain across the teacher-student network, and introduces the distillation of feature prototype to mitigate the noise of pseudo-labels. By requiring the detector to be consistent in the perturbed domain and the target domain, the detector is forced to focus on domaininvariant features. Extensive results of three synthetic-to-real experiments and three cross-sensor experiments have validated the effectiveness of our method which does not require access to source domain RS images. Furthermore, experiments on computer vision datasets show that our method can be extended to other fields as well. Our code will be available at: https://weixliu.github.io/ .","sentences":["Recent studies have used unsupervised domain adaptive object detection (UDAOD) methods to bridge the domain gap in remote sensing (RS) images.","However, UDAOD methods typically assume that the source domain data can be accessed during the domain adaptation process.","This setting is often impractical in the real world due to RS data privacy and transmission difficulty.","To address this challenge, we propose a practical source-free object detection (SFOD) setting for RS images, which aims to perform target domain adaptation using only the source pre-trained model.","We propose a new SFOD method for RS images consisting of two parts: perturbed domain generation and alignment.","The proposed multilevel perturbation constructs the perturbed domain in a simple yet efficient form by perturbing the domain-variant features at the image level and feature level according to the color and style bias.","The proposed multilevel alignment calculates feature and label consistency between the perturbed domain and the target domain across the teacher-student network, and introduces the distillation of feature prototype to mitigate the noise of pseudo-labels.","By requiring the detector to be consistent in the perturbed domain and the target domain, the detector is forced to focus on domaininvariant features.","Extensive results of three synthetic-to-real experiments and three cross-sensor experiments have validated the effectiveness of our method which does not require access to source domain RS images.","Furthermore, experiments on computer vision datasets show that our method can be extended to other fields as well.","Our code will be available at: https://weixliu.github.io/ ."],"url":"http://arxiv.org/abs/2401.17916v1"}
{"created":"2024-01-31 15:24:13","title":"Attention Graph for Multi-Robot Social Navigation with Deep Reinforcement Learning","abstract":"Learning robot navigation strategies among pedestrian is crucial for domain based applications. Combining perception, planning and prediction allows us to model the interactions between robots and pedestrians, resulting in impressive outcomes especially with recent approaches based on deep reinforcement learning (RL). However, these works do not consider multi-robot scenarios. In this paper, we present MultiSoc, a new method for learning multi-agent socially aware navigation strategies using RL. Inspired by recent works on multi-agent deep RL, our method leverages graph-based representation of agent interactions, combining the positions and fields of view of entities (pedestrians and agents). Each agent uses a model based on two Graph Neural Network combined with attention mechanisms. First an edge-selector produces a sparse graph, then a crowd coordinator applies node attention to produce a graph representing the influence of each entity on the others. This is incorporated into a model-free RL framework to learn multi-agent policies. We evaluate our approach on simulation and provide a series of experiments in a set of various conditions (number of agents / pedestrians). Empirical results show that our method learns faster than social navigation deep RL mono-agent techniques, and enables efficient multi-agent implicit coordination in challenging crowd navigation with multiple heterogeneous humans. Furthermore, by incorporating customizable meta-parameters, we can adjust the neighborhood density to take into account in our navigation strategy.","sentences":["Learning robot navigation strategies among pedestrian is crucial for domain based applications.","Combining perception, planning and prediction allows us to model the interactions between robots and pedestrians, resulting in impressive outcomes especially with recent approaches based on deep reinforcement learning (RL).","However, these works do not consider multi-robot scenarios.","In this paper, we present MultiSoc, a new method for learning multi-agent socially aware navigation strategies using RL.","Inspired by recent works on multi-agent deep RL, our method leverages graph-based representation of agent interactions, combining the positions and fields of view of entities (pedestrians and agents).","Each agent uses a model based on two Graph Neural Network combined with attention mechanisms.","First an edge-selector produces a sparse graph, then a crowd coordinator applies node attention to produce a graph representing the influence of each entity on the others.","This is incorporated into a model-free RL framework to learn multi-agent policies.","We evaluate our approach on simulation and provide a series of experiments in a set of various conditions (number of agents / pedestrians).","Empirical results show that our method learns faster than social navigation deep RL mono-agent techniques, and enables efficient multi-agent implicit coordination in challenging crowd navigation with multiple heterogeneous humans.","Furthermore, by incorporating customizable meta-parameters, we can adjust the neighborhood density to take into account in our navigation strategy."],"url":"http://arxiv.org/abs/2401.17914v1"}
{"created":"2024-01-31 15:16:25","title":"SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural Networks","abstract":"As spiking neural networks receive more attention, we look toward applications of this computing paradigm in fields other than computer vision and signal processing. One major field, underexplored in the neuromorphic setting, is Natural Language Processing (NLP), where most state-of-the-art solutions still heavily rely on resource-consuming and power-hungry traditional deep learning architectures. Therefore, it is compelling to design NLP models for neuromorphic architectures due to their low energy requirements, with the additional benefit of a more human-brain-like operating model for processing information. However, one of the biggest issues with bringing NLP to the neuromorphic setting is in properly encoding text into a spike train so that it can be seamlessly handled by both current and future SNN architectures. In this paper, we compare various methods of encoding text as spikes and assess each method's performance in an associated SNN on a downstream NLP task, namely, sentiment analysis. Furthermore, we go on to propose a new method of encoding text as spikes that outperforms a widely-used rate-coding technique, Poisson rate-coding, by around 13\\% on our benchmark NLP tasks. Subsequently, we demonstrate the energy efficiency of SNNs implemented in hardware for the sentiment analysis task compared to traditional deep neural networks, observing an energy efficiency increase of more than 32x during inference and 60x during training while incurring the expected energy-performance tradeoff.","sentences":["As spiking neural networks receive more attention, we look toward applications of this computing paradigm in fields other than computer vision and signal processing.","One major field, underexplored in the neuromorphic setting, is Natural Language Processing (NLP), where most state-of-the-art solutions still heavily rely on resource-consuming and power-hungry traditional deep learning architectures.","Therefore, it is compelling to design NLP models for neuromorphic architectures due to their low energy requirements, with the additional benefit of a more human-brain-like operating model for processing information.","However, one of the biggest issues with bringing NLP to the neuromorphic setting is in properly encoding text into a spike train so that it can be seamlessly handled by both current and future SNN architectures.","In this paper, we compare various methods of encoding text as spikes and assess each method's performance in an associated SNN on a downstream NLP task, namely, sentiment analysis.","Furthermore, we go on to propose a new method of encoding text as spikes that outperforms a widely-used rate-coding technique, Poisson rate-coding, by around 13\\% on our benchmark NLP tasks.","Subsequently, we demonstrate the energy efficiency of SNNs implemented in hardware for the sentiment analysis task compared to traditional deep neural networks, observing an energy efficiency increase of more than 32x during inference and 60x during training while incurring the expected energy-performance tradeoff."],"url":"http://arxiv.org/abs/2401.17911v1"}
{"created":"2024-01-31 15:15:41","title":"Controllable Dense Captioner with Multimodal Embedding Bridging","abstract":"In this paper, we propose a controllable dense captioner (ControlCap), which accommodates user's intention to dense captioning by introducing linguistic guidance. ControlCap is defined as a multimodal embedding bridging architecture, which comprises multimodal embedding generation (MEG) module and bi-directional embedding bridging (BEB) module. While MEG module represents objects/regions by combining embeddings of detailed information with context-aware ones, it also endows ControlCap the adaptability to specialized controls by utilizing them as linguistic guidance. BEB module aligns the linguistic guidance with visual embeddings through borrowing/returning features from/to the visual domain and gathering such features to predict text descriptions. Experiments on Visual Genome and VG-COCO datasets show that ControlCap respectively outperforms the state-of-the-art methods by 1.5% and 3.7% (mAP). Last but not least, with the capability of converting region-category pairs to region-text pairs, ControlCap is able to act as a powerful data engine for dense captioning. Code is available at https://github.com/callsys/ControlCap.","sentences":["In this paper, we propose a controllable dense captioner (ControlCap), which accommodates user's intention to dense captioning by introducing linguistic guidance.","ControlCap is defined as a multimodal embedding bridging architecture, which comprises multimodal embedding generation (MEG) module and bi-directional embedding bridging (BEB) module.","While MEG module represents objects/regions by combining embeddings of detailed information with context-aware ones, it also endows ControlCap the adaptability to specialized controls by utilizing them as linguistic guidance.","BEB module aligns the linguistic guidance with visual embeddings through borrowing/returning features from/to the visual domain and gathering such features to predict text descriptions.","Experiments on Visual Genome and VG-COCO datasets show that ControlCap respectively outperforms the state-of-the-art methods by 1.5% and 3.7% (mAP).","Last but not least, with the capability of converting region-category pairs to region-text pairs, ControlCap is able to act as a powerful data engine for dense captioning.","Code is available at https://github.com/callsys/ControlCap."],"url":"http://arxiv.org/abs/2401.17910v1"}
{"created":"2024-01-31 15:11:20","title":"SubPipe: A Submarine Pipeline Inspection Dataset for Segmentation and Visual-inertial Localization","abstract":"This paper presents SubPipe, an underwater dataset for SLAM, object detection, and image segmentation. SubPipe has been recorded using a \\gls{LAUV}, operated by OceanScan MST, and carrying a sensor suite including two cameras, a side-scan sonar, and an inertial navigation system, among other sensors. The AUV has been deployed in a pipeline inspection environment with a submarine pipe partially covered by sand. The AUV's pose ground truth is estimated from the navigation sensors. The side-scan sonar and RGB images include object detection and segmentation annotations, respectively. State-of-the-art segmentation, object detection, and SLAM methods are benchmarked on SubPipe to demonstrate the dataset's challenges and opportunities for leveraging computer vision algorithms. To the authors' knowledge, this is the first annotated underwater dataset providing a real pipeline inspection scenario. The dataset and experiments are publicly available online at https://github.com/remaro-network/SubPipe-dataset","sentences":["This paper presents SubPipe, an underwater dataset for SLAM, object detection, and image segmentation.","SubPipe has been recorded using a \\gls{LAUV}, operated by OceanScan MST, and carrying a sensor suite including two cameras, a side-scan sonar, and an inertial navigation system, among other sensors.","The AUV has been deployed in a pipeline inspection environment with a submarine pipe partially covered by sand.","The AUV's pose ground truth is estimated from the navigation sensors.","The side-scan sonar and RGB images include object detection and segmentation annotations, respectively.","State-of-the-art segmentation, object detection, and SLAM methods are benchmarked on SubPipe to demonstrate the dataset's challenges and opportunities for leveraging computer vision algorithms.","To the authors' knowledge, this is the first annotated underwater dataset providing a real pipeline inspection scenario.","The dataset and experiments are publicly available online at https://github.com/remaro-network/SubPipe-dataset"],"url":"http://arxiv.org/abs/2401.17907v1"}
{"created":"2024-01-31 15:10:29","title":"Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation","abstract":"The Segment Anything Model (SAM), a profound vision foundation model pre-trained on a large-scale dataset, breaks the boundaries of general segmentation and sparks various downstream applications. This paper introduces Hi-SAM, a unified model leveraging SAM for hierarchical text segmentation. Hi-SAM excels in text segmentation across four hierarchies, including stroke, word, text-line, and paragraph, while realizing layout analysis as well. Specifically, we first turn SAM into a high-quality text stroke segmentation (TSS) model through a parameter-efficient fine-tuning approach. We use this TSS model to iteratively generate the text stroke labels in a semi-automatical manner, unifying labels across the four text hierarchies in the HierText dataset. Subsequently, with these complete labels, we launch the end-to-end trainable Hi-SAM based on the TSS architecture with a customized hierarchical mask decoder. During inference, Hi-SAM offers both automatic mask generation (AMG) mode and promptable segmentation mode. In terms of the AMG mode, Hi-SAM segments text stroke foreground masks initially, then samples foreground points for hierarchical text mask generation and achieves layout analysis in passing. As for the promptable mode, Hi-SAM provides word, text-line, and paragraph masks with a single point click. Experimental results show the state-of-the-art performance of our TSS model: 84.86% fgIOU on Total-Text and 88.96% fgIOU on TextSeg for text stroke segmentation. Moreover, compared to the previous specialist for joint hierarchical detection and layout analysis on HierText, Hi-SAM achieves significant improvements: 4.73% PQ and 5.39% F1 on the text-line level, 5.49% PQ and 7.39% F1 on the paragraph level layout analysis, requiring 20x fewer training epochs. The code is available at https://github.com/ymy-k/Hi-SAM.","sentences":["The Segment Anything Model (SAM), a profound vision foundation model pre-trained on a large-scale dataset, breaks the boundaries of general segmentation and sparks various downstream applications.","This paper introduces Hi-SAM, a unified model leveraging SAM for hierarchical text segmentation.","Hi-SAM excels in text segmentation across four hierarchies, including stroke, word, text-line, and paragraph, while realizing layout analysis as well.","Specifically, we first turn SAM into a high-quality text stroke segmentation (TSS) model through a parameter-efficient fine-tuning approach.","We use this TSS model to iteratively generate the text stroke labels in a semi-automatical manner, unifying labels across the four text hierarchies in the HierText dataset.","Subsequently, with these complete labels, we launch the end-to-end trainable Hi-SAM based on the TSS architecture with a customized hierarchical mask decoder.","During inference, Hi-SAM offers both automatic mask generation (AMG) mode and promptable segmentation mode.","In terms of the AMG mode, Hi-SAM segments text stroke foreground masks initially, then samples foreground points for hierarchical text mask generation and achieves layout analysis in passing.","As for the promptable mode, Hi-SAM provides word, text-line, and paragraph masks with a single point click.","Experimental results show the state-of-the-art performance of our TSS model: 84.86% fgIOU on Total-Text and 88.96% fgIOU on TextSeg for text stroke segmentation.","Moreover, compared to the previous specialist for joint hierarchical detection and layout analysis on HierText, Hi-SAM achieves significant improvements: 4.73% PQ and 5.39% F1 on the text-line level, 5.49% PQ and 7.39% F1 on the paragraph level layout analysis, requiring 20x fewer training epochs.","The code is available at https://github.com/ymy-k/Hi-SAM."],"url":"http://arxiv.org/abs/2401.17904v1"}
{"created":"2024-01-31 15:04:01","title":"Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance","abstract":"The objective of legal text entailment is to ascertain whether the assertions in a legal query logically follow from the information provided in one or multiple legal articles. ChatGPT, a large language model, is robust in many natural language processing tasks, including legal text entailment: when we set the temperature = 0 (the ChatGPT answers are deterministic) and prompt the model, it achieves 70.64% accuracy on COLIEE 2022 dataset, which outperforms the previous SOTA of 67.89%. On the other hand, if the temperature is larger than zero, ChatGPT answers are not deterministic, leading to inconsistent answers and fluctuating results. We propose to leverage label models (a fundamental component of weak supervision techniques) to integrate the provisional answers by ChatGPT into consolidated labels. By that way, we treat ChatGPT provisional answers as noisy predictions which can be consolidated by label models. The experimental results demonstrate that this approach can attain an accuracy of 76.15%, marking a significant improvement of 8.26% over the prior state-of-the-art benchmark. Additionally, we perform an analysis of the instances where ChatGPT produces incorrect answers, then we classify the errors, offering insights that could guide potential enhancements for future research endeavors.","sentences":["The objective of legal text entailment is to ascertain whether the assertions in a legal query logically follow from the information provided in one or multiple legal articles.","ChatGPT, a large language model, is robust in many natural language processing tasks, including legal text entailment: when we set the temperature = 0 (the ChatGPT answers are deterministic) and prompt the model, it achieves 70.64% accuracy on COLIEE 2022 dataset, which outperforms the previous SOTA of 67.89%.","On the other hand, if the temperature is larger than zero, ChatGPT answers are not deterministic, leading to inconsistent answers and fluctuating results.","We propose to leverage label models (a fundamental component of weak supervision techniques) to integrate the provisional answers by ChatGPT into consolidated labels.","By that way, we treat ChatGPT provisional answers as noisy predictions which can be consolidated by label models.","The experimental results demonstrate that this approach can attain an accuracy of 76.15%, marking a significant improvement of 8.26% over the prior state-of-the-art benchmark.","Additionally, we perform an analysis of the instances where ChatGPT produces incorrect answers, then we classify the errors, offering insights that could guide potential enhancements for future research endeavors."],"url":"http://arxiv.org/abs/2401.17897v1"}
{"created":"2024-01-31 15:02:26","title":"ReplaceAnything3D:Text-Guided 3D Scene Editing with Compositional Neural Radiance Fields","abstract":"We introduce ReplaceAnything3D model (RAM3D), a novel text-guided 3D scene editing method that enables the replacement of specific objects within a scene. Given multi-view images of a scene, a text prompt describing the object to replace, and a text prompt describing the new object, our Erase-and-Replace approach can effectively swap objects in the scene with newly generated content while maintaining 3D consistency across multiple viewpoints. We demonstrate the versatility of ReplaceAnything3D by applying it to various realistic 3D scenes, showcasing results of modified foreground objects that are well-integrated with the rest of the scene without affecting its overall integrity.","sentences":["We introduce ReplaceAnything3D model (RAM3D), a novel text-guided 3D scene editing method that enables the replacement of specific objects within a scene.","Given multi-view images of a scene, a text prompt describing the object to replace, and a text prompt describing the new object, our Erase-and-Replace approach can effectively swap objects in the scene with newly generated content while maintaining 3D consistency across multiple viewpoints.","We demonstrate the versatility of ReplaceAnything3D by applying it to various realistic 3D scenes, showcasing results of modified foreground objects that are well-integrated with the rest of the scene without affecting its overall integrity."],"url":"http://arxiv.org/abs/2401.17895v1"}
{"created":"2024-01-31 14:53:33","title":"The inherent randomness of news virality on social media","abstract":"Initially conceived for entertainment, social media platforms have profoundly transformed the dissemination of information and consequently reshaped the dynamics of agenda-setting. In this scenario, understanding the factors that capture audience attention and drive viral content is crucial. Employing Gibrat's Law, which posits that an entity's growth rate is unrelated to its size, we examine the engagement growth dynamics of news outlets on social media. Our analysis encloses the Facebook historical data of over a thousand news outlets, encompassing approximately 57 million posts in four European languages from 2008 to the end of 2022. We discover universal growth dynamics according to which news virality is independent of the traditional size or engagement with the outlet. Moreover, our analysis reveals a significant long-term impact of news source reliability on engagement growth, with engagement induced by unreliable sources decreasing over time. We conclude the paper by presenting a statistical model replicating the observed growth dynamics.","sentences":["Initially conceived for entertainment, social media platforms have profoundly transformed the dissemination of information and consequently reshaped the dynamics of agenda-setting.","In this scenario, understanding the factors that capture audience attention and drive viral content is crucial.","Employing Gibrat's Law, which posits that an entity's growth rate is unrelated to its size, we examine the engagement growth dynamics of news outlets on social media.","Our analysis encloses the Facebook historical data of over a thousand news outlets, encompassing approximately 57 million posts in four European languages from 2008 to the end of 2022.","We discover universal growth dynamics according to which news virality is independent of the traditional size or engagement with the outlet.","Moreover, our analysis reveals a significant long-term impact of news source reliability on engagement growth, with engagement induced by unreliable sources decreasing over time.","We conclude the paper by presenting a statistical model replicating the observed growth dynamics."],"url":"http://arxiv.org/abs/2401.17890v1"}
{"created":"2024-01-31 14:45:11","title":"Detecting Groups in Directed and Non-Directed Bipartite Networks","abstract":"Bipartite networks provide an effective resource for representing, characterizing, and modeling several abstract and real-world systems and structures involving binary relations, which include food webs, social interactions, and customer-product relationships. Of particular interest is the problem of, given a specific bipartite network, to identify possible respective groups or clusters characterized by similar interconnecting patterns. The present work approaches this issue by extending and complementing a previously described coincidence similarity methodology (Bioarxiv, doi.org/10.1101/2022.07.16.500294) in several manners, including the consideration of direct and non-directed bipartite networks, the characterization of groups in those networks, as well as considering synthetic bipartite networks presenting groups as a resource for studying the performance of the described methodology. Several interesting results are described and discussed, including the corroboration of the potential of the coincidence similarity methodology for achieving enhanced separation between the groups in bipartite networks.","sentences":["Bipartite networks provide an effective resource for representing, characterizing, and modeling several abstract and real-world systems and structures involving binary relations, which include food webs, social interactions, and customer-product relationships.","Of particular interest is the problem of, given a specific bipartite network, to identify possible respective groups or clusters characterized by similar interconnecting patterns.","The present work approaches this issue by extending and complementing a previously described coincidence similarity methodology (Bioarxiv, doi.org/10.1101/2022.07.16.500294) in several manners, including the consideration of direct and non-directed bipartite networks, the characterization of groups in those networks, as well as considering synthetic bipartite networks presenting groups as a resource for studying the performance of the described methodology.","Several interesting results are described and discussed, including the corroboration of the potential of the coincidence similarity methodology for achieving enhanced separation between the groups in bipartite networks."],"url":"http://arxiv.org/abs/2401.17887v1"}
{"created":"2024-01-31 14:41:40","title":"Reimagining Reality: A Comprehensive Survey of Video Inpainting Techniques","abstract":"This paper offers a comprehensive analysis of recent advancements in video inpainting techniques, a critical subset of computer vision and artificial intelligence. As a process that restores or fills in missing or corrupted portions of video sequences with plausible content, video inpainting has evolved significantly with the advent of deep learning methodologies. Despite the plethora of existing methods and their swift development, the landscape remains complex, posing challenges to both novices and established researchers. Our study deconstructs major techniques, their underpinning theories, and their effective applications. Moreover, we conduct an exhaustive comparative study, centering on two often-overlooked dimensions: visual quality and computational efficiency. We adopt a human-centric approach to assess visual quality, enlisting a panel of annotators to evaluate the output of different video inpainting techniques. This provides a nuanced qualitative understanding that complements traditional quantitative metrics. Concurrently, we delve into the computational aspects, comparing inference times and memory demands across a standardized hardware setup. This analysis underscores the balance between quality and efficiency: a critical consideration for practical applications where resources may be constrained. By integrating human validation and computational resource comparison, this survey not only clarifies the present landscape of video inpainting techniques but also charts a course for future explorations in this vibrant and evolving field.","sentences":["This paper offers a comprehensive analysis of recent advancements in video inpainting techniques, a critical subset of computer vision and artificial intelligence.","As a process that restores or fills in missing or corrupted portions of video sequences with plausible content, video inpainting has evolved significantly with the advent of deep learning methodologies.","Despite the plethora of existing methods and their swift development, the landscape remains complex, posing challenges to both novices and established researchers.","Our study deconstructs major techniques, their underpinning theories, and their effective applications.","Moreover, we conduct an exhaustive comparative study, centering on two often-overlooked dimensions: visual quality and computational efficiency.","We adopt a human-centric approach to assess visual quality, enlisting a panel of annotators to evaluate the output of different video inpainting techniques.","This provides a nuanced qualitative understanding that complements traditional quantitative metrics.","Concurrently, we delve into the computational aspects, comparing inference times and memory demands across a standardized hardware setup.","This analysis underscores the balance between quality and efficiency: a critical consideration for practical applications where resources may be constrained.","By integrating human validation and computational resource comparison, this survey not only clarifies the present landscape of video inpainting techniques but also charts a course for future explorations in this vibrant and evolving field."],"url":"http://arxiv.org/abs/2401.17883v1"}
{"created":"2024-01-31 14:41:23","title":"I Think, Therefore I am: Awareness in Large Language Models","abstract":"Do large language models (LLMs) exhibit any forms of awareness similar to humans? In this paper, we introduce the concept of awareness to LLMs, arguing that awareness is an essential aspect of trustworthiness for LLMs to enhance their interaction with humans while ensuring ethical responses. We define awareness in LLMs as the ability to perceive and understand themselves as AI models and to exhibit social intelligence. We identify four key dimensions of awareness: capability, mission, emotion, and perspective. To assess LLMs on these dimensions, we introduce a specialized dataset, AwareLLM dataset. Our findings reveal that LLMs demonstrate a decent degree of awareness, though they still lack substantial capability awareness.","sentences":["Do large language models (LLMs) exhibit any forms of awareness similar to humans?","In this paper, we introduce the concept of awareness to LLMs, arguing that awareness is an essential aspect of trustworthiness for LLMs to enhance their interaction with humans while ensuring ethical responses.","We define awareness in LLMs as the ability to perceive and understand themselves as AI models and to exhibit social intelligence.","We identify four key dimensions of awareness: capability, mission, emotion, and perspective.","To assess LLMs on these dimensions, we introduce a specialized dataset, AwareLLM dataset.","Our findings reveal that LLMs demonstrate a decent degree of awareness, though they still lack substantial capability awareness."],"url":"http://arxiv.org/abs/2401.17882v1"}
{"created":"2024-01-31 14:39:11","title":"PVLR: Prompt-driven Visual-Linguistic Representation Learning for Multi-Label Image Recognition","abstract":"Multi-label image recognition is a fundamental task in computer vision. Recently, vision-language models have made notable advancements in this area. However, previous methods often failed to effectively leverage the rich knowledge within language models and instead incorporated label semantics into visual features in a unidirectional manner. In this paper, we propose a Prompt-driven Visual-Linguistic Representation Learning (PVLR) framework to better leverage the capabilities of the linguistic modality. In PVLR, we first introduce a dual-prompting strategy comprising Knowledge-Aware Prompting (KAP) and Context-Aware Prompting (CAP). KAP utilizes fixed prompts to capture the intrinsic semantic knowledge and relationships across all labels, while CAP employs learnable prompts to capture context-aware label semantics and relationships. Later, we propose an Interaction and Fusion Module (IFM) to interact and fuse the representations obtained from KAP and CAP. In contrast to the unidirectional fusion in previous works, we introduce a Dual-Modal Attention (DMA) that enables bidirectional interaction between textual and visual features, yielding context-aware label representations and semantic-related visual representations, which are subsequently used to calculate similarities and generate final predictions for all labels. Extensive experiments on three popular datasets including MS-COCO, Pascal VOC 2007, and NUS-WIDE demonstrate the superiority of PVLR.","sentences":["Multi-label image recognition is a fundamental task in computer vision.","Recently, vision-language models have made notable advancements in this area.","However, previous methods often failed to effectively leverage the rich knowledge within language models and instead incorporated label semantics into visual features in a unidirectional manner.","In this paper, we propose a Prompt-driven Visual-Linguistic Representation Learning (PVLR) framework to better leverage the capabilities of the linguistic modality.","In PVLR, we first introduce a dual-prompting strategy comprising Knowledge-Aware Prompting (KAP) and Context-Aware Prompting (CAP).","KAP utilizes fixed prompts to capture the intrinsic semantic knowledge and relationships across all labels, while CAP employs learnable prompts to capture context-aware label semantics and relationships.","Later, we propose an Interaction and Fusion Module (IFM) to interact and fuse the representations obtained from KAP and CAP.","In contrast to the unidirectional fusion in previous works, we introduce a Dual-Modal Attention (DMA) that enables bidirectional interaction between textual and visual features, yielding context-aware label representations and semantic-related visual representations, which are subsequently used to calculate similarities and generate final predictions for all labels.","Extensive experiments on three popular datasets including MS-COCO, Pascal VOC 2007, and NUS-WIDE demonstrate the superiority of PVLR."],"url":"http://arxiv.org/abs/2401.17881v1"}
{"created":"2024-01-31 14:37:06","title":"Graph Attention-based Reinforcement Learning for Trajectory Design and Resource Assignment in Multi-UAV Assisted Communication","abstract":"In the multiple unmanned aerial vehicle (UAV)- assisted downlink communication, it is challenging for UAV base stations (UAV BSs) to realize trajectory design and resource assignment in unknown environments. The cooperation and competition between UAV BSs in the communication network leads to a Markov game problem. Multi-agent reinforcement learning is a significant solution for the above decision-making. However, there are still many common issues, such as the instability of the system and low utilization of historical data, that limit its application. In this paper, a novel graph-attention multi-agent trust region (GA-MATR) reinforcement learning framework is proposed to solve the multi-UAV assisted communication problem. Graph recurrent network is introduced to process and analyze complex topology of the communication network, so as to extract useful information and patterns from observational information. The attention mechanism provides additional weighting for conveyed information, so that the critic network can accurately evaluate the value of behavior for UAV BSs. This provides more reliable feedback signals and helps the actor network update the strategy more effectively. Ablation simulations indicate that the proposed approach attains improved convergence over the baselines. UAV BSs learn the optimal communication strategies to achieve their maximum cumulative rewards. Additionally, multi-agent trust region method with monotonic convergence provides an estimated Nash equilibrium for the multi-UAV assisted communication Markov game.","sentences":["In the multiple unmanned aerial vehicle (UAV)- assisted downlink communication, it is challenging for UAV base stations (UAV BSs) to realize trajectory design and resource assignment in unknown environments.","The cooperation and competition between UAV BSs in the communication network leads to a Markov game problem.","Multi-agent reinforcement learning is a significant solution for the above decision-making.","However, there are still many common issues, such as the instability of the system and low utilization of historical data, that limit its application.","In this paper, a novel graph-attention multi-agent trust region (GA-MATR) reinforcement learning framework is proposed to solve the multi-UAV assisted communication problem.","Graph recurrent network is introduced to process and analyze complex topology of the communication network, so as to extract useful information and patterns from observational information.","The attention mechanism provides additional weighting for conveyed information, so that the critic network can accurately evaluate the value of behavior for UAV BSs.","This provides more reliable feedback signals and helps the actor network update the strategy more effectively.","Ablation simulations indicate that the proposed approach attains improved convergence over the baselines.","UAV BSs learn the optimal communication strategies to achieve their maximum cumulative rewards.","Additionally, multi-agent trust region method with monotonic convergence provides an estimated Nash equilibrium for the multi-UAV assisted communication Markov game."],"url":"http://arxiv.org/abs/2401.17880v1"}
