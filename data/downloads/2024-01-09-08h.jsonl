{"created":"2024-01-08 18:59:31","title":"Dr$^2$Net: Dynamic Reversible Dual-Residual Networks for Memory-Efficient Finetuning","abstract":"Large pretrained models are increasingly crucial in modern computer vision tasks. These models are typically used in downstream tasks by end-to-end finetuning, which is highly memory-intensive for tasks with high-resolution data, e.g., video understanding, small object detection, and point cloud analysis. In this paper, we propose Dynamic Reversible Dual-Residual Networks, or Dr$^2$Net, a novel family of network architectures that acts as a surrogate network to finetune a pretrained model with substantially reduced memory consumption. Dr$^2$Net contains two types of residual connections, one maintaining the residual structure in the pretrained models, and the other making the network reversible. Due to its reversibility, intermediate activations, which can be reconstructed from output, are cleared from memory during training. We use two coefficients on either type of residual connections respectively, and introduce a dynamic training strategy that seamlessly transitions the pretrained model to a reversible network with much higher numerical precision. We evaluate Dr$^2$Net on various pretrained models and various tasks, and show that it can reach comparable performance to conventional finetuning but with significantly less memory usage.","sentences":["Large pretrained models are increasingly crucial in modern computer vision tasks.","These models are typically used in downstream tasks by end-to-end finetuning, which is highly memory-intensive for tasks with high-resolution data, e.g., video understanding, small object detection, and point cloud analysis.","In this paper, we propose Dynamic Reversible Dual-Residual Networks, or Dr$^2$Net, a novel family of network architectures that acts as a surrogate network to finetune a pretrained model with substantially reduced memory consumption.","Dr$^2$Net contains two types of residual connections, one maintaining the residual structure in the pretrained models, and the other making the network reversible.","Due to its reversibility, intermediate activations, which can be reconstructed from output, are cleared from memory during training.","We use two coefficients on either type of residual connections respectively, and introduce a dynamic training strategy that seamlessly transitions the pretrained model to a reversible network with much higher numerical precision.","We evaluate Dr$^2$Net on various pretrained models and various tasks, and show that it can reach comparable performance to conventional finetuning but with significantly less memory usage."],"url":"http://arxiv.org/abs/2401.04105v1"}
{"created":"2024-01-08 18:56:33","title":"AGG: Amortized Generative 3D Gaussians for Single Image to 3D","abstract":"Given the growing need for automatic 3D content creation pipelines, various 3D representations have been studied to generate 3D objects from a single image. Due to its superior rendering efficiency, 3D Gaussian splatting-based models have recently excelled in both 3D reconstruction and generation. 3D Gaussian splatting approaches for image to 3D generation are often optimization-based, requiring many computationally expensive score-distillation steps. To overcome these challenges, we introduce an Amortized Generative 3D Gaussian framework (AGG) that instantly produces 3D Gaussians from a single image, eliminating the need for per-instance optimization. Utilizing an intermediate hybrid representation, AGG decomposes the generation of 3D Gaussian locations and other appearance attributes for joint optimization. Moreover, we propose a cascaded pipeline that first generates a coarse representation of the 3D data and later upsamples it with a 3D Gaussian super-resolution module. Our method is evaluated against existing optimization-based 3D Gaussian frameworks and sampling-based pipelines utilizing other 3D representations, where AGG showcases competitive generation abilities both qualitatively and quantitatively while being several orders of magnitude faster. Project page: https://ir1d.github.io/AGG/","sentences":["Given the growing need for automatic 3D content creation pipelines, various 3D representations have been studied to generate 3D objects from a single image.","Due to its superior rendering efficiency, 3D Gaussian splatting-based models have recently excelled in both 3D reconstruction and generation.","3D Gaussian splatting approaches for image to 3D generation are often optimization-based, requiring many computationally expensive score-distillation steps.","To overcome these challenges, we introduce an Amortized Generative 3D Gaussian framework (AGG) that instantly produces 3D Gaussians from a single image, eliminating the need for per-instance optimization.","Utilizing an intermediate hybrid representation, AGG decomposes the generation of 3D Gaussian locations and other appearance attributes for joint optimization.","Moreover, we propose a cascaded pipeline that first generates a coarse representation of the 3D data and later upsamples it with a 3D Gaussian super-resolution module.","Our method is evaluated against existing optimization-based 3D Gaussian frameworks and sampling-based pipelines utilizing other 3D representations, where AGG showcases competitive generation abilities both qualitatively and quantitatively while being several orders of magnitude faster.","Project page: https://ir1d.github.io/AGG/"],"url":"http://arxiv.org/abs/2401.04099v1"}
{"created":"2024-01-08 18:55:50","title":"Modeling AoII in Push- and Pull-Based Sampling of Continuous Time Markov Chains","abstract":"Age of incorrect information (AoII) has recently been proposed as an alternative to existing information freshness metrics for real-time sampling and estimation problems involving information sources that are tracked by remote monitors. Different from existing metrics, AoII penalizes the incorrect information by increasing linearly with time as long as the source and the monitor are de-synchronized, and is reset when they are synchronized back. While AoII has generally been investigated for discrete time information sources, we develop a novel analytical model in this paper for push- and pull-based sampling and transmission of a continuous time Markov chain (CTMC) process. In the pull-based model, the sensor starts transmitting information on the observed CTMC only when a pull request from the monitor is received. On the other hand, in the push-based scenario, the sensor, being aware of the AoII process, samples and transmits when the AoII process exceeds a random threshold. The proposed analytical model for both scenarios is based on the construction of a discrete time MC (DTMC) making state transitions at the embedded epochs of synchronization points, using the theory of absorbing CTMCs, and in particular phase-type distributions. For a given sampling policy, analytical models to obtain the mean AoII and the average sampling rate are developed. Numerical results are presented to validate the analytical model as well as to provide insight on optimal sampling policies under sampling rate constraints.","sentences":["Age of incorrect information (AoII) has recently been proposed as an alternative to existing information freshness metrics for real-time sampling and estimation problems involving information sources that are tracked by remote monitors.","Different from existing metrics, AoII penalizes the incorrect information by increasing linearly with time as long as the source and the monitor are de-synchronized, and is reset when they are synchronized back.","While AoII has generally been investigated for discrete time information sources, we develop a novel analytical model in this paper for push- and pull-based sampling and transmission of a continuous time Markov chain (CTMC) process.","In the pull-based model, the sensor starts transmitting information on the observed CTMC only when a pull request from the monitor is received.","On the other hand, in the push-based scenario, the sensor, being aware of the AoII process, samples and transmits when the AoII process exceeds a random threshold.","The proposed analytical model for both scenarios is based on the construction of a discrete time MC (DTMC) making state transitions at the embedded epochs of synchronization points, using the theory of absorbing CTMCs, and in particular phase-type distributions.","For a given sampling policy, analytical models to obtain the mean AoII and the average sampling rate are developed.","Numerical results are presented to validate the analytical model as well as to provide insight on optimal sampling policies under sampling rate constraints."],"url":"http://arxiv.org/abs/2401.04098v1"}
{"created":"2024-01-08 18:52:09","title":"GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation","abstract":"Despite recent advances in text-to-3D generative methods, there is a notable absence of reliable evaluation metrics. Existing metrics usually focus on a single criterion each, such as how well the asset aligned with the input text. These metrics lack the flexibility to generalize to different evaluation criteria and might not align well with human preferences. Conducting user preference studies is an alternative that offers both adaptability and human-aligned results. User studies, however, can be very expensive to scale. This paper presents an automatic, versatile, and human-aligned evaluation metric for text-to-3D generative models. To this end, we first develop a prompt generator using GPT-4V to generate evaluating prompts, which serve as input to compare text-to-3D models. We further design a method instructing GPT-4V to compare two 3D assets according to user-defined criteria. Finally, we use these pairwise comparison results to assign these models Elo ratings. Experimental results suggest our metric strongly align with human preference across different evaluation criteria.","sentences":["Despite recent advances in text-to-3D generative methods, there is a notable absence of reliable evaluation metrics.","Existing metrics usually focus on a single criterion each, such as how well the asset aligned with the input text.","These metrics lack the flexibility to generalize to different evaluation criteria and might not align well with human preferences.","Conducting user preference studies is an alternative that offers both adaptability and human-aligned results.","User studies, however, can be very expensive to scale.","This paper presents an automatic, versatile, and human-aligned evaluation metric for text-to-3D generative models.","To this end, we first develop a prompt generator using GPT-4V to generate evaluating prompts, which serve as input to compare text-to-3D models.","We further design a method instructing GPT-4V to compare two 3D assets according to user-defined criteria.","Finally, we use these pairwise comparison results to assign these models Elo ratings.","Experimental results suggest our metric strongly align with human preference across different evaluation criteria."],"url":"http://arxiv.org/abs/2401.04092v1"}
{"created":"2024-01-08 18:47:34","title":"Mixtral of Experts","abstract":"We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.","sentences":["We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model.","Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts).","For every token, at each layer, a router network selects two experts to process the current state and combine their outputs.","Even though each token only sees two experts, the selected experts can be different at each timestep.","As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference.","Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks.","In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks.","We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5","Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks.","Both the base and instruct models are released under the Apache 2.0 license."],"url":"http://arxiv.org/abs/2401.04088v1"}
{"created":"2024-01-08 18:35:07","title":"MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts","abstract":"State Space Models (SSMs) have become serious contenders in the field of sequential modeling, challenging the dominance of Transformers. At the same time, Mixture of Experts (MoE) has significantly improved Transformer-based LLMs, including recent state-of-the-art open-source models. We propose that to unlock the potential of SSMs for scaling, they should be combined with MoE. We showcase this on Mamba, a recent SSM-based model that achieves remarkable, Transformer-like performance. Our model, MoE-Mamba, outperforms both Mamba and Transformer-MoE. In particular, MoE-Mamba reaches the same performance as Mamba in 2.2x less training steps while preserving the inference performance gains of Mamba against the Transformer.","sentences":["State Space Models (SSMs) have become serious contenders in the field of sequential modeling, challenging the dominance of Transformers.","At the same time, Mixture of Experts (MoE) has significantly improved Transformer-based LLMs, including recent state-of-the-art open-source models.","We propose that to unlock the potential of SSMs for scaling, they should be combined with MoE. We showcase this on Mamba, a recent SSM-based model that achieves remarkable, Transformer-like performance.","Our model, MoE-Mamba, outperforms both Mamba and Transformer-MoE. In particular, MoE-Mamba reaches the same performance as Mamba in 2.2x less training steps while preserving the inference performance gains of Mamba against the Transformer."],"url":"http://arxiv.org/abs/2401.04081v1"}
{"created":"2024-01-08 18:30:03","title":"LoFi User Scheduling for Multiuser MIMO Wireless Systems","abstract":"We propose new low-fidelity (LoFi) user equipment (UE) scheduling algorithms for multiuser multiple-input multiple-output (MIMO) wireless communication systems. The proposed methods rely on an efficient guess-and-check procedure that, given an objective function, performs paired comparisons between random subsets of UEs that should be scheduled in certain time slots. The proposed LoFi scheduling methods are computationally efficient, highly parallelizable, and gradient-free, which enables the use of almost arbitrary, non-differentiable objective functions. System simulations in a millimeter-wave (mmWave) multiuser MIMO scenario demonstrate that the proposed LoFi schedulers outperform a range of state-of-the-art user scheduling algorithms in terms of bit error-rate and/or computational complexity.","sentences":["We propose new low-fidelity (LoFi) user equipment (UE) scheduling algorithms for multiuser multiple-input multiple-output (MIMO) wireless communication systems.","The proposed methods rely on an efficient guess-and-check procedure that, given an objective function, performs paired comparisons between random subsets of UEs that should be scheduled in certain time slots.","The proposed LoFi scheduling methods are computationally efficient, highly parallelizable, and gradient-free, which enables the use of almost arbitrary, non-differentiable objective functions.","System simulations in a millimeter-wave (mmWave) multiuser MIMO scenario demonstrate that the proposed LoFi schedulers outperform a range of state-of-the-art user scheduling algorithms in terms of bit error-rate and/or computational complexity."],"url":"http://arxiv.org/abs/2401.04077v1"}
{"created":"2024-01-08 18:27:57","title":"Security and Privacy Issues in Cloud Storage","abstract":"Even with the vast potential that cloud computing has, so far, it has not been adopted by the consumers with the enthusiasm and pace that it be worthy; this is a very reason statement why consumers still hesitated of using cloud computing for their sensitive data and the threats that prevent the consumers from shifting to use cloud computing in general and cloud storage in particular. The cloud computing inherits the traditional potential security and privacy threats besides its own issues due to its unique structures. Some threats related to cloud computing are the insider malicious attacks from the employees that even sometime the provider unconscious about, the lack of transparency of agreement between consumer and provider, data loss, traffic hijacking, shared technology and insecure application interface. Such threats need remedies to make the consumer use its features in secure way. In this review, we spot the light on the most security and privacy issues which can be attributed as gaps that sometimes the consumers or even the enterprises are not aware of. We also define the parties that involve in scenario of cloud computing that also may attack the entire cloud systems. We also show the consequences of these threats.","sentences":["Even with the vast potential that cloud computing has, so far, it has not been adopted by the consumers with the enthusiasm and pace that it be worthy; this is a very reason statement why consumers still hesitated of using cloud computing for their sensitive data and the threats that prevent the consumers from shifting to use cloud computing in general and cloud storage in particular.","The cloud computing inherits the traditional potential security and privacy threats besides its own issues due to its unique structures.","Some threats related to cloud computing are the insider malicious attacks from the employees that even sometime the provider unconscious about, the lack of transparency of agreement between consumer and provider, data loss, traffic hijacking, shared technology and insecure application interface.","Such threats need remedies to make the consumer use its features in secure way.","In this review, we spot the light on the most security and privacy issues which can be attributed as gaps that sometimes the consumers or even the enterprises are not aware of.","We also define the parties that involve in scenario of cloud computing that also may attack the entire cloud systems.","We also show the consequences of these threats."],"url":"http://arxiv.org/abs/2401.04076v1"}
{"created":"2024-01-08 18:18:02","title":"Fun with Flags: Robust Principal Directions via Flag Manifolds","abstract":"Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \\ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations. The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types. Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold. Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds.","sentences":["Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning.","In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \\ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously.","We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error.","We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold.","To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds.","We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations.","The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types.","Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold.","Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds."],"url":"http://arxiv.org/abs/2401.04071v1"}
{"created":"2024-01-08 18:10:25","title":"Convex SGD: Generalization Without Early Stopping","abstract":"We consider the generalization error associated with stochastic gradient descent on a smooth convex function over a compact set. We show the first bound on the generalization error that vanishes when the number of iterations $T$ and the dataset size $n$ go to zero at arbitrary rates; our bound scales as $\\tilde{O}(1/\\sqrt{T} + 1/\\sqrt{n})$ with step-size $\\alpha_t = 1/\\sqrt{t}$. In particular, strong convexity is not needed for stochastic gradient descent to generalize well.","sentences":["We consider the generalization error associated with stochastic gradient descent on a smooth convex function over a compact set.","We show the first bound on the generalization error that vanishes when the number of iterations $T$ and the dataset size $n$ go to zero at arbitrary rates; our bound scales as $\\tilde{O}(1/\\sqrt{T} + 1/\\sqrt{n})$ with step-size $\\alpha_t = 1/\\sqrt{t}$. In particular, strong convexity is not needed for stochastic gradient descent to generalize well."],"url":"http://arxiv.org/abs/2401.04067v1"}
{"created":"2024-01-08 18:01:09","title":"Variance Reduction in Ratio Metrics for Efficient Online Experiments","abstract":"Online controlled experiments, such as A/B-tests, are commonly used by modern tech companies to enable continuous system improvements. Despite their paramount importance, A/B-tests are expensive: by their very definition, a percentage of traffic is assigned an inferior system variant. To ensure statistical significance on top-level metrics, online experiments typically run for several weeks. Even then, a considerable amount of experiments will lead to inconclusive results (i.e. false negatives, or type-II error). The main culprit for this inefficiency is the variance of the online metrics. Variance reduction techniques have been proposed in the literature, but their direct applicability to commonly used ratio metrics (e.g. click-through rate or user retention) is limited.   In this work, we successfully apply variance reduction techniques to ratio metrics on a large-scale short-video platform: ShareChat. Our empirical results show that we can either improve A/B-test confidence in 77% of cases, or can retain the same level of confidence with 30% fewer data points. Importantly, we show that the common approach of including as many covariates as possible in regression is counter-productive, highlighting that control variates based on Gradient-Boosted Decision Tree predictors are most effective. We discuss the practicalities of implementing these methods at scale and showcase the cost reduction they beget.","sentences":["Online controlled experiments, such as A/B-tests, are commonly used by modern tech companies to enable continuous system improvements.","Despite their paramount importance, A/B-tests are expensive: by their very definition, a percentage of traffic is assigned an inferior system variant.","To ensure statistical significance on top-level metrics, online experiments typically run for several weeks.","Even then, a considerable amount of experiments will lead to inconclusive results (i.e. false negatives, or type-II error).","The main culprit for this inefficiency is the variance of the online metrics.","Variance reduction techniques have been proposed in the literature, but their direct applicability to commonly used ratio metrics (e.g. click-through rate or user retention) is limited.   ","In this work, we successfully apply variance reduction techniques to ratio metrics on a large-scale short-video platform: ShareChat.","Our empirical results show that we can either improve A/B-test confidence in 77% of cases, or can retain the same level of confidence with 30% fewer data points.","Importantly, we show that the common approach of including as many covariates as possible in regression is counter-productive, highlighting that control variates based on Gradient-Boosted Decision Tree predictors are most effective.","We discuss the practicalities of implementing these methods at scale and showcase the cost reduction they beget."],"url":"http://arxiv.org/abs/2401.04062v1"}
{"created":"2024-01-08 17:58:56","title":"Physical Layer Security Performance of Dual RIS-aided V2V NOMA Communications","abstract":"This paper investigates the performance of physical layer security (PLS) in a vehicle-to-vehicle (V2V) communication system, where a transmitter vehicle exploits a dual reconfigurable intelligent surface (RIS) to send confidential information to legitimate receiver vehicles under the non-orthogonal multiple access (NOMA) scheme in the presence of an eavesdropper vehicle. In particular, it is assumed that an RIS is near the transmitter vehicle and another RIS is close to the receiver vehicles to provide a wider smart radio environment. Besides, we suppose that the channels between two RISs suffer from the Fisher-Snedecor F fading model. Under this scenario, we first provide the marginal distributions of equivalent channels at the legitimate receiver vehicles by exploiting the central limit theorem (CLT). Then, in order to evaluate the PLS performance of the considered secure communication system, we derive analytical expressions of the average secrecy capacity (ASC), secrecy outage probability (SOP), and secrecy energy efficiency (SEE) by using the Gauss-Laguerre quadrature and the Gaussian quadrature techniques. Moreover, to gain more insights into the secrecy performance, the asymptotic expression of the ASC is obtained. The numerical results indicate that incorporating the dual RIS in the secure V2V communication under the NOMA scheme can significantly provide ultra-reliable transmission and guarantee more secure communication for intelligent transportation systems (ITS).","sentences":["This paper investigates the performance of physical layer security (PLS) in a vehicle-to-vehicle (V2V) communication system, where a transmitter vehicle exploits a dual reconfigurable intelligent surface (RIS) to send confidential information to legitimate receiver vehicles under the non-orthogonal multiple access (NOMA) scheme in the presence of an eavesdropper vehicle.","In particular, it is assumed that an RIS is near the transmitter vehicle and another RIS is close to the receiver vehicles to provide a wider smart radio environment.","Besides, we suppose that the channels between two RISs suffer from the Fisher-Snedecor F fading model.","Under this scenario, we first provide the marginal distributions of equivalent channels at the legitimate receiver vehicles by exploiting the central limit theorem (CLT).","Then, in order to evaluate the PLS performance of the considered secure communication system, we derive analytical expressions of the average secrecy capacity (ASC), secrecy outage probability (SOP), and secrecy energy efficiency (SEE) by using the Gauss-Laguerre quadrature and the Gaussian quadrature techniques.","Moreover, to gain more insights into the secrecy performance, the asymptotic expression of the ASC is obtained.","The numerical results indicate that incorporating the dual RIS in the secure V2V communication under the NOMA scheme can significantly provide ultra-reliable transmission and guarantee more secure communication for intelligent transportation systems (ITS)."],"url":"http://arxiv.org/abs/2401.04059v1"}
{"created":"2024-01-08 17:57:29","title":"Unveiling Bias in Fairness Evaluations of Large Language Models: A Critical Literature Review of Music and Movie Recommendation Systems","abstract":"The rise of generative artificial intelligence, particularly Large Language Models (LLMs), has intensified the imperative to scrutinize fairness alongside accuracy. Recent studies have begun to investigate fairness evaluations for LLMs within domains such as recommendations. Given that personalization is an intrinsic aspect of recommendation systems, its incorporation into fairness assessments is paramount. Yet, the degree to which current fairness evaluation frameworks account for personalization remains unclear. Our comprehensive literature review aims to fill this gap by examining how existing frameworks handle fairness evaluations of LLMs, with a focus on the integration of personalization factors. Despite an exhaustive collection and analysis of relevant works, we discovered that most evaluations overlook personalization, a critical facet of recommendation systems, thereby inadvertently perpetuating unfair practices. Our findings shed light on this oversight and underscore the urgent need for more nuanced fairness evaluations that acknowledge personalization. Such improvements are vital for fostering equitable development within the AI community.","sentences":["The rise of generative artificial intelligence, particularly Large Language Models (LLMs), has intensified the imperative to scrutinize fairness alongside accuracy.","Recent studies have begun to investigate fairness evaluations for LLMs within domains such as recommendations.","Given that personalization is an intrinsic aspect of recommendation systems, its incorporation into fairness assessments is paramount.","Yet, the degree to which current fairness evaluation frameworks account for personalization remains unclear.","Our comprehensive literature review aims to fill this gap by examining how existing frameworks handle fairness evaluations of LLMs, with a focus on the integration of personalization factors.","Despite an exhaustive collection and analysis of relevant works, we discovered that most evaluations overlook personalization, a critical facet of recommendation systems, thereby inadvertently perpetuating unfair practices.","Our findings shed light on this oversight and underscore the urgent need for more nuanced fairness evaluations that acknowledge personalization.","Such improvements are vital for fostering equitable development within the AI community."],"url":"http://arxiv.org/abs/2401.04057v1"}
{"created":"2024-01-08 17:55:02","title":"A Minimaximalist Approach to Reinforcement Learning from Human Feedback","abstract":"We present Self-Play Preference Optimization (SPO), an algorithm for reinforcement learning from human feedback. Our approach is minimalist in that it does not require training a reward model nor unstable adversarial training and is therefore rather simple to implement. Our approach is maximalist in that it provably handles non-Markovian, intransitive, and stochastic preferences while being robust to the compounding errors that plague offline approaches to sequential prediction. To achieve the preceding qualities, we build upon the concept of a Minimax Winner (MW), a notion of preference aggregation from the social choice theory literature that frames learning from preferences as a zero-sum game between two policies. By leveraging the symmetry of this game, we prove that rather than using the traditional technique of dueling two policies to compute the MW, we can simply have a single agent play against itself while maintaining strong convergence guarantees. Practically, this corresponds to sampling multiple trajectories from a policy, asking a rater or preference model to compare them, and then using the proportion of wins as the reward for a particular trajectory. We demonstrate that on a suite of continuous control tasks, we are able to learn significantly more efficiently than reward-model based approaches while maintaining robustness to the intransitive and stochastic preferences that frequently occur in practice when aggregating human judgments.","sentences":["We present Self-Play Preference Optimization (SPO), an algorithm for reinforcement learning from human feedback.","Our approach is minimalist in that it does not require training a reward model nor unstable adversarial training and is therefore rather simple to implement.","Our approach is maximalist in that it provably handles non-Markovian, intransitive, and stochastic preferences while being robust to the compounding errors that plague offline approaches to sequential prediction.","To achieve the preceding qualities, we build upon the concept of a Minimax Winner (MW), a notion of preference aggregation from the social choice theory literature that frames learning from preferences as a zero-sum game between two policies.","By leveraging the symmetry of this game, we prove that rather than using the traditional technique of dueling two policies to compute the MW, we can simply have a single agent play against itself while maintaining strong convergence guarantees.","Practically, this corresponds to sampling multiple trajectories from a policy, asking a rater or preference model to compare them, and then using the proportion of wins as the reward for a particular trajectory.","We demonstrate that on a suite of continuous control tasks, we are able to learn significantly more efficiently than reward-model based approaches while maintaining robustness to the intransitive and stochastic preferences that frequently occur in practice when aggregating human judgments."],"url":"http://arxiv.org/abs/2401.04056v1"}
{"created":"2024-01-08 17:53:06","title":"Sparse Meets Dense: A Hybrid Approach to Enhance Scientific Document Retrieval","abstract":"Traditional information retrieval is based on sparse bag-of-words vector representations of documents and queries. More recent deep-learning approaches have used dense embeddings learned using a transformer-based large language model. We show that on a classic benchmark on scientific document retrieval in the medical domain of cystic fibrosis, that both of these models perform roughly equivalently. Notably, dense vectors from the state-of-the-art SPECTER2 model do not significantly enhance performance. However, a hybrid model that we propose combining these methods yields significantly better results, underscoring the merits of integrating classical and contemporary deep learning techniques in information retrieval in the domain of specialized scientific documents.","sentences":["Traditional information retrieval is based on sparse bag-of-words vector representations of documents and queries.","More recent deep-learning approaches have used dense embeddings learned using a transformer-based large language model.","We show that on a classic benchmark on scientific document retrieval in the medical domain of cystic fibrosis, that both of these models perform roughly equivalently.","Notably, dense vectors from the state-of-the-art SPECTER2 model do not significantly enhance performance.","However, a hybrid model that we propose combining these methods yields significantly better results, underscoring the merits of integrating classical and contemporary deep learning techniques in information retrieval in the domain of specialized scientific documents."],"url":"http://arxiv.org/abs/2401.04055v1"}
{"created":"2024-01-08 17:45:38","title":"Learning-to-Rank with Nested Feedback","abstract":"Many platforms on the web present ranked lists of content to users, typically optimized for engagement-, satisfaction- or retention- driven metrics. Advances in the Learning-to-Rank (LTR) research literature have enabled rapid growth in this application area. Several popular interfaces now include nested lists, where users can enter a 2nd-level feed via any given 1st-level item. Naturally, this has implications for evaluation metrics, objective functions, and the ranking policies we wish to learn. We propose a theoretically grounded method to incorporate 2nd-level feedback into any 1st-level ranking model. Online experiments on a large-scale recommendation system confirm our theoretical findings.","sentences":["Many platforms on the web present ranked lists of content to users, typically optimized for engagement-, satisfaction- or retention- driven metrics.","Advances in the Learning-to-Rank (LTR) research literature have enabled rapid growth in this application area.","Several popular interfaces now include nested lists, where users can enter a 2nd-level feed via any given 1st-level item.","Naturally, this has implications for evaluation metrics, objective functions, and the ranking policies we wish to learn.","We propose a theoretically grounded method to incorporate 2nd-level feedback into any 1st-level ranking model.","Online experiments on a large-scale recommendation system confirm our theoretical findings."],"url":"http://arxiv.org/abs/2401.04053v1"}
{"created":"2024-01-08 17:45:01","title":"The Role of Text in Visualizations: How Annotations Shape Perceptions of Bias and Influence Predictions","abstract":"This paper investigates the role of text in visualizations, specifically the impact of text position, semantic content, and biased wording. Two empirical studies were conducted based on two tasks (predicting data trends and appraising bias) using two visualization types (bar and line charts). While the addition of text had a minimal effect on how people perceive data trends, there was a significant impact on how biased they perceive the authors to be. This finding revealed a relationship between the degree of bias in textual information and the perception of the authors' bias. Exploratory analyses support an interaction between a person's prediction and the degree of bias they perceived. This paper also develops a crowdsourced method for creating chart annotations that range from neutral to highly biased. This research highlights the need for designers to mitigate potential polarization of readers' opinions based on how authors' ideas are expressed.","sentences":["This paper investigates the role of text in visualizations, specifically the impact of text position, semantic content, and biased wording.","Two empirical studies were conducted based on two tasks (predicting data trends and appraising bias) using two visualization types (bar and line charts).","While the addition of text had a minimal effect on how people perceive data trends, there was a significant impact on how biased they perceive the authors to be.","This finding revealed a relationship between the degree of bias in textual information and the perception of the authors' bias.","Exploratory analyses support an interaction between a person's prediction and the degree of bias they perceived.","This paper also develops a crowdsourced method for creating chart annotations that range from neutral to highly biased.","This research highlights the need for designers to mitigate potential polarization of readers' opinions based on how authors' ideas are expressed."],"url":"http://arxiv.org/abs/2401.04052v1"}
{"created":"2024-01-08 17:44:43","title":"Empirical Analysis of Efficient Fine-Tuning Methods for Large Pre-Trained Language Models","abstract":"Fine-tuning large pre-trained language models for downstream tasks remains a critical challenge in natural language processing. This paper presents an empirical analysis comparing two efficient fine-tuning methods - BitFit and adapter modules - to standard full model fine-tuning. Experiments conducted on GLUE benchmark datasets (MRPC, COLA, STS-B) reveal several key insights. The BitFit approach, which trains only bias terms and task heads, matches full fine-tuning performance across varying amounts of training data and time constraints. It demonstrates remarkable stability even with only 30\\% of data, outperforming full fine-tuning at intermediate data levels. Adapter modules exhibit high variability, with inconsistent gains over default models. The findings indicate BitFit offers an attractive balance between performance and parameter efficiency. Our work provides valuable perspectives on model tuning, emphasizing robustness and highlighting BitFit as a promising alternative for resource-constrained or streaming task settings. The analysis offers actionable guidelines for efficient adaptation of large pre-trained models, while illustrating open challenges in stabilizing techniques like adapter modules.","sentences":["Fine-tuning large pre-trained language models for downstream tasks remains a critical challenge in natural language processing.","This paper presents an empirical analysis comparing two efficient fine-tuning methods - BitFit and adapter modules - to standard full model fine-tuning.","Experiments conducted on GLUE benchmark datasets (MRPC, COLA, STS-B) reveal several key insights.","The BitFit approach, which trains only bias terms and task heads, matches full fine-tuning performance across varying amounts of training data and time constraints.","It demonstrates remarkable stability even with only 30\\% of data, outperforming full fine-tuning at intermediate data levels.","Adapter modules exhibit high variability, with inconsistent gains over default models.","The findings indicate BitFit offers an attractive balance between performance and parameter efficiency.","Our work provides valuable perspectives on model tuning, emphasizing robustness and highlighting BitFit as a promising alternative for resource-constrained or streaming task settings.","The analysis offers actionable guidelines for efficient adaptation of large pre-trained models, while illustrating open challenges in stabilizing techniques like adapter modules."],"url":"http://arxiv.org/abs/2401.04051v1"}
{"created":"2024-01-08 17:29:16","title":"FFSplit: Split Feed-Forward Network For Optimizing Accuracy-Efficiency Trade-off in Language Model Inference","abstract":"The large number of parameters in Pretrained Language Models enhance their performance, but also make them resource-intensive, making it challenging to deploy them on commodity hardware like a single GPU. Due to the memory and power limitations of these devices, model compression techniques are often used to decrease both the model's size and its inference latency. This usually results in a trade-off between model accuracy and efficiency. Therefore, optimizing this balance is essential for effectively deploying LLMs on commodity hardware. A significant portion of the efficiency challenge is the Feed-forward network (FFN) component, which accounts for roughly $\\frac{2}{3}$ total parameters and inference latency. In this paper, we first observe that only a few neurons of FFN module have large output norm for any input tokens, a.k.a. heavy hitters, while the others are sparsely triggered by different tokens. Based on this observation, we explicitly split the FFN into two parts according to the heavy hitters. We improve the efficiency-accuracy trade-off of existing compression methods by allocating more resource to FFN parts with heavy hitters. In practice, our method can reduce model size by 43.1\\% and bring $1.25\\sim1.56\\times$ wall clock time speedup on different hardware with negligible accuracy drop.","sentences":["The large number of parameters in Pretrained Language Models enhance their performance, but also make them resource-intensive, making it challenging to deploy them on commodity hardware like a single GPU.","Due to the memory and power limitations of these devices, model compression techniques are often used to decrease both the model's size and its inference latency.","This usually results in a trade-off between model accuracy and efficiency.","Therefore, optimizing this balance is essential for effectively deploying LLMs on commodity hardware.","A significant portion of the efficiency challenge is the Feed-forward network (FFN) component, which accounts for roughly $\\frac{2}{3}$ total parameters and inference latency.","In this paper, we first observe that only a few neurons of FFN module have large output norm for any input tokens, a.k.a. heavy hitters, while the others are sparsely triggered by different tokens.","Based on this observation, we explicitly split the FFN into two parts according to the heavy hitters.","We improve the efficiency-accuracy trade-off of existing compression methods by allocating more resource to FFN parts with heavy hitters.","In practice, our method can reduce model size by 43.1\\% and bring $1.25\\sim1.56\\times$ wall clock time speedup on different hardware with negligible accuracy drop."],"url":"http://arxiv.org/abs/2401.04044v1"}
{"created":"2024-01-08 17:24:16","title":"Bj\u00f8ntegaard Delta (BD): A Tutorial Overview of the Metric, Evolution, Challenges, and Recommendations","abstract":"The Bj{\\o}ntegaard Delta (BD) method proposed in 2001 has become a popular tool for comparing video codec compression efficiency. It was initially proposed to compute bitrate and quality differences between two Rate-Distortion curves using PSNR as a distortion metric. Over the years, many works have calculated and reported BD results using other objective quality metrics such as SSIM, VMAF and, in some cases, even subjective ratings (mean opinion scores). However, the lack of consolidated literature explaining the metric, its evolution over the years, and a systematic evaluation of the same under different test conditions can result in a wrong interpretation of the BD results thus obtained.   Towards this end, this paper presents a detailed tutorial describing the BD method and example cases where the metric might fail. We also provide a detailed history of its evolution, including a discussion of various proposed improvements and variations over the last 20 years. In addition, we evaluate the various BD methods and their open-source implementations, considering different objective quality metrics and subjective ratings taking into account different RD characteristics. Based on our results, we present a set of recommendations on using existing BD metrics and various insights for possible exploration towards developing more effective tools for codec compression efficiency evaluation and comparison.","sentences":["The Bj{\\o}ntegaard Delta (BD) method proposed in 2001 has become a popular tool for comparing video codec compression efficiency.","It was initially proposed to compute bitrate and quality differences between two Rate-Distortion curves using PSNR as a distortion metric.","Over the years, many works have calculated and reported BD results using other objective quality metrics such as SSIM, VMAF and, in some cases, even subjective ratings (mean opinion scores).","However, the lack of consolidated literature explaining the metric, its evolution over the years, and a systematic evaluation of the same under different test conditions can result in a wrong interpretation of the BD results thus obtained.   ","Towards this end, this paper presents a detailed tutorial describing the BD method and example cases where the metric might fail.","We also provide a detailed history of its evolution, including a discussion of various proposed improvements and variations over the last 20 years.","In addition, we evaluate the various BD methods and their open-source implementations, considering different objective quality metrics and subjective ratings taking into account different RD characteristics.","Based on our results, we present a set of recommendations on using existing BD metrics and various insights for possible exploration towards developing more effective tools for codec compression efficiency evaluation and comparison."],"url":"http://arxiv.org/abs/2401.04039v1"}
{"created":"2024-01-08 17:17:08","title":"Digital Twin for Autonomous Surface Vessels for Safe Maritime Navigation","abstract":"Autonomous surface vessels (ASVs) play an increasingly important role in the safety and sustainability of open sea operations. Since most maritime accidents are related to human failure, intelligent algorithms for autonomous collision avoidance and path following can drastically reduce the risk in the maritime sector. A DT is a virtual representative of a real physical system and can enhance the situational awareness (SITAW) of such an ASV to generate optimal decisions. This work builds on an existing DT framework for ASVs and demonstrates foundations for enabling predictive, prescriptive, and autonomous capabilities. In this context, sophisticated target tracking approaches are crucial for estimating and predicting the position and motion of other dynamic objects. The applied tracking method is enabled by real-time automatic identification system (AIS) data and synthetic light detection and ranging (Lidar) measurements. To guarantee safety during autonomous operations, we applied a predictive safety filter, based on the concept of nonlinear model predictive control (NMPC). The approaches are implemented into a DT built with the Unity game engine. As a result, this work demonstrates the potential of a DT capable of making predictions, playing through various what-if scenarios, and providing optimal control decisions according to its enhanced SITAW.","sentences":["Autonomous surface vessels (ASVs) play an increasingly important role in the safety and sustainability of open sea operations.","Since most maritime accidents are related to human failure, intelligent algorithms for autonomous collision avoidance and path following can drastically reduce the risk in the maritime sector.","A DT is a virtual representative of a real physical system and can enhance the situational awareness (SITAW) of such an ASV to generate optimal decisions.","This work builds on an existing DT framework for ASVs and demonstrates foundations for enabling predictive, prescriptive, and autonomous capabilities.","In this context, sophisticated target tracking approaches are crucial for estimating and predicting the position and motion of other dynamic objects.","The applied tracking method is enabled by real-time automatic identification system (AIS) data and synthetic light detection and ranging (Lidar) measurements.","To guarantee safety during autonomous operations, we applied a predictive safety filter, based on the concept of nonlinear model predictive control (NMPC).","The approaches are implemented into a DT built with the Unity game engine.","As a result, this work demonstrates the potential of a DT capable of making predictions, playing through various what-if scenarios, and providing optimal control decisions according to its enhanced SITAW."],"url":"http://arxiv.org/abs/2401.04032v1"}
{"created":"2024-01-08 17:07:37","title":"IDoFew: Intermediate Training Using Dual-Clustering in Language Models for Few Labels Text Classification","abstract":"Language models such as Bidirectional Encoder Representations from Transformers (BERT) have been very effective in various Natural Language Processing (NLP) and text mining tasks including text classification. However, some tasks still pose challenges for these models, including text classification with limited labels. This can result in a cold-start problem. Although some approaches have attempted to address this problem through single-stage clustering as an intermediate training step coupled with a pre-trained language model, which generates pseudo-labels to improve classification, these methods are often error-prone due to the limitations of the clustering algorithms. To overcome this, we have developed a novel two-stage intermediate clustering with subsequent fine-tuning that models the pseudo-labels reliably, resulting in reduced prediction errors. The key novelty in our model, IDoFew, is that the two-stage clustering coupled with two different clustering algorithms helps exploit the advantages of the complementary algorithms that reduce the errors in generating reliable pseudo-labels for fine-tuning. Our approach has shown significant improvements compared to strong comparative models.","sentences":["Language models such as Bidirectional Encoder Representations from Transformers (BERT) have been very effective in various Natural Language Processing (NLP) and text mining tasks including text classification.","However, some tasks still pose challenges for these models, including text classification with limited labels.","This can result in a cold-start problem.","Although some approaches have attempted to address this problem through single-stage clustering as an intermediate training step coupled with a pre-trained language model, which generates pseudo-labels to improve classification, these methods are often error-prone due to the limitations of the clustering algorithms.","To overcome this, we have developed a novel two-stage intermediate clustering with subsequent fine-tuning that models the pseudo-labels reliably, resulting in reduced prediction errors.","The key novelty in our model, IDoFew, is that the two-stage clustering coupled with two different clustering algorithms helps exploit the advantages of the complementary algorithms that reduce the errors in generating reliable pseudo-labels for fine-tuning.","Our approach has shown significant improvements compared to strong comparative models."],"url":"http://arxiv.org/abs/2401.04025v1"}
{"created":"2024-01-08 17:02:25","title":"Efficient Multiscale Multimodal Bottleneck Transformer for Audio-Video Classification","abstract":"In recent years, researchers combine both audio and video signals to deal with challenges where actions are not well represented or captured by visual cues. However, how to effectively leverage the two modalities is still under development. In this work, we develop a multiscale multimodal Transformer (MMT) that leverages hierarchical representation learning. Particularly, MMT is composed of a novel multiscale audio Transformer (MAT) and a multiscale video Transformer [43]. To learn a discriminative cross-modality fusion, we further design multimodal supervised contrastive objectives called audio-video contrastive loss (AVC) and intra-modal contrastive loss (IMC) that robustly align the two modalities. MMT surpasses previous state-of-the-art approaches by 7.3% and 2.1% on Kinetics-Sounds and VGGSound in terms of the top-1 accuracy without external training data. Moreover, the proposed MAT significantly outperforms AST [28] by 22.2%, 4.4% and 4.7% on three public benchmark datasets, and is about 3% more efficient based on the number of FLOPs and 9.8% more efficient based on GPU memory usage.","sentences":["In recent years, researchers combine both audio and video signals to deal with challenges where actions are not well represented or captured by visual cues.","However, how to effectively leverage the two modalities is still under development.","In this work, we develop a multiscale multimodal Transformer (MMT) that leverages hierarchical representation learning.","Particularly, MMT is composed of a novel multiscale audio Transformer (MAT) and a multiscale video Transformer [43].","To learn a discriminative cross-modality fusion, we further design multimodal supervised contrastive objectives called audio-video contrastive loss (AVC) and intra-modal contrastive loss (IMC) that robustly align the two modalities.","MMT surpasses previous state-of-the-art approaches by 7.3% and 2.1% on Kinetics-Sounds and VGGSound in terms of the top-1 accuracy without external training data.","Moreover, the proposed MAT significantly outperforms AST","[28] by 22.2%, 4.4% and 4.7% on three public benchmark datasets, and is about 3% more efficient based on the number of FLOPs and 9.8% more efficient based on GPU memory usage."],"url":"http://arxiv.org/abs/2401.04023v1"}
{"created":"2024-01-08 17:02:12","title":"Identifying Fabricated Networks within Authorship-for-Sale Enterprises","abstract":"Fabricated papers do not just need text, images, and data, they also require a fabricated or partially fabricated network of authors. Most `authors' on a fabricated paper have not been associated with the research, but rather are added through a transaction. This lack of deeper connection means that there is a low likelihood that co-authors on fabricated papers will ever appear together on the same paper more than once. This paper constructs a model that encodes some of the key characteristics of this activity in an `authorship-for-sale' network with the aim to create a robust method to detect this type of activity. A characteristic network fingerprint arises from this model that provides a robust statistical approach to the detection of paper-mill networks. The model suggested in this paper detects networks that have a statistically significant overlap with other approaches that principally rely on textual analysis for the detection of fraudulent papers. Researchers connected to networks identified using the methodology outlined in this paper are shown to be connected with 37% of papers identified through the tortured-phrase and clay-feet methods deployed in the Problematic Paper Screener website. Finally, methods to limit the expansion and propagation of these networks is discussed both in technological and social terms.","sentences":["Fabricated papers do not just need text, images, and data, they also require a fabricated or partially fabricated network of authors.","Most `authors' on a fabricated paper have not been associated with the research, but rather are added through a transaction.","This lack of deeper connection means that there is a low likelihood that co-authors on fabricated papers will ever appear together on the same paper more than once.","This paper constructs a model that encodes some of the key characteristics of this activity in an `authorship-for-sale' network with the aim to create a robust method to detect this type of activity.","A characteristic network fingerprint arises from this model that provides a robust statistical approach to the detection of paper-mill networks.","The model suggested in this paper detects networks that have a statistically significant overlap with other approaches that principally rely on textual analysis for the detection of fraudulent papers.","Researchers connected to networks identified using the methodology outlined in this paper are shown to be connected with 37% of papers identified through the tortured-phrase and clay-feet methods deployed in the Problematic Paper Screener website.","Finally, methods to limit the expansion and propagation of these networks is discussed both in technological and social terms."],"url":"http://arxiv.org/abs/2401.04022v1"}
{"created":"2024-01-08 16:55:33","title":"On the Long-Term behavior of $k$-tuples Frequencies in Mutation Systems","abstract":"In response to the evolving landscape of data storage, researchers have increasingly explored non-traditional platforms, with DNA-based storage emerging as a cutting-edge solution. Our work is motivated by the potential of in-vivo DNA storage, known for its capacity to store vast amounts of information efficiently and confidentially within an organism's native DNA. While promising, in-vivo DNA storage faces challenges, including susceptibility to errors introduced by mutations. To understand the long-term behavior of such mutation systems, we investigate the frequency of $k$-tuples after multiple mutation applications.   Drawing inspiration from related works, we generalize results from the study of mutation systems, particularly focusing on the frequency of $k$-tuples. In this work, we provide a broad analysis through the construction of a specialized matrix and the identification of its eigenvectors. In the context of substitution and duplication systems, we leverage previous results on almost sure convergence, equating the expected frequency to the limiting frequency. Moreover, we demonstrate convergence in probability under certain assumptions.","sentences":["In response to the evolving landscape of data storage, researchers have increasingly explored non-traditional platforms, with DNA-based storage emerging as a cutting-edge solution.","Our work is motivated by the potential of in-vivo DNA storage, known for its capacity to store vast amounts of information efficiently and confidentially within an organism's native DNA.","While promising, in-vivo DNA storage faces challenges, including susceptibility to errors introduced by mutations.","To understand the long-term behavior of such mutation systems, we investigate the frequency of $k$-tuples after multiple mutation applications.   ","Drawing inspiration from related works, we generalize results from the study of mutation systems, particularly focusing on the frequency of $k$-tuples.","In this work, we provide a broad analysis through the construction of a specialized matrix and the identification of its eigenvectors.","In the context of substitution and duplication systems, we leverage previous results on almost sure convergence, equating the expected frequency to the limiting frequency.","Moreover, we demonstrate convergence in probability under certain assumptions."],"url":"http://arxiv.org/abs/2401.04020v1"}
{"created":"2024-01-08 16:44:23","title":"Weak Correlations as the Underlying Principle for Linearization of Gradient-Based Learning Systems","abstract":"Deep learning models, such as wide neural networks, can be conceptualized as nonlinear dynamical physical systems characterized by a multitude of interacting degrees of freedom. Such systems in the infinite limit, tend to exhibit simplified dynamics. This paper delves into gradient descent-based learning algorithms, that display a linear structure in their parameter dynamics, reminiscent of the neural tangent kernel. We establish this apparent linearity arises due to weak correlations between the first and higher-order derivatives of the hypothesis function, concerning the parameters, taken around their initial values. This insight suggests that these weak correlations could be the underlying reason for the observed linearization in such systems. As a case in point, we showcase this weak correlations structure within neural networks in the large width limit. Exploiting the relationship between linearity and weak correlations, we derive a bound on deviations from linearity observed during the training trajectory of stochastic gradient descent. To facilitate our proof, we introduce a novel method to characterise the asymptotic behavior of random tensors.","sentences":["Deep learning models, such as wide neural networks, can be conceptualized as nonlinear dynamical physical systems characterized by a multitude of interacting degrees of freedom.","Such systems in the infinite limit, tend to exhibit simplified dynamics.","This paper delves into gradient descent-based learning algorithms, that display a linear structure in their parameter dynamics, reminiscent of the neural tangent kernel.","We establish this apparent linearity arises due to weak correlations between the first and higher-order derivatives of the hypothesis function, concerning the parameters, taken around their initial values.","This insight suggests that these weak correlations could be the underlying reason for the observed linearization in such systems.","As a case in point, we showcase this weak correlations structure within neural networks in the large width limit.","Exploiting the relationship between linearity and weak correlations, we derive a bound on deviations from linearity observed during the training trajectory of stochastic gradient descent.","To facilitate our proof, we introduce a novel method to characterise the asymptotic behavior of random tensors."],"url":"http://arxiv.org/abs/2401.04013v1"}
{"created":"2024-01-08 16:44:21","title":"MX: Enhancing RISC-V's Vector ISA for Ultra-Low Overhead, Energy-Efficient Matrix Multiplication","abstract":"Dense Matrix Multiplication (MatMul) is arguably one of the most ubiquitous compute-intensive kernels, spanning linear algebra, DSP, graphics, and machine learning applications. Thus, MatMul optimization is crucial not only in high-performance processors but also in embedded low-power platforms. Several Instruction Set Architectures (ISAs) have recently included matrix extensions to improve MatMul performance and efficiency at the cost of added matrix register files and units. In this paper, we propose Matrix eXtension (MX), a lightweight approach that builds upon the open-source RISC-V Vector (RVV) ISA to boost MatMul energy efficiency. Instead of adding expensive dedicated hardware, MX uses the pre-existing vector register file and functional units to create a hybrid vector/matrix engine at a negligible area cost (< 3%), which comes from a compact near-FPU tile buffer for higher data reuse, and no clock frequency overhead. We implement MX on a compact and highly energy-optimized RVV processor and evaluate it in both a Dual- and 64-Core cluster in a 12-nm technology node. MX boosts the Dual-Core's energy efficiency by 10% for a double-precision 64x64x64 matrix multiplication with the same FPU utilization (~97%) and by 25% on the 64-Core cluster for the same benchmark on 32-bit data, with a 56% performance gain.","sentences":["Dense Matrix Multiplication (MatMul) is arguably one of the most ubiquitous compute-intensive kernels, spanning linear algebra, DSP, graphics, and machine learning applications.","Thus, MatMul optimization is crucial not only in high-performance processors but also in embedded low-power platforms.","Several Instruction Set Architectures (ISAs) have recently included matrix extensions to improve MatMul performance and efficiency at the cost of added matrix register files and units.","In this paper, we propose Matrix eXtension (MX), a lightweight approach that builds upon the open-source RISC-V Vector (RVV) ISA to boost MatMul energy efficiency.","Instead of adding expensive dedicated hardware, MX uses the pre-existing vector register file and functional units to create a hybrid vector/matrix engine at a negligible area cost (< 3%), which comes from a compact near-FPU tile buffer for higher data reuse, and no clock frequency overhead.","We implement MX on a compact and highly energy-optimized RVV processor and evaluate it in both a Dual- and 64-Core cluster in a 12-nm technology node.","MX boosts the Dual-Core's energy efficiency by 10% for a double-precision 64x64x64 matrix multiplication with the same FPU utilization (~97%) and by 25% on the 64-Core cluster for the same benchmark on 32-bit data, with a 56% performance gain."],"url":"http://arxiv.org/abs/2401.04012v1"}
{"created":"2024-01-08 16:37:55","title":"Task-Oriented Active Learning of Model Preconditions for Inaccurate Dynamics Models","abstract":"When planning with an inaccurate dynamics model, a practical strategy is to restrict planning to regions of state-action space where the model is accurate: also known as a model precondition. Empirical real-world trajectory data is valuable for defining data-driven model preconditions regardless of the model form (analytical, simulator, learned, etc...). However, real-world data is often expensive and dangerous to collect. In order to achieve data efficiency, this paper presents an algorithm for actively selecting trajectories to learn a model precondition for an inaccurate pre-specified dynamics model. Our proposed techniques address challenges arising from the sequential nature of trajectories, and potential benefit of prioritizing task-relevant data. The experimental analysis shows how algorithmic properties affect performance in three planning scenarios: icy gridworld, simulated plant watering, and real-world plant watering. Results demonstrate an improvement of approximately 80% after only four real-world trajectories when using our proposed techniques.","sentences":["When planning with an inaccurate dynamics model, a practical strategy is to restrict planning to regions of state-action space where the model is accurate: also known as a model precondition.","Empirical real-world trajectory data is valuable for defining data-driven model preconditions regardless of the model form (analytical, simulator, learned, etc...).","However, real-world data is often expensive and dangerous to collect.","In order to achieve data efficiency, this paper presents an algorithm for actively selecting trajectories to learn a model precondition for an inaccurate pre-specified dynamics model.","Our proposed techniques address challenges arising from the sequential nature of trajectories, and potential benefit of prioritizing task-relevant data.","The experimental analysis shows how algorithmic properties affect performance in three planning scenarios: icy gridworld, simulated plant watering, and real-world plant watering.","Results demonstrate an improvement of approximately 80% after only four real-world trajectories when using our proposed techniques."],"url":"http://arxiv.org/abs/2401.04007v1"}
{"created":"2024-01-08 16:36:47","title":"Generative adversarial wavelet neural operator: Application to fault detection and isolation of multivariate time series data","abstract":"Fault detection and isolation in complex systems are critical to ensure reliable and efficient operation. However, traditional fault detection methods often struggle with issues such as nonlinearity and multivariate characteristics of the time series variables. This article proposes a generative adversarial wavelet neural operator (GAWNO) as a novel unsupervised deep learning approach for fault detection and isolation of multivariate time series processes.The GAWNO combines the strengths of wavelet neural operators and generative adversarial networks (GANs) to effectively capture both the temporal distributions and the spatial dependencies among different variables of an underlying system. The approach of fault detection and isolation using GAWNO consists of two main stages. In the first stage, the GAWNO is trained on a dataset of normal operating conditions to learn the underlying data distribution. In the second stage, a reconstruction error-based threshold approach using the trained GAWNO is employed to detect and isolate faults based on the discrepancy values. We validate the proposed approach using the Tennessee Eastman Process (TEP) dataset and Avedore wastewater treatment plant (WWTP) and N2O emissions named as WWTPN2O datasets. Overall, we showcase that the idea of harnessing the power of wavelet analysis, neural operators, and generative models in a single framework to detect and isolate faults has shown promising results compared to various well-established baselines in the literature.","sentences":["Fault detection and isolation in complex systems are critical to ensure reliable and efficient operation.","However, traditional fault detection methods often struggle with issues such as nonlinearity and multivariate characteristics of the time series variables.","This article proposes a generative adversarial wavelet neural operator (GAWNO) as a novel unsupervised deep learning approach for fault detection and isolation of multivariate time series processes.","The GAWNO combines the strengths of wavelet neural operators and generative adversarial networks (GANs) to effectively capture both the temporal distributions and the spatial dependencies among different variables of an underlying system.","The approach of fault detection and isolation using GAWNO consists of two main stages.","In the first stage, the GAWNO is trained on a dataset of normal operating conditions to learn the underlying data distribution.","In the second stage, a reconstruction error-based threshold approach using the trained GAWNO is employed to detect and isolate faults based on the discrepancy values.","We validate the proposed approach using the Tennessee Eastman Process (TEP) dataset and Avedore wastewater treatment plant (WWTP) and N2O emissions named as WWTPN2O datasets.","Overall, we showcase that the idea of harnessing the power of wavelet analysis, neural operators, and generative models in a single framework to detect and isolate faults has shown promising results compared to various well-established baselines in the literature."],"url":"http://arxiv.org/abs/2401.04004v1"}
{"created":"2024-01-08 16:35:13","title":"Simultaneous Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications","abstract":"Past research into robotic planning with temporal logic specifications, notably Linear Temporal Logic (LTL), was largely based on singular formulas for individual or groups of robots. But with increasing task complexity, LTL formulas unavoidably grow lengthy, complicating interpretation and specification generation, and straining the computational capacities of the planners. In order to maximize the potential of LTL specifications, we capitalized on the intrinsic structure of tasks and introduced a hierarchical structure to LTL specifications, and designed an algorithm to ascertain whether they are satisfied given an input sequence. Second, we employ a search-based approach to synthesize plans for a multi-robot system, accomplishing simultaneous task allocation and planning. The search space is approximated by loosely interconnected sub-spaces, with each sub-space corresponding to one LTL specification. The search is predominantly confined to a single sub-space, transitioning to another sub-space under certain conditions, determined by the decomposition of automatons. Moreover, multiple heuristics are formulated to expedite the search significantly. A theoretical analysis concerning completeness and optimality is conducted under mild assumptions. When compared with existing methods on service tasks, our method outperforms in terms of execution times with comparable solution quality. Finally, scalability is evaluated by testing a group of 30 robots and achieving reasonable runtimes.","sentences":["Past research into robotic planning with temporal logic specifications, notably Linear Temporal Logic (LTL), was largely based on singular formulas for individual or groups of robots.","But with increasing task complexity, LTL formulas unavoidably grow lengthy, complicating interpretation and specification generation, and straining the computational capacities of the planners.","In order to maximize the potential of LTL specifications, we capitalized on the intrinsic structure of tasks and introduced a hierarchical structure to LTL specifications, and designed an algorithm to ascertain whether they are satisfied given an input sequence.","Second, we employ a search-based approach to synthesize plans for a multi-robot system, accomplishing simultaneous task allocation and planning.","The search space is approximated by loosely interconnected sub-spaces, with each sub-space corresponding to one LTL specification.","The search is predominantly confined to a single sub-space, transitioning to another sub-space under certain conditions, determined by the decomposition of automatons.","Moreover, multiple heuristics are formulated to expedite the search significantly.","A theoretical analysis concerning completeness and optimality is conducted under mild assumptions.","When compared with existing methods on service tasks, our method outperforms in terms of execution times with comparable solution quality.","Finally, scalability is evaluated by testing a group of 30 robots and achieving reasonable runtimes."],"url":"http://arxiv.org/abs/2401.04003v1"}
{"created":"2024-01-08 16:25:45","title":"Polynomial Precision Dependence Solutions to Alignment Research Center Matrix Completion Problems","abstract":"We present solutions to the matrix completion problems proposed by the Alignment Research Center that have a polynomial dependence on the precision $\\varepsilon$. The motivation for these problems is to enable efficient computation of heuristic estimators to formally evaluate and reason about different quantities of deep neural networks in the interest of AI alignment. Our solutions involve reframing the matrix completion problems as a semidefinite program (SDP) and using recent advances in spectral bundle methods for fast, efficient, and scalable SDP solving.","sentences":["We present solutions to the matrix completion problems proposed by the Alignment Research Center that have a polynomial dependence on the precision $\\varepsilon$. The motivation for these problems is to enable efficient computation of heuristic estimators to formally evaluate and reason about different quantities of deep neural networks in the interest of AI alignment.","Our solutions involve reframing the matrix completion problems as a semidefinite program (SDP) and using recent advances in spectral bundle methods for fast, efficient, and scalable SDP solving."],"url":"http://arxiv.org/abs/2401.03999v1"}
{"created":"2024-01-08 16:19:31","title":"Nigeria's ICT and Economic Sustainability in the Digital Age","abstract":"Nigeria's remarkable information and communication technology (ICT) journey spans decades, playing a pivotal role in economic sustainability, especially as the nation celebrates its Republic at Sixty. This paper provides an overview of Nigeria's ICT journey, underscoring its central role in sustainable economic prosperity. We explore the potential of artificial intelligence, blockchain, and the Internet of Things (IoT), revealing the remarkable opportunities on the horizon. We stress the urgency of achieving digital inclusivity, bridging the urban-rural gap, and reducing the technological divide, all of which are critical as Nigeria marks its sixtieth year. We intend to prove the invaluable opportunities of ICT for policymakers, business leaders, and educational institutes as Nigeria looks towards enduring economic development in this digital age. Specifically, we envision a dynamic landscape where emerging technologies are set to redefine industries, supercharge economic growth, and enhance the quality of life for every Nigerian.","sentences":["Nigeria's remarkable information and communication technology (ICT) journey spans decades, playing a pivotal role in economic sustainability, especially as the nation celebrates its Republic at Sixty.","This paper provides an overview of Nigeria's ICT journey, underscoring its central role in sustainable economic prosperity.","We explore the potential of artificial intelligence, blockchain, and the Internet of Things (IoT), revealing the remarkable opportunities on the horizon.","We stress the urgency of achieving digital inclusivity, bridging the urban-rural gap, and reducing the technological divide, all of which are critical as Nigeria marks its sixtieth year.","We intend to prove the invaluable opportunities of ICT for policymakers, business leaders, and educational institutes as Nigeria looks towards enduring economic development in this digital age.","Specifically, we envision a dynamic landscape where emerging technologies are set to redefine industries, supercharge economic growth, and enhance the quality of life for every Nigerian."],"url":"http://arxiv.org/abs/2401.03996v1"}
{"created":"2024-01-08 16:15:43","title":"Behavioural Cloning in VizDoom","abstract":"This paper describes methods for training autonomous agents to play the game \"Doom 2\" through Imitation Learning (IL) using only pixel data as input. We also explore how Reinforcement Learning (RL) compares to IL for humanness by comparing camera movement and trajectory data. Through behavioural cloning, we examine the ability of individual models to learn varying behavioural traits. We attempt to mimic the behaviour of real players with different play styles, and find we can train agents that behave aggressively, passively, or simply more human-like than traditional AIs. We propose these methods of introducing more depth and human-like behaviour to agents in video games. The trained IL agents perform on par with the average players in our dataset, whilst outperforming the worst players. While performance was not as strong as common RL approaches, it provides much stronger human-like behavioural traits to the agent.","sentences":["This paper describes methods for training autonomous agents to play the game \"Doom 2\" through Imitation Learning (IL) using only pixel data as input.","We also explore how Reinforcement Learning (RL) compares to IL for humanness by comparing camera movement and trajectory data.","Through behavioural cloning, we examine the ability of individual models to learn varying behavioural traits.","We attempt to mimic the behaviour of real players with different play styles, and find we can train agents that behave aggressively, passively, or simply more human-like than traditional AIs.","We propose these methods of introducing more depth and human-like behaviour to agents in video games.","The trained IL agents perform on par with the average players in our dataset, whilst outperforming the worst players.","While performance was not as strong as common RL approaches, it provides much stronger human-like behavioural traits to the agent."],"url":"http://arxiv.org/abs/2401.03993v1"}
{"created":"2024-01-08 16:13:08","title":"Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark","abstract":"Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities. Despite these achievements, spatial reasoning remains a significant challenge for these models. Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance. However, the presence of template errors in the benchmark has an impact on the evaluation results. Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities. In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation. We analyze GPT's spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning. We provide a flawless solution to the benchmark by combining template-to-relation mapping with logic-based reasoning. This combination demonstrates proficiency in performing qualitative reasoning on StepGame without encountering any errors. We then address the limitations of GPT models in spatial reasoning. We deploy Chain-of-thought and Tree-of-thoughts prompting strategies, offering insights into GPT's ``cognitive process\", and achieving remarkable improvements in accuracy. Our investigation not only sheds light on model deficiencies but also proposes enhancements, contributing to the advancement of AI with more robust spatial reasoning capabilities.","sentences":["Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities.","Despite these achievements, spatial reasoning remains a significant challenge for these models.","Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance.","However, the presence of template errors in the benchmark has an impact on the evaluation results.","Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities.","In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation.","We analyze GPT's spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning.","We provide a flawless solution to the benchmark by combining template-to-relation mapping with logic-based reasoning.","This combination demonstrates proficiency in performing qualitative reasoning on StepGame without encountering any errors.","We then address the limitations of GPT models in spatial reasoning.","We deploy Chain-of-thought and Tree-of-thoughts prompting strategies, offering insights into GPT's ``cognitive process\", and achieving remarkable improvements in accuracy.","Our investigation not only sheds light on model deficiencies but also proposes enhancements, contributing to the advancement of AI with more robust spatial reasoning capabilities."],"url":"http://arxiv.org/abs/2401.03991v1"}
{"created":"2024-01-08 16:08:53","title":"MS-DETR: Efficient DETR Training with Mixed Supervision","abstract":"DETR accomplishes end-to-end object detection through iteratively generating multiple object candidates based on image features and promoting one candidate for each ground-truth object. The traditional training procedure using one-to-one supervision in the original DETR lacks direct supervision for the object detection candidates.   We aim at improving the DETR training efficiency by explicitly supervising the candidate generation procedure through mixing one-to-one supervision and one-to-many supervision. Our approach, namely MS-DETR, is simple, and places one-to-many supervision to the object queries of the primary decoder that is used for inference. In comparison to existing DETR variants with one-to-many supervision, such as Group DETR and Hybrid DETR, our approach does not need additional decoder branches or object queries. The object queries of the primary decoder in our approach directly benefit from one-to-many supervision and thus are superior in object candidate prediction. Experimental results show that our approach outperforms related DETR variants, such as DN-DETR, Hybrid DETR, and Group DETR, and the combination with related DETR variants further improves the performance.","sentences":["DETR accomplishes end-to-end object detection through iteratively generating multiple object candidates based on image features and promoting one candidate for each ground-truth object.","The traditional training procedure using one-to-one supervision in the original DETR lacks direct supervision for the object detection candidates.   ","We aim at improving the DETR training efficiency by explicitly supervising the candidate generation procedure through mixing one-to-one supervision and one-to-many supervision.","Our approach, namely MS-DETR, is simple, and places one-to-many supervision to the object queries of the primary decoder that is used for inference.","In comparison to existing DETR variants with one-to-many supervision, such as Group DETR and Hybrid DETR, our approach does not need additional decoder branches or object queries.","The object queries of the primary decoder in our approach directly benefit from one-to-many supervision and thus are superior in object candidate prediction.","Experimental results show that our approach outperforms related DETR variants, such as DN-DETR, Hybrid DETR, and Group DETR, and the combination with related DETR variants further improves the performance."],"url":"http://arxiv.org/abs/2401.03989v1"}
{"created":"2024-01-08 16:08:21","title":"A Primer on Temporal Graph Learning","abstract":"This document aims to familiarize readers with temporal graph learning (TGL) through a concept-first approach. We have systematically presented vital concepts essential for understanding the workings of a TGL framework. In addition to qualitative explanations, we have incorporated mathematical formulations where applicable, enhancing the clarity of the text. Since TGL involves temporal and spatial learning, we introduce relevant learning architectures ranging from recurrent and convolutional neural networks to transformers and graph neural networks. We also discuss classical time series forecasting methods to inspire interpretable learning solutions for TGL.","sentences":["This document aims to familiarize readers with temporal graph learning (TGL) through a concept-first approach.","We have systematically presented vital concepts essential for understanding the workings of a TGL framework.","In addition to qualitative explanations, we have incorporated mathematical formulations where applicable, enhancing the clarity of the text.","Since TGL involves temporal and spatial learning, we introduce relevant learning architectures ranging from recurrent and convolutional neural networks to transformers and graph neural networks.","We also discuss classical time series forecasting methods to inspire interpretable learning solutions for TGL."],"url":"http://arxiv.org/abs/2401.03988v1"}
{"created":"2024-01-08 15:40:11","title":"Differential Equations for Continuous-Time Deep Learning","abstract":"This short, self-contained article seeks to introduce and survey continuous-time deep learning approaches that are based on neural ordinary differential equations (neural ODEs). It primarily targets readers familiar with ordinary and partial differential equations and their analysis who are curious to see their role in machine learning. Using three examples from machine learning and applied mathematics, we will see how neural ODEs can provide new insights into deep learning and a foundation for more efficient algorithms.","sentences":["This short, self-contained article seeks to introduce and survey continuous-time deep learning approaches that are based on neural ordinary differential equations (neural ODEs).","It primarily targets readers familiar with ordinary and partial differential equations and their analysis who are curious to see their role in machine learning.","Using three examples from machine learning and applied mathematics, we will see how neural ODEs can provide new insights into deep learning and a foundation for more efficient algorithms."],"url":"http://arxiv.org/abs/2401.03965v1"}
{"created":"2024-01-08 15:29:23","title":"Comparing Data-Driven and Mechanistic Models for Predicting Phenology in Deciduous Broadleaf Forests","abstract":"Understanding the future climate is crucial for informed policy decisions on climate change prevention and mitigation. Earth system models play an important role in predicting future climate, requiring accurate representation of complex sub-processes that span multiple time scales and spatial scales. One such process that links seasonal and interannual climate variability to cyclical biological events is tree phenology in deciduous broadleaf forests. Phenological dates, such as the start and end of the growing season, are critical for understanding the exchange of carbon and water between the biosphere and the atmosphere. Mechanistic prediction of these dates is challenging. Hybrid modelling, which integrates data-driven approaches into complex models, offers a solution. In this work, as a first step towards this goal, train a deep neural network to predict a phenological index from meteorological time series. We find that this approach outperforms traditional process-based models. This highlights the potential of data-driven methods to improve climate predictions. We also analyze which variables and aspects of the time series influence the predicted onset of the season, in order to gain a better understanding of the advantages and limitations of our model.","sentences":["Understanding the future climate is crucial for informed policy decisions on climate change prevention and mitigation.","Earth system models play an important role in predicting future climate, requiring accurate representation of complex sub-processes that span multiple time scales and spatial scales.","One such process that links seasonal and interannual climate variability to cyclical biological events is tree phenology in deciduous broadleaf forests.","Phenological dates, such as the start and end of the growing season, are critical for understanding the exchange of carbon and water between the biosphere and the atmosphere.","Mechanistic prediction of these dates is challenging.","Hybrid modelling, which integrates data-driven approaches into complex models, offers a solution.","In this work, as a first step towards this goal, train a deep neural network to predict a phenological index from meteorological time series.","We find that this approach outperforms traditional process-based models.","This highlights the potential of data-driven methods to improve climate predictions.","We also analyze which variables and aspects of the time series influence the predicted onset of the season, in order to gain a better understanding of the advantages and limitations of our model."],"url":"http://arxiv.org/abs/2401.03960v1"}
{"created":"2024-01-08 15:21:21","title":"TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series","abstract":"Large Pretrained models for Zero/Few-shot learning excel in language and vision domains but encounter challenges in multivariate time series (TS) due to the diverse nature and scarcity of publicly available pretraining data. Consequently, there has been a recent surge in utilizing pretrained large language models (LLMs) with various adaptations for time series forecasting. These approaches employ cross-domain transfer learning, yielding highly impressive results. However, these models are typically very large ($\\sim$ billion parameters), exhibit slow execution, and do not consider cross-channel correlations. To address this, we present Multi-level Tiny Time Mixers (TTM), a significantly smaller model based on the lightweight TSMixer architecture. TTM marks the first success in developing tiny pretrained models ($\\le$1 million parameters), exclusively trained on public TS data with effective transfer learning capabilities. To tackle the complexity of pretraining on multiple datasets with varied temporal resolutions, we introduce several novel enhancements such as adaptive patching, dataset augmentation via downsampling, and resolution prefix tuning. Moreover, we employ a multi-level modeling strategy to effectively model channel correlations and incorporate exogenous signals during finetuning, a crucial capability lacking in existing benchmarks. TTM excels in few/zero-shot forecasting, demonstrating significant accuracy gains (12-38%) over existing benchmarks. Further, it achieves a remarkable 14-106X reduction in model parameters, enabling 54-65X faster training/inference as compared to the LLM-TS benchmarks. In fact, TTM's zero-shot results often surpass the few-shot results in many benchmarks, highlighting the efficacy of our approach. Code and Pretrained Models will be open-sourced.","sentences":["Large Pretrained models for Zero/Few-shot learning excel in language and vision domains but encounter challenges in multivariate time series (TS) due to the diverse nature and scarcity of publicly available pretraining data.","Consequently, there has been a recent surge in utilizing pretrained large language models (LLMs) with various adaptations for time series forecasting.","These approaches employ cross-domain transfer learning, yielding highly impressive results.","However, these models are typically very large ($\\sim$ billion parameters), exhibit slow execution, and do not consider cross-channel correlations.","To address this, we present Multi-level Tiny Time Mixers (TTM), a significantly smaller model based on the lightweight TSMixer architecture.","TTM marks the first success in developing tiny pretrained models ($\\le$1 million parameters), exclusively trained on public TS data with effective transfer learning capabilities.","To tackle the complexity of pretraining on multiple datasets with varied temporal resolutions, we introduce several novel enhancements such as adaptive patching, dataset augmentation via downsampling, and resolution prefix tuning.","Moreover, we employ a multi-level modeling strategy to effectively model channel correlations and incorporate exogenous signals during finetuning, a crucial capability lacking in existing benchmarks.","TTM excels in few/zero-shot forecasting, demonstrating significant accuracy gains (12-38%) over existing benchmarks.","Further, it achieves a remarkable 14-106X reduction in model parameters, enabling 54-65X faster training/inference as compared to the LLM-TS benchmarks.","In fact, TTM's zero-shot results often surpass the few-shot results in many benchmarks, highlighting the efficacy of our approach.","Code and Pretrained Models will be open-sourced."],"url":"http://arxiv.org/abs/2401.03955v1"}
{"created":"2024-01-08 15:13:23","title":"Guiding drones by information gain","abstract":"The accurate estimation of locations and emission rates of gas sources is crucial across various domains, including environmental monitoring and greenhouse gas emission analysis. This study investigates two drone sampling strategies for inferring source term parameters of gas plumes from atmospheric measurements. Both strategies are guided by the goal of maximizing information gain attained from observations at sequential locations. Our research compares the myopic approach of infotaxis to a far-sighted navigation strategy trained through deep reinforcement learning. We demonstrate the superior performance of deep reinforcement learning over infotaxis in environments with non-isotropic gas plumes.","sentences":["The accurate estimation of locations and emission rates of gas sources is crucial across various domains, including environmental monitoring and greenhouse gas emission analysis.","This study investigates two drone sampling strategies for inferring source term parameters of gas plumes from atmospheric measurements.","Both strategies are guided by the goal of maximizing information gain attained from observations at sequential locations.","Our research compares the myopic approach of infotaxis to a far-sighted navigation strategy trained through deep reinforcement learning.","We demonstrate the superior performance of deep reinforcement learning over infotaxis in environments with non-isotropic gas plumes."],"url":"http://arxiv.org/abs/2401.03947v1"}
{"created":"2024-01-08 15:05:32","title":"TextMachina: Seamless Generation of Machine-Generated Text Datasets","abstract":"Recent advancements in Large Language Models (LLMs) have led to high-quality Machine-Generated Text (MGT), giving rise to countless new use cases and applications. However, easy access to LLMs is posing new challenges due to misuse. To address malicious usage, researchers have released datasets to effectively train models on MGT-related tasks. Similar strategies are used to compile these datasets, but no tool currently unifies them. In this scenario, we introduce TextMachina, a modular and extensible Python framework, designed to aid in the creation of high-quality, unbiased datasets to build robust models for MGT-related tasks such as detection, attribution, or boundary detection. It provides a user-friendly pipeline that abstracts away the inherent intricacies of building MGT datasets, such as LLM integrations, prompt templating, and bias mitigation. The quality of the datasets generated by TextMachina has been assessed in previous works, including shared tasks where more than one hundred teams trained robust MGT detectors.","sentences":["Recent advancements in Large Language Models (LLMs) have led to high-quality Machine-Generated Text (MGT), giving rise to countless new use cases and applications.","However, easy access to LLMs is posing new challenges due to misuse.","To address malicious usage, researchers have released datasets to effectively train models on MGT-related tasks.","Similar strategies are used to compile these datasets, but no tool currently unifies them.","In this scenario, we introduce TextMachina, a modular and extensible Python framework, designed to aid in the creation of high-quality, unbiased datasets to build robust models for MGT-related tasks such as detection, attribution, or boundary detection.","It provides a user-friendly pipeline that abstracts away the inherent intricacies of building MGT datasets, such as LLM integrations, prompt templating, and bias mitigation.","The quality of the datasets generated by TextMachina has been assessed in previous works, including shared tasks where more than one hundred teams trained robust MGT detectors."],"url":"http://arxiv.org/abs/2401.03946v1"}
{"created":"2024-01-08 15:01:08","title":"SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems","abstract":"Human communication is a complex and diverse process that not only involves multiple factors such as language, commonsense, and cultural backgrounds but also requires the participation of multimodal information, such as speech. Large Language Model (LLM)-based multi-agent systems have demonstrated promising performance in simulating human society. Can we leverage LLM-based multi-agent systems to simulate human communication? However, current LLM-based multi-agent systems mainly rely on text as the primary medium. In this paper, we propose SpeechAgents, a multi-modal LLM based multi-agent system designed for simulating human communication. SpeechAgents utilizes multi-modal LLM as the control center for individual agent and employes multi-modal signals as the medium for exchanged messages among agents. Additionally, we propose Multi-Agent Tuning to enhance the multi-agent capabilities of LLM without compromising general abilities. To strengthen and evaluate the effectiveness of human communication simulation, we build the Human-Communication Simulation Benchmark. Experimental results demonstrate that SpeechAgents can simulate human communication dialogues with consistent content, authentic rhythm, and rich emotions and demonstrate excellent scalability even with up to 25 agents, which can apply to tasks such as drama creation and audio novels generation. Code and models will be open-sourced at https://github. com/0nutation/SpeechAgents","sentences":["Human communication is a complex and diverse process that not only involves multiple factors such as language, commonsense, and cultural backgrounds but also requires the participation of multimodal information, such as speech.","Large Language Model (LLM)-based multi-agent systems have demonstrated promising performance in simulating human society.","Can we leverage LLM-based multi-agent systems to simulate human communication?","However, current LLM-based multi-agent systems mainly rely on text as the primary medium.","In this paper, we propose SpeechAgents, a multi-modal LLM based multi-agent system designed for simulating human communication.","SpeechAgents utilizes multi-modal LLM as the control center for individual agent and employes multi-modal signals as the medium for exchanged messages among agents.","Additionally, we propose Multi-Agent Tuning to enhance the multi-agent capabilities of LLM without compromising general abilities.","To strengthen and evaluate the effectiveness of human communication simulation, we build the Human-Communication Simulation Benchmark.","Experimental results demonstrate that SpeechAgents can simulate human communication dialogues with consistent content, authentic rhythm, and rich emotions and demonstrate excellent scalability even with up to 25 agents, which can apply to tasks such as drama creation and audio novels generation.","Code and models will be open-sourced at https://github. com/0nutation/SpeechAgents"],"url":"http://arxiv.org/abs/2401.03945v1"}
{"created":"2024-01-08 15:00:46","title":"Diegetic Graphical User Interfaces and Intuitive Control of Assistive Robots via Eye-gaze","abstract":"Individuals with tetraplegia and similar forms of paralysis suffer physically and emotionally due to a lack of autonomy. To help regain part of this autonomy, assistive robotic arms have been shown to increase living independence. However, users with paralysis pose unique challenging conditions for the control of these devices. In this article, we present the use of Diegetic Graphical User Interfaces, a novel, intuitive, and computationally inexpensive approach for gaze-controlled interfaces applied to robots. By using symbols paired with fiducial markers, interactive buttons can be defined in the real world which the user can trigger via gaze, and which can be embedded easily into the environment. We apply this system to pilot a 3-degree-of-freedom robotic arm for precision pick-and-place tasks. The interface is placed directly on the robot to allow intuitive and direct interaction, eliminating the need for context-switching between external screens, menus, and the robot. After calibration and a brief habituation period, twenty-one participants from multiple backgrounds, ages and eye-sight conditions completed the Yale-CMU-Berkeley (YCB) Block Pick and Place Protocol to benchmark the system, achieving a mean score of 13.71 out of the maximum 16.00 points. Good usability and user experience were reported (System Usability Score of 75.36) while achieving a low task workload measure (NASA-TLX of 44.76). Results show that users can employ multiple interface elements to perform actions with minimal practice and with a small cognitive load. To our knowledge, this is the first easily reconfigurable screenless system that enables robot control entirely via gaze for Cartesian robot control without the need for eye or face gestures.","sentences":["Individuals with tetraplegia and similar forms of paralysis suffer physically and emotionally due to a lack of autonomy.","To help regain part of this autonomy, assistive robotic arms have been shown to increase living independence.","However, users with paralysis pose unique challenging conditions for the control of these devices.","In this article, we present the use of Diegetic Graphical User Interfaces, a novel, intuitive, and computationally inexpensive approach for gaze-controlled interfaces applied to robots.","By using symbols paired with fiducial markers, interactive buttons can be defined in the real world which the user can trigger via gaze, and which can be embedded easily into the environment.","We apply this system to pilot a 3-degree-of-freedom robotic arm for precision pick-and-place tasks.","The interface is placed directly on the robot to allow intuitive and direct interaction, eliminating the need for context-switching between external screens, menus, and the robot.","After calibration and a brief habituation period, twenty-one participants from multiple backgrounds, ages and eye-sight conditions completed the Yale-CMU-Berkeley (YCB) Block Pick and Place Protocol to benchmark the system, achieving a mean score of 13.71 out of the maximum 16.00 points.","Good usability and user experience were reported (System Usability Score of 75.36) while achieving a low task workload measure (NASA-TLX of 44.76).","Results show that users can employ multiple interface elements to perform actions with minimal practice and with a small cognitive load.","To our knowledge, this is the first easily reconfigurable screenless system that enables robot control entirely via gaze for Cartesian robot control without the need for eye or face gestures."],"url":"http://arxiv.org/abs/2401.03944v1"}
{"created":"2024-01-08 14:57:32","title":"Multi-scale attention-based instance segmentation for measuring crystals with large size variation","abstract":"Quantitative measurement of crystals in high-resolution images allows for important insights into underlying material characteristics. Deep learning has shown great progress in vision-based automatic crystal size measurement, but current instance segmentation methods reach their limits with images that have large variation in crystal size or hard to detect crystal boundaries. Even small image segmentation errors, such as incorrectly fused or separated segments, can significantly lower the accuracy of the measured results. Instead of improving the existing pixel-wise boundary segmentation methods, we propose to use an instance-based segmentation method, which gives more robust segmentation results to improve measurement accuracy. Our novel method enhances flow maps with a size-aware multi-scale attention module. The attention module adaptively fuses information from multiple scales and focuses on the most relevant scale for each segmented image area. We demonstrate that our proposed attention fusion strategy outperforms state-of-the-art instance and boundary segmentation methods, as well as simple average fusion of multi-scale predictions. We evaluate our method on a refractory raw material dataset of high-resolution images with large variation in crystal size and show that our model can be used to calculate the crystal size more accurately than existing methods.","sentences":["Quantitative measurement of crystals in high-resolution images allows for important insights into underlying material characteristics.","Deep learning has shown great progress in vision-based automatic crystal size measurement, but current instance segmentation methods reach their limits with images that have large variation in crystal size or hard to detect crystal boundaries.","Even small image segmentation errors, such as incorrectly fused or separated segments, can significantly lower the accuracy of the measured results.","Instead of improving the existing pixel-wise boundary segmentation methods, we propose to use an instance-based segmentation method, which gives more robust segmentation results to improve measurement accuracy.","Our novel method enhances flow maps with a size-aware multi-scale attention module.","The attention module adaptively fuses information from multiple scales and focuses on the most relevant scale for each segmented image area.","We demonstrate that our proposed attention fusion strategy outperforms state-of-the-art instance and boundary segmentation methods, as well as simple average fusion of multi-scale predictions.","We evaluate our method on a refractory raw material dataset of high-resolution images with large variation in crystal size and show that our model can be used to calculate the crystal size more accurately than existing methods."],"url":"http://arxiv.org/abs/2401.03939v1"}
{"created":"2024-01-08 14:57:22","title":"Recovering the 3D UUV Position using UAV Imagery in Shallow-Water Environments","abstract":"In this paper we propose a novel approach aimed at recovering the 3D position of an UUV from UAV imagery in shallow-water environments. Through combination of UAV and UUV measurements, we show that our method can be utilized as an accurate and cost-effective alternative when compared to acoustic sensing methods, typically required to obtain ground truth information in underwater localization problems. Furthermore, our approach allows for a seamless conversion to geo-referenced coordinates which can be utilized for navigation purposes. To validate our method, we present the results with data collected through a simulation environment and field experiments, demonstrating the ability to successfully recover the UUV position with sub-meter accuracy.","sentences":["In this paper we propose a novel approach aimed at recovering the 3D position of an UUV from UAV imagery in shallow-water environments.","Through combination of UAV and UUV measurements, we show that our method can be utilized as an accurate and cost-effective alternative when compared to acoustic sensing methods, typically required to obtain ground truth information in underwater localization problems.","Furthermore, our approach allows for a seamless conversion to geo-referenced coordinates which can be utilized for navigation purposes.","To validate our method, we present the results with data collected through a simulation environment and field experiments, demonstrating the ability to successfully recover the UUV position with sub-meter accuracy."],"url":"http://arxiv.org/abs/2401.03938v1"}
{"created":"2024-01-08 14:45:15","title":"Using reinforcement learning to improve drone-based inference of greenhouse gas fluxes","abstract":"Accurate mapping of greenhouse gas fluxes at the Earth's surface is essential for the validation and calibration of climate models. In this study, we present a framework for surface flux estimation with drones. Our approach uses data assimilation (DA) to infer fluxes from drone-based observations, and reinforcement learning (RL) to optimize the drone's sampling strategy. Herein, we demonstrate that a RL-trained drone can quantify a CO2 hotspot more accurately than a drone sampling along a predefined flight path that traverses the emission plume. We find that information-based reward functions can match the performance of an error-based reward function that quantifies the difference between the estimated surface flux and the true value. Reward functions based on information gain and information entropy can motivate actions that increase the drone's confidence in its updated belief, without requiring knowledge of the true surface flux. These findings provide valuable insights for further development of the framework for the mapping of more complex surface flux fields.","sentences":["Accurate mapping of greenhouse gas fluxes at the Earth's surface is essential for the validation and calibration of climate models.","In this study, we present a framework for surface flux estimation with drones.","Our approach uses data assimilation (DA) to infer fluxes from drone-based observations, and reinforcement learning (RL) to optimize the drone's sampling strategy.","Herein, we demonstrate that a RL-trained drone can quantify a CO2 hotspot more accurately than a drone sampling along a predefined flight path that traverses the emission plume.","We find that information-based reward functions can match the performance of an error-based reward function that quantifies the difference between the estimated surface flux and the true value.","Reward functions based on information gain and information entropy can motivate actions that increase the drone's confidence in its updated belief, without requiring knowledge of the true surface flux.","These findings provide valuable insights for further development of the framework for the mapping of more complex surface flux fields."],"url":"http://arxiv.org/abs/2401.03932v1"}
{"created":"2024-01-08 14:39:21","title":"Rastro-DM: data mining with a trail","abstract":"This paper proposes a methodology for documenting data mining (DM) projects, Rastro-DM (Trail Data Mining), with a focus not on the model that is generated, but on the processes behind its construction, in order to leave a trail (Rastro in Portuguese) of planned actions, training completed, results obtained, and lessons learned. The proposed practices are complementary to structuring methodologies of DM, such as CRISP-DM, which establish a methodological and paradigmatic framework for the DM process. The application of best practices and their benefits is illustrated in a project called 'Cladop' that was created for the classification of PDF documents associated with the investigative process of damages to the Brazilian Federal Public Treasury. Building the Rastro-DM kit in the context of a project is a small step that can lead to an institutional leap to be achieved by sharing and using the trail across the enterprise.","sentences":["This paper proposes a methodology for documenting data mining (DM) projects, Rastro-DM (Trail Data Mining), with a focus not on the model that is generated, but on the processes behind its construction, in order to leave a trail (Rastro in Portuguese) of planned actions, training completed, results obtained, and lessons learned.","The proposed practices are complementary to structuring methodologies of DM, such as CRISP-DM, which establish a methodological and paradigmatic framework for the DM process.","The application of best practices and their benefits is illustrated in a project called 'Cladop' that was created for the classification of PDF documents associated with the investigative process of damages to the Brazilian Federal Public Treasury.","Building the Rastro-DM kit in the context of a project is a small step that can lead to an institutional leap to be achieved by sharing and using the trail across the enterprise."],"url":"http://arxiv.org/abs/2401.03925v1"}
{"created":"2024-01-08 14:34:47","title":"On the Exact Matching Problem in Dense Graphs","abstract":"In the Exact Matching problem, we are given a graph whose edges are colored red or blue and the task is to decide for a given integer k, if there is a perfect matching with exactly k red edges. Since 1987 it is known that the Exact Matching Problem can be solved in randomized polynomial time. Despite numerous efforts, it is still not known today whether a deterministic polynomial-time algorithm exists as well. In this paper, we make substantial progress by solving the problem for a multitude of different classes of dense graphs. We solve the Exact Matching problem in deterministic polynomial time for complete r-partite graphs, for unit interval graphs, for bipartite unit interval graphs, for graphs of bounded neighborhood diversity, for chain graphs, and for graphs without a complete bipartite t-hole. We solve the problem in quasi-polynomial time for Erd\\H{o}s-R\\'enyi random graphs G(n, 1/2). We also reprove an earlier result for bounded independence number/bipartite independence number. We use two main tools to obtain these results: A local search algorithm as well as a generalization of an earlier result by Karzanov.","sentences":["In the Exact Matching problem, we are given a graph whose edges are colored red or blue and the task is to decide for a given integer k, if there is a perfect matching with exactly k red edges.","Since 1987 it is known that the Exact Matching Problem can be solved in randomized polynomial time.","Despite numerous efforts, it is still not known today whether a deterministic polynomial-time algorithm exists as well.","In this paper, we make substantial progress by solving the problem for a multitude of different classes of dense graphs.","We solve the Exact Matching problem in deterministic polynomial time for complete r-partite graphs, for unit interval graphs, for bipartite unit interval graphs, for graphs of bounded neighborhood diversity, for chain graphs, and for graphs without a complete bipartite t-hole.","We solve the problem in quasi-polynomial time for Erd\\H{o}s-R\\'enyi random graphs G(n, 1/2).","We also reprove an earlier result for bounded independence number/bipartite independence number.","We use two main tools to obtain these results: A local search algorithm as well as a generalization of an earlier result by Karzanov."],"url":"http://arxiv.org/abs/2401.03924v1"}
{"created":"2024-01-08 14:24:54","title":"Toward a comprehensive simulation framework for hypergraphs: a Python-base approach","abstract":"Hypergraphs, or generalization of graphs such that edges can contain more than two nodes, have become increasingly prominent in understanding complex network analysis. Unlike graphs, hypergraphs have relatively few supporting platforms, and such dearth presents a barrier to more widespread adaptation of hypergraph computational toolboxes that could enable further research in several areas. Here, we introduce HyperRD, a Python package for hypergraph computation, simulation, and interoperability with other powerful Python packages in graph and hypergraph research. Then, we will introduce two models on hypergraph, the general Schelling's model and the SIR model, and simulate them with HyperRD.","sentences":["Hypergraphs, or generalization of graphs such that edges can contain more than two nodes, have become increasingly prominent in understanding complex network analysis.","Unlike graphs, hypergraphs have relatively few supporting platforms, and such dearth presents a barrier to more widespread adaptation of hypergraph computational toolboxes that could enable further research in several areas.","Here, we introduce HyperRD, a Python package for hypergraph computation, simulation, and interoperability with other powerful Python packages in graph and hypergraph research.","Then, we will introduce two models on hypergraph, the general Schelling's model and the SIR model, and simulate them with HyperRD."],"url":"http://arxiv.org/abs/2401.03917v1"}
{"created":"2024-01-08 14:21:02","title":"D3PRefiner: A Diffusion-based Denoise Method for 3D Human Pose Refinement","abstract":"Three-dimensional (3D) human pose estimation using a monocular camera has gained increasing attention due to its ease of implementation and the abundance of data available from daily life. However, owing to the inherent depth ambiguity in images, the accuracy of existing monocular camera-based 3D pose estimation methods remains unsatisfactory, and the estimated 3D poses usually include much noise. By observing the histogram of this noise, we find each dimension of the noise follows a certain distribution, which indicates the possibility for a neural network to learn the mapping between noisy poses and ground truth poses. In this work, in order to obtain more accurate 3D poses, a Diffusion-based 3D Pose Refiner (D3PRefiner) is proposed to refine the output of any existing 3D pose estimator. We first introduce a conditional multivariate Gaussian distribution to model the distribution of noisy 3D poses, using paired 2D poses and noisy 3D poses as conditions to achieve greater accuracy. Additionally, we leverage the architecture of current diffusion models to convert the distribution of noisy 3D poses into ground truth 3D poses. To evaluate the effectiveness of the proposed method, two state-of-the-art sequence-to-sequence 3D pose estimators are used as basic 3D pose estimation models, and the proposed method is evaluated on different types of 2D poses and different lengths of the input sequence. Experimental results demonstrate the proposed architecture can significantly improve the performance of current sequence-to-sequence 3D pose estimators, with a reduction of at least 10.3% in the mean per joint position error (MPJPE) and at least 11.0% in the Procrustes MPJPE (P-MPJPE).","sentences":["Three-dimensional (3D) human pose estimation using a monocular camera has gained increasing attention due to its ease of implementation and the abundance of data available from daily life.","However, owing to the inherent depth ambiguity in images, the accuracy of existing monocular camera-based 3D pose estimation methods remains unsatisfactory, and the estimated 3D poses usually include much noise.","By observing the histogram of this noise, we find each dimension of the noise follows a certain distribution, which indicates the possibility for a neural network to learn the mapping between noisy poses and ground truth poses.","In this work, in order to obtain more accurate 3D poses, a Diffusion-based 3D Pose Refiner (D3PRefiner) is proposed to refine the output of any existing 3D pose estimator.","We first introduce a conditional multivariate Gaussian distribution to model the distribution of noisy 3D poses, using paired 2D poses and noisy 3D poses as conditions to achieve greater accuracy.","Additionally, we leverage the architecture of current diffusion models to convert the distribution of noisy 3D poses into ground truth 3D poses.","To evaluate the effectiveness of the proposed method, two state-of-the-art sequence-to-sequence 3D pose estimators are used as basic 3D pose estimation models, and the proposed method is evaluated on different types of 2D poses and different lengths of the input sequence.","Experimental results demonstrate the proposed architecture can significantly improve the performance of current sequence-to-sequence 3D pose estimators, with a reduction of at least 10.3% in the mean per joint position error (MPJPE) and at least 11.0% in the Procrustes MPJPE (P-MPJPE)."],"url":"http://arxiv.org/abs/2401.03914v1"}
{"created":"2024-01-08 14:16:55","title":"A Wasserstein Graph Distance Based on Distributions of Probabilistic Node Embeddings","abstract":"Distance measures between graphs are important primitives for a variety of learning tasks. In this work, we describe an unsupervised, optimal transport based approach to define a distance between graphs. Our idea is to derive representations of graphs as Gaussian mixture models, fitted to distributions of sampled node embeddings over the same space. The Wasserstein distance between these Gaussian mixture distributions then yields an interpretable and easily computable distance measure, which can further be tailored for the comparison at hand by choosing appropriate embeddings. We propose two embeddings for this framework and show that under certain assumptions about the shape of the resulting Gaussian mixture components, further computational improvements of this Wasserstein distance can be achieved. An empirical validation of our findings on synthetic data and real-world Functional Brain Connectivity networks shows promising performance compared to existing embedding methods.","sentences":["Distance measures between graphs are important primitives for a variety of learning tasks.","In this work, we describe an unsupervised, optimal transport based approach to define a distance between graphs.","Our idea is to derive representations of graphs as Gaussian mixture models, fitted to distributions of sampled node embeddings over the same space.","The Wasserstein distance between these Gaussian mixture distributions then yields an interpretable and easily computable distance measure, which can further be tailored for the comparison at hand by choosing appropriate embeddings.","We propose two embeddings for this framework and show that under certain assumptions about the shape of the resulting Gaussian mixture components, further computational improvements of this Wasserstein distance can be achieved.","An empirical validation of our findings on synthetic data and real-world Functional Brain Connectivity networks shows promising performance compared to existing embedding methods."],"url":"http://arxiv.org/abs/2401.03913v1"}
{"created":"2024-01-08 14:12:31","title":"A Philosophical Introduction to Language Models -- Part I: Continuity With Classic Debates","abstract":"Large language models like GPT-4 have achieved remarkable proficiency in a broad spectrum of language-based tasks, some of which are traditionally associated with hallmarks of human intelligence. This has prompted ongoing disagreements about the extent to which we can meaningfully ascribe any kind of linguistic or cognitive competence to language models. Such questions have deep philosophical roots, echoing longstanding debates about the status of artificial neural networks as cognitive models. This article -- the first part of two companion papers -- serves both as a primer on language models for philosophers, and as an opinionated survey of their significance in relation to classic debates in the philosophy cognitive science, artificial intelligence, and linguistics. We cover topics such as compositionality, language acquisition, semantic competence, grounding, world models, and the transmission of cultural knowledge. We argue that the success of language models challenges several long-held assumptions about artificial neural networks. However, we also highlight the need for further empirical investigation to better understand their internal mechanisms. This sets the stage for the companion paper (Part II), which turns to novel empirical methods for probing the inner workings of language models, and new philosophical questions prompted by their latest developments.","sentences":["Large language models like GPT-4 have achieved remarkable proficiency in a broad spectrum of language-based tasks, some of which are traditionally associated with hallmarks of human intelligence.","This has prompted ongoing disagreements about the extent to which we can meaningfully ascribe any kind of linguistic or cognitive competence to language models.","Such questions have deep philosophical roots, echoing longstanding debates about the status of artificial neural networks as cognitive models.","This article -- the first part of two companion papers -- serves both as a primer on language models for philosophers, and as an opinionated survey of their significance in relation to classic debates in the philosophy cognitive science, artificial intelligence, and linguistics.","We cover topics such as compositionality, language acquisition, semantic competence, grounding, world models, and the transmission of cultural knowledge.","We argue that the success of language models challenges several long-held assumptions about artificial neural networks.","However, we also highlight the need for further empirical investigation to better understand their internal mechanisms.","This sets the stage for the companion paper (Part II), which turns to novel empirical methods for probing the inner workings of language models, and new philosophical questions prompted by their latest developments."],"url":"http://arxiv.org/abs/2401.03910v1"}
{"created":"2024-01-08 14:10:24","title":"RoboFusion: Towards Robust Multi-Modal 3D obiect Detection via SAM","abstract":"Multi-modal 3D object detectors are dedicated to exploring secure and reliable perception systems for autonomous driving (AD). However, while achieving state-of-the-art (SOTA) performance on clean benchmark datasets, they tend to overlook the complexity and harsh conditions of real-world environments. Meanwhile, with the emergence of visual foundation models (VFMs), opportunities and challenges are presented for improving the robustness and generalization of multi-modal 3D object detection in autonomous driving. Therefore, we propose RoboFusion, a robust framework that leverages VFMs like SAM to tackle out-of-distribution (OOD) noise scenarios. We first adapt the original SAM for autonomous driving scenarios named SAM-AD. To align SAM or SAM-AD with multi-modal methods, we then introduce AD-FPN for upsampling the image features extracted by SAM. We employ wavelet decomposition to denoise the depth-guided images for further noise reduction and weather interference. Lastly, we employ self-attention mechanisms to adaptively reweight the fused features, enhancing informative features while suppressing excess noise. In summary, our RoboFusion gradually reduces noise by leveraging the generalization and robustness of VFMs, thereby enhancing the resilience of multi-modal 3D object detection. Consequently, our RoboFusion achieves state-of-the-art performance in noisy scenarios, as demonstrated by the KITTI-C and nuScenes-C benchmarks.","sentences":["Multi-modal 3D object detectors are dedicated to exploring secure and reliable perception systems for autonomous driving (AD).","However, while achieving state-of-the-art (SOTA) performance on clean benchmark datasets, they tend to overlook the complexity and harsh conditions of real-world environments.","Meanwhile, with the emergence of visual foundation models (VFMs), opportunities and challenges are presented for improving the robustness and generalization of multi-modal 3D object detection in autonomous driving.","Therefore, we propose RoboFusion, a robust framework that leverages VFMs like SAM to tackle out-of-distribution (OOD) noise scenarios.","We first adapt the original SAM for autonomous driving scenarios named SAM-AD.","To align SAM or SAM-AD with multi-modal methods, we then introduce AD-FPN for upsampling the image features extracted by SAM.","We employ wavelet decomposition to denoise the depth-guided images for further noise reduction and weather interference.","Lastly, we employ self-attention mechanisms to adaptively reweight the fused features, enhancing informative features while suppressing excess noise.","In summary, our RoboFusion gradually reduces noise by leveraging the generalization and robustness of VFMs, thereby enhancing the resilience of multi-modal 3D object detection.","Consequently, our RoboFusion achieves state-of-the-art performance in noisy scenarios, as demonstrated by the KITTI-C and nuScenes-C benchmarks."],"url":"http://arxiv.org/abs/2401.03907v1"}
