{"created":"2024-02-08 18:59:53","title":"InstaGen: Enhancing Object Detection by Training on Synthetic Dataset","abstract":"In this paper, we introduce a novel paradigm to enhance the ability of object detector, e.g., expanding categories or improving detection performance, by training on synthetic dataset generated from diffusion models. Specifically, we integrate an instance-level grounding head into a pre-trained, generative diffusion model, to augment it with the ability of localising arbitrary instances in the generated images. The grounding head is trained to align the text embedding of category names with the regional visual feature of the diffusion model, using supervision from an off-the-shelf object detector, and a novel self-training scheme on (novel) categories not covered by the detector. This enhanced version of diffusion model, termed as InstaGen, can serve as a data synthesizer for object detection. We conduct thorough experiments to show that, object detector can be enhanced while training on the synthetic dataset from InstaGen, demonstrating superior performance over existing state-of-the-art methods in open-vocabulary (+4.5 AP) and data-sparse (+1.2 to 5.2 AP) scenarios.","sentences":["In this paper, we introduce a novel paradigm to enhance the ability of object detector, e.g., expanding categories or improving detection performance, by training on synthetic dataset generated from diffusion models.","Specifically, we integrate an instance-level grounding head into a pre-trained, generative diffusion model, to augment it with the ability of localising arbitrary instances in the generated images.","The grounding head is trained to align the text embedding of category names with the regional visual feature of the diffusion model, using supervision from an off-the-shelf object detector, and a novel self-training scheme on (novel) categories not covered by the detector.","This enhanced version of diffusion model, termed as InstaGen, can serve as a data synthesizer for object detection.","We conduct thorough experiments to show that, object detector can be enhanced while training on the synthetic dataset from InstaGen, demonstrating superior performance over existing state-of-the-art methods in open-vocabulary (+4.5 AP) and data-sparse (+1.2 to 5.2 AP) scenarios."],"url":"http://arxiv.org/abs/2402.05937v1"}
{"created":"2024-02-08 18:59:48","title":"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models","abstract":"We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM) series developed upon SPHINX. To improve the architecture and training efficiency, we modify the SPHINX framework by removing redundant visual encoders, bypassing fully-padded sub-images with skip tokens, and simplifying multi-stage training into a one-stage all-in-one paradigm. To fully unleash the potential of MLLMs, we assemble a comprehensive multi-domain and multimodal dataset covering publicly available resources in language, vision, and vision-language tasks. We further enrich this collection with our curated OCR intensive and Set-of-Mark datasets, extending the diversity and generality. By training over different base LLMs including TinyLlama1.1B, InternLM2-7B, LLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in parameter size and multilingual capabilities. Comprehensive benchmarking reveals a strong correlation between the multi-modal performance with the data and parameter scales. Code and models are released at https://github.com/Alpha-VLLM/LLaMA2-Accessory","sentences":["We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM) series developed upon SPHINX.","To improve the architecture and training efficiency, we modify the SPHINX framework by removing redundant visual encoders, bypassing fully-padded sub-images with skip tokens, and simplifying multi-stage training into a one-stage all-in-one paradigm.","To fully unleash the potential of MLLMs, we assemble a comprehensive multi-domain and multimodal dataset covering publicly available resources in language, vision, and vision-language tasks.","We further enrich this collection with our curated OCR intensive and Set-of-Mark datasets, extending the diversity and generality.","By training over different base LLMs including TinyLlama1.1B, InternLM2-7B, LLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in parameter size and multilingual capabilities.","Comprehensive benchmarking reveals a strong correlation between the multi-modal performance with the data and parameter scales.","Code and models are released at https://github.com/Alpha-VLLM/LLaMA2-Accessory"],"url":"http://arxiv.org/abs/2402.05935v1"}
{"created":"2024-02-08 18:59:30","title":"Classifying Nodes in Graphs without GNNs","abstract":"Graph neural networks (GNNs) are the dominant paradigm for classifying nodes in a graph, but they have several undesirable attributes stemming from their message passing architecture. Recently, distillation methods succeeded in eliminating the use of GNNs at test time but they still require them during training. We perform a careful analysis of the role that GNNs play in distillation methods. This analysis leads us to propose a fully GNN-free approach for node classification, not requiring them at train or test time. Our method consists of three key components: smoothness constraints, pseudo-labeling iterations and neighborhood-label histograms. Our final approach can match the state-of-the-art accuracy on standard popular benchmarks such as citation and co-purchase networks, without training a GNN.","sentences":["Graph neural networks (GNNs) are the dominant paradigm for classifying nodes in a graph, but they have several undesirable attributes stemming from their message passing architecture.","Recently, distillation methods succeeded in eliminating the use of GNNs at test time but they still require them during training.","We perform a careful analysis of the role that GNNs play in distillation methods.","This analysis leads us to propose a fully GNN-free approach for node classification, not requiring them at train or test time.","Our method consists of three key components: smoothness constraints, pseudo-labeling iterations and neighborhood-label histograms.","Our final approach can match the state-of-the-art accuracy on standard popular benchmarks such as citation and co-purchase networks, without training a GNN."],"url":"http://arxiv.org/abs/2402.05934v1"}
{"created":"2024-02-08 18:59:05","title":"Time Series Diffusion in the Frequency Domain","abstract":"Fourier analysis has been an instrumental tool in the development of signal processing. This leads us to wonder whether this framework could similarly benefit generative modelling. In this paper, we explore this question through the scope of time series diffusion models. More specifically, we analyze whether representing time series in the frequency domain is a useful inductive bias for score-based diffusion models. By starting from the canonical SDE formulation of diffusion in the time domain, we show that a dual diffusion process occurs in the frequency domain with an important nuance: Brownian motions are replaced by what we call mirrored Brownian motions, characterized by mirror symmetries among their components. Building on this insight, we show how to adapt the denoising score matching approach to implement diffusion models in the frequency domain. This results in frequency diffusion models, which we compare to canonical time diffusion models. Our empirical evaluation on real-world datasets, covering various domains like healthcare and finance, shows that frequency diffusion models better capture the training distribution than time diffusion models. We explain this observation by showing that time series from these datasets tend to be more localized in the frequency domain than in the time domain, which makes them easier to model in the former case. All our observations point towards impactful synergies between Fourier analysis and diffusion models.","sentences":["Fourier analysis has been an instrumental tool in the development of signal processing.","This leads us to wonder whether this framework could similarly benefit generative modelling.","In this paper, we explore this question through the scope of time series diffusion models.","More specifically, we analyze whether representing time series in the frequency domain is a useful inductive bias for score-based diffusion models.","By starting from the canonical SDE formulation of diffusion in the time domain, we show that a dual diffusion process occurs in the frequency domain with an important nuance: Brownian motions are replaced by what we call mirrored Brownian motions, characterized by mirror symmetries among their components.","Building on this insight, we show how to adapt the denoising score matching approach to implement diffusion models in the frequency domain.","This results in frequency diffusion models, which we compare to canonical time diffusion models.","Our empirical evaluation on real-world datasets, covering various domains like healthcare and finance, shows that frequency diffusion models better capture the training distribution than time diffusion models.","We explain this observation by showing that time series from these datasets tend to be more localized in the frequency domain than in the time domain, which makes them easier to model in the former case.","All our observations point towards impactful synergies between Fourier analysis and diffusion models."],"url":"http://arxiv.org/abs/2402.05933v1"}
{"created":"2024-02-08 18:59:03","title":"Driving Everywhere with Large Language Model Policy Adaptation","abstract":"Adapting driving behavior to new environments, customs, and laws is a long-standing problem in autonomous driving, precluding the widespread deployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a simple yet powerful tool that enables human drivers and autonomous vehicles alike to drive everywhere by adapting their tasks and motion plans to traffic rules in new locations. LLaDA achieves this by leveraging the impressive zero-shot generalizability of large language models (LLMs) in interpreting the traffic rules in the local driver handbook. Through an extensive user study, we show that LLaDA's instructions are useful in disambiguating in-the-wild unexpected situations. We also demonstrate LLaDA's ability to adapt AV motion planning policies in real-world datasets; LLaDA outperforms baseline planning approaches on all our metrics. Please check our website for more details: https://boyiliee.github.io/llada.","sentences":["Adapting driving behavior to new environments, customs, and laws is a long-standing problem in autonomous driving, precluding the widespread deployment of autonomous vehicles (AVs).","In this paper, we present LLaDA, a simple yet powerful tool that enables human drivers and autonomous vehicles alike to drive everywhere by adapting their tasks and motion plans to traffic rules in new locations.","LLaDA achieves this by leveraging the impressive zero-shot generalizability of large language models (LLMs) in interpreting the traffic rules in the local driver handbook.","Through an extensive user study, we show that LLaDA's instructions are useful in disambiguating in-the-wild unexpected situations.","We also demonstrate LLaDA's ability to adapt AV motion planning policies in real-world datasets; LLaDA outperforms baseline planning approaches on all our metrics.","Please check our website for more details: https://boyiliee.github.io/llada."],"url":"http://arxiv.org/abs/2402.05932v1"}
{"created":"2024-02-08 18:58:02","title":"An Interactive Agent Foundation Model","abstract":"The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications. We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks. Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework. We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare. Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area. The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effective multimodal and multi-task learning. Our approach provides a promising avenue for developing generalist, action-taking, multimodal systems.","sentences":["The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications.","We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks.","Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework.","We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare.","Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area.","The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effective multimodal and multi-task learning.","Our approach provides a promising avenue for developing generalist, action-taking, multimodal systems."],"url":"http://arxiv.org/abs/2402.05929v1"}
{"created":"2024-02-08 18:58:02","title":"WebLINX: Real-World Website Navigation with Multi-Turn Dialogue","abstract":"We propose the problem of conversational web navigation, where a digital agent controls a web browser and follows user instructions to solve real-world tasks in a multi-turn dialogue fashion. To support this problem, we introduce WEBLINX - a large-scale benchmark of 100K interactions across 2300 expert demonstrations of conversational web navigation. Our benchmark covers a broad range of patterns on over 150 real-world websites and can be used to train and evaluate agents in diverse scenarios. Due to the magnitude of information present, Large Language Models (LLMs) cannot process entire web pages in real-time. To solve this bottleneck, we design a retrieval-inspired model that efficiently prunes HTML pages by ranking relevant elements. We use the selected elements, along with screenshots and action history, to assess a variety of models for their ability to replicate human behavior when navigating the web. Our experiments span from small text-only to proprietary multimodal LLMs. We find that smaller finetuned decoders surpass the best zero-shot LLMs (including GPT-4V), but also larger finetuned multimodal models which were explicitly pretrained on screenshots. However, all finetuned models struggle to generalize to unseen websites. Our findings highlight the need for large multimodal models that can generalize to novel settings. Our code, data and models are available for research: https://mcgill-nlp.github.io/weblinx","sentences":["We propose the problem of conversational web navigation, where a digital agent controls a web browser and follows user instructions to solve real-world tasks in a multi-turn dialogue fashion.","To support this problem, we introduce WEBLINX - a large-scale benchmark of 100K interactions across 2300 expert demonstrations of conversational web navigation.","Our benchmark covers a broad range of patterns on over 150 real-world websites and can be used to train and evaluate agents in diverse scenarios.","Due to the magnitude of information present, Large Language Models (LLMs) cannot process entire web pages in real-time.","To solve this bottleneck, we design a retrieval-inspired model that efficiently prunes HTML pages by ranking relevant elements.","We use the selected elements, along with screenshots and action history, to assess a variety of models for their ability to replicate human behavior when navigating the web.","Our experiments span from small text-only to proprietary multimodal LLMs.","We find that smaller finetuned decoders surpass the best zero-shot LLMs (including GPT-4V), but also larger finetuned multimodal models which were explicitly pretrained on screenshots.","However, all finetuned models struggle to generalize to unseen websites.","Our findings highlight the need for large multimodal models that can generalize to novel settings.","Our code, data and models are available for research: https://mcgill-nlp.github.io/weblinx"],"url":"http://arxiv.org/abs/2402.05930v1"}
{"created":"2024-02-08 18:57:42","title":"Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss","abstract":"In this work, we study statistical learning with dependent ($\\beta$-mixing) data and square loss in a hypothesis class $\\mathscr{F}\\subset L_{\\Psi_p}$ where $\\Psi_p$ is the norm $\\|f\\|_{\\Psi_p} \\triangleq \\sup_{m\\geq 1} m^{-1/p} \\|f\\|_{L^m} $ for some $p\\in [2,\\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \\emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\\Psi_p$ are comparable on our hypothesis class $\\mathscr{F}$ -- that is, $\\mathscr{F}$ is a weakly sub-Gaussian class: $\\|f\\|_{\\Psi_p} \\lesssim \\|f\\|_{L^2}^\\eta$ for some $\\eta\\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether the problem is realizable or not and we refer to this as a \\emph{near mixing-free rate}, since direct dependence on mixing is relegated to an additive higher order term. We arrive at our result by combining the above notion of a weakly sub-Gaussian class with mixed tail generic chaining. This combination allows us to compute sharp, instance-optimal rates for a wide range of problems. %Our approach, reliant on mixed tail generic chaining, allows us to obtain sharp, instance-optimal rates. Examples that satisfy our framework include sub-Gaussian linear regression, more general smoothly parameterized function classes, finite hypothesis classes, and bounded smoothness classes.","sentences":["In this work, we study statistical learning with dependent ($\\beta$-mixing) data and square loss in a hypothesis class $\\mathscr{F}\\subset L_{\\Psi_p}$ where $\\Psi_p$ is the norm $\\|f\\|_{\\Psi_p} \\triangleq \\sup_{m\\geq 1} m^{-1/p} \\|f\\|_{L^m} $ for some $p\\in [2,\\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data.","Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \\emph{multiplicatively} by the mixing time of the underlying covariates process.","We show that whenever the topologies of $L^2$ and $\\Psi_p$ are comparable on our hypothesis class $\\mathscr{F}$ -- that is, $\\mathscr{F}$ is a weakly sub-Gaussian class: $\\|f\\|_{\\Psi_p} \\lesssim \\|f\\|_{L^2}^\\eta$ for some $\\eta\\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term.","Our result holds whether the problem is realizable or not and we refer to this as a \\emph{near mixing-free rate}, since direct dependence on mixing is relegated to an additive higher order term.","We arrive at our result by combining the above notion of a weakly sub-Gaussian class with mixed tail generic chaining.","This combination allows us to compute sharp, instance-optimal rates for a wide range of problems.","%Our approach, reliant on mixed tail generic chaining, allows us to obtain sharp, instance-optimal rates.","Examples that satisfy our framework include sub-Gaussian linear regression, more general smoothly parameterized function classes, finite hypothesis classes, and bounded smoothness classes."],"url":"http://arxiv.org/abs/2402.05928v1"}
{"created":"2024-02-08 18:56:40","title":"On the Convergence of Zeroth-Order Federated Tuning in Large Language Models","abstract":"The confluence of Federated Learning (FL) and Large Language Models (LLMs) is ushering in a new era in privacy-preserving natural language processing. However, the intensive memory requirements for fine-tuning LLMs pose significant challenges, especially when deploying on edge devices with limited computational resources. To circumvent this, we explore the novel integration of Memory-efficient Zeroth-Order Optimization within a federated setting, a synergy we denote as FedMeZO. Our study is the first to examine the theoretical underpinnings of FedMeZO in the context of LLMs, tackling key questions regarding the influence of large parameter spaces on optimization behavior, the establishment of convergence properties, and the identification of critical parameters for convergence to inform personalized federated strategies. Our extensive empirical evidence supports the theory, showing that FedMeZO not only converges faster than traditional first-order methods such as SGD but also significantly reduces GPU memory usage during training to levels comparable to those during inference. Moreover, the proposed personalized FL strategy that is built upon the theoretical insights to customize the client-wise learning rate can effectively accelerate loss reduction. We hope our work can help to bridge theoretical and practical aspects of federated fine-tuning for LLMs and facilitate further development and research.","sentences":["The confluence of Federated Learning (FL) and Large Language Models (LLMs) is ushering in a new era in privacy-preserving natural language processing.","However, the intensive memory requirements for fine-tuning LLMs pose significant challenges, especially when deploying on edge devices with limited computational resources.","To circumvent this, we explore the novel integration of Memory-efficient Zeroth-Order Optimization within a federated setting, a synergy we denote as FedMeZO.","Our study is the first to examine the theoretical underpinnings of FedMeZO in the context of LLMs, tackling key questions regarding the influence of large parameter spaces on optimization behavior, the establishment of convergence properties, and the identification of critical parameters for convergence to inform personalized federated strategies.","Our extensive empirical evidence supports the theory, showing that FedMeZO not only converges faster than traditional first-order methods such as SGD but also significantly reduces GPU memory usage during training to levels comparable to those during inference.","Moreover, the proposed personalized FL strategy that is built upon the theoretical insights to customize the client-wise learning rate can effectively accelerate loss reduction.","We hope our work can help to bridge theoretical and practical aspects of federated fine-tuning for LLMs and facilitate further development and research."],"url":"http://arxiv.org/abs/2402.05926v1"}
{"created":"2024-02-08 18:53:21","title":"Collaborative Control for Geometry-Conditioned PBR Image Generation","abstract":"Current 3D content generation builds on generative models that output RGB images. Modern graphics pipelines, however, require physically-based rendering (PBR) material properties. We propose to model the PBR image distribution directly to avoid photometric inaccuracies in RGB generation and the inherent ambiguity in extracting PBR from RGB. Existing paradigms for cross-modal finetuning are not suited for PBR generation due to a lack of data and the high dimensionality of the output modalities: we overcome both challenges by retaining a frozen RGB model and tightly linking a newly trained PBR model using a novel cross-network communication paradigm. As the base RGB model is fully frozen, the proposed method does not risk catastrophic forgetting during finetuning and remains compatible with techniques such as IPAdapter pretrained for the base RGB model. We validate our design choices, robustness to data sparsity, and compare against existing paradigms with an extensive experimental section.","sentences":["Current 3D content generation builds on generative models that output RGB images.","Modern graphics pipelines, however, require physically-based rendering (PBR) material properties.","We propose to model the PBR image distribution directly to avoid photometric inaccuracies in RGB generation and the inherent ambiguity in extracting PBR from RGB.","Existing paradigms for cross-modal finetuning are not suited for PBR generation due to a lack of data and the high dimensionality of the output modalities: we overcome both challenges by retaining a frozen RGB model and tightly linking a newly trained PBR model using a novel cross-network communication paradigm.","As the base RGB model is fully frozen, the proposed method does not risk catastrophic forgetting during finetuning and remains compatible with techniques such as IPAdapter pretrained for the base RGB model.","We validate our design choices, robustness to data sparsity, and compare against existing paradigms with an extensive experimental section."],"url":"http://arxiv.org/abs/2402.05919v1"}
{"created":"2024-02-08 18:52:23","title":"Point-VOS: Pointing Up Video Object Segmentation","abstract":"Current state-of-the-art Video Object Segmentation (VOS) methods rely on dense per-object mask annotations both during training and testing. This requires time-consuming and costly video annotation mechanisms. We propose a novel Point-VOS task with a spatio-temporally sparse point-wise annotation scheme that substantially reduces the annotation effort. We apply our annotation scheme to two large-scale video datasets with text descriptions and annotate over 19M points across 133K objects in 32K videos. Based on our annotations, we propose a new Point-VOS benchmark, and a corresponding point-based training mechanism, which we use to establish strong baseline results. We show that existing VOS methods can easily be adapted to leverage our point annotations during training, and can achieve results close to the fully-supervised performance when trained on pseudo-masks generated from these points. In addition, we show that our data can be used to improve models that connect vision and language, by evaluating it on the Video Narrative Grounding (VNG) task. We will make our code and annotations available at https://pointvos.github.io.","sentences":["Current state-of-the-art Video Object Segmentation (VOS) methods rely on dense per-object mask annotations both during training and testing.","This requires time-consuming and costly video annotation mechanisms.","We propose a novel Point-VOS task with a spatio-temporally sparse point-wise annotation scheme that substantially reduces the annotation effort.","We apply our annotation scheme to two large-scale video datasets with text descriptions and annotate over 19M points across 133K objects in 32K videos.","Based on our annotations, we propose a new Point-VOS benchmark, and a corresponding point-based training mechanism, which we use to establish strong baseline results.","We show that existing VOS methods can easily be adapted to leverage our point annotations during training, and can achieve results close to the fully-supervised performance when trained on pseudo-masks generated from these points.","In addition, we show that our data can be used to improve models that connect vision and language, by evaluating it on the Video Narrative Grounding (VNG) task.","We will make our code and annotations available at https://pointvos.github.io."],"url":"http://arxiv.org/abs/2402.05917v1"}
{"created":"2024-02-08 18:51:55","title":"GenEFT: Understanding Statics and Dynamics of Model Generalization via Effective Theory","abstract":"We present GenEFT: an effective theory framework for shedding light on the statics and dynamics of neural network generalization, and illustrate it with graph learning examples. We first investigate the generalization phase transition as data size increases, comparing experimental results with information-theory-based approximations. We find generalization in a Goldilocks zone where the decoder is neither too weak nor too powerful. We then introduce an effective theory for the dynamics of representation learning, where latent-space representations are modeled as interacting particles (repons), and find that it explains our experimentally observed phase transition between generalization and overfitting as encoder and decoder learning rates are scanned. This highlights the power of physics-inspired effective theories for bridging the gap between theoretical predictions and practice in machine learning.","sentences":["We present GenEFT: an effective theory framework for shedding light on the statics and dynamics of neural network generalization, and illustrate it with graph learning examples.","We first investigate the generalization phase transition as data size increases, comparing experimental results with information-theory-based approximations.","We find generalization in a Goldilocks zone where the decoder is neither too weak nor too powerful.","We then introduce an effective theory for the dynamics of representation learning, where latent-space representations are modeled as interacting particles (repons), and find that it explains our experimentally observed phase transition between generalization and overfitting as encoder and decoder learning rates are scanned.","This highlights the power of physics-inspired effective theories for bridging the gap between theoretical predictions and practice in machine learning."],"url":"http://arxiv.org/abs/2402.05916v1"}
{"created":"2024-02-08 18:49:09","title":"Efficient Stagewise Pretraining via Progressive Subnetworks","abstract":"Recent developments in large language models have sparked interest in efficient pretraining methods. A recent effective paradigm is to perform stage-wise training, where the size of the model is gradually increased over the course of training (e.g. gradual stacking (Reddi et al., 2023)). While the resource and wall-time savings are appealing, it has limitations, particularly the inability to evaluate the full model during earlier stages, and degradation in model quality due to smaller model capacity in the initial stages. In this work, we propose an alternative framework, progressive subnetwork training, that maintains the full model throughout training, but only trains subnetworks within the model in each step. We focus on a simple instantiation of this framework, Random Path Training (RaPTr) that only trains a sub-path of layers in each step, progressively increasing the path lengths in stages. RaPTr achieves better pre-training loss for BERT and UL2 language models while requiring 20-33% fewer FLOPs compared to standard training, and is competitive or better than other efficient training methods. Furthermore, RaPTr shows better downstream performance on UL2, improving QA tasks and SuperGLUE by 1-5% compared to standard training and stacking. Finally, we provide a theoretical basis for RaPTr to justify (a) the increasing complexity of subnetworks in stages, and (b) the stability in loss across stage transitions due to residual connections and layer norm.","sentences":["Recent developments in large language models have sparked interest in efficient pretraining methods.","A recent effective paradigm is to perform stage-wise training, where the size of the model is gradually increased over the course of training (e.g. gradual stacking (Reddi et al., 2023)).","While the resource and wall-time savings are appealing, it has limitations, particularly the inability to evaluate the full model during earlier stages, and degradation in model quality due to smaller model capacity in the initial stages.","In this work, we propose an alternative framework, progressive subnetwork training, that maintains the full model throughout training, but only trains subnetworks within the model in each step.","We focus on a simple instantiation of this framework, Random Path Training (RaPTr) that only trains a sub-path of layers in each step, progressively increasing the path lengths in stages.","RaPTr","achieves better pre-training loss for BERT and UL2 language models while requiring 20-33% fewer FLOPs compared to standard training, and is competitive or better than other efficient training methods.","Furthermore, RaPTr shows better downstream performance on UL2, improving QA tasks and SuperGLUE by 1-5% compared to standard training and stacking.","Finally, we provide a theoretical basis for RaPTr to justify (a) the increasing complexity of subnetworks in stages, and (b) the stability in loss across stage transitions due to residual connections and layer norm."],"url":"http://arxiv.org/abs/2402.05913v1"}
{"created":"2024-02-08 18:43:27","title":"Risk-Sensitive Multi-Agent Reinforcement Learning in Network Aggregative Markov Games","abstract":"Classical multi-agent reinforcement learning (MARL) assumes risk neutrality and complete objectivity for agents. However, in settings where agents need to consider or model human economic or social preferences, a notion of risk must be incorporated into the RL optimization problem. This will be of greater importance in MARL where other human or non-human agents are involved, possibly with their own risk-sensitive policies. In this work, we consider risk-sensitive and non-cooperative MARL with cumulative prospect theory (CPT), a non-convex risk measure and a generalization of coherent measures of risk. CPT is capable of explaining loss aversion in humans and their tendency to overestimate/underestimate small/large probabilities. We propose a distributed sampling-based actor-critic (AC) algorithm with CPT risk for network aggregative Markov games (NAMGs), which we call Distributed Nested CPT-AC. Under a set of assumptions, we prove the convergence of the algorithm to a subjective notion of Markov perfect Nash equilibrium in NAMGs. The experimental results show that subjective CPT policies obtained by our algorithm can be different from the risk-neutral ones, and agents with a higher loss aversion are more inclined to socially isolate themselves in an NAMG.","sentences":["Classical multi-agent reinforcement learning (MARL) assumes risk neutrality and complete objectivity for agents.","However, in settings where agents need to consider or model human economic or social preferences, a notion of risk must be incorporated into the RL optimization problem.","This will be of greater importance in MARL where other human or non-human agents are involved, possibly with their own risk-sensitive policies.","In this work, we consider risk-sensitive and non-cooperative MARL with cumulative prospect theory (CPT), a non-convex risk measure and a generalization of coherent measures of risk.","CPT is capable of explaining loss aversion in humans and their tendency to overestimate/underestimate small/large probabilities.","We propose a distributed sampling-based actor-critic (AC) algorithm with CPT risk for network aggregative Markov games (NAMGs), which we call Distributed Nested CPT-AC.","Under a set of assumptions, we prove the convergence of the algorithm to a subjective notion of Markov perfect Nash equilibrium in NAMGs.","The experimental results show that subjective CPT policies obtained by our algorithm can be different from the risk-neutral ones, and agents with a higher loss aversion are more inclined to socially isolate themselves in an NAMG."],"url":"http://arxiv.org/abs/2402.05906v1"}
{"created":"2024-02-08 18:43:05","title":"FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs","abstract":"Our society is facing rampant misinformation harming public health and trust. To address the societal challenge, we introduce FACT-GPT, a system leveraging Large Language Models (LLMs) to automate the claim matching stage of fact-checking. FACT-GPT, trained on a synthetic dataset, identifies social media content that aligns with, contradicts, or is irrelevant to previously debunked claims. Our evaluation shows that our specialized LLMs can match the accuracy of larger models in identifying related claims, closely mirroring human judgment. This research provides an automated solution for efficient claim matching, demonstrates the potential of LLMs in supporting fact-checkers, and offers valuable resources for further research in the field.","sentences":["Our society is facing rampant misinformation harming public health and trust.","To address the societal challenge, we introduce FACT-GPT, a system leveraging Large Language Models (LLMs) to automate the claim matching stage of fact-checking.","FACT-GPT, trained on a synthetic dataset, identifies social media content that aligns with, contradicts, or is irrelevant to previously debunked claims.","Our evaluation shows that our specialized LLMs can match the accuracy of larger models in identifying related claims, closely mirroring human judgment.","This research provides an automated solution for efficient claim matching, demonstrates the potential of LLMs in supporting fact-checkers, and offers valuable resources for further research in the field."],"url":"http://arxiv.org/abs/2402.05904v1"}
{"created":"2024-02-08 18:41:41","title":"ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation","abstract":"The newly released Segment Anything Model (SAM) is a popular tool used in image processing due to its superior segmentation accuracy, variety of input prompts, training capabilities, and efficient model design. However, its current model is trained on a diverse dataset not tailored to medical images, particularly ultrasound images. Ultrasound images tend to have a lot of noise, making it difficult to segment out important structures. In this project, we developed ClickSAM, which fine-tunes the Segment Anything Model using click prompts for ultrasound images. ClickSAM has two stages of training: the first stage is trained on single-click prompts centered in the ground-truth contours, and the second stage focuses on improving the model performance through additional positive and negative click prompts. By comparing the first stage predictions to the ground-truth masks, true positive, false positive, and false negative segments are calculated. Positive clicks are generated using the true positive and false negative segments, and negative clicks are generated using the false positive segments. The Centroidal Voronoi Tessellation algorithm is then employed to collect positive and negative click prompts in each segment that are used to enhance the model performance during the second stage of training. With click-train methods, ClickSAM exhibits superior performance compared to other existing models for ultrasound image segmentation.","sentences":["The newly released Segment Anything Model (SAM) is a popular tool used in image processing due to its superior segmentation accuracy, variety of input prompts, training capabilities, and efficient model design.","However, its current model is trained on a diverse dataset not tailored to medical images, particularly ultrasound images.","Ultrasound images tend to have a lot of noise, making it difficult to segment out important structures.","In this project, we developed ClickSAM, which fine-tunes the Segment Anything Model using click prompts for ultrasound images.","ClickSAM has two stages of training: the first stage is trained on single-click prompts centered in the ground-truth contours, and the second stage focuses on improving the model performance through additional positive and negative click prompts.","By comparing the first stage predictions to the ground-truth masks, true positive, false positive, and false negative segments are calculated.","Positive clicks are generated using the true positive and false negative segments, and negative clicks are generated using the false positive segments.","The Centroidal Voronoi Tessellation algorithm is then employed to collect positive and negative click prompts in each segment that are used to enhance the model performance during the second stage of training.","With click-train methods, ClickSAM exhibits superior performance compared to other existing models for ultrasound image segmentation."],"url":"http://arxiv.org/abs/2402.05902v1"}
{"created":"2024-02-08 18:35:38","title":"Combining Voting and Abstract Argumentation to Understand Online Discussions","abstract":"Online discussion platforms are a vital part of the public discourse in a deliberative democracy. However, how to interpret the outcomes of the discussions on these platforms is often unclear. In this paper, we propose a novel and explainable method for selecting a set of most representative, consistent points of view by combining methods from computational social choice and abstract argumentation. Specifically, we model online discussions as abstract argumentation frameworks combined with information regarding which arguments voters approve of. Based on ideas from approval-based multiwinner voting, we introduce several voting rules for selecting a set of preferred extensions that represents voters' points of view. We compare the proposed methods across several dimensions, theoretically and in numerical simulations, and give clear suggestions on which methods to use depending on the specific situation.","sentences":["Online discussion platforms are a vital part of the public discourse in a deliberative democracy.","However, how to interpret the outcomes of the discussions on these platforms is often unclear.","In this paper, we propose a novel and explainable method for selecting a set of most representative, consistent points of view by combining methods from computational social choice and abstract argumentation.","Specifically, we model online discussions as abstract argumentation frameworks combined with information regarding which arguments voters approve of.","Based on ideas from approval-based multiwinner voting, we introduce several voting rules for selecting a set of preferred extensions that represents voters' points of view.","We compare the proposed methods across several dimensions, theoretically and in numerical simulations, and give clear suggestions on which methods to use depending on the specific situation."],"url":"http://arxiv.org/abs/2402.05895v1"}
{"created":"2024-02-08 18:33:21","title":"Large Language Model Meets Graph Neural Network in Knowledge Distillation","abstract":"Despite recent community revelations about the advancements and potential of Large Language Models (LLMs) in understanding Text-Attributed Graphs (TAG), the deployment of LLMs for production is hindered by their high computational and storage requirements, as well as long latencies during inference. Simultaneously, although traditional Graph Neural Networks (GNNs) are light weight and adept at learning structural features of graphs, their ability to grasp the complex semantics in TAGs is somewhat constrained for real applications. To address these limitations, we concentrate on the downstream task of node classification in TAG and propose a novel graph knowledge distillation framework, termed Linguistic Graph Knowledge Distillation (LinguGKD), using LLMs as teacher models and GNNs as student models for knowledge distillation. It involves TAG-oriented instruction tuning of LLM on designed node classification prompts, followed by aligning the hierarchically learned node features of the teacher LLM and the student GNN in latent space, employing a layer-adaptive contrastive learning strategy. Through extensive experiments on a variety of LLM and GNN models and multiple benchmark datasets, the proposed LinguGKD significantly boosts the student GNN's predictive accuracy and convergence rate, without the need of extra data or model parameters. Compared to teacher LLM, distilled GNN achieves superior inference speed equipped with much fewer computing and storage demands, when surpassing the teacher LLM's classification performance on some of benchmark datasets.","sentences":["Despite recent community revelations about the advancements and potential of Large Language Models (LLMs) in understanding Text-Attributed Graphs (TAG), the deployment of LLMs for production is hindered by their high computational and storage requirements, as well as long latencies during inference.","Simultaneously, although traditional Graph Neural Networks (GNNs) are light weight and adept at learning structural features of graphs, their ability to grasp the complex semantics in TAGs is somewhat constrained for real applications.","To address these limitations, we concentrate on the downstream task of node classification in TAG and propose a novel graph knowledge distillation framework, termed Linguistic Graph Knowledge Distillation (LinguGKD), using LLMs as teacher models and GNNs as student models for knowledge distillation.","It involves TAG-oriented instruction tuning of LLM on designed node classification prompts, followed by aligning the hierarchically learned node features of the teacher LLM and the student GNN in latent space, employing a layer-adaptive contrastive learning strategy.","Through extensive experiments on a variety of LLM and GNN models and multiple benchmark datasets, the proposed LinguGKD significantly boosts the student GNN's predictive accuracy and convergence rate, without the need of extra data or model parameters.","Compared to teacher LLM, distilled GNN achieves superior inference speed equipped with much fewer computing and storage demands, when surpassing the teacher LLM's classification performance on some of benchmark datasets."],"url":"http://arxiv.org/abs/2402.05894v1"}
{"created":"2024-02-08 18:32:10","title":"Personalizing Driver Safety Interfaces via Driver Cognitive Factors Inference","abstract":"Recent advances in AI and intelligent vehicle technology hold promise to revolutionize mobility and transportation, in the form of advanced driving assistance (ADAS) interfaces. Although it is widely recognized that certain cognitive factors, such as impulsivity and inhibitory control, are related to risky driving behavior, play a significant role in on-road risk-taking, existing systems fail to leverage such factors. Varying levels of these cognitive factors could influence the effectiveness and acceptance of driver safety interfaces.   We demonstrate an approach for personalizing driver interaction via driver safety interfaces that are triggered based on a learned recurrent neural network. The network is trained from a population of human drivers to infer impulsivity and inhibitory control from recent driving behavior. Using a high-fidelity vehicle motion simulator, we demonstrate the ability to deduce these factors from driver behavior. We then use these inferred factors to make instantaneous determinations on whether or not to engage a driver safety interface. This interface aims to decrease a driver's speed during yellow lights and reduce their inclination to run through them.","sentences":["Recent advances in AI and intelligent vehicle technology hold promise to revolutionize mobility and transportation, in the form of advanced driving assistance (ADAS) interfaces.","Although it is widely recognized that certain cognitive factors, such as impulsivity and inhibitory control, are related to risky driving behavior, play a significant role in on-road risk-taking, existing systems fail to leverage such factors.","Varying levels of these cognitive factors could influence the effectiveness and acceptance of driver safety interfaces.   ","We demonstrate an approach for personalizing driver interaction via driver safety interfaces that are triggered based on a learned recurrent neural network.","The network is trained from a population of human drivers to infer impulsivity and inhibitory control from recent driving behavior.","Using a high-fidelity vehicle motion simulator, we demonstrate the ability to deduce these factors from driver behavior.","We then use these inferred factors to make instantaneous determinations on whether or not to engage a driver safety interface.","This interface aims to decrease a driver's speed during yellow lights and reduce their inclination to run through them."],"url":"http://arxiv.org/abs/2402.05893v1"}
{"created":"2024-02-08 18:30:50","title":"Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data","abstract":"In recent years, Transformers have become the de-facto architecture for sequence modeling on text and a variety of multi-dimensional data, such as images and video. However, the use of self-attention layers in a Transformer incurs prohibitive compute and memory complexity that scales quadratically w.r.t. the sequence length. A recent architecture, Mamba, based on state space models has been shown to achieve comparable performance for modeling text sequences, while scaling linearly with the sequence length. In this work, we present Mamba-ND, a generalized design extending the Mamba architecture to arbitrary multi-dimensional data. Our design alternatively unravels the input data across different dimensions following row-major orderings. We provide a systematic comparison of Mamba-ND with several other alternatives, based on prior multi-dimensional extensions such as Bi-directional LSTMs and S4ND. Empirically, we show that Mamba-ND demonstrates performance competitive with the state-of-the-art on a variety of multi-dimensional benchmarks, including ImageNet-1K classification, HMDB-51 action recognition, and ERA5 weather forecasting.","sentences":["In recent years, Transformers have become the de-facto architecture for sequence modeling on text and a variety of multi-dimensional data, such as images and video.","However, the use of self-attention layers in a Transformer incurs prohibitive compute and memory complexity that scales quadratically w.r.t.","the sequence length.","A recent architecture, Mamba, based on state space models has been shown to achieve comparable performance for modeling text sequences, while scaling linearly with the sequence length.","In this work, we present Mamba-ND, a generalized design extending the Mamba architecture to arbitrary multi-dimensional data.","Our design alternatively unravels the input data across different dimensions following row-major orderings.","We provide a systematic comparison of Mamba-ND with several other alternatives, based on prior multi-dimensional extensions such as Bi-directional LSTMs and S4ND.","Empirically, we show that Mamba-ND demonstrates performance competitive with the state-of-the-art on a variety of multi-dimensional benchmarks, including ImageNet-1K classification, HMDB-51 action recognition, and ERA5 weather forecasting."],"url":"http://arxiv.org/abs/2402.05892v1"}
{"created":"2024-02-08 18:30:44","title":"On benefits of cooperation under strategic power","abstract":"We introduce a new model involving TU-games and exogenous structures. Specifically, we consider that each player in a population can choose an element in a strategy set and that, for every possible strategy profile, a TU-game is associated with the population. This is what we call a TU-game with strategies. We propose and characterize the maxmin procedure to map every game with strategies to a TU-game. We also study whether or not the relevant properties of TU-games are transmitted by applying the maxmin procedure. Finally, we examine two relevant classes of TU-games with strategies: airport and simple games with strategies.","sentences":["We introduce a new model involving TU-games and exogenous structures.","Specifically, we consider that each player in a population can choose an element in a strategy set and that, for every possible strategy profile, a TU-game is associated with the population.","This is what we call a TU-game with strategies.","We propose and characterize the maxmin procedure to map every game with strategies to a TU-game.","We also study whether or not the relevant properties of TU-games are transmitted by applying the maxmin procedure.","Finally, we examine two relevant classes of TU-games with strategies: airport and simple games with strategies."],"url":"http://arxiv.org/abs/2402.05891v1"}
{"created":"2024-02-08 18:27:22","title":"CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion","abstract":"Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters. This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning. We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models. Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality. It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation. Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additional modalities. We validate our method on video-3D, video-audio, and video-language reasoning tasks and achieve better/equivalent performance against strong multimodal LLMs, including BLIP-2, 3D-LLM, and SeViLA while using 96% fewer trainable parameters. We provide extensive analyses of CREMA, including the impact of each modality on reasoning domains, the design of the fusion module, and example visualizations.","sentences":["Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters.","This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning.","We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models.","Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality.","It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation.","Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additional modalities.","We validate our method on video-3D, video-audio, and video-language reasoning tasks and achieve better/equivalent performance against strong multimodal LLMs, including BLIP-2, 3D-LLM, and SeViLA while using 96% fewer trainable parameters.","We provide extensive analyses of CREMA, including the impact of each modality on reasoning domains, the design of the fusion module, and example visualizations."],"url":"http://arxiv.org/abs/2402.05889v1"}
{"created":"2024-02-08 18:23:05","title":"EUGENE: Explainable Unsupervised Approximation of Graph Edit Distance","abstract":"The need to identify graphs having small structural distance from a query arises in biology, chemistry, recommender systems, and social network analysis. Among several methods to measure inter graph distance, Graph Edit Distance (GED) is preferred for its comprehensibility, yet hindered by the NP-hardness of its computation. State-of-the-art GED approximations predominantly employ neural methods, which, however, (i) lack an explanatory edit path corresponding to the approximated GED; (ii) require the NP-hard generation of ground-truth GEDs for training; and (iii) necessitate separate training on each dataset. In this paper, we propose an efficient algebraic unsuper vised method, EUGENE, that approximates GED and yields edit paths corresponding to the approx imated cost, while eliminating the need for ground truth generation and data-specific training. Extensive experimental evaluation demonstrates that the aforementioned benefits of EUGENE do not come at the cost of efficacy. Specifically, EUGENE consistently ranks among the most accurate methods across all of the benchmark datasets and outperforms majority of the neural approaches.","sentences":["The need to identify graphs having small structural distance from a query arises in biology, chemistry, recommender systems, and social network analysis.","Among several methods to measure inter graph distance, Graph Edit Distance (GED) is preferred for its comprehensibility, yet hindered by the NP-hardness of its computation.","State-of-the-art GED approximations predominantly employ neural methods, which, however, (i) lack an explanatory edit path corresponding to the approximated GED; (ii) require the NP-hard generation of ground-truth GEDs for training; and (iii) necessitate separate training on each dataset.","In this paper, we propose an efficient algebraic unsuper vised method, EUGENE, that approximates GED and yields edit paths corresponding to the approx imated cost, while eliminating the need for ground truth generation and data-specific training.","Extensive experimental evaluation demonstrates that the aforementioned benefits of EUGENE do not come at the cost of efficacy.","Specifically, EUGENE consistently ranks among the most accurate methods across all of the benchmark datasets and outperforms majority of the neural approaches."],"url":"http://arxiv.org/abs/2402.05885v1"}
{"created":"2024-02-08 18:18:29","title":"Cutsets and EF1 Fair Division of Graphs","abstract":"In fair division of a connected graph $G = (V, E)$, each of $n$ agents receives a share of $G$'s vertex set $V$. These shares partition $V$, with each share required to induce a connected subgraph. Agents use their own valuation functions to determine the non-negative numerical values of the shares, which determine whether the allocation is fair in some specified sense. We introduce forbidden substructures called graph cutsets, which block divisions that are fair in the EF1 (envy-free up to one item) sense by cutting the graph into \"too many pieces\". Two parameters - gap and valence - determine blocked values of $n$. If $G$ guarantees connected EF1 allocations for $n$ agents with valuations that are CA (common and additive), then $G$ contains no elementary cutset of gap $k \\ge 2$ and valence in the interval $\\[n - k + 1, n - 1\\]$. If $G$ guarantees connected EF1 allocations for $n$ agents with valuations in the broader CM (common and monotone) class, then $G$ contains no cutset of gap $k \\ge 2$ and valence in the interval $\\[n - k + 1, n - 1\\]$. These results rule out the existence of connected EF1 allocations in a variety of situations. For some graphs $G$ we can, with help from some new positive results, pin down $G$'s spectrum - the list of exactly which values of $n$ do/do not guarantee connected EF1 allocations. Examples suggest a conjectured common spectral pattern for all graphs. Further, we show that it is NP-hard to determine whether a graph admits a cutset. We also provide an example of a (non-traceable) graph on eight vertices that has no cutsets of gap $\\ge 2$ at all, yet fails to guarantee connected EF1 allocations for three agents with CA preferences.","sentences":["In fair division of a connected graph $G = (V, E)$, each of $n$ agents receives a share of $G$'s vertex set $V$. These shares partition $V$, with each share required to induce a connected subgraph.","Agents use their own valuation functions to determine the non-negative numerical values of the shares, which determine whether the allocation is fair in some specified sense.","We introduce forbidden substructures called graph cutsets, which block divisions that are fair in the EF1 (envy-free up to one item) sense by cutting the graph into \"too many pieces\".","Two parameters - gap and valence - determine blocked values of $n$. If $G$ guarantees connected EF1 allocations for $n$ agents with valuations that are CA (common and additive), then $G$ contains no elementary cutset of gap $k \\ge 2$ and valence in the interval $\\[n - k + 1, n - 1\\]$. If $G$ guarantees connected EF1 allocations for $n$ agents with valuations in the broader CM (common and monotone) class, then $G$ contains no cutset of gap $k \\ge 2$ and valence in the interval $\\[n - k + 1, n - 1\\]$.","These results rule out the existence of connected EF1 allocations in a variety of situations.","For some graphs $G$ we can, with help from some new positive results, pin down $G$'s spectrum - the list of exactly which values of $n$ do/do not guarantee connected EF1 allocations.","Examples suggest a conjectured common spectral pattern for all graphs.","Further, we show that it is NP-hard to determine whether a graph admits a cutset.","We also provide an example of a (non-traceable) graph on eight vertices that has no cutsets of gap $\\ge 2$ at all, yet fails to guarantee connected EF1 allocations for three agents with CA preferences."],"url":"http://arxiv.org/abs/2402.05884v1"}
{"created":"2024-02-08 18:16:47","title":"GET-Tok: A GenAI-Enriched Multimodal TikTok Dataset Documenting the 2022 Attempted Coup in Peru","abstract":"TikTok is one of the largest and fastest-growing social media sites in the world. TikTok features, however, such as voice transcripts, are often missing and other important features, such as OCR or video descriptions, do not exist. We introduce the Generative AI Enriched TikTok (GET-Tok) data, a pipeline for collecting TikTok videos and enriched data by augmenting the TikTok Research API with generative AI models. As a case study, we collect videos about the attempted coup in Peru initiated by its former President, Pedro Castillo, and its accompanying protests. The data includes information on 43,697 videos published from November 20, 2022 to March 1, 2023 (102 days). Generative AI augments the collected data via transcripts of TikTok videos, text descriptions of what is shown in the videos, what text is displayed within the video, and the stances expressed in the video. Overall, this pipeline will contribute to a better understanding of online discussion in a multimodal setting with applications of Generative AI, especially outlining the utility of this pipeline in non-English-language social media. Our code used to produce the pipeline is in a public Github repository: https://github.com/gabbypinto/GET-Tok-Peru.","sentences":["TikTok is one of the largest and fastest-growing social media sites in the world.","TikTok features, however, such as voice transcripts, are often missing and other important features, such as OCR or video descriptions, do not exist.","We introduce the Generative AI Enriched TikTok (GET-Tok) data, a pipeline for collecting TikTok videos and enriched data by augmenting the TikTok Research API with generative AI models.","As a case study, we collect videos about the attempted coup in Peru initiated by its former President, Pedro Castillo, and its accompanying protests.","The data includes information on 43,697 videos published from November 20, 2022 to March 1, 2023 (102 days).","Generative AI augments the collected data via transcripts of TikTok videos, text descriptions of what is shown in the videos, what text is displayed within the video, and the stances expressed in the video.","Overall, this pipeline will contribute to a better understanding of online discussion in a multimodal setting with applications of Generative AI, especially outlining the utility of this pipeline in non-English-language social media.","Our code used to produce the pipeline is in a public Github repository: https://github.com/gabbypinto/GET-Tok-Peru."],"url":"http://arxiv.org/abs/2402.05882v1"}
{"created":"2024-02-08 18:15:41","title":"Localized and Distributed Beyond Diagonal Reconfigurable Intelligent Surfaces with Lossy Interconnections: Modeling and Optimization","abstract":"Reconfigurable intelligent surface (RIS) is a key technology to control the communication environment in future wireless networks. Recently, beyond diagonal RIS (BD-RIS) emerged as a generalization of RIS achieving larger coverage through additional tunable impedance components interconnecting the RIS elements. However, conventional RIS and BD-RIS can effectively serve only users in their proximity, resulting in limited coverage. To overcome this limitation, in this paper, we investigate distributed RIS, whose elements are distributed over a wide region, in opposition to localized RIS commonly considered in the literature. The scaling laws of distributed BD-RIS reveal that it offers significant gains over distributed conventional RIS and localized BD-RIS, enabled by its interconnections allowing signal propagation within the BD-RIS. To assess the practical performance of distributed BD-RIS, we model and optimize BD-RIS with lossy interconnections through transmission line theory. Our model accounts for phase changes and losses over the BD-RIS interconnections arising when the interconnection lengths are not much smaller than the wavelength. Numerical results show that the performance of localized BD-RIS is only slightly impacted by losses, given the short interconnection lengths. Besides, distributed BD-RIS can achieve orders of magnitude of gains over conventional RIS, even in the presence of low losses.","sentences":["Reconfigurable intelligent surface (RIS) is a key technology to control the communication environment in future wireless networks.","Recently, beyond diagonal RIS (BD-RIS) emerged as a generalization of RIS achieving larger coverage through additional tunable impedance components interconnecting the RIS elements.","However, conventional RIS and BD-RIS can effectively serve only users in their proximity, resulting in limited coverage.","To overcome this limitation, in this paper, we investigate distributed RIS, whose elements are distributed over a wide region, in opposition to localized RIS commonly considered in the literature.","The scaling laws of distributed BD-RIS reveal that it offers significant gains over distributed conventional RIS and localized BD-RIS, enabled by its interconnections allowing signal propagation within the BD-RIS.","To assess the practical performance of distributed BD-RIS, we model and optimize BD-RIS with lossy interconnections through transmission line theory.","Our model accounts for phase changes and losses over the BD-RIS interconnections arising when the interconnection lengths are not much smaller than the wavelength.","Numerical results show that the performance of localized BD-RIS is only slightly impacted by losses, given the short interconnection lengths.","Besides, distributed BD-RIS can achieve orders of magnitude of gains over conventional RIS, even in the presence of low losses."],"url":"http://arxiv.org/abs/2402.05881v1"}
{"created":"2024-02-08 18:14:33","title":"Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking","abstract":"Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers -- limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user's view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies.","sentences":["Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search.","However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers -- limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search.","We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user's view change the effect.","Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias.","These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies."],"url":"http://arxiv.org/abs/2402.05880v1"}
{"created":"2024-02-08 18:09:17","title":"Federated Offline Reinforcement Learning: Collaborative Single-Policy Coverage Suffices","abstract":"Offline reinforcement learning (RL), which seeks to learn an optimal policy using offline data, has garnered significant interest due to its potential in critical applications where online data collection is infeasible or expensive. This work explores the benefit of federated learning for offline RL, aiming at collaboratively leveraging offline datasets at multiple agents. Focusing on finite-horizon episodic tabular Markov decision processes (MDPs), we design FedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for federated offline RL. FedLCB-Q updates local Q-functions at agents with novel learning rate schedules and aggregates them at a central server using importance averaging and a carefully designed pessimistic penalty term. Our sample complexity analysis reveals that, with appropriately chosen parameters and synchronization schedules, FedLCB-Q achieves linear speedup in terms of the number of agents without requiring high-quality datasets at individual agents, as long as the local datasets collectively cover the state-action space visited by the optimal policy, highlighting the power of collaboration in the federated setting. In fact, the sample complexity almost matches that of the single-agent counterpart, as if all the data are stored at a central location, up to polynomial factors of the horizon length. Furthermore, FedLCB-Q is communication-efficient, where the number of communication rounds is only linear with respect to the horizon length up to logarithmic factors.","sentences":["Offline reinforcement learning (RL), which seeks to learn an optimal policy using offline data, has garnered significant interest due to its potential in critical applications where online data collection is infeasible or expensive.","This work explores the benefit of federated learning for offline RL, aiming at collaboratively leveraging offline datasets at multiple agents.","Focusing on finite-horizon episodic tabular Markov decision processes (MDPs), we design FedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for federated offline RL.","FedLCB-Q updates local Q-functions at agents with novel learning rate schedules and aggregates them at a central server using importance averaging and a carefully designed pessimistic penalty term.","Our sample complexity analysis reveals that, with appropriately chosen parameters and synchronization schedules, FedLCB-Q achieves linear speedup in terms of the number of agents without requiring high-quality datasets at individual agents, as long as the local datasets collectively cover the state-action space visited by the optimal policy, highlighting the power of collaboration in the federated setting.","In fact, the sample complexity almost matches that of the single-agent counterpart, as if all the data are stored at a central location, up to polynomial factors of the horizon length.","Furthermore, FedLCB-Q is communication-efficient, where the number of communication rounds is only linear with respect to the horizon length up to logarithmic factors."],"url":"http://arxiv.org/abs/2402.05876v1"}
{"created":"2024-02-08 18:07:17","title":"Coordinated Activity Modulates the Behavior and Emotions of Organic Users: A Case Study on Tweets about the Gaza Conflict","abstract":"Social media has become a crucial conduit for the swift dissemination of information during global crises. However, this also paves the way for the manipulation of narratives by malicious actors. This research delves into the interaction dynamics between coordinated (malicious) entities and organic (regular) users on Twitter amidst the Gaza conflict. Through the analysis of approximately 3.5 million tweets from over 1.3 million users, our study uncovers that coordinated users significantly impact the information landscape, successfully disseminating their content across the network: a substantial fraction of their messages is adopted and shared by organic users. Furthermore, the study documents a progressive increase in organic users' engagement with coordinated content, which is paralleled by a discernible shift towards more emotionally polarized expressions in their subsequent communications. These results highlight the critical need for vigilance and a nuanced understanding of information manipulation on social media platforms.","sentences":["Social media has become a crucial conduit for the swift dissemination of information during global crises.","However, this also paves the way for the manipulation of narratives by malicious actors.","This research delves into the interaction dynamics between coordinated (malicious) entities and organic (regular) users on Twitter amidst the Gaza conflict.","Through the analysis of approximately 3.5 million tweets from over 1.3 million users, our study uncovers that coordinated users significantly impact the information landscape, successfully disseminating their content across the network: a substantial fraction of their messages is adopted and shared by organic users.","Furthermore, the study documents a progressive increase in organic users' engagement with coordinated content, which is paralleled by a discernible shift towards more emotionally polarized expressions in their subsequent communications.","These results highlight the critical need for vigilance and a nuanced understanding of information manipulation on social media platforms."],"url":"http://arxiv.org/abs/2402.05873v1"}
{"created":"2024-02-08 18:01:19","title":"You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for Semantic and Property Prediction","abstract":"Robots must be able to understand their surroundings to perform complex tasks in challenging environments and many of these complex tasks require estimates of physical properties such as friction or weight. Estimating such properties using learning is challenging due to the large amounts of labelled data required for training and the difficulty of updating these learned models online at run time. To overcome these challenges, this paper introduces a novel, multi-modal approach for representing semantic predictions and physical property estimates jointly in a probabilistic manner. By using conjugate pairs, the proposed method enables closed-form Bayesian updates given visual and tactile measurements without requiring additional training data. The efficacy of the proposed algorithm is demonstrated through several hardware experiments. In particular, this paper illustrates that by conditioning semantic classifications on physical properties, the proposed method quantitatively outperforms state-of-the-art semantic classification methods that rely on vision alone. To further illustrate its utility, the proposed method is used in several applications including to represent affordance-based properties probabilistically and a challenging terrain traversal task using a legged robot. In the latter task, the proposed method represents the coefficient of friction of the terrain probabilistically, which enables the use of an on-line risk-aware planner that switches the legged robot from a dynamic gait to a static, stable gait when the expected value of the coefficient of friction falls below a given threshold. Videos of these case studies are presented in the multimedia attachment. The proposed framework includes an open-source C++ and ROS interface.","sentences":["Robots must be able to understand their surroundings to perform complex tasks in challenging environments and many of these complex tasks require estimates of physical properties such as friction or weight.","Estimating such properties using learning is challenging due to the large amounts of labelled data required for training and the difficulty of updating these learned models online at run time.","To overcome these challenges, this paper introduces a novel, multi-modal approach for representing semantic predictions and physical property estimates jointly in a probabilistic manner.","By using conjugate pairs, the proposed method enables closed-form Bayesian updates given visual and tactile measurements without requiring additional training data.","The efficacy of the proposed algorithm is demonstrated through several hardware experiments.","In particular, this paper illustrates that by conditioning semantic classifications on physical properties, the proposed method quantitatively outperforms state-of-the-art semantic classification methods that rely on vision alone.","To further illustrate its utility, the proposed method is used in several applications including to represent affordance-based properties probabilistically and a challenging terrain traversal task using a legged robot.","In the latter task, the proposed method represents the coefficient of friction of the terrain probabilistically, which enables the use of an on-line risk-aware planner that switches the legged robot from a dynamic gait to a static, stable gait when the expected value of the coefficient of friction falls below a given threshold.","Videos of these case studies are presented in the multimedia attachment.","The proposed framework includes an open-source C++ and ROS interface."],"url":"http://arxiv.org/abs/2402.05872v1"}
{"created":"2024-02-08 17:57:59","title":"Adaptive Surface Normal Constraint for Geometric Estimation from Monocular Images","abstract":"We introduce a novel approach to learn geometries such as depth and surface normal from images while incorporating geometric context. The difficulty of reliably capturing geometric context in existing methods impedes their ability to accurately enforce the consistency between the different geometric properties, thereby leading to a bottleneck of geometric estimation quality. We therefore propose the Adaptive Surface Normal (ASN) constraint, a simple yet efficient method. Our approach extracts geometric context that encodes the geometric variations present in the input image and correlates depth estimation with geometric constraints. By dynamically determining reliable local geometry from randomly sampled candidates, we establish a surface normal constraint, where the validity of these candidates is evaluated using the geometric context. Furthermore, our normal estimation leverages the geometric context to prioritize regions that exhibit significant geometric variations, which makes the predicted normals accurately capture intricate and detailed geometric information. Through the integration of geometric context, our method unifies depth and surface normal estimations within a cohesive framework, which enables the generation of high-quality 3D geometry from images. We validate the superiority of our approach over state-of-the-art methods through extensive evaluations and comparisons on diverse indoor and outdoor datasets, showcasing its efficiency and robustness.","sentences":["We introduce a novel approach to learn geometries such as depth and surface normal from images while incorporating geometric context.","The difficulty of reliably capturing geometric context in existing methods impedes their ability to accurately enforce the consistency between the different geometric properties, thereby leading to a bottleneck of geometric estimation quality.","We therefore propose the Adaptive Surface Normal (ASN) constraint, a simple yet efficient method.","Our approach extracts geometric context that encodes the geometric variations present in the input image and correlates depth estimation with geometric constraints.","By dynamically determining reliable local geometry from randomly sampled candidates, we establish a surface normal constraint, where the validity of these candidates is evaluated using the geometric context.","Furthermore, our normal estimation leverages the geometric context to prioritize regions that exhibit significant geometric variations, which makes the predicted normals accurately capture intricate and detailed geometric information.","Through the integration of geometric context, our method unifies depth and surface normal estimations within a cohesive framework, which enables the generation of high-quality 3D geometry from images.","We validate the superiority of our approach over state-of-the-art methods through extensive evaluations and comparisons on diverse indoor and outdoor datasets, showcasing its efficiency and robustness."],"url":"http://arxiv.org/abs/2402.05869v1"}
{"created":"2024-02-08 17:57:11","title":"PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models","abstract":"Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications. While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services. To address these concerns, this paper proposes a simple yet effective mechanism PromptCrypt to protect user privacy. It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the model's performance remains unaffected. We conduct experiments on three tasks, personalized recommendation, sentiment analysis, and tabular data analysis. Experiment results reveal that PromptCrypt can encrypt personal information within prompts in such a manner that not only prevents the discernment of sensitive data by humans or LLM itself, but also maintains or even improves the precision without further tuning, achieving comparable or even better task accuracy than directly prompting the LLM without prompt encryption. These results highlight the practicality of adopting encryption measures that safeguard user privacy without compromising the functional integrity and performance of LLMs. Code and dataset are available at https://github.com/agiresearch/PromptCrypt.","sentences":["Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications.","While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services.","To address these concerns, this paper proposes a simple yet effective mechanism PromptCrypt to protect user privacy.","It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the model's performance remains unaffected.","We conduct experiments on three tasks, personalized recommendation, sentiment analysis, and tabular data analysis.","Experiment results reveal that PromptCrypt can encrypt personal information within prompts in such a manner that not only prevents the discernment of sensitive data by humans or LLM itself, but also maintains or even improves the precision without further tuning, achieving comparable or even better task accuracy than directly prompting the LLM without prompt encryption.","These results highlight the practicality of adopting encryption measures that safeguard user privacy without compromising the functional integrity and performance of LLMs.","Code and dataset are available at https://github.com/agiresearch/PromptCrypt."],"url":"http://arxiv.org/abs/2402.05868v1"}
{"created":"2024-02-08 17:57:03","title":"\"Can You Play Anything Else?\" Understanding Play Style Flexibility in League of Legends","abstract":"This study investigates the concept of flexibility within League of Legends, a popular online multiplayer game, focusing on the relationship between user adaptability and team success. Utilizing a dataset encompassing players of varying skill levels and play styles, we calculate two measures of flexibility for each player: overall flexibility and temporal flexibility. Our findings suggest that the flexibility of a user is dependent upon a user's preferred play style, and flexibility does impact match outcome. This work also shows that skill level not only indicates how willing a player is to adapt their play style but also how their adaptability changes over time. This paper highlights the the duality and balance of mastery versus flexibility, providing insights that can inform strategic planning, collaboration and resource allocation in competitive environments.","sentences":["This study investigates the concept of flexibility within League of Legends, a popular online multiplayer game, focusing on the relationship between user adaptability and team success.","Utilizing a dataset encompassing players of varying skill levels and play styles, we calculate two measures of flexibility for each player: overall flexibility and temporal flexibility.","Our findings suggest that the flexibility of a user is dependent upon a user's preferred play style, and flexibility does impact match outcome.","This work also shows that skill level not only indicates how willing a player is to adapt their play style but also how their adaptability changes over time.","This paper highlights the the duality and balance of mastery versus flexibility, providing insights that can inform strategic planning, collaboration and resource allocation in competitive environments."],"url":"http://arxiv.org/abs/2402.05865v1"}
{"created":"2024-02-08 17:54:23","title":"Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs","abstract":"In this paper, we propose a new decoding method called Permute-and-Flip (PF) decoder. It enjoys robustness properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-robustness tradeoff than sampling and never worse than any other decoder. We also design a cryptographic watermarking scheme analogous to Aaronson's Gumbel watermark, but naturally tailored for PF decoder. The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall whenever the generated text has high entropy. Our experiments show that the PF decoder (and its watermarked counterpart) significantly outperform(s) naive sampling (and it's Gumbel watermarked counterpart) in terms of perplexity, while retaining the same robustness (and detectability), hence making it a promising new approach for LLM decoding. The code is available at https://github.com/XuandongZhao/pf-decoding","sentences":["In this paper, we propose a new decoding method called Permute-and-Flip (PF) decoder.","It enjoys robustness properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-robustness tradeoff than sampling and never worse than any other decoder.","We also design a cryptographic watermarking scheme analogous to Aaronson's Gumbel watermark, but naturally tailored for PF decoder.","The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall whenever the generated text has high entropy.","Our experiments show that the PF decoder (and its watermarked counterpart) significantly outperform(s) naive sampling (and it's Gumbel watermarked counterpart) in terms of perplexity, while retaining the same robustness (and detectability), hence making it a promising new approach for LLM decoding.","The code is available at https://github.com/XuandongZhao/pf-decoding"],"url":"http://arxiv.org/abs/2402.05864v1"}
{"created":"2024-02-08 17:51:48","title":"How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis","abstract":"Negotiation is the basis of social interactions; humans negotiate everything from the price of cars to how to share common resources. With rapidly growing interest in using large language models (LLMs) to act as agents on behalf of human users, such LLM agents would also need to be able to negotiate. In this paper, we study how well LLMs can negotiate with each other. We develop NegotiationArena: a flexible framework for evaluating and probing the negotiation abilities of LLM agents. We implemented three types of scenarios in NegotiationArena to assess LLM's behaviors in allocating shared resources (ultimatum games), aggregate resources (trading games) and buy/sell goods (price negotiations). Each scenario allows for multiple turns of flexible dialogues between LLM agents to allow for more complex negotiations. Interestingly, LLM agents can significantly boost their negotiation outcomes by employing certain behavioral tactics. For example, by pretending to be desolate and desperate, LLMs can improve their payoffs by 20\\% when negotiating against the standard GPT-4. We also quantify irrational negotiation behaviors exhibited by the LLM agents, many of which also appear in humans. Together, \\NegotiationArena offers a new environment to investigate LLM interactions, enabling new insights into LLM's theory of mind, irrationality, and reasoning abilities.","sentences":["Negotiation is the basis of social interactions; humans negotiate everything from the price of cars to how to share common resources.","With rapidly growing interest in using large language models (LLMs) to act as agents on behalf of human users, such LLM agents would also need to be able to negotiate.","In this paper, we study how well LLMs can negotiate with each other.","We develop NegotiationArena: a flexible framework for evaluating and probing the negotiation abilities of LLM agents.","We implemented three types of scenarios in NegotiationArena to assess LLM's behaviors in allocating shared resources (ultimatum games), aggregate resources (trading games) and buy/sell goods (price negotiations).","Each scenario allows for multiple turns of flexible dialogues between LLM agents to allow for more complex negotiations.","Interestingly, LLM agents can significantly boost their negotiation outcomes by employing certain behavioral tactics.","For example, by pretending to be desolate and desperate, LLMs can improve their payoffs by 20\\% when negotiating against the standard GPT-4.","We also quantify irrational negotiation behaviors exhibited by the LLM agents, many of which also appear in humans.","Together, \\NegotiationArena offers a new environment to investigate LLM interactions, enabling new insights into LLM's theory of mind, irrationality, and reasoning abilities."],"url":"http://arxiv.org/abs/2402.05863v1"}
{"created":"2024-02-08 17:51:44","title":"Let Your Graph Do the Talking: Encoding Structured Data for LLMs","abstract":"How can we best encode structured data into sequential form for use in large language models (LLMs)? In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs. Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information. Unlike other work which focuses on limited domains (e.g. knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks. We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks. Specifically, we see across the board improvements - up to 73% points - on node, edge and, graph-level tasks from the GraphQA benchmark.","sentences":["How can we best encode structured data into sequential form for use in large language models (LLMs)?","In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs.","Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information.","Unlike other work which focuses on limited domains (e.g. knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks.","We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks.","Specifically, we see across the board improvements - up to 73% points - on node, edge and, graph-level tasks from the GraphQA benchmark."],"url":"http://arxiv.org/abs/2402.05862v1"}
{"created":"2024-02-08 17:50:22","title":"Memory Consolidation Enables Long-Context Video Understanding","abstract":"Most transformer-based video encoders are limited to short temporal contexts due to their quadratic complexity. While various attempts have been made to extend this context, this has often come at the cost of both conceptual and computational complexity. We propose to instead re-purpose existing pre-trained video transformers by simply fine-tuning them to attend to memories derived non-parametrically from past activations. By leveraging redundancy reduction, our memory-consolidated vision transformer (MC-ViT) effortlessly extends its context far into the past and exhibits excellent scaling behavior when learning from longer videos. In doing so, MC-ViT sets a new state-of-the-art in long-context video understanding on EgoSchema, Perception Test, and Diving48, outperforming methods that benefit from orders of magnitude more parameters.","sentences":["Most transformer-based video encoders are limited to short temporal contexts due to their quadratic complexity.","While various attempts have been made to extend this context, this has often come at the cost of both conceptual and computational complexity.","We propose to instead re-purpose existing pre-trained video transformers by simply fine-tuning them to attend to memories derived non-parametrically from past activations.","By leveraging redundancy reduction, our memory-consolidated vision transformer (MC-ViT) effortlessly extends its context far into the past and exhibits excellent scaling behavior when learning from longer videos.","In doing so, MC-ViT sets a new state-of-the-art in long-context video understanding on EgoSchema, Perception Test, and Diving48, outperforming methods that benefit from orders of magnitude more parameters."],"url":"http://arxiv.org/abs/2402.05861v1"}
{"created":"2024-02-08 17:44:06","title":"Privacy-Preserving Synthetic Continual Semantic Segmentation for Robotic Surgery","abstract":"Deep Neural Networks (DNNs) based semantic segmentation of the robotic instruments and tissues can enhance the precision of surgical activities in robot-assisted surgery. However, in biological learning, DNNs cannot learn incremental tasks over time and exhibit catastrophic forgetting, which refers to the sharp decline in performance on previously learned tasks after learning a new one. Specifically, when data scarcity is the issue, the model shows a rapid drop in performance on previously learned instruments after learning new data with new instruments. The problem becomes worse when it limits releasing the dataset of the old instruments for the old model due to privacy concerns and the unavailability of the data for the new or updated version of the instruments for the continual learning model. For this purpose, we develop a privacy-preserving synthetic continual semantic segmentation framework by blending and harmonizing (i) open-source old instruments foreground to the synthesized background without revealing real patient data in public and (ii) new instruments foreground to extensively augmented real background. To boost the balanced logit distillation from the old model to the continual learning model, we design overlapping class-aware temperature normalization (CAT) by controlling model learning utility. We also introduce multi-scale shifted-feature distillation (SD) to maintain long and short-range spatial relationships among the semantic objects where conventional short-range spatial features with limited information reduce the power of feature distillation. We demonstrate the effectiveness of our framework on the EndoVis 2017 and 2018 instrument segmentation dataset with a generalized continual learning setting. Code is available at~\\url{https://github.com/XuMengyaAmy/Synthetic_CAT_SD}.","sentences":["Deep Neural Networks (DNNs) based semantic segmentation of the robotic instruments and tissues can enhance the precision of surgical activities in robot-assisted surgery.","However, in biological learning, DNNs cannot learn incremental tasks over time and exhibit catastrophic forgetting, which refers to the sharp decline in performance on previously learned tasks after learning a new one.","Specifically, when data scarcity is the issue, the model shows a rapid drop in performance on previously learned instruments after learning new data with new instruments.","The problem becomes worse when it limits releasing the dataset of the old instruments for the old model due to privacy concerns and the unavailability of the data for the new or updated version of the instruments for the continual learning model.","For this purpose, we develop a privacy-preserving synthetic continual semantic segmentation framework by blending and harmonizing (i) open-source old instruments foreground to the synthesized background without revealing real patient data in public and (ii) new instruments foreground to extensively augmented real background.","To boost the balanced logit distillation from the old model to the continual learning model, we design overlapping class-aware temperature normalization (CAT) by controlling model learning utility.","We also introduce multi-scale shifted-feature distillation (SD) to maintain long and short-range spatial relationships among the semantic objects where conventional short-range spatial features with limited information reduce the power of feature distillation.","We demonstrate the effectiveness of our framework on the EndoVis 2017 and 2018 instrument segmentation dataset with a generalized continual learning setting.","Code is available at~\\url{https://github.com/XuMengyaAmy/Synthetic_CAT_SD}."],"url":"http://arxiv.org/abs/2402.05860v1"}
{"created":"2024-02-08 17:43:22","title":"Learning to Route Among Specialized Experts for Zero-Shot Generalization","abstract":"Recently, there has been a widespread proliferation of \"expert\" language models that are specialized to a specific task or domain through parameter-efficient fine-tuning. How can we recycle large collections of expert language models to improve zero-shot generalization to unseen tasks? In this work, we propose Post-Hoc Adaptive Tokenwise Gating Over an Ocean of Specialized Experts (PHATGOOSE), which learns to route among specialized modules that were produced through parameter-efficient fine-tuning. Unlike past methods that learn to route among specialized models, PHATGOOSE explores the possibility that zero-shot generalization will be improved if different experts can be adaptively chosen for each token and at each layer in the model. Crucially, our method is post-hoc - it does not require simultaneous access to the datasets used to create the specialized models and only requires a modest amount of additional compute after each expert model is trained. In experiments covering a range of specialized model collections and zero-shot generalization benchmarks, we find that PHATGOOSE outperforms past methods for post-hoc routing and, in some cases, outperforms explicit multitask training (which requires simultaneous data access). To better understand the routing strategy learned by PHATGOOSE, we perform qualitative experiments to validate that PHATGOOSE's performance stems from its ability to make adaptive per-token and per-module expert choices. We release all of our code to support future work on improving zero-shot generalization by recycling specialized experts.","sentences":["Recently, there has been a widespread proliferation of \"expert\" language models that are specialized to a specific task or domain through parameter-efficient fine-tuning.","How can we recycle large collections of expert language models to improve zero-shot generalization to unseen tasks?","In this work, we propose Post-Hoc Adaptive Tokenwise Gating Over an Ocean of Specialized Experts (PHATGOOSE), which learns to route among specialized modules that were produced through parameter-efficient fine-tuning.","Unlike past methods that learn to route among specialized models, PHATGOOSE explores the possibility that zero-shot generalization will be improved if different experts can be adaptively chosen for each token and at each layer in the model.","Crucially, our method is post-hoc - it does not require simultaneous access to the datasets used to create the specialized models and only requires a modest amount of additional compute after each expert model is trained.","In experiments covering a range of specialized model collections and zero-shot generalization benchmarks, we find that PHATGOOSE outperforms past methods for post-hoc routing and, in some cases, outperforms explicit multitask training (which requires simultaneous data access).","To better understand the routing strategy learned by PHATGOOSE, we perform qualitative experiments to validate that PHATGOOSE's performance stems from its ability to make adaptive per-token and per-module expert choices.","We release all of our code to support future work on improving zero-shot generalization by recycling specialized experts."],"url":"http://arxiv.org/abs/2402.05859v1"}
{"created":"2024-02-08 17:38:29","title":"(Almost) Affine Higher-Order Tree Transducers","abstract":"We investigate the tree-to-tree functions computed by \\enquote{affine$\\lambda$-transducers}: tree automata whose memory consists of an affine $\\lambda$-term instead of a finite state. They can be seen as variations on Gallot, Lemay and Salvati's Linear High-Order Deterministic Tree Transducers. When the memory is almost purely affine (\\textit{\\`a la} Kanazawa), we show that these machines can be translated to tree-walking transducers (and with a purely affine memory, we get a reversible tree-walking transducer). This leads to a proof of an inexpressivity conjecture of \\titocecilia on \\enquote{implicit automata} in an affine $\\lambda$-calculus. The key technical tool in our proofs is the Interaction Abstract Machine (IAM), an operational avatar of the \\enquote{geometry of interaction} semantics of linear logic. We work with ad-hoc specializations to (almost) affine $\\lambda$-terms of a tree-generating version of the IAM.","sentences":["We investigate the tree-to-tree functions computed by \\enquote{affine$\\lambda$-transducers}: tree automata whose memory consists of an affine $\\lambda$-term instead of a finite state.","They can be seen as variations on Gallot, Lemay and Salvati's Linear High-Order Deterministic Tree Transducers.","When the memory is almost purely affine (\\textit{\\`a la} Kanazawa), we show that these machines can be translated to tree-walking transducers (and with a purely affine memory, we get a reversible tree-walking transducer).","This leads to a proof of an inexpressivity conjecture of \\titocecilia on \\enquote{implicit automata} in an affine $\\lambda$-calculus.","The key technical tool in our proofs is the Interaction Abstract Machine (IAM), an operational avatar of the \\enquote{geometry of interaction} semantics of linear logic.","We work with ad-hoc specializations to (almost) affine $\\lambda$-terms of a tree-generating version of the IAM."],"url":"http://arxiv.org/abs/2402.05854v1"}
{"created":"2024-02-08 17:35:47","title":"On Experimental Emulation of Printability and Fleet Aware Generic Mesh Decomposition for Enabling Aerial 3D Printing","abstract":"This article introduces an experimental emulation of a novel chunk-based flexible multi-DoF aerial 3D printing framework. The experimental demonstration of the overall autonomy focuses on precise motion planning and task allocation for a UAV, traversing through a series of planned space-filling paths involved in the aerial 3D printing process without physically depositing the overlaying material. The flexible multi-DoF aerial 3D printing is a newly developed framework and has the potential to strategically distribute the envisioned 3D model to be printed into small, manageable chunks suitable for distributed 3D printing. Moreover, by harnessing the dexterous flexibility due to the 6 DoF motion of UAV, the framework enables the provision of integrating the overall autonomy stack, potentially opening up an entirely new frontier in additive manufacturing. However, it's essential to note that the feasibility of this pioneering concept is still in its very early stage of development, which yet needs to be experimentally verified. Towards this direction, experimental emulation serves as the crucial stepping stone, providing a pseudo mockup scenario by virtual material deposition, helping to identify technological gaps from simulation to reality. Experimental emulation results, supported by critical analysis and discussion, lay the foundation for addressing the technological and research challenges to significantly push the boundaries of the state-of-the-art 3D printing mechanism.","sentences":["This article introduces an experimental emulation of a novel chunk-based flexible multi-DoF aerial 3D printing framework.","The experimental demonstration of the overall autonomy focuses on precise motion planning and task allocation for a UAV, traversing through a series of planned space-filling paths involved in the aerial 3D printing process without physically depositing the overlaying material.","The flexible multi-DoF aerial 3D printing is a newly developed framework and has the potential to strategically distribute the envisioned 3D model to be printed into small, manageable chunks suitable for distributed 3D printing.","Moreover, by harnessing the dexterous flexibility due to the 6 DoF motion of UAV, the framework enables the provision of integrating the overall autonomy stack, potentially opening up an entirely new frontier in additive manufacturing.","However, it's essential to note that the feasibility of this pioneering concept is still in its very early stage of development, which yet needs to be experimentally verified.","Towards this direction, experimental emulation serves as the crucial stepping stone, providing a pseudo mockup scenario by virtual material deposition, helping to identify technological gaps from simulation to reality.","Experimental emulation results, supported by critical analysis and discussion, lay the foundation for addressing the technological and research challenges to significantly push the boundaries of the state-of-the-art 3D printing mechanism."],"url":"http://arxiv.org/abs/2402.05853v1"}
{"created":"2024-02-08 17:17:06","title":"uPLAM: Robust Panoptic Localization and Mapping Leveraging Perception Uncertainties","abstract":"The availability of a reliable map and a robust localization system is critical for the operation of an autonomous vehicle. In a modern system, both mapping and localization solutions generally employ convolutional neural network (CNN) --based perception. Hence, any algorithm should consider potential errors in perception for safe and robust functioning. In this work, we present uncertainty-aware panoptic Localization and Mapping (uPLAM), which employs perception uncertainty as a bridge to fuse the perception information with classical localization and mapping approaches. We introduce an uncertainty-based map aggregation technique to create a long-term panoptic bird's eye view map and provide an associated mapping uncertainty. Our map consists of surface semantics and landmarks with unique IDs. Moreover, we present panoptic uncertainty-aware particle filter-based localization. To this end, we propose an uncertainty-based particle importance weight calculation for the adaptive incorporation of perception information into localization. We also present a new dataset for evaluating long-term panoptic mapping and map-based localization. Extensive evaluations showcase that our proposed uncertainty incorporation leads to better mapping with reliable uncertainty estimates and accurate localization. We make our dataset and code available at: \\url{http://uplam.cs.uni-freiburg.de}","sentences":["The availability of a reliable map and a robust localization system is critical for the operation of an autonomous vehicle.","In a modern system, both mapping and localization solutions generally employ convolutional neural network (CNN) --based perception.","Hence, any algorithm should consider potential errors in perception for safe and robust functioning.","In this work, we present uncertainty-aware panoptic Localization and Mapping (uPLAM), which employs perception uncertainty as a bridge to fuse the perception information with classical localization and mapping approaches.","We introduce an uncertainty-based map aggregation technique to create a long-term panoptic bird's eye view map and provide an associated mapping uncertainty.","Our map consists of surface semantics and landmarks with unique IDs.","Moreover, we present panoptic uncertainty-aware particle filter-based localization.","To this end, we propose an uncertainty-based particle importance weight calculation for the adaptive incorporation of perception information into localization.","We also present a new dataset for evaluating long-term panoptic mapping and map-based localization.","Extensive evaluations showcase that our proposed uncertainty incorporation leads to better mapping with reliable uncertainty estimates and accurate localization.","We make our dataset and code available at: \\url{http://uplam.cs.uni-freiburg.de}"],"url":"http://arxiv.org/abs/2402.05840v1"}
{"created":"2024-02-08 17:13:17","title":"Shape Optimization of Eigenfrequencies in MEMS Gyroscopes","abstract":"Microelectromechanical systems (MEMS) gyroscopes are widely used in consumer and automotive applications. They have to fulfill a vast number of product requirements which lead to complex mechanical designs of the resonating structure. Arriving at a final design is a cumbersome process that relies heavily on human experience in conjunction with design optimization methods. In this work, we apply node-based shape optimization to the design of a MEMS gyroscope. For that purpose, we parametrize the coordinates of the nodes of the finite element method (FEM) mesh that discretize the shapes of the springs. We then implement the gradients of the mechanical eigenfrequencies and typical MEMS manufacturability constraints, with respect to the design parameters, in a FEM code. Using gradient-based optimization we tune the gyroscope's frequency split and shift spurious modes away from the first three multiples of the gyroscope's drive frequency while manufacturability constraints are fulfilled. The resulting optimized design exhibits novel geometrical shapes which defy any human intuition. Overall, we demonstrate that shape optimization can not only solve optimization problems in MEMS design without required human intervention, but also explores geometry solutions which can otherwise not be addressed. In this way, node-based shape optimization opens up a much larger space of possible design solutions, which is crucial for facing the ever increasing product requirements. Our approach is generic and applicable to many other types of MEMS resonators.","sentences":["Microelectromechanical systems (MEMS) gyroscopes are widely used in consumer and automotive applications.","They have to fulfill a vast number of product requirements which lead to complex mechanical designs of the resonating structure.","Arriving at a final design is a cumbersome process that relies heavily on human experience in conjunction with design optimization methods.","In this work, we apply node-based shape optimization to the design of a MEMS gyroscope.","For that purpose, we parametrize the coordinates of the nodes of the finite element method (FEM) mesh that discretize the shapes of the springs.","We then implement the gradients of the mechanical eigenfrequencies and typical MEMS manufacturability constraints, with respect to the design parameters, in a FEM code.","Using gradient-based optimization we tune the gyroscope's frequency split and shift spurious modes away from the first three multiples of the gyroscope's drive frequency while manufacturability constraints are fulfilled.","The resulting optimized design exhibits novel geometrical shapes which defy any human intuition.","Overall, we demonstrate that shape optimization can not only solve optimization problems in MEMS design without required human intervention, but also explores geometry solutions which can otherwise not be addressed.","In this way, node-based shape optimization opens up a much larger space of possible design solutions, which is crucial for facing the ever increasing product requirements.","Our approach is generic and applicable to many other types of MEMS resonators."],"url":"http://arxiv.org/abs/2402.05837v1"}
{"created":"2024-02-08 17:12:49","title":"How Much is Unseen Depends Chiefly on Information About the Seen","abstract":"It might seem counter-intuitive at first: We find that, in expectation, the proportion of data points in an unknown population-that belong to classes that do not appear in the training data-is almost entirely determined by the number $f_k$ of classes that do appear in the training data the same number of times. While in theory we show that the difference of the induced estimator decays exponentially in the size of the sample, in practice the high variance prevents us from using it directly for an estimator of the sample coverage. However, our precise characterization of the dependency between $f_k$'s induces a large search space of different representations of the expected value, which can be deterministically instantiated as estimators. Hence, we turn to optimization and develop a genetic algorithm that, given only the sample, searches for an estimator with minimal mean-squared error (MSE). In our experiments, our genetic algorithm discovers estimators that have a substantially smaller MSE than the state-of-the-art Good-Turing estimator. This holds for over 96% of runs when there are at least as many samples as classes. Our estimators' MSE is roughly 80% of the Good-Turing estimator's.","sentences":["It might seem counter-intuitive at first: We find that, in expectation, the proportion of data points in an unknown population-that belong to classes that do not appear in the training data-is almost entirely determined by the number $f_k$ of classes that do appear in the training data the same number of times.","While in theory we show that the difference of the induced estimator decays exponentially in the size of the sample, in practice the high variance prevents us from using it directly for an estimator of the sample coverage.","However, our precise characterization of the dependency between $f_k$'s induces a large search space of different representations of the expected value, which can be deterministically instantiated as estimators.","Hence, we turn to optimization and develop a genetic algorithm that, given only the sample, searches for an estimator with minimal mean-squared error (MSE).","In our experiments, our genetic algorithm discovers estimators that have a substantially smaller MSE than the state-of-the-art Good-Turing estimator.","This holds for over 96% of runs when there are at least as many samples as classes.","Our estimators' MSE is roughly 80% of the Good-Turing estimator's."],"url":"http://arxiv.org/abs/2402.05835v1"}
{"created":"2024-02-08 17:09:12","title":"Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization for Enhanced Time Series Forecasting","abstract":"Time series analysis is vital for numerous applications, and transformers have become increasingly prominent in this domain. Leading methods customize the transformer architecture from NLP and CV, utilizing a patching technique to convert continuous signals into segments. Yet, time series data are uniquely challenging due to significant distribution shifts and intrinsic noise levels. To address these two challenges,we introduce the Sparse Vector Quantized FFN-Free Transformer (Sparse-VQ). Our methodology capitalizes on a sparse vector quantization technique coupled with Reverse Instance Normalization (RevIN) to reduce noise impact and capture sufficient statistics for forecasting, serving as an alternative to the Feed-Forward layer (FFN) in the transformer architecture. Our FFN-free approach trims the parameter count, enhancing computational efficiency and reducing overfitting. Through evaluations across ten benchmark datasets, including the newly introduced CAISO dataset, Sparse-VQ surpasses leading models with a 7.84% and 4.17% decrease in MAE for univariate and multivariate time series forecasting, respectively. Moreover, it can be seamlessly integrated with existing transformer-based models to elevate their performance.","sentences":["Time series analysis is vital for numerous applications, and transformers have become increasingly prominent in this domain.","Leading methods customize the transformer architecture from NLP and CV, utilizing a patching technique to convert continuous signals into segments.","Yet, time series data are uniquely challenging due to significant distribution shifts and intrinsic noise levels.","To address these two challenges,we introduce the Sparse Vector Quantized FFN-Free Transformer (Sparse-VQ).","Our methodology capitalizes on a sparse vector quantization technique coupled with Reverse Instance Normalization (RevIN) to reduce noise impact and capture sufficient statistics for forecasting, serving as an alternative to the Feed-Forward layer (FFN) in the transformer architecture.","Our FFN-free approach trims the parameter count, enhancing computational efficiency and reducing overfitting.","Through evaluations across ten benchmark datasets, including the newly introduced CAISO dataset, Sparse-VQ surpasses leading models with a 7.84% and 4.17% decrease in MAE for univariate and multivariate time series forecasting, respectively.","Moreover, it can be seamlessly integrated with existing transformer-based models to elevate their performance."],"url":"http://arxiv.org/abs/2402.05830v1"}
{"created":"2024-02-08 17:08:08","title":"Limitations of Agents Simulated by Predictive Models","abstract":"There is increasing focus on adapting predictive models into agent-like systems, most notably AI assistants based on language models. We outline two structural reasons for why these models can fail when turned into agents. First, we discuss auto-suggestive delusions. Prior work has shown theoretically that models fail to imitate agents that generated the training data if the agents relied on hidden observations: the hidden observations act as confounding variables, and the models treat actions they generate as evidence for nonexistent observations. Second, we introduce and formally study a related, novel limitation: predictor-policy incoherence. When a model generates a sequence of actions, the model's implicit prediction of the policy that generated those actions can serve as a confounding variable. The result is that models choose actions as if they expect future actions to be suboptimal, causing them to be overly conservative. We show that both of those failures are fixed by including a feedback loop from the environment, that is, re-training the models on their own actions. We give simple demonstrations of both limitations using Decision Transformers and confirm that empirical results agree with our conceptual and formal analysis. Our treatment provides a unifying view of those failure modes, and informs the question of why fine-tuning offline learned policies with online learning makes them more effective.","sentences":["There is increasing focus on adapting predictive models into agent-like systems, most notably AI assistants based on language models.","We outline two structural reasons for why these models can fail when turned into agents.","First, we discuss auto-suggestive delusions.","Prior work has shown theoretically that models fail to imitate agents that generated the training data if the agents relied on hidden observations: the hidden observations act as confounding variables, and the models treat actions they generate as evidence for nonexistent observations.","Second, we introduce and formally study a related, novel limitation: predictor-policy incoherence.","When a model generates a sequence of actions, the model's implicit prediction of the policy that generated those actions can serve as a confounding variable.","The result is that models choose actions as if they expect future actions to be suboptimal, causing them to be overly conservative.","We show that both of those failures are fixed by including a feedback loop from the environment, that is, re-training the models on their own actions.","We give simple demonstrations of both limitations using Decision Transformers and confirm that empirical results agree with our conceptual and formal analysis.","Our treatment provides a unifying view of those failure modes, and informs the question of why fine-tuning offline learned policies with online learning makes them more effective."],"url":"http://arxiv.org/abs/2402.05829v1"}
{"created":"2024-02-08 17:07:42","title":"Discovering Temporally-Aware Reinforcement Learning Algorithms","abstract":"Recent advancements in meta-learning have enabled the automatic discovery of novel reinforcement learning algorithms parameterized by surrogate objective functions. To improve upon manually designed algorithms, the parameterization of this learned objective function must be expressive enough to represent novel principles of learning (instead of merely recovering already established ones) while still generalizing to a wide range of settings outside of its meta-training distribution. However, existing methods focus on discovering objective functions that, like many widely used objective functions in reinforcement learning, do not take into account the total number of steps allowed for training, or \"training horizon\". In contrast, humans use a plethora of different learning objectives across the course of acquiring a new ability. For instance, students may alter their studying techniques based on the proximity to exam deadlines and their self-assessed capabilities. This paper contends that ignoring the optimization time horizon significantly restricts the expressive potential of discovered learning algorithms. We propose a simple augmentation to two existing objective discovery approaches that allows the discovered algorithm to dynamically update its objective function throughout the agent's training procedure, resulting in expressive schedules and increased generalization across different training horizons. In the process, we find that commonly used meta-gradient approaches fail to discover such adaptive objective functions while evolution strategies discover highly dynamic learning rules. We demonstrate the effectiveness of our approach on a wide range of tasks and analyze the resulting learned algorithms, which we find effectively balance exploration and exploitation by modifying the structure of their learning rules throughout the agent's lifetime.","sentences":["Recent advancements in meta-learning have enabled the automatic discovery of novel reinforcement learning algorithms parameterized by surrogate objective functions.","To improve upon manually designed algorithms, the parameterization of this learned objective function must be expressive enough to represent novel principles of learning (instead of merely recovering already established ones) while still generalizing to a wide range of settings outside of its meta-training distribution.","However, existing methods focus on discovering objective functions that, like many widely used objective functions in reinforcement learning, do not take into account the total number of steps allowed for training, or \"training horizon\".","In contrast, humans use a plethora of different learning objectives across the course of acquiring a new ability.","For instance, students may alter their studying techniques based on the proximity to exam deadlines and their self-assessed capabilities.","This paper contends that ignoring the optimization time horizon significantly restricts the expressive potential of discovered learning algorithms.","We propose a simple augmentation to two existing objective discovery approaches that allows the discovered algorithm to dynamically update its objective function throughout the agent's training procedure, resulting in expressive schedules and increased generalization across different training horizons.","In the process, we find that commonly used meta-gradient approaches fail to discover such adaptive objective functions while evolution strategies discover highly dynamic learning rules.","We demonstrate the effectiveness of our approach on a wide range of tasks and analyze the resulting learned algorithms, which we find effectively balance exploration and exploitation by modifying the structure of their learning rules throughout the agent's lifetime."],"url":"http://arxiv.org/abs/2402.05828v1"}
{"created":"2024-02-08 17:06:45","title":"Is it Possible to Edit Large Language Models Robustly?","abstract":"Large language models (LLMs) have played a pivotal role in building communicative AI to imitate human behaviors but face the challenge of efficient customization. To tackle this challenge, recent studies have delved into the realm of model editing, which manipulates specific memories of language models and changes the related language generation. However, the robustness of model editing remains an open question. This work seeks to understand the strengths and limitations of editing methods, thus facilitating robust, realistic applications of communicative AI. Concretely, we conduct extensive analysis to address the three key research questions. Q1: Can edited LLMs behave consistently resembling communicative AI in realistic situations? Q2: To what extent does the rephrasing of prompts lead LLMs to deviate from the edited knowledge memory? Q3: Which knowledge features are correlated with the performance and robustness of editing? Our experimental results uncover a substantial disparity between existing editing methods and the practical application of LLMs. On rephrased prompts that are complex and flexible but common in realistic applications, the performance of editing experiences a significant decline. Further analysis shows that more popular knowledge is memorized better, easier to recall, and more challenging to edit effectively.","sentences":["Large language models (LLMs) have played a pivotal role in building communicative AI to imitate human behaviors but face the challenge of efficient customization.","To tackle this challenge, recent studies have delved into the realm of model editing, which manipulates specific memories of language models and changes the related language generation.","However, the robustness of model editing remains an open question.","This work seeks to understand the strengths and limitations of editing methods, thus facilitating robust, realistic applications of communicative AI.","Concretely, we conduct extensive analysis to address the three key research questions.","Q1:","Can edited LLMs behave consistently resembling communicative AI in realistic situations?","Q2:","To what extent does the rephrasing of prompts lead LLMs to deviate from the edited knowledge memory?","Q3:","Which knowledge features are correlated with the performance and robustness of editing?","Our experimental results uncover a substantial disparity between existing editing methods and the practical application of LLMs.","On rephrased prompts that are complex and flexible but common in realistic applications, the performance of editing experiences a significant decline.","Further analysis shows that more popular knowledge is memorized better, easier to recall, and more challenging to edit effectively."],"url":"http://arxiv.org/abs/2402.05827v1"}
{"created":"2024-02-08 17:03:10","title":"FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework for Robust Solar Power Forecasting","abstract":"Accurate solar power forecasting is crucial to integrate photovoltaic plants into the electric grid, schedule and secure the power grid safety. This problem becomes more demanding for those newly installed solar plants which lack sufficient data. Current research predominantly relies on historical solar power data or numerical weather prediction in a single-modality format, ignoring the complementary information provided in different modalities. In this paper, we propose a multi-modality fusion framework to integrate historical power data, numerical weather prediction, and satellite images, significantly improving forecast performance. We introduce a vector quantized framework that aligns modalities with varying information densities, striking a balance between integrating sufficient information and averting model overfitting. Our framework demonstrates strong zero-shot forecasting capability, which is especially useful for those newly installed plants. Moreover, we collect and release a multi-modal solar power (MMSP) dataset from real-world plants to further promote the research of multi-modal solar forecasting algorithms. Our extensive experiments show that our model not only operates with robustness but also boosts accuracy in both zero-shot forecasting and scenarios rich with training data, surpassing leading models. We have incorporated it into our eForecaster platform and deployed it for more than 300 solar plants with a capacity of over 15GW.","sentences":["Accurate solar power forecasting is crucial to integrate photovoltaic plants into the electric grid, schedule and secure the power grid safety.","This problem becomes more demanding for those newly installed solar plants which lack sufficient data.","Current research predominantly relies on historical solar power data or numerical weather prediction in a single-modality format, ignoring the complementary information provided in different modalities.","In this paper, we propose a multi-modality fusion framework to integrate historical power data, numerical weather prediction, and satellite images, significantly improving forecast performance.","We introduce a vector quantized framework that aligns modalities with varying information densities, striking a balance between integrating sufficient information and averting model overfitting.","Our framework demonstrates strong zero-shot forecasting capability, which is especially useful for those newly installed plants.","Moreover, we collect and release a multi-modal solar power (MMSP) dataset from real-world plants to further promote the research of multi-modal solar forecasting algorithms.","Our extensive experiments show that our model not only operates with robustness but also boosts accuracy in both zero-shot forecasting and scenarios rich with training data, surpassing leading models.","We have incorporated it into our eForecaster platform and deployed it for more than 300 solar plants with a capacity of over 15GW."],"url":"http://arxiv.org/abs/2402.05823v1"}
{"created":"2024-02-08 16:59:24","title":"Guided Evolution with Binary Discriminators for ML Program Search","abstract":"How to automatically design better machine learning programs is an open problem within AutoML. While evolution has been a popular tool to search for better ML programs, using learning itself to guide the search has been less successful and less understood on harder problems but has the promise to dramatically increase the speed and final performance of the optimization process. We propose guiding evolution with a binary discriminator, trained online to distinguish which program is better given a pair of programs. The discriminator selects better programs without having to perform a costly evaluation and thus speed up the convergence of evolution. Our method can encode a wide variety of ML components including symbolic optimizers, neural architectures, RL loss functions, and symbolic regression equations with the same directed acyclic graph representation. By combining this representation with modern GNNs and an adaptive mutation strategy, we demonstrate our method can speed up evolution across a set of diverse problems including a 3.7x speedup on the symbolic search for ML optimizers and a 4x speedup for RL loss functions.","sentences":["How to automatically design better machine learning programs is an open problem within AutoML.","While evolution has been a popular tool to search for better ML programs, using learning itself to guide the search has been less successful and less understood on harder problems but has the promise to dramatically increase the speed and final performance of the optimization process.","We propose guiding evolution with a binary discriminator, trained online to distinguish which program is better given a pair of programs.","The discriminator selects better programs without having to perform a costly evaluation and thus speed up the convergence of evolution.","Our method can encode a wide variety of ML components including symbolic optimizers, neural architectures, RL loss functions, and symbolic regression equations with the same directed acyclic graph representation.","By combining this representation with modern GNNs and an adaptive mutation strategy, we demonstrate our method can speed up evolution across a set of diverse problems including a 3.7x speedup on the symbolic search for ML optimizers and a 4x speedup for RL loss functions."],"url":"http://arxiv.org/abs/2402.05821v1"}
{"created":"2024-02-08 16:50:01","title":"Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models","abstract":"The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data. Here, a novel approach is introduced to achieve precise and selective forgetting within language models. Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks. Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination. To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies. The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline annotation entails a robust two-stage process based on Large Language Models (LLMs).","sentences":["The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data.","Here, a novel approach is introduced to achieve precise and selective forgetting within language models.","Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks.","Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination.","To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies.","The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline annotation entails a robust two-stage process based on Large Language Models (LLMs)."],"url":"http://arxiv.org/abs/2402.05813v1"}
{"created":"2024-02-08 16:49:41","title":"FAQ-Gen: An automated system to generate domain-specific FAQs to aid content comprehension","abstract":"Frequently Asked Questions (FAQs) refer to the most common inquiries about specific content. They serve as content comprehension aids by simplifying topics and enhancing understanding through succinct presentation of information. In this paper, we address FAQ generation as a well-defined Natural Language Processing (NLP) task through the development of an end-to-end system leveraging text-to-text transformation models. We present a literature review covering traditional question-answering systems, highlighting their limitations when applied directly to the FAQ generation task. We propose our system capable of building FAQs from textual content tailored to specific domains, enhancing their accuracy and relevance. We utilise self-curated algorithms for obtaining optimal representation of information to be provided as input and also for ranking the question-answer pairs to maximise human comprehension. Qualitative human evaluation showcases the generated FAQs to be well-constructed and readable, while also utilising domain-specific constructs to highlight domain-based nuances and jargon in the original content.","sentences":["Frequently Asked Questions (FAQs) refer to the most common inquiries about specific content.","They serve as content comprehension aids by simplifying topics and enhancing understanding through succinct presentation of information.","In this paper, we address FAQ generation as a well-defined Natural Language Processing (NLP) task through the development of an end-to-end system leveraging text-to-text transformation models.","We present a literature review covering traditional question-answering systems, highlighting their limitations when applied directly to the FAQ generation task.","We propose our system capable of building FAQs from textual content tailored to specific domains, enhancing their accuracy and relevance.","We utilise self-curated algorithms for obtaining optimal representation of information to be provided as input and also for ranking the question-answer pairs to maximise human comprehension.","Qualitative human evaluation showcases the generated FAQs to be well-constructed and readable, while also utilising domain-specific constructs to highlight domain-based nuances and jargon in the original content."],"url":"http://arxiv.org/abs/2402.05812v1"}
{"created":"2024-02-08 16:47:54","title":"Natural Language User Profiles for Transparent and Scrutable Recommendations","abstract":"Current state-of-the-art recommender systems predominantly rely on either implicit or explicit feedback from users to suggest new items. While effective in recommending novel options, these conventional systems often use uninterpretable embeddings. This lack of transparency not only limits user understanding of why certain items are suggested but also reduces the user's ability to easily scrutinize and edit their preferences. For example, if a user has a change in interests, they would need to make significant changes to their interaction history to adjust the model's recommendations. To address these limitations, we introduce a novel method that utilizes user reviews to craft personalized, natural language profiles describing users' preferences. Through these descriptive profiles, our system provides transparent recommendations in natural language. Our evaluations show that this novel approach maintains a performance level on par with established recommender systems, but with the added benefits of transparency and user control. By enabling users to scrutinize why certain items are recommended, they can more easily verify, adjust, and have greater autonomy over their recommendations.","sentences":["Current state-of-the-art recommender systems predominantly rely on either implicit or explicit feedback from users to suggest new items.","While effective in recommending novel options, these conventional systems often use uninterpretable embeddings.","This lack of transparency not only limits user understanding of why certain items are suggested but also reduces the user's ability to easily scrutinize and edit their preferences.","For example, if a user has a change in interests, they would need to make significant changes to their interaction history to adjust the model's recommendations.","To address these limitations, we introduce a novel method that utilizes user reviews to craft personalized, natural language profiles describing users' preferences.","Through these descriptive profiles, our system provides transparent recommendations in natural language.","Our evaluations show that this novel approach maintains a performance level on par with established recommender systems, but with the added benefits of transparency and user control.","By enabling users to scrutinize why certain items are recommended, they can more easily verify, adjust, and have greater autonomy over their recommendations."],"url":"http://arxiv.org/abs/2402.05810v1"}
{"created":"2024-02-08 16:47:43","title":"You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement","abstract":"Low-Light Image Enhancement (LLIE) task tends to restore the details and visual information from corrupted low-light images. Most existing methods learn the mapping function between low/normal-light images by Deep Neural Networks (DNNs) on sRGB and HSV color space. Nevertheless, enhancement involves amplifying image signals, and applying these color spaces to low-light images with a low signal-to-noise ratio can introduce sensitivity and instability into the enhancement process. Consequently, this results in the presence of color artifacts and brightness artifacts in the enhanced images. To alleviate this problem, we propose a novel trainable color space, named Horizontal/Vertical-Intensity (HVI). It not only decouples brightness and color from RGB channels to mitigate the instability during enhancement but also adapts to low-light images in different illumination ranges due to the trainable parameters. Further, we design a novel Color and Intensity Decoupling Network (CIDNet) with two branches dedicated to processing the decoupled image brightness and color in the HVI space. Within CIDNet, we introduce the Lightweight Cross-Attention (LCA) module to facilitate interaction between image structure and content information in both branches, while also suppressing noise in low-light images. Finally, we conducted 22 quantitative and qualitative experiments to show that the proposed CIDNet outperforms the state-of-the-art methods on 11 datasets. The code will be available at https://github.com/Fediory/HVI-CIDNet.","sentences":["Low-Light Image Enhancement (LLIE) task tends to restore the details and visual information from corrupted low-light images.","Most existing methods learn the mapping function between low/normal-light images by Deep Neural Networks (DNNs) on sRGB and HSV color space.","Nevertheless, enhancement involves amplifying image signals, and applying these color spaces to low-light images with a low signal-to-noise ratio can introduce sensitivity and instability into the enhancement process.","Consequently, this results in the presence of color artifacts and brightness artifacts in the enhanced images.","To alleviate this problem, we propose a novel trainable color space, named Horizontal/Vertical-Intensity (HVI).","It not only decouples brightness and color from RGB channels to mitigate the instability during enhancement but also adapts to low-light images in different illumination ranges due to the trainable parameters.","Further, we design a novel Color and Intensity Decoupling Network (CIDNet) with two branches dedicated to processing the decoupled image brightness and color in the HVI space.","Within CIDNet, we introduce the Lightweight Cross-Attention (LCA) module to facilitate interaction between image structure and content information in both branches, while also suppressing noise in low-light images.","Finally, we conducted 22 quantitative and qualitative experiments to show that the proposed CIDNet outperforms the state-of-the-art methods on 11 datasets.","The code will be available at https://github.com/Fediory/HVI-CIDNet."],"url":"http://arxiv.org/abs/2402.05809v1"}
{"created":"2024-02-08 16:46:26","title":"Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning","abstract":"In this paper, we propose R$^3$: Learning Reasoning through Reverse Curriculum Reinforcement Learning (RL), a novel method that employs only outcome supervision to achieve the benefits of process supervision for large language models. The core challenge in applying RL to complex reasoning is to identify a sequence of actions that result in positive rewards and provide appropriate supervision for optimization. Outcome supervision provides sparse rewards for final results without identifying error locations, whereas process supervision offers step-wise rewards but requires extensive manual annotation. R$^3$ overcomes these limitations by learning from correct demonstrations. Specifically, R$^3$ progressively slides the start state of reasoning from a demonstration's end to its beginning, facilitating easier model exploration at all stages. Thus, R$^3$ establishes a step-wise curriculum, allowing outcome supervision to offer step-level signals and precisely pinpoint errors. Using Llama2-7B, our method surpasses RL baseline on eight reasoning tasks by $4.1$ points on average. Notebaly, in program-based reasoning on GSM8K, it exceeds the baseline by $4.2$ points across three backbone models, and without any extra data, Codellama-7B + R$^3$ performs comparable to larger models or closed-source models.","sentences":["In this paper, we propose R$^3$: Learning Reasoning through Reverse Curriculum Reinforcement Learning (RL), a novel method that employs only outcome supervision to achieve the benefits of process supervision for large language models.","The core challenge in applying RL to complex reasoning is to identify a sequence of actions that result in positive rewards and provide appropriate supervision for optimization.","Outcome supervision provides sparse rewards for final results without identifying error locations, whereas process supervision offers step-wise rewards but requires extensive manual annotation.","R$^3$ overcomes these limitations by learning from correct demonstrations.","Specifically, R$^3$ progressively slides the start state of reasoning from a demonstration's end to its beginning, facilitating easier model exploration at all stages.","Thus, R$^3$ establishes a step-wise curriculum, allowing outcome supervision to offer step-level signals and precisely pinpoint errors.","Using Llama2-7B, our method surpasses RL baseline on eight reasoning tasks by $4.1$ points on average.","Notebaly, in program-based reasoning on GSM8K, it exceeds the baseline by $4.2$ points across three backbone models, and without any extra data, Codellama-7B + R$^3$ performs comparable to larger models or closed-source models."],"url":"http://arxiv.org/abs/2402.05808v1"}
{"created":"2024-02-08 16:45:12","title":"On Calibration and Conformal Prediction of Deep Classifiers","abstract":"In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication. Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced. While in practice both types of indications can be desired, so far the interplay between them has not been investigated. Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods. We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive CP methods: it frequently leads to larger prediction sets. Then, we turn to theoretically analyze this behavior. We reveal several mathematical properties of the procedure, according to which we provide a reasoning for the phenomenon. Our study suggests that it may be worthwhile to utilize adaptive CP methods, chosen for their enhanced conditional coverage, based on softmax values prior to (or after canceling) temperature scaling calibration.","sentences":["In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication.","Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced.","While in practice both types of indications can be desired, so far the interplay between them has not been investigated.","Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods.","We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive CP methods: it frequently leads to larger prediction sets.","Then, we turn to theoretically analyze this behavior.","We reveal several mathematical properties of the procedure, according to which we provide a reasoning for the phenomenon.","Our study suggests that it may be worthwhile to utilize adaptive CP methods, chosen for their enhanced conditional coverage, based on softmax values prior to (or after canceling) temperature scaling calibration."],"url":"http://arxiv.org/abs/2402.05806v1"}
{"created":"2024-02-08 16:41:41","title":"InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write","abstract":"Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in the vectorized form, known as digital ink. However, a substantial gap remains between this way of note-taking and traditional pen-and-paper note-taking, a practice still favored by a vast majority. Our work, InkSight, aims to bridge the gap by empowering physical note-takers to effortlessly convert their work (offline handwriting) to digital ink (online handwriting), a process we refer to as Derendering. Prior research on the topic has focused on the geometric properties of images, resulting in limited generalization beyond their training domains. Our approach combines reading and writing priors, allowing training a model in the absence of large amounts of paired samples, which are difficult to obtain. To our knowledge, this is the first work that effectively derenders handwritten text in arbitrary photos with diverse visual characteristics and backgrounds. Furthermore, it generalizes beyond its training domain into simple sketches. Our human evaluation reveals that 87% of the samples produced by our model on the challenging HierText dataset are considered as a valid tracing of the input image and 67% look like a pen trajectory traced by a human.","sentences":["Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in the vectorized form, known as digital ink.","However, a substantial gap remains between this way of note-taking and traditional pen-and-paper note-taking, a practice still favored by a vast majority.","Our work, InkSight, aims to bridge the gap by empowering physical note-takers to effortlessly convert their work (offline handwriting) to digital ink (online handwriting), a process we refer to as Derendering.","Prior research on the topic has focused on the geometric properties of images, resulting in limited generalization beyond their training domains.","Our approach combines reading and writing priors, allowing training a model in the absence of large amounts of paired samples, which are difficult to obtain.","To our knowledge, this is the first work that effectively derenders handwritten text in arbitrary photos with diverse visual characteristics and backgrounds.","Furthermore, it generalizes beyond its training domain into simple sketches.","Our human evaluation reveals that 87% of the samples produced by our model on the challenging HierText dataset are considered as a valid tracing of the input image and 67% look like a pen trajectory traced by a human."],"url":"http://arxiv.org/abs/2402.05804v1"}
{"created":"2024-02-08 16:41:20","title":"AvatarMMC: 3D Head Avatar Generation and Editing with Multi-Modal Conditioning","abstract":"We introduce an approach for 3D head avatar generation and editing with multi-modal conditioning based on a 3D Generative Adversarial Network (GAN) and a Latent Diffusion Model (LDM). 3D GANs can generate high-quality head avatars given a single or no condition. However, it is challenging to generate samples that adhere to multiple conditions of different modalities. On the other hand, LDMs excel at learning complex conditional distributions. To this end, we propose to exploit the conditioning capabilities of LDMs to enable multi-modal control over the latent space of a pre-trained 3D GAN. Our method can generate and edit 3D head avatars given a mixture of control signals such as RGB input, segmentation masks, and global attributes. This provides better control over the generation and editing of synthetic avatars both globally and locally. Experiments show that our proposed approach outperforms a solely GAN-based approach both qualitatively and quantitatively on generation and editing tasks. To the best of our knowledge, our approach is the first to introduce multi-modal conditioning to 3D avatar generation and editing. \\\\href{avatarmmc-sig24.github.io}{Project Page}","sentences":["We introduce an approach for 3D head avatar generation and editing with multi-modal conditioning based on a 3D Generative Adversarial Network (GAN) and a Latent Diffusion Model (LDM).","3D GANs can generate high-quality head avatars given a single or no condition.","However, it is challenging to generate samples that adhere to multiple conditions of different modalities.","On the other hand, LDMs excel at learning complex conditional distributions.","To this end, we propose to exploit the conditioning capabilities of LDMs to enable multi-modal control over the latent space of a pre-trained 3D GAN.","Our method can generate and edit 3D head avatars given a mixture of control signals such as RGB input, segmentation masks, and global attributes.","This provides better control over the generation and editing of synthetic avatars both globally and locally.","Experiments show that our proposed approach outperforms a solely GAN-based approach both qualitatively and quantitatively on generation and editing tasks.","To the best of our knowledge, our approach is the first to introduce multi-modal conditioning to 3D avatar generation and editing.","\\\\href{avatarmmc-sig24.github.io}{Project Page}"],"url":"http://arxiv.org/abs/2402.05803v1"}
{"created":"2024-02-08 16:41:03","title":"Unsupervised Discovery of Clinical Disease Signatures Using Probabilistic Independence","abstract":"Insufficiently precise diagnosis of clinical disease is likely responsible for many treatment failures, even for common conditions and treatments. With a large enough dataset, it may be possible to use unsupervised machine learning to define clinical disease patterns more precisely. We present an approach to learning these patterns by using probabilistic independence to disentangle the imprint on the medical record of causal latent sources of disease. We inferred a broad set of 2000 clinical signatures of latent sources from 9195 variables in 269,099 Electronic Health Records. The learned signatures produced better discrimination than the original variables in a lung cancer prediction task unknown to the inference algorithm, predicting 3-year malignancy in patients with no history of cancer before a solitary lung nodule was discovered. More importantly, the signatures' greater explanatory power identified pre-nodule signatures of apparently undiagnosed cancer in many of those patients.","sentences":["Insufficiently precise diagnosis of clinical disease is likely responsible for many treatment failures, even for common conditions and treatments.","With a large enough dataset, it may be possible to use unsupervised machine learning to define clinical disease patterns more precisely.","We present an approach to learning these patterns by using probabilistic independence to disentangle the imprint on the medical record of causal latent sources of disease.","We inferred a broad set of 2000 clinical signatures of latent sources from 9195 variables in 269,099 Electronic Health Records.","The learned signatures produced better discrimination than the original variables in a lung cancer prediction task unknown to the inference algorithm, predicting 3-year malignancy in patients with no history of cancer before a solitary lung nodule was discovered.","More importantly, the signatures' greater explanatory power identified pre-nodule signatures of apparently undiagnosed cancer in many of those patients."],"url":"http://arxiv.org/abs/2402.05802v1"}
{"created":"2024-02-08 16:38:13","title":"Visual Harmony: Text-Visual Interplay in Circular Infographics","abstract":"Infographics are visual representations designed for efficient and effective communication of data and knowledge. One crucial aspect of infographic design is the interplay between text and visual elements, particularly in circular visualizations where the textual descriptions can either be embedded within the graphics or placed adjacent to the visual representation. While several studies have examined text layout design in visualizations in general, the text-visual interplay in infographics and its subsequent perceptual effects remain underexplored. To address this, our study investigates how varying text placement and descriptiveness impact pleasantness, comprehension and overall memorability in the infographics viewing experience. We recruited 30 participants and presented them with a collection of 15 infographics across a diverse set of topics, including media and public events, health and nutrition, science and research, and sustainability. The text placement (embed, side-to-side) and descriptiveness (simplistic, normal, descriptive) were systematically manipulated, resulting in a total of six experimental conditions. Our key findings indicate that text placement can significantly influence the memorability of infographics, whereas descriptiveness can significantly impact the pleasantness of the viewing experience. Embedding text placement and simplistic text can potentially contribute to more effective infographic designs. These results offer valuable insights for infographic designers, contributing to the creation of more effective and memorable visual representations.","sentences":["Infographics are visual representations designed for efficient and effective communication of data and knowledge.","One crucial aspect of infographic design is the interplay between text and visual elements, particularly in circular visualizations where the textual descriptions can either be embedded within the graphics or placed adjacent to the visual representation.","While several studies have examined text layout design in visualizations in general, the text-visual interplay in infographics and its subsequent perceptual effects remain underexplored.","To address this, our study investigates how varying text placement and descriptiveness impact pleasantness, comprehension and overall memorability in the infographics viewing experience.","We recruited 30 participants and presented them with a collection of 15 infographics across a diverse set of topics, including media and public events, health and nutrition, science and research, and sustainability.","The text placement (embed, side-to-side) and descriptiveness (simplistic, normal, descriptive) were systematically manipulated, resulting in a total of six experimental conditions.","Our key findings indicate that text placement can significantly influence the memorability of infographics, whereas descriptiveness can significantly impact the pleasantness of the viewing experience.","Embedding text placement and simplistic text can potentially contribute to more effective infographic designs.","These results offer valuable insights for infographic designers, contributing to the creation of more effective and memorable visual representations."],"url":"http://arxiv.org/abs/2402.05798v1"}
{"created":"2024-02-08 16:37:04","title":"TaE: Task-aware Expandable Representation for Long Tail Class Incremental Learning","abstract":"Class-incremental learning (CIL) aims to train classifiers that learn new classes without forgetting old ones. Most CIL methods focus on balanced data distribution for each task, overlooking real-world long-tailed distributions. Therefore, Long-Tailed Class-Incremental Learning (LT-CIL) has been introduced, which trains on data where head classes have more samples than tail classes. Existing methods mainly focus on preserving representative samples from previous classes to combat catastrophic forgetting. Recently, dynamic network algorithms frozen old network structures and expanded new ones, achieving significant performance. However, with the introduction of the long-tail problem, merely extending task-specific parameters can lead to miscalibrated predictions, while expanding the entire model results in an explosion of memory size. To address these issues, we introduce a novel Task-aware Expandable (TaE) framework, dynamically allocating and updating task-specific trainable parameters to learn diverse representations from each incremental task, while resisting forgetting through the majority of frozen model parameters. To further encourage the class-specific feature representation, we develop a Centroid-Enhanced (CEd) method to guide the update of these task-aware parameters. This approach is designed to adaptively minimize the distances between intra-class features while simultaneously maximizing the distances between inter-class features across all seen classes. The utility of this centroid-enhanced method extends to all \"training from scratch\" CIL algorithms. Extensive experiments were conducted on CIFAR-100 and ImageNet100 under different settings, which demonstrates that TaE achieves state-of-the-art performance.","sentences":["Class-incremental learning (CIL) aims to train classifiers that learn new classes without forgetting old ones.","Most CIL methods focus on balanced data distribution for each task, overlooking real-world long-tailed distributions.","Therefore, Long-Tailed Class-Incremental Learning (LT-CIL) has been introduced, which trains on data where head classes have more samples than tail classes.","Existing methods mainly focus on preserving representative samples from previous classes to combat catastrophic forgetting.","Recently, dynamic network algorithms frozen old network structures and expanded new ones, achieving significant performance.","However, with the introduction of the long-tail problem, merely extending task-specific parameters can lead to miscalibrated predictions, while expanding the entire model results in an explosion of memory size.","To address these issues, we introduce a novel Task-aware Expandable (TaE) framework, dynamically allocating and updating task-specific trainable parameters to learn diverse representations from each incremental task, while resisting forgetting through the majority of frozen model parameters.","To further encourage the class-specific feature representation, we develop a Centroid-Enhanced (CEd) method to guide the update of these task-aware parameters.","This approach is designed to adaptively minimize the distances between intra-class features while simultaneously maximizing the distances between inter-class features across all seen classes.","The utility of this centroid-enhanced method extends to all \"training from scratch\" CIL algorithms.","Extensive experiments were conducted on CIFAR-100 and ImageNet100 under different settings, which demonstrates that TaE achieves state-of-the-art performance."],"url":"http://arxiv.org/abs/2402.05797v1"}
{"created":"2024-02-08 16:36:11","title":"Phonetically rich corpus construction for a low-resourced language","abstract":"Speech technologies rely on capturing a speaker's voice variability while obtaining comprehensive language information. Textual prompts and sentence selection methods have been proposed in the literature to comprise such adequate phonetic data, referred to as a phonetically rich \\textit{corpus}. However, they are still insufficient for acoustic modeling, especially critical for languages with limited resources. Hence, this paper proposes a novel approach and outlines the methodological aspects required to create a \\textit{corpus} with broad phonetic coverage for a low-resourced language, Brazilian Portuguese. Our methodology includes text dataset collection up to a sentence selection algorithm based on triphone distribution. Furthermore, we propose a new phonemic classification according to acoustic-articulatory speech features since the absolute number of distinct triphones, or low-probability triphones, does not guarantee an adequate representation of every possible combination. Using our algorithm, we achieve a 55.8\\% higher percentage of distinct triphones -- for samples of similar size -- while the currently available phonetic-rich corpus, CETUC and TTS-Portuguese, 12.6\\% and 12.3\\% in comparison to a non-phonetically rich dataset.","sentences":["Speech technologies rely on capturing a speaker's voice variability while obtaining comprehensive language information.","Textual prompts and sentence selection methods have been proposed in the literature to comprise such adequate phonetic data, referred to as a phonetically rich \\textit{corpus}.","However, they are still insufficient for acoustic modeling, especially critical for languages with limited resources.","Hence, this paper proposes a novel approach and outlines the methodological aspects required to create a \\textit{corpus} with broad phonetic coverage for a low-resourced language, Brazilian Portuguese.","Our methodology includes text dataset collection up to a sentence selection algorithm based on triphone distribution.","Furthermore, we propose a new phonemic classification according to acoustic-articulatory speech features since the absolute number of distinct triphones, or low-probability triphones, does not guarantee an adequate representation of every possible combination.","Using our algorithm, we achieve a 55.8\\% higher percentage of distinct triphones -- for samples of similar size -- while the currently available phonetic-rich corpus, CETUC and TTS-Portuguese, 12.6\\% and 12.3\\% in comparison to a non-phonetically rich dataset."],"url":"http://arxiv.org/abs/2402.05794v1"}
{"created":"2024-02-08 16:34:00","title":"Determining the significance and relative importance of parameters of a simulated quenching algorithm using statistical tools","abstract":"When search methods are being designed it is very important to know which parameters have the greatest influence on the behaviour and performance of the algorithm. To this end, algorithm parameters are commonly calibrated by means of either theoretic analysis or intensive experimentation. When undertaking a detailed statistical analysis of the influence of each parameter, the designer should pay attention mostly to the parameters that are statistically significant. In this paper the ANOVA (ANalysis Of the VAriance) method is used to carry out an exhaustive analysis of a simulated annealing based method and the different parameters it requires. Following this idea, the significance and relative importance of the parameters regarding the obtained results, as well as suitable values for each of these, were obtained using ANOVA and post-hoc Tukey HSD test, on four well known function optimization problems and the likelihood function that is used to estimate the parameters involved in the lognormal diffusion process. Through this statistical study we have verified the adequacy of parameter values available in the bibliography using parametric hypothesis tests.","sentences":["When search methods are being designed it is very important to know which parameters have the greatest influence on the behaviour and performance of the algorithm.","To this end, algorithm parameters are commonly calibrated by means of either theoretic analysis or intensive experimentation.","When undertaking a detailed statistical analysis of the influence of each parameter, the designer should pay attention mostly to the parameters that are statistically significant.","In this paper the ANOVA (ANalysis Of the VAriance) method is used to carry out an exhaustive analysis of a simulated annealing based method and the different parameters it requires.","Following this idea, the significance and relative importance of the parameters regarding the obtained results, as well as suitable values for each of these, were obtained using ANOVA and post-hoc Tukey HSD test, on four well known function optimization problems and the likelihood function that is used to estimate the parameters involved in the lognormal diffusion process.","Through this statistical study we have verified the adequacy of parameter values available in the bibliography using parametric hypothesis tests."],"url":"http://arxiv.org/abs/2402.05791v1"}
{"created":"2024-02-08 16:24:40","title":"Prompting Fairness: Artificial Intelligence as Game Players","abstract":"Utilitarian games such as dictator games to measure fairness have been studied in the social sciences for decades. These games have given us insight into not only how humans view fairness but also in what conditions the frequency of fairness, altruism and greed increase or decrease. While these games have traditionally been focused on humans, the rise of AI gives us the ability to study how these models play these games. AI is becoming a constant in human interaction and examining how these models portray fairness in game play can give us some insight into how AI makes decisions. Over 101 rounds of the dictator game, I conclude that AI has a strong sense of fairness that is dependant of it it deems the person it is playing with as trustworthy, framing has a strong effect on how much AI gives a recipient when designated the trustee, and there may be evidence that AI experiences inequality aversion just as humans.","sentences":["Utilitarian games such as dictator games to measure fairness have been studied in the social sciences for decades.","These games have given us insight into not only how humans view fairness but also in what conditions the frequency of fairness, altruism and greed increase or decrease.","While these games have traditionally been focused on humans, the rise of AI gives us the ability to study how these models play these games.","AI is becoming a constant in human interaction and examining how these models portray fairness in game play can give us some insight into how AI makes decisions.","Over 101 rounds of the dictator game",", I conclude that AI has a strong sense of fairness that is dependant of it it deems the person it is playing with as trustworthy, framing has a strong effect on how much AI gives a recipient when designated the trustee, and there may be evidence that AI experiences inequality aversion just as humans."],"url":"http://arxiv.org/abs/2402.05786v1"}
{"created":"2024-02-08 16:23:29","title":"Limits of Transformer Language Models on Algorithmic Learning","abstract":"We analyze the capabilities of Transformer language models on learning discrete algorithms. To this end, we introduce two new tasks demanding the composition of several discrete sub-tasks. On both training LLaMA models from scratch and prompting on GPT-4 and Gemini we measure learning compositions of learned primitives. We observe that the compositional capabilities of state-of-the-art Transformer language models are very limited and sample-wise scale worse than relearning all sub-tasks for a new algorithmic composition. We also present a theorem in complexity theory, showing that gradient descent on memorizing feedforward models can be exponentially data inefficient.","sentences":["We analyze the capabilities of Transformer language models on learning discrete algorithms.","To this end, we introduce two new tasks demanding the composition of several discrete sub-tasks.","On both training LLaMA models from scratch and prompting on GPT-4 and Gemini we measure learning compositions of learned primitives.","We observe that the compositional capabilities of state-of-the-art Transformer language models are very limited and sample-wise scale worse than relearning all sub-tasks for a new algorithmic composition.","We also present a theorem in complexity theory, showing that gradient descent on memorizing feedforward models can be exponentially data inefficient."],"url":"http://arxiv.org/abs/2402.05785v1"}
{"created":"2024-02-08 16:17:24","title":"Text-to-Code Generation with Modality-relative Pre-training","abstract":"Large pre-trained language models have recently been expanded and applied to programming language tasks with great success, often through further pre-training of a strictly-natural language model--where training sequences typically contain both natural and (linearised) programming language. Such approaches effectively map both modalities of the sequence into the same embedding space. However, programming language keywords (e.g. ``while'') often have very strictly defined semantics. As such, transfer learning from their natural language usage may not necessarily be beneficial to their code application and vise versa. Assuming an already pre-trained language model, in this work we investigate how sequence tokens can be adapted and represented differently, depending on which modality they belong to, and to the ultimate benefit of the downstream task. We experiment with separating embedding spaces between modalities during further model pre-training with modality-relative training objectives. We focus on text-to-code generation and observe consistent improvements across two backbone models and two test sets, measuring pass@$k$ and a novel incremental variation.","sentences":["Large pre-trained language models have recently been expanded and applied to programming language tasks with great success, often through further pre-training of a strictly-natural language model--where training sequences typically contain both natural and (linearised) programming language.","Such approaches effectively map both modalities of the sequence into the same embedding space.","However, programming language keywords (e.g. ``while'') often have very strictly defined semantics.","As such, transfer learning from their natural language usage may not necessarily be beneficial to their code application and vise versa.","Assuming an already pre-trained language model, in this work we investigate how sequence tokens can be adapted and represented differently, depending on which modality they belong to, and to the ultimate benefit of the downstream task.","We experiment with separating embedding spaces between modalities during further model pre-training with modality-relative training objectives.","We focus on text-to-code generation and observe consistent improvements across two backbone models and two test sets, measuring pass@$k$ and a novel incremental variation."],"url":"http://arxiv.org/abs/2402.05783v1"}
{"created":"2024-02-08 16:17:18","title":"Analysing the Sample Complexity of Opponent Shaping","abstract":"Learning in general-sum games often yields collectively sub-optimal results. Addressing this, opponent shaping (OS) methods actively guide the learning processes of other agents, empirically leading to improved individual and group performances in many settings. Early OS methods use higher-order derivatives to shape the learning of co-players, making them unsuitable for shaping multiple learning steps. Follow-up work, Model-free Opponent Shaping (M-FOS), addresses these by reframing the OS problem as a meta-game. In contrast to early OS methods, there is little theoretical understanding of the M-FOS framework. Providing theoretical guarantees for M-FOS is hard because A) there is little literature on theoretical sample complexity bounds for meta-reinforcement learning B) M-FOS operates in continuous state and action spaces, so theoretical analysis is challenging. In this work, we present R-FOS, a tabular version of M-FOS that is more suitable for theoretical analysis. R-FOS discretises the continuous meta-game MDP into a tabular MDP. Within this discretised MDP, we adapt the $R_{max}$ algorithm, most prominently used to derive PAC-bounds for MDPs, as the meta-learner in the R-FOS algorithm. We derive a sample complexity bound that is exponential in the cardinality of the inner state and action space and the number of agents. Our bound guarantees that, with high probability, the final policy learned by an R-FOS agent is close to the optimal policy, apart from a constant factor. Finally, we investigate how R-FOS's sample complexity scales in the size of state-action space. Our theoretical results on scaling are supported empirically in the Matching Pennies environment.","sentences":["Learning in general-sum games often yields collectively sub-optimal results.","Addressing this, opponent shaping (OS) methods actively guide the learning processes of other agents, empirically leading to improved individual and group performances in many settings.","Early OS methods use higher-order derivatives to shape the learning of co-players, making them unsuitable for shaping multiple learning steps.","Follow-up work, Model-free Opponent Shaping (M-FOS), addresses these by reframing the OS problem as a meta-game.","In contrast to early OS methods, there is little theoretical understanding of the M-FOS framework.","Providing theoretical guarantees for M-FOS is hard because A) there is little literature on theoretical sample complexity bounds for meta-reinforcement learning B) M-FOS operates in continuous state and action spaces, so theoretical analysis is challenging.","In this work, we present R-FOS, a tabular version of M-FOS that is more suitable for theoretical analysis.","R-FOS discretises the continuous meta-game MDP into a tabular MDP.","Within this discretised MDP, we adapt the $R_{max}$ algorithm, most prominently used to derive PAC-bounds for MDPs, as the meta-learner in the R-FOS algorithm.","We derive a sample complexity bound that is exponential in the cardinality of the inner state and action space and the number of agents.","Our bound guarantees that, with high probability, the final policy learned by an R-FOS agent is close to the optimal policy, apart from a constant factor.","Finally, we investigate how R-FOS's sample complexity scales in the size of state-action space.","Our theoretical results on scaling are supported empirically in the Matching Pennies environment."],"url":"http://arxiv.org/abs/2402.05782v1"}
{"created":"2024-02-08 16:11:23","title":"Examining Gender and Racial Bias in Large Vision-Language Models Using a Novel Dataset of Parallel Images","abstract":"Following on recent advances in large language models (LLMs) and subsequent chat models, a new wave of large vision-language models (LVLMs) has emerged. Such models can incorporate images as input in addition to text, and perform tasks such as visual question answering, image captioning, story generation, etc. Here, we examine potential gender and racial biases in such systems, based on the perceived characteristics of the people in the input images. To accomplish this, we present a new dataset PAIRS (PArallel Images for eveRyday Scenarios). The PAIRS dataset contains sets of AI-generated images of people, such that the images are highly similar in terms of background and visual content, but differ along the dimensions of gender (man, woman) and race (Black, white). By querying the LVLMs with such images, we observe significant differences in the responses according to the perceived gender or race of the person depicted.","sentences":["Following on recent advances in large language models (LLMs) and subsequent chat models, a new wave of large vision-language models (LVLMs) has emerged.","Such models can incorporate images as input in addition to text, and perform tasks such as visual question answering, image captioning, story generation, etc.","Here, we examine potential gender and racial biases in such systems, based on the perceived characteristics of the people in the input images.","To accomplish this, we present a new dataset PAIRS (PArallel Images for eveRyday Scenarios).","The PAIRS dataset contains sets of AI-generated images of people, such that the images are highly similar in terms of background and visual content, but differ along the dimensions of gender (man, woman) and race (Black, white).","By querying the LVLMs with such images, we observe significant differences in the responses according to the perceived gender or race of the person depicted."],"url":"http://arxiv.org/abs/2402.05779v1"}
{"created":"2024-02-08 16:01:24","title":"Stable Autonomous Flow Matching","abstract":"In contexts where data samples represent a physically stable state, it is often assumed that the data points represent the local minima of an energy landscape. In control theory, it is well-known that energy can serve as an effective Lyapunov function. Despite this, connections between control theory and generative models in the literature are sparse, even though there are several machine learning applications with physically stable data points. In this paper, we focus on such data and a recent class of deep generative models called flow matching. We apply tools of stochastic stability for time-independent systems to flow matching models. In doing so, we characterize the space of flow matching models that are amenable to this treatment, as well as draw connections to other control theory principles. We demonstrate our theoretical results on two examples.","sentences":["In contexts where data samples represent a physically stable state, it is often assumed that the data points represent the local minima of an energy landscape.","In control theory, it is well-known that energy can serve as an effective Lyapunov function.","Despite this, connections between control theory and generative models in the literature are sparse, even though there are several machine learning applications with physically stable data points.","In this paper, we focus on such data and a recent class of deep generative models called flow matching.","We apply tools of stochastic stability for time-independent systems to flow matching models.","In doing so, we characterize the space of flow matching models that are amenable to this treatment, as well as draw connections to other control theory principles.","We demonstrate our theoretical results on two examples."],"url":"http://arxiv.org/abs/2402.05774v1"}
{"created":"2024-02-08 16:00:25","title":"UAV-Rain1k: A Benchmark for Raindrop Removal from UAV Aerial Imagery","abstract":"Raindrops adhering to the lens of UAVs can obstruct visibility of the background scene and degrade image quality. Despite recent progress in image deraining methods and datasets, there is a lack of focus on raindrop removal from UAV aerial imagery due to the unique challenges posed by varying angles and rapid movement during drone flight. To fill the gap in this research, we first construct a new benchmark dataset for removing raindrops from UAV images, called UAV-Rain1k. In this letter, we provide a dataset generation pipeline, which includes modeling raindrop shapes using Blender, collecting background images from various UAV angles, random sampling of rain masks and etc. Based on the proposed benchmark, we further present a comprehensive evaluation of existing representative image deraining algorithms, and reveal future research opportunities worth exploring. The proposed dataset will be publicly available at https://github.com/cschenxiang/UAV-Rain1k.","sentences":["Raindrops adhering to the lens of UAVs can obstruct visibility of the background scene and degrade image quality.","Despite recent progress in image deraining methods and datasets, there is a lack of focus on raindrop removal from UAV aerial imagery due to the unique challenges posed by varying angles and rapid movement during drone flight.","To fill the gap in this research, we first construct a new benchmark dataset for removing raindrops from UAV images, called UAV-Rain1k.","In this letter, we provide a dataset generation pipeline, which includes modeling raindrop shapes using Blender, collecting background images from various UAV angles, random sampling of rain masks and etc.","Based on the proposed benchmark, we further present a comprehensive evaluation of existing representative image deraining algorithms, and reveal future research opportunities worth exploring.","The proposed dataset will be publicly available at https://github.com/cschenxiang/UAV-Rain1k."],"url":"http://arxiv.org/abs/2402.05773v1"}
{"created":"2024-02-08 15:51:50","title":"Off-policy Distributional Q($\u03bb$): Distributional RL without Importance Sampling","abstract":"We introduce off-policy distributional Q($\\lambda$), a new addition to the family of off-policy distributional evaluation algorithms. Off-policy distributional Q($\\lambda$) does not apply importance sampling for off-policy learning, which introduces intriguing interactions with signed measures. Such unique properties distributional Q($\\lambda$) from other existing alternatives such as distributional Retrace. We characterize the algorithmic properties of distributional Q($\\lambda$) and validate theoretical insights with tabular experiments. We show how distributional Q($\\lambda$)-C51, a combination of Q($\\lambda$) with the C51 agent, exhibits promising results on deep RL benchmarks.","sentences":["We introduce off-policy distributional Q($\\lambda$), a new addition to the family of off-policy distributional evaluation algorithms.","Off-policy distributional Q($\\lambda$) does not apply importance sampling for off-policy learning, which introduces intriguing interactions with signed measures.","Such unique properties distributional Q($\\lambda$) from other existing alternatives such as distributional Retrace.","We characterize the algorithmic properties of distributional Q($\\lambda$) and validate theoretical insights with tabular experiments.","We show how distributional Q($\\lambda$)-C51, a combination of Q($\\lambda$) with the C51 agent, exhibits promising results on deep RL benchmarks."],"url":"http://arxiv.org/abs/2402.05766v1"}
{"created":"2024-02-08 15:49:58","title":"Datastringer: easy dataset monitoring for journalists","abstract":"We created a software enabling journalists to define a set of criteria they would like to see applied regularly to a constantly-updated dataset, sending them an alert when these criteria are met, thus signaling them that there may be a story to write. The main challenges were to keep the product scalable and powerful, while making sure that it could be used by journalists who would not possess all the technical knowledge to exploit it fully. In order to do so, we had to choose Javascript as our main language, as well as designing the code in such a way that it would allow re-usability and further improvements. This project is a proof of concept being tested in a real-life environment, and will be developed towards more and more accessibility.","sentences":["We created a software enabling journalists to define a set of criteria they would like to see applied regularly to a constantly-updated dataset, sending them an alert when these criteria are met, thus signaling them that there may be a story to write.","The main challenges were to keep the product scalable and powerful, while making sure that it could be used by journalists who would not possess all the technical knowledge to exploit it fully.","In order to do so, we had to choose Javascript as our main language, as well as designing the code in such a way that it would allow re-usability and further improvements.","This project is a proof of concept being tested in a real-life environment, and will be developed towards more and more accessibility."],"url":"http://arxiv.org/abs/2402.05764v1"}
{"created":"2024-02-08 15:41:48","title":"Latent variable model for high-dimensional point process with structured missingness","abstract":"Longitudinal data are important in numerous fields, such as healthcare, sociology and seismology, but real-world datasets present notable challenges for practitioners because they can be high-dimensional, contain structured missingness patterns, and measurement time points can be governed by an unknown stochastic process. While various solutions have been suggested, the majority of them have been designed to account for only one of these challenges. In this work, we propose a flexible and efficient latent-variable model that is capable of addressing all these limitations. Our approach utilizes Gaussian processes to capture temporal correlations between samples and their associated missingness masks as well as to model the underlying point process. We construct our model as a variational autoencoder together with deep neural network parameterised encoder and decoder models, and develop a scalable amortised variational inference approach for efficient model training. We demonstrate competitive performance using both simulated and real datasets.","sentences":["Longitudinal data are important in numerous fields, such as healthcare, sociology and seismology, but real-world datasets present notable challenges for practitioners because they can be high-dimensional, contain structured missingness patterns, and measurement time points can be governed by an unknown stochastic process.","While various solutions have been suggested, the majority of them have been designed to account for only one of these challenges.","In this work, we propose a flexible and efficient latent-variable model that is capable of addressing all these limitations.","Our approach utilizes Gaussian processes to capture temporal correlations between samples and their associated missingness masks as well as to model the underlying point process.","We construct our model as a variational autoencoder together with deep neural network parameterised encoder and decoder models, and develop a scalable amortised variational inference approach for efficient model training.","We demonstrate competitive performance using both simulated and real datasets."],"url":"http://arxiv.org/abs/2402.05758v1"}
{"created":"2024-02-08 15:41:22","title":"When is Mean-Field Reinforcement Learning Tractable and Relevant?","abstract":"Mean-field reinforcement learning has become a popular theoretical framework for efficiently approximating large-scale multi-agent reinforcement learning (MARL) problems exhibiting symmetry. However, questions remain regarding the applicability of mean-field approximations: in particular, their approximation accuracy of real-world systems and conditions under which they become computationally tractable. We establish explicit finite-agent bounds for how well the MFG solution approximates the true $N$-player game for two popular mean-field solution concepts. Furthermore, for the first time, we establish explicit lower bounds indicating that MFGs are poor or uninformative at approximating $N$-player games assuming only Lipschitz dynamics and rewards. Finally, we analyze the computational complexity of solving MFGs with only Lipschitz properties and prove that they are in the class of \\textsc{PPAD}-complete problems conjectured to be intractable, similar to general sum $N$ player games. Our theoretical results underscore the limitations of MFGs and complement and justify existing work by proving difficulty in the absence of common theoretical assumptions.","sentences":["Mean-field reinforcement learning has become a popular theoretical framework for efficiently approximating large-scale multi-agent reinforcement learning (MARL) problems exhibiting symmetry.","However, questions remain regarding the applicability of mean-field approximations: in particular, their approximation accuracy of real-world systems and conditions under which they become computationally tractable.","We establish explicit finite-agent bounds for how well the MFG solution approximates the true $N$-player game for two popular mean-field solution concepts.","Furthermore, for the first time, we establish explicit lower bounds indicating that MFGs are poor or uninformative at approximating $N$-player games assuming only Lipschitz dynamics and rewards.","Finally, we analyze the computational complexity of solving MFGs with only Lipschitz properties and prove that they are in the class of \\textsc{PPAD}-complete problems conjectured to be intractable, similar to general sum $N$ player games.","Our theoretical results underscore the limitations of MFGs and complement and justify existing work by proving difficulty in the absence of common theoretical assumptions."],"url":"http://arxiv.org/abs/2402.05757v1"}
{"created":"2024-02-08 15:39:32","title":"SpiRit-LM: Interleaved Spoken and Written Language Model","abstract":"We introduce SPIRIT-LM, a foundation multimodal language model that freely mixes text and speech. Our model is based on a pretrained text language model that we extend to the speech modality by continuously training it on text and speech units. Speech and text sequences are concatenated as a single set of tokens, and trained with a word-level interleaving method using a small automatically-curated speech-text parallel corpus. SPIRIT-LM comes in two versions: a BASE version that uses speech semantic units and an EXPRESSIVE version that models expressivity using pitch and style units in addition to the semantic units. For both versions, the text is encoded with subword BPE tokens. The resulting model displays both the semantic abilities of text models and the expressive abilities of speech models. Additionally, we demonstrate that SPIRIT-LM is able to learn new tasks in a few-shot fashion across modalities (i.e. ASR, TTS, Speech Classification).","sentences":["We introduce SPIRIT-LM, a foundation multimodal language model that freely mixes text and speech.","Our model is based on a pretrained text language model that we extend to the speech modality by continuously training it on text and speech units.","Speech and text sequences are concatenated as a single set of tokens, and trained with a word-level interleaving method using a small automatically-curated speech-text parallel corpus.","SPIRIT-LM comes in two versions: a BASE version that uses speech semantic units and an EXPRESSIVE version that models expressivity using pitch and style units in addition to the semantic units.","For both versions, the text is encoded with subword BPE tokens.","The resulting model displays both the semantic abilities of text models and the expressive abilities of speech models.","Additionally, we demonstrate that SPIRIT-LM is able to learn new tasks in a few-shot fashion across modalities (i.e. ASR, TTS, Speech Classification)."],"url":"http://arxiv.org/abs/2402.05755v1"}
{"created":"2024-02-08 15:33:09","title":"Generalized Preference Optimization: A Unified Approach to Offline Alignment","abstract":"Offline preference optimization allows fine-tuning large models directly from offline data, and has proved effective in recent alignment practices. We propose generalized preference optimization (GPO), a family of offline losses parameterized by a general class of convex functions. GPO enables a unified view over preference optimization, encompassing existing algorithms such as DPO, IPO and SLiC as special cases, while naturally introducing new variants. The GPO framework also sheds light on how offline algorithms enforce regularization, through the design of the convex function that defines the loss. Our analysis and experiments reveal the connections and subtle differences between the offline regularization and the KL divergence regularization intended by the canonical RLHF formulation. In all, our results present new algorithmic toolkits and empirical insights to alignment practitioners.","sentences":["Offline preference optimization allows fine-tuning large models directly from offline data, and has proved effective in recent alignment practices.","We propose generalized preference optimization (GPO), a family of offline losses parameterized by a general class of convex functions.","GPO enables a unified view over preference optimization, encompassing existing algorithms such as DPO, IPO and SLiC as special cases, while naturally introducing new variants.","The GPO framework also sheds light on how offline algorithms enforce regularization, through the design of the convex function that defines the loss.","Our analysis and experiments reveal the connections and subtle differences between the offline regularization and the KL divergence regularization intended by the canonical RLHF formulation.","In all, our results present new algorithmic toolkits and empirical insights to alignment practitioners."],"url":"http://arxiv.org/abs/2402.05749v1"}
{"created":"2024-02-08 15:32:22","title":"Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method","abstract":"In the context of rapid advancements in industrial automation, vision-based robotic grasping plays an increasingly crucial role. In order to enhance visual recognition accuracy, the utilization of large-scale datasets is imperative for training models to acquire implicit knowledge related to the handling of various objects. Creating datasets from scratch is a time and labor-intensive process. Moreover, existing datasets often contain errors due to automated annotations aimed at expediency, making the improvement of these datasets a substantial research challenge. Consequently, several issues have been identified in the annotation of grasp bounding boxes within the popular Jacquard Grasp. We propose utilizing a Human-In-The-Loop(HIL) method to enhance dataset quality. This approach relies on backbone deep learning networks to predict object positions and orientations for robotic grasping. Predictions with Intersection over Union (IOU) values below 0.2 undergo an assessment by human operators. After their evaluation, the data is categorized into False Negatives(FN) and True Negatives(TN). FN are then subcategorized into either missing annotations or catastrophic labeling errors. Images lacking labels are augmented with valid grasp bounding box information, whereas images afflicted by catastrophic labeling errors are completely removed. The open-source tool Labelbee was employed for 53,026 iterations of HIL dataset enhancement, leading to the removal of 2,884 images and the incorporation of ground truth information for 30,292 images. The enhanced dataset, named the Jacquard V2 Grasping Dataset, served as the training data for a range of neural networks.","sentences":["In the context of rapid advancements in industrial automation, vision-based robotic grasping plays an increasingly crucial role.","In order to enhance visual recognition accuracy, the utilization of large-scale datasets is imperative for training models to acquire implicit knowledge related to the handling of various objects.","Creating datasets from scratch is a time and labor-intensive process.","Moreover, existing datasets often contain errors due to automated annotations aimed at expediency, making the improvement of these datasets a substantial research challenge.","Consequently, several issues have been identified in the annotation of grasp bounding boxes within the popular Jacquard Grasp.","We propose utilizing a Human-In-The-Loop(HIL) method to enhance dataset quality.","This approach relies on backbone deep learning networks to predict object positions and orientations for robotic grasping.","Predictions with Intersection over Union (IOU) values below 0.2 undergo an assessment by human operators.","After their evaluation, the data is categorized into False Negatives(FN) and True Negatives(TN).","FN are then subcategorized into either missing annotations or catastrophic labeling errors.","Images lacking labels are augmented with valid grasp bounding box information, whereas images afflicted by catastrophic labeling errors are completely removed.","The open-source tool Labelbee was employed for 53,026 iterations of HIL dataset enhancement, leading to the removal of 2,884 images and the incorporation of ground truth information for 30,292 images.","The enhanced dataset, named the Jacquard V2 Grasping Dataset, served as the training data for a range of neural networks."],"url":"http://arxiv.org/abs/2402.05747v1"}
{"created":"2024-02-08 15:26:28","title":"Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents","abstract":"Scene simulation in autonomous driving has gained significant attention because of its huge potential for generating customized data. However, existing editable scene simulation approaches face limitations in terms of user interaction efficiency, multi-camera photo-realistic rendering and external digital assets integration. To address these challenges, this paper introduces ChatSim, the first system that enables editable photo-realistic 3D driving scene simulations via natural language commands with external digital assets. To enable editing with high command flexibility,~ChatSim leverages a large language model (LLM) agent collaboration framework. To generate photo-realistic outcomes, ChatSim employs a novel multi-camera neural radiance field method. Furthermore, to unleash the potential of extensive high-quality digital assets, ChatSim employs a novel multi-camera lighting estimation method to achieve scene-consistent assets' rendering. Our experiments on Waymo Open Dataset demonstrate that ChatSim can handle complex language commands and generate corresponding photo-realistic scene videos.","sentences":["Scene simulation in autonomous driving has gained significant attention because of its huge potential for generating customized data.","However, existing editable scene simulation approaches face limitations in terms of user interaction efficiency, multi-camera photo-realistic rendering and external digital assets integration.","To address these challenges, this paper introduces ChatSim, the first system that enables editable photo-realistic 3D driving scene simulations via natural language commands with external digital assets.","To enable editing with high command flexibility,~ChatSim leverages a large language model (LLM) agent collaboration framework.","To generate photo-realistic outcomes, ChatSim employs a novel multi-camera neural radiance field method.","Furthermore, to unleash the potential of extensive high-quality digital assets, ChatSim employs a novel multi-camera lighting estimation method to achieve scene-consistent assets' rendering.","Our experiments on Waymo Open Dataset demonstrate that ChatSim can handle complex language commands and generate corresponding photo-realistic scene videos."],"url":"http://arxiv.org/abs/2402.05746v1"}
{"created":"2024-02-08 15:19:50","title":"Real-World Robot Applications of Foundation Models: A Review","abstract":"Recent developments in foundation models, like Large Language Models (LLMs) and Vision-Language Models (VLMs), trained on extensive data, facilitate flexible application across different tasks and modalities. Their impact spans various fields, including healthcare, education, and robotics. This paper provides an overview of the practical application of foundation models in real-world robotics, with a primary emphasis on the replacement of specific components within existing robot systems. The summary encompasses the perspective of input-output relationships in foundation models, as well as their role in perception, motion planning, and control within the field of robotics. This paper concludes with a discussion of future challenges and implications for practical robot applications.","sentences":["Recent developments in foundation models, like Large Language Models (LLMs) and Vision-Language Models (VLMs), trained on extensive data, facilitate flexible application across different tasks and modalities.","Their impact spans various fields, including healthcare, education, and robotics.","This paper provides an overview of the practical application of foundation models in real-world robotics, with a primary emphasis on the replacement of specific components within existing robot systems.","The summary encompasses the perspective of input-output relationships in foundation models, as well as their role in perception, motion planning, and control within the field of robotics.","This paper concludes with a discussion of future challenges and implications for practical robot applications."],"url":"http://arxiv.org/abs/2402.05741v1"}
{"created":"2024-02-08 15:18:54","title":"CounterCLR: Counterfactual Contrastive Learning with Non-random Missing Data in Recommendation","abstract":"Recommender systems are designed to learn user preferences from observed feedback and comprise many fundamental tasks, such as rating prediction and post-click conversion rate (pCVR) prediction. However, the observed feedback usually suffer from two issues: selection bias and data sparsity, where biased and insufficient feedback seriously degrade the performance of recommender systems in terms of accuracy and ranking. Existing solutions for handling the issues, such as data imputation and inverse propensity score, are highly susceptible to additional trained imputation or propensity models. In this work, we propose a novel counterfactual contrastive learning framework for recommendation, named CounterCLR, to tackle the problem of non-random missing data by exploiting the advances in contrast learning. Specifically, the proposed CounterCLR employs a deep representation network, called CauNet, to infer non-random missing data in recommendations and perform user preference modeling by further introducing a self-supervised contrastive learning task. Our CounterCLR mitigates the selection bias problem without the need for additional models or estimators, while also enhancing the generalization ability in cases of sparse data. Experiments on real-world datasets demonstrate the effectiveness and superiority of our method.","sentences":["Recommender systems are designed to learn user preferences from observed feedback and comprise many fundamental tasks, such as rating prediction and post-click conversion rate (pCVR) prediction.","However, the observed feedback usually suffer from two issues: selection bias and data sparsity, where biased and insufficient feedback seriously degrade the performance of recommender systems in terms of accuracy and ranking.","Existing solutions for handling the issues, such as data imputation and inverse propensity score, are highly susceptible to additional trained imputation or propensity models.","In this work, we propose a novel counterfactual contrastive learning framework for recommendation, named CounterCLR, to tackle the problem of non-random missing data by exploiting the advances in contrast learning.","Specifically, the proposed CounterCLR employs a deep representation network, called CauNet, to infer non-random missing data in recommendations and perform user preference modeling by further introducing a self-supervised contrastive learning task.","Our CounterCLR mitigates the selection bias problem without the need for additional models or estimators, while also enhancing the generalization ability in cases of sparse data.","Experiments on real-world datasets demonstrate the effectiveness and superiority of our method."],"url":"http://arxiv.org/abs/2402.05740v1"}
{"created":"2024-02-08 15:15:09","title":"Implicit Bias and Fast Convergence Rates for Self-attention","abstract":"Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance. Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification. Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects. Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape. Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in the attention map. Thirdly, through an analysis of normalized GD and Polyak step-size, we demonstrate analytically that adaptive step-size rules can accelerate the convergence of self-attention. Additionally, we remove the restriction of prior work on a fixed linear decoder. Our results reinforce the implicit-bias perspective of self-attention and strengthen its connections to implicit-bias in linear logistic regression, despite the intricate non-convex nature of the former.","sentences":["Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance.","Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification.","Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects.","Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape.","Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in the attention map.","Thirdly, through an analysis of normalized GD and Polyak step-size, we demonstrate analytically that adaptive step-size rules can accelerate the convergence of self-attention.","Additionally, we remove the restriction of prior work on a fixed linear decoder.","Our results reinforce the implicit-bias perspective of self-attention and strengthen its connections to implicit-bias in linear logistic regression, despite the intricate non-convex nature of the former."],"url":"http://arxiv.org/abs/2402.05738v1"}
{"created":"2024-02-08 15:14:39","title":"Blockchain Based Residential Smart Rent","abstract":"The real estate market includes complex and inefficient mediation processes. Renting a property envolves multiple entities with different responsibilities and interests. Therefore it is imperative to establish a trustful relationship between parties through intermediaries such as notaries, banks or real estate agencies to avoid eventual disputes. Although an intermediary ensures trust, the current process still has some drawbacks concerning efficiency, costs, transparency, bureaucracy and data security. The blockchain technology aims to reduce this issues by providing transparent and secure real estate transactions. We propose a GDPR compliant blockchain-based residential smart rental platform, designed to allow both landlords and tenants to establish rental contracts and make rental payments securely.","sentences":["The real estate market includes complex and inefficient mediation processes.","Renting a property envolves multiple entities with different responsibilities and interests.","Therefore it is imperative to establish a trustful relationship between parties through intermediaries such as notaries, banks or real estate agencies to avoid eventual disputes.","Although an intermediary ensures trust, the current process still has some drawbacks concerning efficiency, costs, transparency, bureaucracy and data security.","The blockchain technology aims to reduce this issues by providing transparent and secure real estate transactions.","We propose a GDPR compliant blockchain-based residential smart rental platform, designed to allow both landlords and tenants to establish rental contracts and make rental payments securely."],"url":"http://arxiv.org/abs/2402.05737v1"}
