{"created":"2024-02-05 18:59:52","title":"Test-Time Adaptation for Depth Completion","abstract":"It is common to observe performance degradation when transferring models trained on some (source) datasets to target testing data due to a domain gap between them. Existing methods for bridging this gap, such as domain adaptation (DA), may require the source data on which the model was trained (often not available), while others, i.e., source-free DA, require many passes through the testing data. We propose an online test-time adaptation method for depth completion, the task of inferring a dense depth map from a single image and associated sparse depth map, that closes the performance gap in a single pass. We first present a study on how the domain shift in each data modality affects model performance. Based on our observations that the sparse depth modality exhibits a much smaller covariate shift than the image, we design an embedding module trained in the source domain that preserves a mapping from features encoding only sparse depth to those encoding image and sparse depth. During test time, sparse depth features are projected using this map as a proxy for source domain features and are used as guidance to train a set of auxiliary parameters (i.e., adaptation layer) to align image and sparse depth features from the target test domain to that of the source domain. We evaluate our method on indoor and outdoor scenarios and show that it improves over baselines by an average of 21.1%.","sentences":["It is common to observe performance degradation when transferring models trained on some (source) datasets to target testing data due to a domain gap between them.","Existing methods for bridging this gap, such as domain adaptation (DA), may require the source data on which the model was trained (often not available), while others, i.e., source-free DA, require many passes through the testing data.","We propose an online test-time adaptation method for depth completion, the task of inferring a dense depth map from a single image and associated sparse depth map, that closes the performance gap in a single pass.","We first present a study on how the domain shift in each data modality affects model performance.","Based on our observations that the sparse depth modality exhibits a much smaller covariate shift than the image, we design an embedding module trained in the source domain that preserves a mapping from features encoding only sparse depth to those encoding image and sparse depth.","During test time, sparse depth features are projected using this map as a proxy for source domain features and are used as guidance to train a set of auxiliary parameters (i.e., adaptation layer) to align image and sparse depth features from the target test domain to that of the source domain.","We evaluate our method on indoor and outdoor scenarios and show that it improves over baselines by an average of 21.1%."],"url":"http://arxiv.org/abs/2402.03312v1"}
{"created":"2024-02-05 18:59:41","title":"HASSOD: Hierarchical Adaptive Self-Supervised Object Detection","abstract":"The human visual perception system demonstrates exceptional capabilities in learning without explicit supervision and understanding the part-to-whole composition of objects. Drawing inspiration from these two abilities, we propose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a novel approach that learns to detect objects and understand their compositions without human supervision. HASSOD employs a hierarchical adaptive clustering strategy to group regions into object masks based on self-supervised visual representations, adaptively determining the number of objects per image. Furthermore, HASSOD identifies the hierarchical levels of objects in terms of composition, by analyzing coverage relations between masks and constructing tree structures. This additional self-supervised learning task leads to improved detection performance and enhanced interpretability. Lastly, we abandon the inefficient multi-round self-training process utilized in prior methods and instead adapt the Mean Teacher framework from semi-supervised learning, which leads to a smoother and more efficient training process. Through extensive experiments on prevalent image datasets, we demonstrate the superiority of HASSOD over existing methods, thereby advancing the state of the art in self-supervised object detection. Notably, we improve Mask AR from 20.2 to 22.5 on LVIS, and from 17.0 to 26.0 on SA-1B. Project page: https://HASSOD-NeurIPS23.github.io.","sentences":["The human visual perception system demonstrates exceptional capabilities in learning without explicit supervision and understanding the part-to-whole composition of objects.","Drawing inspiration from these two abilities, we propose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a novel approach that learns to detect objects and understand their compositions without human supervision.","HASSOD employs a hierarchical adaptive clustering strategy to group regions into object masks based on self-supervised visual representations, adaptively determining the number of objects per image.","Furthermore, HASSOD identifies the hierarchical levels of objects in terms of composition, by analyzing coverage relations between masks and constructing tree structures.","This additional self-supervised learning task leads to improved detection performance and enhanced interpretability.","Lastly, we abandon the inefficient multi-round self-training process utilized in prior methods and instead adapt the Mean Teacher framework from semi-supervised learning, which leads to a smoother and more efficient training process.","Through extensive experiments on prevalent image datasets, we demonstrate the superiority of HASSOD over existing methods, thereby advancing the state of the art in self-supervised object detection.","Notably, we improve Mask AR from 20.2 to 22.5 on LVIS, and from 17.0 to 26.0 on SA-1B. Project page: https://HASSOD-NeurIPS23.github.io."],"url":"http://arxiv.org/abs/2402.03311v1"}
{"created":"2024-02-05 18:59:36","title":"V-IRL: Grounding Virtual Intelligence in Real Life","abstract":"There is a sensory gulf between the Earth that humans inhabit and the digital realms in which modern AI agents are created. To develop AI agents that can sense, think, and act as flexibly as humans in real-world settings, it is imperative to bridge the realism gap between the digital and physical worlds. How can we embody agents in an environment as rich and diverse as the one we inhabit, without the constraints imposed by real hardware and control? Towards this end, we introduce V-IRL: a platform that enables agents to scalably interact with the real world in a virtual yet realistic environment. Our platform serves as a playground for developing agents that can accomplish various practical tasks and as a vast testbed for measuring progress in capabilities spanning perception, decision-making, and interaction with real-world data across the entire globe.","sentences":["There is a sensory gulf between the Earth that humans inhabit and the digital realms in which modern AI agents are created.","To develop AI agents that can sense, think, and act as flexibly as humans in real-world settings, it is imperative to bridge the realism gap between the digital and physical worlds.","How can we embody agents in an environment as rich and diverse as the one we inhabit, without the constraints imposed by real hardware and control?","Towards this end, we introduce V-IRL: a platform that enables agents to scalably interact with the real world in a virtual yet realistic environment.","Our platform serves as a playground for developing agents that can accomplish various practical tasks and as a vast testbed for measuring progress in capabilities spanning perception, decision-making, and interaction with real-world data across the entire globe."],"url":"http://arxiv.org/abs/2402.03310v1"}
{"created":"2024-02-05 18:59:31","title":"AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion","abstract":"Underwater perception and 3D surface reconstruction are challenging problems with broad applications in construction, security, marine archaeology, and environmental monitoring. Treacherous operating conditions, fragile surroundings, and limited navigation control often dictate that submersibles restrict their range of motion and, thus, the baseline over which they can capture measurements. In the context of 3D scene reconstruction, it is well-known that smaller baselines make reconstruction more challenging. Our work develops a physics-based multimodal acoustic-optical neural surface reconstruction framework (AONeuS) capable of effectively integrating high-resolution RGB measurements with low-resolution depth-resolved imaging sonar measurements. By fusing these complementary modalities, our framework can reconstruct accurate high-resolution 3D surfaces from measurements captured over heavily-restricted baselines. Through extensive simulations and in-lab experiments, we demonstrate that AONeuS dramatically outperforms recent RGB-only and sonar-only inverse-differentiable-rendering--based surface reconstruction methods. A website visualizing the results of our paper is located at this address: https://aoneus.github.io/","sentences":["Underwater perception and 3D surface reconstruction are challenging problems with broad applications in construction, security, marine archaeology, and environmental monitoring.","Treacherous operating conditions, fragile surroundings, and limited navigation control often dictate that submersibles restrict their range of motion and, thus, the baseline over which they can capture measurements.","In the context of 3D scene reconstruction, it is well-known that smaller baselines make reconstruction more challenging.","Our work develops a physics-based multimodal acoustic-optical neural surface reconstruction framework (AONeuS) capable of effectively integrating high-resolution RGB measurements with low-resolution depth-resolved imaging sonar measurements.","By fusing these complementary modalities, our framework can reconstruct accurate high-resolution 3D surfaces from measurements captured over heavily-restricted baselines.","Through extensive simulations and in-lab experiments, we demonstrate that AONeuS dramatically outperforms recent RGB-only and sonar-only inverse-differentiable-rendering--based surface reconstruction methods.","A website visualizing the results of our paper is located at this address: https://aoneus.github.io/"],"url":"http://arxiv.org/abs/2402.03309v1"}
{"created":"2024-02-05 18:59:04","title":"4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes","abstract":"We consider the problem of novel view synthesis (NVS) for dynamic scenes. Recent neural approaches have accomplished exceptional NVS results for static 3D scenes, but extensions to 4D time-varying scenes remain non-trivial. Prior efforts often encode dynamics by learning a canonical space plus implicit or explicit deformation fields, which struggle in challenging scenarios like sudden movements or capturing high-fidelity renderings. In this paper, we introduce 4D Gaussian Splatting (4DGS), a novel method that represents dynamic scenes with anisotropic 4D XYZT Gaussians, inspired by the success of 3D Gaussian Splatting in static scenes. We model dynamics at each timestamp by temporally slicing the 4D Gaussians, which naturally compose dynamic 3D Gaussians and can be seamlessly projected into images. As an explicit spatial-temporal representation, 4DGS demonstrates powerful capabilities for modeling complicated dynamics and fine details, especially for scenes with abrupt motions. We further implement our temporal slicing and splatting techniques in a highly optimized CUDA acceleration framework, achieving real-time inference rendering speeds of up to 277 FPS on an RTX 3090 GPU and 583 FPS on an RTX 4090 GPU. Rigorous evaluations on scenes with diverse motions showcase the superior efficiency and effectiveness of 4DGS, which consistently outperforms existing methods both quantitatively and qualitatively.","sentences":["We consider the problem of novel view synthesis (NVS) for dynamic scenes.","Recent neural approaches have accomplished exceptional NVS results for static 3D scenes, but extensions to 4D time-varying scenes remain non-trivial.","Prior efforts often encode dynamics by learning a canonical space plus implicit or explicit deformation fields, which struggle in challenging scenarios like sudden movements or capturing high-fidelity renderings.","In this paper, we introduce 4D Gaussian Splatting (4DGS), a novel method that represents dynamic scenes with anisotropic 4D XYZT Gaussians, inspired by the success of 3D Gaussian Splatting in static scenes.","We model dynamics at each timestamp by temporally slicing the 4D Gaussians, which naturally compose dynamic 3D Gaussians and can be seamlessly projected into images.","As an explicit spatial-temporal representation, 4DGS demonstrates powerful capabilities for modeling complicated dynamics and fine details, especially for scenes with abrupt motions.","We further implement our temporal slicing and splatting techniques in a highly optimized CUDA acceleration framework, achieving real-time inference rendering speeds of up to 277 FPS on an RTX 3090 GPU and 583 FPS on an RTX 4090 GPU.","Rigorous evaluations on scenes with diverse motions showcase the superior efficiency and effectiveness of 4DGS, which consistently outperforms existing methods both quantitatively and qualitatively."],"url":"http://arxiv.org/abs/2402.03307v1"}
{"created":"2024-02-05 18:58:57","title":"Fast solutions to k-parity and k-synchronisation using parallel automata networks","abstract":"We present a family of automata networks that solve the k-parity problem when run in parallel. These solutions are constructed by connecting cliques in a non-cyclical fashion. The size of the local neighbourhood is linear in the size of the alphabet, and the convergence time is proven to always be the diameter of the interaction graph. We show that this family of solutions can be slightly altered to obtain an equivalent family of solutions to the k-synchronisation problem, which means that these solutions converge from any initial configuration to the cycle which contains all the uniform configurations over the alphabet, in order.","sentences":["We present a family of automata networks that solve the k-parity problem when run in parallel.","These solutions are constructed by connecting cliques in a non-cyclical fashion.","The size of the local neighbourhood is linear in the size of the alphabet, and the convergence time is proven to always be the diameter of the interaction graph.","We show that this family of solutions can be slightly altered to obtain an equivalent family of solutions to the k-synchronisation problem, which means that these solutions converge from any initial configuration to the cycle which contains all the uniform configurations over the alphabet, in order."],"url":"http://arxiv.org/abs/2402.03306v1"}
{"created":"2024-02-05 18:58:38","title":"Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?","abstract":"Diffusion models are capable of impressive feats of image generation with uncommon juxtapositions such as astronauts riding horses on the moon with properly placed shadows. These outputs indicate the ability to perform compositional generalization, but how do the models do so? We perform controlled experiments on conditional DDPMs learning to generate 2D spherical Gaussian bumps centered at specified $x$- and $y$-positions. Our results show that the emergence of semantically meaningful latent representations is key to achieving high performance. En route to successful performance over learning, the model traverses three distinct phases of latent representations: (phase A) no latent structure, (phase B) a 2D manifold of disordered states, and (phase C) a 2D ordered manifold. Corresponding to each of these phases, we identify qualitatively different generation behaviors: 1) multiple bumps are generated, 2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is generated at the correct $x$ and y location. Furthermore, we show that even under imbalanced datasets where features ($x$- versus $y$-positions) are represented with skewed frequencies, the learning process for $x$ and $y$ is coupled rather than factorized, demonstrating that simple vanilla-flavored diffusion models cannot learn efficient representations in which localization in $x$ and $y$ are factorized into separate 1D tasks. These findings suggest the need for future work to find inductive biases that will push generative models to discover and exploit factorizable independent structures in their inputs, which will be required to vault these models into more data-efficient regimes.","sentences":["Diffusion models are capable of impressive feats of image generation with uncommon juxtapositions such as astronauts riding horses on the moon with properly placed shadows.","These outputs indicate the ability to perform compositional generalization, but how do the models do so?","We perform controlled experiments on conditional DDPMs learning to generate 2D spherical Gaussian bumps centered at specified $x$- and $y$-positions.","Our results show that the emergence of semantically meaningful latent representations is key to achieving high performance.","En route to successful performance over learning, the model traverses three distinct phases of latent representations: (phase A) no latent structure, (phase B) a 2D manifold of disordered states, and (phase C) a 2D ordered manifold.","Corresponding to each of these phases, we identify qualitatively different generation behaviors: 1) multiple bumps are generated, 2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is generated at the correct $x$ and y location.","Furthermore, we show that even under imbalanced datasets where features ($x$- versus $y$-positions) are represented with skewed frequencies, the learning process for $x$ and $y$ is coupled rather than factorized, demonstrating that simple vanilla-flavored diffusion models cannot learn efficient representations in which localization in $x$ and $y$ are factorized into separate 1D tasks.","These findings suggest the need for future work to find inductive biases that will push generative models to discover and exploit factorizable independent structures in their inputs, which will be required to vault these models into more data-efficient regimes."],"url":"http://arxiv.org/abs/2402.03305v1"}
{"created":"2024-02-05 18:58:19","title":"Nevermind: Instruction Override and Moderation in Large Language Models","abstract":"Given the impressive capabilities of recent Large Language Models (LLMs), we investigate and benchmark the most popular proprietary and different sized open source models on the task of explicit instruction following in conflicting situations, e.g. overrides. These include the ability of the model to override the knowledge within the weights of the model, the ability to override (or moderate) extracted knowledge in the prompt, and lastly the ability to perform a full jailbreak. Experimentation performed suggest several key findings to improve instruction following - larger models perform the best in following instructions that override internal and contextual instructions, and are obedient, even to a fault. When scaling to longer contexts via rope scaling, a significant buffer needs to be maintained from the edge of the perplexity cliff in order to maintain instruction following capabilities. Finally, we observe improving instruction following, and subsequently instruction overrides/jailbreaks, is fundamentally at odds with the ability of a language model to follow given safety filters or guidelines. Thus, we postulate the most effective approach for safe, trustworthy AI should be dealt external to the LLM itself.","sentences":["Given the impressive capabilities of recent Large Language Models (LLMs), we investigate and benchmark the most popular proprietary and different sized open source models on the task of explicit instruction following in conflicting situations, e.g. overrides.","These include the ability of the model to override the knowledge within the weights of the model, the ability to override (or moderate) extracted knowledge in the prompt, and lastly the ability to perform a full jailbreak.","Experimentation performed suggest several key findings to improve instruction following - larger models perform the best in following instructions that override internal and contextual instructions, and are obedient, even to a fault.","When scaling to longer contexts via rope scaling, a significant buffer needs to be maintained from the edge of the perplexity cliff in order to maintain instruction following capabilities.","Finally, we observe improving instruction following, and subsequently instruction overrides/jailbreaks, is fundamentally at odds with the ability of a language model to follow given safety filters or guidelines.","Thus, we postulate the most effective approach for safe, trustworthy AI should be dealt external to the LLM itself."],"url":"http://arxiv.org/abs/2402.03303v1"}
{"created":"2024-02-05 18:58:11","title":"Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining","abstract":"Accurate medical image segmentation demands the integration of multi-scale information, spanning from local features to global dependencies. However, it is challenging for existing methods to model long-range global information, where convolutional neural networks (CNNs) are constrained by their local receptive fields, and vision transformers (ViTs) suffer from high quadratic complexity of their attention mechanism. Recently, Mamba-based models have gained great attention for their impressive ability in long sequence modeling. Several studies have demonstrated that these models can outperform popular vision models in various tasks, offering higher accuracy, lower memory consumption, and less computational burden. However, existing Mamba-based models are mostly trained from scratch and do not explore the power of pretraining, which has been proven to be quite effective for data-efficient medical image analysis. This paper introduces a novel Mamba-based model, Swin-UMamba, designed specifically for medical image segmentation tasks, leveraging the advantages of ImageNet-based pretraining. Our experimental results reveal the vital role of ImageNet-based training in enhancing the performance of Mamba-based models. Swin-UMamba demonstrates superior performance with a large margin compared to CNNs, ViTs, and latest Mamba-based models. Notably, on AbdomenMRI, Encoscopy, and Microscopy datasets, Swin-UMamba outperforms its closest counterpart U-Mamba by an average score of 3.58%. The code and models of Swin-UMamba are publicly available at: https://github.com/JiarunLiu/Swin-UMamba","sentences":["Accurate medical image segmentation demands the integration of multi-scale information, spanning from local features to global dependencies.","However, it is challenging for existing methods to model long-range global information, where convolutional neural networks (CNNs) are constrained by their local receptive fields, and vision transformers (ViTs) suffer from high quadratic complexity of their attention mechanism.","Recently, Mamba-based models have gained great attention for their impressive ability in long sequence modeling.","Several studies have demonstrated that these models can outperform popular vision models in various tasks, offering higher accuracy, lower memory consumption, and less computational burden.","However, existing Mamba-based models are mostly trained from scratch and do not explore the power of pretraining, which has been proven to be quite effective for data-efficient medical image analysis.","This paper introduces a novel Mamba-based model, Swin-UMamba, designed specifically for medical image segmentation tasks, leveraging the advantages of ImageNet-based pretraining.","Our experimental results reveal the vital role of ImageNet-based training in enhancing the performance of Mamba-based models.","Swin-UMamba demonstrates superior performance with a large margin compared to CNNs, ViTs, and latest Mamba-based models.","Notably, on AbdomenMRI, Encoscopy, and Microscopy datasets, Swin-UMamba outperforms its closest counterpart U-Mamba by an average score of 3.58%.","The code and models of Swin-UMamba are publicly available at: https://github.com/JiarunLiu/Swin-UMamba"],"url":"http://arxiv.org/abs/2402.03302v1"}
{"created":"2024-02-05 18:55:32","title":"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models","abstract":"Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.","sentences":["Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature.","In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data.","DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4.","Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH.","The mathematical reasoning capability of DeepSeekMath is attributed to two key factors:","First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline.","Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO."],"url":"http://arxiv.org/abs/2402.03300v1"}
{"created":"2024-02-05 18:54:43","title":"GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models","abstract":"The discovery of \"jailbreaks\" to bypass safety filters of Large Language Models (LLMs) and harmful responses have encouraged the community to implement safety measures. One major safety measure is to proactively test the LLMs with jailbreaks prior to the release. Therefore, such testing will require a method that can generate jailbreaks massively and efficiently. In this paper, we follow a novel yet intuitive strategy to generate jailbreaks in the style of the human generation. We propose a role-playing system that assigns four different roles to the user LLMs to collaborate on new jailbreaks. Furthermore, we collect existing jailbreaks and split them into different independent characteristics using clustering frequency and semantic patterns sentence by sentence. We organize these characteristics into a knowledge graph, making them more accessible and easier to retrieve. Our system of different roles will leverage this knowledge graph to generate new jailbreaks, which have proved effective in inducing LLMs to generate unethical or guideline-violating responses. In addition, we also pioneer a setting in our system that will automatically follow the government-issued guidelines to generate jailbreaks to test whether LLMs follow the guidelines accordingly. We refer to our system as GUARD (Guideline Upholding through Adaptive Role-play Diagnostics). We have empirically validated the effectiveness of GUARD on three cutting-edge open-sourced LLMs (Vicuna-13B, LongChat-7B, and Llama-2-7B), as well as a widely-utilized commercial LLM (ChatGPT). Moreover, our work extends to the realm of vision language models (MiniGPT-v2 and Gemini Vision Pro), showcasing GUARD's versatility and contributing valuable insights for the development of safer, more reliable LLM-based applications across diverse modalities.","sentences":["The discovery of \"jailbreaks\" to bypass safety filters of Large Language Models (LLMs) and harmful responses have encouraged the community to implement safety measures.","One major safety measure is to proactively test the LLMs with jailbreaks prior to the release.","Therefore, such testing will require a method that can generate jailbreaks massively and efficiently.","In this paper, we follow a novel yet intuitive strategy to generate jailbreaks in the style of the human generation.","We propose a role-playing system that assigns four different roles to the user LLMs to collaborate on new jailbreaks.","Furthermore, we collect existing jailbreaks and split them into different independent characteristics using clustering frequency and semantic patterns sentence by sentence.","We organize these characteristics into a knowledge graph, making them more accessible and easier to retrieve.","Our system of different roles will leverage this knowledge graph to generate new jailbreaks, which have proved effective in inducing LLMs to generate unethical or guideline-violating responses.","In addition, we also pioneer a setting in our system that will automatically follow the government-issued guidelines to generate jailbreaks to test whether LLMs follow the guidelines accordingly.","We refer to our system as GUARD (Guideline Upholding through Adaptive Role-play Diagnostics).","We have empirically validated the effectiveness of GUARD on three cutting-edge open-sourced LLMs (Vicuna-13B, LongChat-7B, and Llama-2-7B), as well as a widely-utilized commercial LLM (ChatGPT).","Moreover, our work extends to the realm of vision language models (MiniGPT-v2 and Gemini Vision Pro), showcasing GUARD's versatility and contributing valuable insights for the development of safer, more reliable LLM-based applications across diverse modalities."],"url":"http://arxiv.org/abs/2402.03299v1"}
{"created":"2024-02-05 18:51:17","title":"Ginger: An Efficient Curvature Approximation with Linear Complexity for General Neural Networks","abstract":"Second-order optimization approaches like the generalized Gauss-Newton method are considered more powerful as they utilize the curvature information of the objective function with preconditioning matrices. Albeit offering tempting theoretical benefits, they are not easily applicable to modern deep learning. The major reason is due to the quadratic memory and cubic time complexity to compute the inverse of the matrix. These requirements are infeasible even with state-of-the-art hardware. In this work, we propose Ginger, an eigendecomposition for the inverse of the generalized Gauss-Newton matrix. Our method enjoys efficient linear memory and time complexity for each iteration. Instead of approximating the conditioning matrix, we directly maintain its inverse to make the approximation more accurate. We provide the convergence result of Ginger for non-convex objectives. Our experiments on different tasks with different model architectures verify the effectiveness of our method. Our code is publicly available.","sentences":["Second-order optimization approaches like the generalized Gauss-Newton method are considered more powerful as they utilize the curvature information of the objective function with preconditioning matrices.","Albeit offering tempting theoretical benefits, they are not easily applicable to modern deep learning.","The major reason is due to the quadratic memory and cubic time complexity to compute the inverse of the matrix.","These requirements are infeasible even with state-of-the-art hardware.","In this work, we propose Ginger, an eigendecomposition for the inverse of the generalized Gauss-Newton matrix.","Our method enjoys efficient linear memory and time complexity for each iteration.","Instead of approximating the conditioning matrix, we directly maintain its inverse to make the approximation more accurate.","We provide the convergence result of Ginger for non-convex objectives.","Our experiments on different tasks with different model architectures verify the effectiveness of our method.","Our code is publicly available."],"url":"http://arxiv.org/abs/2402.03295v1"}
{"created":"2024-02-05 18:50:39","title":"Flora: Low-Rank Adapters Are Secretly Gradient Compressors","abstract":"Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training. To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters. However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance. In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection. Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states. We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach.","sentences":["Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training.","To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters.","However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance.","In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection.","Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states.","We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach."],"url":"http://arxiv.org/abs/2402.03293v1"}
{"created":"2024-02-05 18:50:27","title":"Zero-shot Object-Level OOD Detection with Context-Aware Inpainting","abstract":"Machine learning algorithms are increasingly provided as black-box cloud services or pre-trained models, without access to their training data. This motivates the problem of zero-shot out-of-distribution (OOD) detection. Concretely, we aim to detect OOD objects that do not belong to the classifier's label set but are erroneously classified as in-distribution (ID) objects. Our approach, RONIN, uses an off-the-shelf diffusion model to replace detected objects with inpainting. RONIN conditions the inpainting process with the predicted ID label, drawing the input object closer to the in-distribution domain. As a result, the reconstructed object is very close to the original in the ID cases and far in the OOD cases, allowing RONIN to effectively distinguish ID and OOD samples. Throughout extensive experiments, we demonstrate that RONIN achieves competitive results compared to previous approaches across several datasets, both in zero-shot and non-zero-shot settings.","sentences":["Machine learning algorithms are increasingly provided as black-box cloud services or pre-trained models, without access to their training data.","This motivates the problem of zero-shot out-of-distribution (OOD) detection.","Concretely, we aim to detect OOD objects that do not belong to the classifier's label set but are erroneously classified as in-distribution (ID) objects.","Our approach, RONIN, uses an off-the-shelf diffusion model to replace detected objects with inpainting.","RONIN conditions the inpainting process with the predicted ID label, drawing the input object closer to the in-distribution domain.","As a result, the reconstructed object is very close to the original in the ID cases and far in the OOD cases, allowing RONIN to effectively distinguish ID and OOD samples.","Throughout extensive experiments, we demonstrate that RONIN achieves competitive results compared to previous approaches across several datasets, both in zero-shot and non-zero-shot settings."],"url":"http://arxiv.org/abs/2402.03292v1"}
{"created":"2024-02-05 18:49:55","title":"Knowledge Acquisition and Integration with Expert-in-the-loop","abstract":"Constructing and serving knowledge graphs (KGs) is an iterative and human-centered process involving on-demand programming and analysis. In this paper, we present Kyurem, a programmable and interactive widget library that facilitates human-in-the-loop knowledge acquisition and integration to enable continuous curation a knowledge graph (KG). Kyurem provides a seamless environment within computational notebooks where data scientists explore a KG to identify opportunities for acquiring new knowledge and verify recommendations provided by AI agents for integrating the acquired knowledge in the KG. We refined Kyurem through participatory design and conducted case studies in a real-world setting for evaluation. The case-studies show that introduction of Kyurem within an existing HR knowledge graph construction and serving platform improved the user experience of the experts and helped eradicate inefficiencies related to knowledge acquisition and integration tasks","sentences":["Constructing and serving knowledge graphs (KGs) is an iterative and human-centered process involving on-demand programming and analysis.","In this paper, we present Kyurem, a programmable and interactive widget library that facilitates human-in-the-loop knowledge acquisition and integration to enable continuous curation a knowledge graph (KG).","Kyurem provides a seamless environment within computational notebooks where data scientists explore a KG to identify opportunities for acquiring new knowledge and verify recommendations provided by AI agents for integrating the acquired knowledge in the KG.","We refined Kyurem through participatory design and conducted case studies in a real-world setting for evaluation.","The case-studies show that introduction of Kyurem within an existing HR knowledge graph construction and serving platform improved the user experience of the experts and helped eradicate inefficiencies related to knowledge acquisition and integration tasks"],"url":"http://arxiv.org/abs/2402.03291v1"}
{"created":"2024-02-05 18:49:17","title":"InstanceDiffusion: Instance-level Control for Image Generation","abstract":"Text-to-image diffusion models produce high quality images but do not offer control over individual instances in the image. We introduce InstanceDiffusion that adds precise instance-level control to text-to-image diffusion models. InstanceDiffusion supports free-form language conditions per instance and allows flexible ways to specify instance locations such as simple single points, scribbles, bounding boxes or intricate instance segmentation masks, and combinations thereof. We propose three major changes to text-to-image models that enable precise instance-level control. Our UniFusion block enables instance-level conditions for text-to-image models, the ScaleU block improves image fidelity, and our Multi-instance Sampler improves generations for multiple instances. InstanceDiffusion significantly surpasses specialized state-of-the-art models for each location condition. Notably, on the COCO dataset, we outperform previous state-of-the-art by 20.4% AP$_{50}^\\text{box}$ for box inputs, and 25.4% IoU for mask inputs.","sentences":["Text-to-image diffusion models produce high quality images but do not offer control over individual instances in the image.","We introduce InstanceDiffusion that adds precise instance-level control to text-to-image diffusion models.","InstanceDiffusion supports free-form language conditions per instance and allows flexible ways to specify instance locations such as simple single points, scribbles, bounding boxes or intricate instance segmentation masks, and combinations thereof.","We propose three major changes to text-to-image models that enable precise instance-level control.","Our UniFusion block enables instance-level conditions for text-to-image models, the ScaleU block improves image fidelity, and our Multi-instance Sampler improves generations for multiple instances.","InstanceDiffusion significantly surpasses specialized state-of-the-art models for each location condition.","Notably, on the COCO dataset, we outperform previous state-of-the-art by 20.4% AP$_{50}^\\text{box}$ for box inputs, and 25.4% IoU for mask inputs."],"url":"http://arxiv.org/abs/2402.03290v1"}
{"created":"2024-02-05 18:47:04","title":"Make Every Move Count: LLM-based High-Quality RTL Code Generation Using MCTS","abstract":"Existing large language models (LLMs) for register transfer level code generation face challenges like compilation failures and suboptimal power, performance, and area (PPA) efficiency. This is due to the lack of PPA awareness in conventional transformer decoding algorithms. In response, we present an automated transformer decoding algorithm that integrates Monte Carlo tree-search for lookahead, guiding the transformer to produce compilable, functionally correct, and PPA-optimized code. Empirical evaluation with a fine-tuned language model on RTL codesets shows that our proposed technique consistently generates functionally correct code compared to prompting-only methods and effectively addresses the PPA-unawareness drawback of naive large language models. For the largest design generated by the state-of-the-art LLM (16-bit adder), our technique can achieve a 31.8% improvement in the area-delay product.","sentences":["Existing large language models (LLMs) for register transfer level code generation face challenges like compilation failures and suboptimal power, performance, and area (PPA) efficiency.","This is due to the lack of PPA awareness in conventional transformer decoding algorithms.","In response, we present an automated transformer decoding algorithm that integrates Monte Carlo tree-search for lookahead, guiding the transformer to produce compilable, functionally correct, and PPA-optimized code.","Empirical evaluation with a fine-tuned language model on RTL codesets shows that our proposed technique consistently generates functionally correct code compared to prompting-only methods and effectively addresses the PPA-unawareness drawback of naive large language models.","For the largest design generated by the state-of-the-art LLM (16-bit adder), our technique can achieve a 31.8% improvement in the area-delay product."],"url":"http://arxiv.org/abs/2402.03289v1"}
{"created":"2024-02-05 18:43:05","title":"A Lennard-Jones Layer for Distribution Normalization","abstract":"We introduce the Lennard-Jones layer (LJL) for the equalization of the density of 2D and 3D point clouds through systematically rearranging points without destroying their overall structure (distribution normalization). LJL simulates a dissipative process of repulsive and weakly attractive interactions between individual points by considering the nearest neighbor of each point at a given moment in time. This pushes the particles into a potential valley, reaching a well-defined stable configuration that approximates an equidistant sampling after the stabilization process. We apply LJLs to redistribute randomly generated point clouds into a randomized uniform distribution. Moreover, LJLs are embedded in the generation process of point cloud networks by adding them at later stages of the inference process. The improvements in 3D point cloud generation utilizing LJLs are evaluated qualitatively and quantitatively. Finally, we apply LJLs to improve the point distribution of a score-based 3D point cloud denoising network. In general, we demonstrate that LJLs are effective for distribution normalization which can be applied at negligible cost without retraining the given neural network.","sentences":["We introduce the Lennard-Jones layer (LJL) for the equalization of the density of 2D and 3D point clouds through systematically rearranging points without destroying their overall structure (distribution normalization).","LJL simulates a dissipative process of repulsive and weakly attractive interactions between individual points by considering the nearest neighbor of each point at a given moment in time.","This pushes the particles into a potential valley, reaching a well-defined stable configuration that approximates an equidistant sampling after the stabilization process.","We apply LJLs to redistribute randomly generated point clouds into a randomized uniform distribution.","Moreover, LJLs are embedded in the generation process of point cloud networks by adding them at later stages of the inference process.","The improvements in 3D point cloud generation utilizing LJLs are evaluated qualitatively and quantitatively.","Finally, we apply LJLs to improve the point distribution of a score-based 3D point cloud denoising network.","In general, we demonstrate that LJLs are effective for distribution normalization which can be applied at negligible cost without retraining the given neural network."],"url":"http://arxiv.org/abs/2402.03287v1"}
{"created":"2024-02-05 18:42:34","title":"Training-Free Consistent Text-to-Image Generation","abstract":"Text-to-image models offer a new level of creative flexibility by allowing users to guide the image generation process through natural language. However, using these models to consistently portray the same subject across diverse prompts remains challenging. Existing approaches fine-tune the model to teach it new words that describe specific user-provided subjects or add image conditioning to the model. These methods require lengthy per-subject optimization or large-scale pre-training. Moreover, they struggle to align generated images with text prompts and face difficulties in portraying multiple subjects. Here, we present ConsiStory, a training-free approach that enables consistent subject generation by sharing the internal activations of the pretrained model. We introduce a subject-driven shared attention block and correspondence-based feature injection to promote subject consistency between images. Additionally, we develop strategies to encourage layout diversity while maintaining subject consistency. We compare ConsiStory to a range of baselines, and demonstrate state-of-the-art performance on subject consistency and text alignment, without requiring a single optimization step. Finally, ConsiStory can naturally extend to multi-subject scenarios, and even enable training-free personalization for common objects.","sentences":["Text-to-image models offer a new level of creative flexibility by allowing users to guide the image generation process through natural language.","However, using these models to consistently portray the same subject across diverse prompts remains challenging.","Existing approaches fine-tune the model to teach it new words that describe specific user-provided subjects or add image conditioning to the model.","These methods require lengthy per-subject optimization or large-scale pre-training.","Moreover, they struggle to align generated images with text prompts and face difficulties in portraying multiple subjects.","Here, we present ConsiStory, a training-free approach that enables consistent subject generation by sharing the internal activations of the pretrained model.","We introduce a subject-driven shared attention block and correspondence-based feature injection to promote subject consistency between images.","Additionally, we develop strategies to encourage layout diversity while maintaining subject consistency.","We compare ConsiStory to a range of baselines, and demonstrate state-of-the-art performance on subject consistency and text alignment, without requiring a single optimization step.","Finally, ConsiStory can naturally extend to multi-subject scenarios, and even enable training-free personalization for common objects."],"url":"http://arxiv.org/abs/2402.03286v1"}
{"created":"2024-02-05 18:39:47","title":"Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models","abstract":"Effective interlocutors account for the uncertain goals, beliefs, and emotions of others. But even the best human conversationalist cannot perfectly anticipate the trajectory of a dialogue. How well can language models represent inherent uncertainty in conversations? We propose FortUne Dial, an expansion of the long-standing \"conversation forecasting\" task: instead of just accuracy, evaluation is conducted with uncertainty-aware metrics, effectively enabling abstention on individual instances. We study two ways in which language models potentially represent outcome uncertainty (internally, using scores and directly, using tokens) and propose fine-tuning strategies to improve calibration of both representations. Experiments on eight difficult negotiation corpora demonstrate that our proposed fine-tuning strategies (a traditional supervision strategy and an off-policy reinforcement learning strategy) can calibrate smaller open-source models to compete with pre-trained models 10x their size.","sentences":["Effective interlocutors account for the uncertain goals, beliefs, and emotions of others.","But even the best human conversationalist cannot perfectly anticipate the trajectory of a dialogue.","How well can language models represent inherent uncertainty in conversations?","We propose FortUne Dial, an expansion of the long-standing \"conversation forecasting\" task: instead of just accuracy, evaluation is conducted with uncertainty-aware metrics, effectively enabling abstention on individual instances.","We study two ways in which language models potentially represent outcome uncertainty (internally, using scores and directly, using tokens) and propose fine-tuning strategies to improve calibration of both representations.","Experiments on eight difficult negotiation corpora demonstrate that our proposed fine-tuning strategies (a traditional supervision strategy and an off-policy reinforcement learning strategy) can calibrate smaller open-source models to compete with pre-trained models 10x their size."],"url":"http://arxiv.org/abs/2402.03284v1"}
{"created":"2024-02-05 18:39:04","title":"Towards a Flexible Scale-out Framework for Efficient Visual Data Query Processing","abstract":"There is growing interest in visual data management systems that support queries with specialized operations ranging from resizing an image to running complex machine learning models. With a plethora of such operations, the basic need to receive query responses in minimal time takes a hit, especially when the client desires to run multiple such operations in a single query. Existing systems provide an ad-hoc approach where different solutions are clubbed together to provide an end-to-end visual data management system. Unlike such solutions, the Visual Data Management System (VDMS) natively executes queries with multiple operations, thus providing an end-to-end solution. However, a fixed subset of native operations and a synchronous threading architecture limit its generality and scalability.   In this paper, we develop VDMS-Async that adds the capability to run user-defined operations with VDMS and execute operations within a query on a remote server. VDMS-Async utilizes an event-driven architecture to create an efficient pipeline for executing operations within a query. Our experiments have shown that VDMS-Async reduces the query execution time by 2-3X compared to existing state-of-the-art systems. Further, remote operations coupled with an event-driven architecture enables VDMS-Async to scale query execution time linearly with the addition of every new remote server. We demonstrate a 64X reduction in query execution time when adding 64 remote servers.","sentences":["There is growing interest in visual data management systems that support queries with specialized operations ranging from resizing an image to running complex machine learning models.","With a plethora of such operations, the basic need to receive query responses in minimal time takes a hit, especially when the client desires to run multiple such operations in a single query.","Existing systems provide an ad-hoc approach where different solutions are clubbed together to provide an end-to-end visual data management system.","Unlike such solutions, the Visual Data Management System (VDMS) natively executes queries with multiple operations, thus providing an end-to-end solution.","However, a fixed subset of native operations and a synchronous threading architecture limit its generality and scalability.   ","In this paper, we develop VDMS-Async that adds the capability to run user-defined operations with VDMS and execute operations within a query on a remote server.","VDMS-Async utilizes an event-driven architecture to create an efficient pipeline for executing operations within a query.","Our experiments have shown that VDMS-Async reduces the query execution time by 2-3X compared to existing state-of-the-art systems.","Further, remote operations coupled with an event-driven architecture enables VDMS-Async to scale query execution time linearly with the addition of every new remote server.","We demonstrate a 64X reduction in query execution time when adding 64 remote servers."],"url":"http://arxiv.org/abs/2402.03283v1"}
{"created":"2024-02-05 18:38:55","title":"A Framework for Partially Observed Reward-States in RLHF","abstract":"The study of reinforcement learning from human feedback (RLHF) has gained prominence in recent years due to its role in the development of LLMs. Neuroscience research shows that human responses to stimuli are known to depend on partially-observed \"internal states.\" Unfortunately current models of RLHF do not take take this into consideration. Moreover most RLHF models do not account for intermediate feedback, which is gaining importance in empirical work and can help improve both sample complexity and alignment. To address these limitations, we model RLHF as reinforcement learning with partially observed reward-states (PORRL). We show reductions from the the two dominant forms of human feedback in RLHF - cardinal and dueling feedback to PORRL. For cardinal feedback, we develop generic statistically efficient algorithms and instantiate them to present POR-UCRL and POR-UCBVI. For dueling feedback, we show that a naive reduction to cardinal feedback fails to achieve sublinear dueling regret. We then present the first explicit reduction that converts guarantees for cardinal regret to dueling regret. We show that our models and guarantees in both settings generalize and extend existing ones. Finally, we identify a recursive structure on our model that could improve the statistical and computational tractability of PORRL, giving examples from past work on RLHF as well as learning perfect reward machines, which PORRL subsumes.","sentences":["The study of reinforcement learning from human feedback (RLHF) has gained prominence in recent years due to its role in the development of LLMs.","Neuroscience research shows that human responses to stimuli are known to depend on partially-observed \"internal states.\"","Unfortunately current models of RLHF do not take take this into consideration.","Moreover most RLHF models do not account for intermediate feedback, which is gaining importance in empirical work and can help improve both sample complexity and alignment.","To address these limitations, we model RLHF as reinforcement learning with partially observed reward-states (PORRL).","We show reductions from the the two dominant forms of human feedback in RLHF - cardinal and dueling feedback to PORRL.","For cardinal feedback, we develop generic statistically efficient algorithms and instantiate them to present POR-UCRL and POR-UCBVI.","For dueling feedback, we show that a naive reduction to cardinal feedback fails to achieve sublinear dueling regret.","We then present the first explicit reduction that converts guarantees for cardinal regret to dueling regret.","We show that our models and guarantees in both settings generalize and extend existing ones.","Finally, we identify a recursive structure on our model that could improve the statistical and computational tractability of PORRL, giving examples from past work on RLHF as well as learning perfect reward machines, which PORRL subsumes."],"url":"http://arxiv.org/abs/2402.03282v1"}
{"created":"2024-02-05 18:36:11","title":"Stepping into the Right Shoes: The Effects of User-Matched Avatar Ethnicity and Gender on Sense of Embodiment in Virtual Reality","abstract":"In many consumer virtual reality (VR) applications, users embody predefined characters that offer minimal customization options, frequently emphasizing storytelling over user choice. We explore whether matching a user's physical characteristics, specifically ethnicity and gender, with their virtual self-avatar affects their sense of embodiment in VR. We conducted a 2 x 2 within-subjects experiment (n=32) with a diverse user population to explore the impact of matching or not matching a user's self-avatar to their ethnicity and gender on their sense of embodiment. Our results indicate that matching the ethnicity of the user and their self-avatar significantly enhances sense of embodiment regardless of gender, extending across various aspects, including appearance, response, and ownership. We also found that matching gender significantly enhanced ownership, suggesting that this aspect is influenced by matching both ethnicity and gender. Interestingly, we found that matching ethnicity specifically affects self-location while matching gender specifically affects one's body ownership.","sentences":["In many consumer virtual reality (VR) applications, users embody predefined characters that offer minimal customization options, frequently emphasizing storytelling over user choice.","We explore whether matching a user's physical characteristics, specifically ethnicity and gender, with their virtual self-avatar affects their sense of embodiment in VR.","We conducted a 2 x 2 within-subjects experiment (n=32) with a diverse user population to explore the impact of matching or not matching a user's self-avatar to their ethnicity and gender on their sense of embodiment.","Our results indicate that matching the ethnicity of the user and their self-avatar significantly enhances sense of embodiment regardless of gender, extending across various aspects, including appearance, response, and ownership.","We also found that matching gender significantly enhanced ownership, suggesting that this aspect is influenced by matching both ethnicity and gender.","Interestingly, we found that matching ethnicity specifically affects self-location while matching gender specifically affects one's body ownership."],"url":"http://arxiv.org/abs/2402.03279v1"}
{"created":"2024-02-05 18:35:16","title":"Event-based Product Carousel Recommendation with Query-Click Graph","abstract":"Many current recommender systems mainly focus on the product-to-product recommendations and user-to-product recommendations even during the time of events rather than modeling the typical recommendations for the target event (e.g., festivals, seasonal activities, or social activities) without addressing the multiple aspects of the shopping demands for the target event. Product recommendations for the multiple aspects of the target event are usually generated by human curators who manually identify the aspects and select a list of aspect-related products (i.e., product carousel) for each aspect as recommendations. However, building a recommender system with machine learning is non-trivial due to the lack of both the ground truth of event-related aspects and the aspect-related products. To fill this gap, we define the novel problem as the event-based product carousel recommendations in e-commerce and propose an effective recommender system based on the query-click bipartite graph. We apply the iterative clustering algorithm over the query-click bipartite graph and infer the event-related aspects by the clusters of queries. The aspect-related recommendations are powered by the click-through rate of products regarding each aspect. We show through experiments that this approach effectively mines product carousels for the target event.","sentences":["Many current recommender systems mainly focus on the product-to-product recommendations and user-to-product recommendations even during the time of events rather than modeling the typical recommendations for the target event (e.g., festivals, seasonal activities, or social activities) without addressing the multiple aspects of the shopping demands for the target event.","Product recommendations for the multiple aspects of the target event are usually generated by human curators who manually identify the aspects and select a list of aspect-related products (i.e., product carousel) for each aspect as recommendations.","However, building a recommender system with machine learning is non-trivial due to the lack of both the ground truth of event-related aspects and the aspect-related products.","To fill this gap, we define the novel problem as the event-based product carousel recommendations in e-commerce and propose an effective recommender system based on the query-click bipartite graph.","We apply the iterative clustering algorithm over the query-click bipartite graph and infer the event-related aspects by the clusters of queries.","The aspect-related recommendations are powered by the click-through rate of products regarding each aspect.","We show through experiments that this approach effectively mines product carousels for the target event."],"url":"http://arxiv.org/abs/2402.03277v1"}
{"created":"2024-02-05 18:31:44","title":"Bounding the Weisfeiler-Leman Dimension via a Depth Analysis of I/R-Trees","abstract":"The Weisfeiler-Leman (WL) dimension is an established measure for the inherent descriptive complexity of graphs and relational structures. It corresponds to the number of variables that are needed and sufficient to define the object of interest in a counting version of first-order logic (FO). These bounded-variable counting logics were even candidates to capture graph isomorphism, until a celebrated construction due to Cai, F\\\"urer, and Immerman [Combinatorica 1992] showed that $\\Omega(n)$ variables are required to distinguish all non-isomorphic $n$-vertex graphs.   Still, very little is known about the precise number of variables required and sufficient to define every $n$-vertex graph. For the bounded-variable (non-counting) FO fragments, Pikhurko, Veith, and Verbitsky [Discret. Appl. Math. 2006] provided an upper bound of $\\frac{n+3}{2}$ and showed that it is essentially tight. Our main result yields that, in the presence of counting quantifiers, $\\frac{n}{4} + o(n)$ variables suffice. This shows that counting does allow us to save variables when defining graphs. As an application of our techniques, we also show new bounds in terms of the vertex cover number of the graph.   To obtain the results, we introduce a new concept called the WL depth of a graph. We use it to analyze branching trees within the Individualization/Refinement (I/R) paradigm from the domain of isomorphism algorithms. We extend the recursive procedure from the I/R paradigm by the possibility of splitting the graphs into independent parts. Then we bound the depth of the obtained branching trees, which translates into bounds on the WL dimension and thereby on the number of variables that suffice to define the graphs.","sentences":["The Weisfeiler-Leman (WL) dimension is an established measure for the inherent descriptive complexity of graphs and relational structures.","It corresponds to the number of variables that are needed and sufficient to define the object of interest in a counting version of first-order logic (FO).","These bounded-variable counting logics were even candidates to capture graph isomorphism, until a celebrated construction due to Cai, F\\\"urer, and Immerman [Combinatorica 1992] showed that $\\Omega(n)$ variables are required to distinguish all non-isomorphic $n$-vertex graphs.   ","Still, very little is known about the precise number of variables required and sufficient to define every $n$-vertex graph.","For the bounded-variable (non-counting) FO fragments, Pikhurko, Veith, and Verbitsky [Discret.","Appl.","Math. 2006] provided an upper bound of $\\frac{n+3}{2}$ and showed that it is essentially tight.","Our main result yields that, in the presence of counting quantifiers, $\\frac{n}{4} + o(n)$ variables suffice.","This shows that counting does allow us to save variables when defining graphs.","As an application of our techniques, we also show new bounds in terms of the vertex cover number of the graph.   ","To obtain the results, we introduce a new concept called the WL depth of a graph.","We use it to analyze branching trees within the Individualization/Refinement (I/R) paradigm from the domain of isomorphism algorithms.","We extend the recursive procedure from the I/R paradigm by the possibility of splitting the graphs into independent parts.","Then we bound the depth of the obtained branching trees, which translates into bounds on the WL dimension and thereby on the number of variables that suffice to define the graphs."],"url":"http://arxiv.org/abs/2402.03274v1"}
{"created":"2024-02-05 18:31:00","title":"Algorithms and Complexity of Difference Logic","abstract":"Difference Logic (DL) is a fragment of linear arithmetics where atoms are constraints x+k <= y for variables x,y (ranging over Q or Z) and integer k. We study the complexity of deciding the truth of existential DL sentences. This problem appears in many contexts: examples include verification, bioinformatics, telecommunications, and spatio-temporal reasoning in AI. We begin by considering sentences in CNF with rational-valued variables. We restrict the allowed clauses via two natural parameters: arity and coefficient bounds. The problem is NP-hard for most choices of these parameters. As a response to this, we refine our understanding by analyzing the time complexity and the parameterized complexity (with respect to well-studied parameters such as primal and incidence treewidth). We obtain a comprehensive picture of the complexity landscape in both cases. Finally, we generalize our results to integer domains and sentences that are not in CNF.","sentences":["Difference Logic (DL) is a fragment of linear arithmetics where atoms are constraints x+k <= y for variables x,y (ranging over Q or Z) and","integer k. We study the complexity of deciding the truth of existential DL sentences.","This problem appears in many contexts: examples include verification, bioinformatics, telecommunications, and spatio-temporal reasoning in AI.","We begin by considering sentences in CNF with rational-valued variables.","We restrict the allowed clauses via two natural parameters: arity and coefficient bounds.","The problem is NP-hard for most choices of these parameters.","As a response to this, we refine our understanding by analyzing the time complexity and the parameterized complexity (with respect to well-studied parameters such as primal and incidence treewidth).","We obtain a comprehensive picture of the complexity landscape in both cases.","Finally, we generalize our results to integer domains and sentences that are not in CNF."],"url":"http://arxiv.org/abs/2402.03273v1"}
{"created":"2024-02-05 18:28:44","title":"Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models","abstract":"In the face of uncertainty, the ability to seek information is of fundamental importance. In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms). In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions. UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertainty-based rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. In experiments on medical diagnosis, troubleshooting and the '20 Questions' game, UoT achieves an average performance improvement of 57.8% in the rate of successful task completion across multiple LLMs compared with direct prompting, and also improves efficiency (i.e., the number of questions needed to complete the task).","sentences":["In the face of uncertainty, the ability to seek information is of fundamental importance.","In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms).","In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions.","UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertainty-based rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward.","In experiments on medical diagnosis, troubleshooting and the '20 Questions' game, UoT achieves an average performance improvement of 57.8% in the rate of successful task completion across multiple LLMs compared with direct prompting, and also improves efficiency (i.e., the number of questions needed to complete the task)."],"url":"http://arxiv.org/abs/2402.03271v1"}
{"created":"2024-02-05 18:27:46","title":"Multiclass Classification Procedure for Detecting Attacks on MQTT-IoT Protocol","abstract":"The large number of sensors and actuators that make up the Internet of Things obliges these systems to use diverse technologies and protocols. This means that IoT networks are more heterogeneous than traditional networks. This gives rise to new challenges in cybersecurity to protect these systems and devices which are characterized by being connected continuously to the Internet. Intrusion detection systems (IDS) are used to protect IoT systems from the various anomalies and attacks at the network level. Intrusion Detection Systems (IDS) can be improved through machine learning techniques. Our work focuses on creating classification models that can feed an IDS using a dataset containing frames under attacks of an IoT system that uses the MQTT protocol. We have addressed two types of method for classifying the attacks, ensemble methods and deep learning models, more specifically recurrent networks with very satisfactory results.","sentences":["The large number of sensors and actuators that make up the Internet of Things obliges these systems to use diverse technologies and protocols.","This means that IoT networks are more heterogeneous than traditional networks.","This gives rise to new challenges in cybersecurity to protect these systems and devices which are characterized by being connected continuously to the Internet.","Intrusion detection systems (IDS) are used to protect IoT systems from the various anomalies and attacks at the network level.","Intrusion Detection Systems (IDS) can be improved through machine learning techniques.","Our work focuses on creating classification models that can feed an IDS using a dataset containing frames under attacks of an IoT system that uses the MQTT protocol.","We have addressed two types of method for classifying the attacks, ensemble methods and deep learning models, more specifically recurrent networks with very satisfactory results."],"url":"http://arxiv.org/abs/2402.03270v1"}
{"created":"2024-02-05 18:27:27","title":"ISPA: Inter-Species Phonetic Alphabet for Transcribing Animal Sounds","abstract":"Traditionally, bioacoustics has relied on spectrograms and continuous, per-frame audio representations for the analysis of animal sounds, also serving as input to machine learning models. Meanwhile, the International Phonetic Alphabet (IPA) system has provided an interpretable, language-independent method for transcribing human speech sounds. In this paper, we introduce ISPA (Inter-Species Phonetic Alphabet), a precise, concise, and interpretable system designed for transcribing animal sounds into text. We compare acoustics-based and feature-based methods for transcribing and classifying animal sounds, demonstrating their comparable performance with baseline methods utilizing continuous, dense audio representations. By representing animal sounds with text, we effectively treat them as a \"foreign language,\" and we show that established human language ML paradigms and models, such as language models, can be successfully applied to improve performance.","sentences":["Traditionally, bioacoustics has relied on spectrograms and continuous, per-frame audio representations for the analysis of animal sounds, also serving as input to machine learning models.","Meanwhile, the International Phonetic Alphabet (IPA) system has provided an interpretable, language-independent method for transcribing human speech sounds.","In this paper, we introduce ISPA (Inter-Species Phonetic Alphabet), a precise, concise, and interpretable system designed for transcribing animal sounds into text.","We compare acoustics-based and feature-based methods for transcribing and classifying animal sounds, demonstrating their comparable performance with baseline methods utilizing continuous, dense audio representations.","By representing animal sounds with text, we effectively treat them as a \"foreign language,\" and we show that established human language ML paradigms and models, such as language models, can be successfully applied to improve performance."],"url":"http://arxiv.org/abs/2402.03269v1"}
{"created":"2024-02-05 18:25:51","title":"Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation","abstract":"Pre-trained language models (LMs) are able to perform complex reasoning without explicit fine-tuning. To understand how pre-training with a next-token prediction objective contributes to the emergence of such reasoning capability, we propose that we can view an LM as deriving new conclusions by aggregating indirect reasoning paths seen at pre-training time. We found this perspective effective in two important cases of reasoning: logic reasoning with knowledge graphs (KGs) and math reasoning with math word problems (MWPs). More specifically, we formalize the reasoning paths as random walk paths on the knowledge/reasoning graphs. Analyses of learned LM distributions suggest that a weighted sum of relevant random walk path probabilities is a reasonable way to explain how LMs reason. Experiments and analysis on multiple KG and MWP datasets reveal the effect of training on random walk paths and suggest that augmenting unlabeled random walk reasoning paths can improve real-world multi-step reasoning performance.","sentences":["Pre-trained language models (LMs) are able to perform complex reasoning without explicit fine-tuning.","To understand how pre-training with a next-token prediction objective contributes to the emergence of such reasoning capability, we propose that we can view an LM as deriving new conclusions by aggregating indirect reasoning paths seen at pre-training time.","We found this perspective effective in two important cases of reasoning: logic reasoning with knowledge graphs (KGs) and math reasoning with math word problems (MWPs).","More specifically, we formalize the reasoning paths as random walk paths on the knowledge/reasoning graphs.","Analyses of learned LM distributions suggest that a weighted sum of relevant random walk path probabilities is a reasonable way to explain how LMs reason.","Experiments and analysis on multiple KG and MWP datasets reveal the effect of training on random walk paths and suggest that augmenting unlabeled random walk reasoning paths can improve real-world multi-step reasoning performance."],"url":"http://arxiv.org/abs/2402.03268v1"}
{"created":"2024-02-05 18:22:21","title":"MobilityGPT: Enhanced Human Mobility Modeling with a GPT model","abstract":"Generative models have shown promising results in capturing human mobility characteristics and generating synthetic trajectories. However, it remains challenging to ensure that the generated geospatial mobility data is semantically realistic, including consistent location sequences, and reflects real-world characteristics, such as constraining on geospatial limits. To address these issues, we reformat human mobility modeling as an autoregressive generation task, leveraging Generative Pre-trained Transformer (GPT). To ensure its controllable generation to alleviate the above challenges, we propose a geospatially-aware generative model, MobilityGPT. We propose a gravity-based sampling method to train a transformer for semantic sequence similarity. Then, we constrained the training process via a road connectivity matrix that provides the connectivity of sequences in trajectory generation, thereby keeping generated trajectories in geospatial limits. Lastly, we constructed a Reinforcement Learning from Trajectory Feedback (RLTF) to minimize the travel distance between training and the synthetically generated trajectories. Our experiments on real-world datasets demonstrate that MobilityGPT outperforms state-of-the-art methods in generating high-quality mobility trajectories that are closest to real data in terms of origin-destination similarity, trip length, travel radius, link, and gravity distributions.","sentences":["Generative models have shown promising results in capturing human mobility characteristics and generating synthetic trajectories.","However, it remains challenging to ensure that the generated geospatial mobility data is semantically realistic, including consistent location sequences, and reflects real-world characteristics, such as constraining on geospatial limits.","To address these issues, we reformat human mobility modeling as an autoregressive generation task, leveraging Generative Pre-trained Transformer (GPT).","To ensure its controllable generation to alleviate the above challenges, we propose a geospatially-aware generative model, MobilityGPT.","We propose a gravity-based sampling method to train a transformer for semantic sequence similarity.","Then, we constrained the training process via a road connectivity matrix that provides the connectivity of sequences in trajectory generation, thereby keeping generated trajectories in geospatial limits.","Lastly, we constructed a Reinforcement Learning from Trajectory Feedback (RLTF) to minimize the travel distance between training and the synthetically generated trajectories.","Our experiments on real-world datasets demonstrate that MobilityGPT outperforms state-of-the-art methods in generating high-quality mobility trajectories that are closest to real data in terms of origin-destination similarity, trip length, travel radius, link, and gravity distributions."],"url":"http://arxiv.org/abs/2402.03264v1"}
{"created":"2024-02-05 18:17:15","title":"Meeting Bridges: Designing Information Artifacts that Bridge from Synchronous Meetings to Asynchronous Collaboration","abstract":"A recent surge in remote meetings has led to complaints of ``Zoom fatigue'' and ``collaboration overload,'' negatively impacting worker productivity and well-being. One way to alleviate the burden of meetings is to de-emphasize their synchronous participation by shifting work to and enabling sensemaking during post-meeting asynchronous activities. Towards this goal, we propose the design concept of meeting bridges, or information artifacts that can encapsulate meeting information towards bridging to and facilitating post-meeting activities. Through 13 interviews and a survey of 198 information workers, we learn how people use online meeting information after meetings are over, finding five main uses: as an archive, as task reminders, to onboard or support inclusion, for group sensemaking, and as a launching point for follow-on collaboration. However, we also find that current common meeting artifacts, such as notes and recordings, present challenges in serving as meeting bridges. After conducting co-design sessions with 16 participants, we distill key principles for the design of meeting bridges to optimally support asynchronous collaboration goals. Overall, our findings point to the opportunity of designing information artifacts that not only support users to access but also continue to transform and engage in meeting information post-meeting.","sentences":["A recent surge in remote meetings has led to complaints of ``Zoom fatigue'' and ``collaboration overload,'' negatively impacting worker productivity and well-being.","One way to alleviate the burden of meetings is to de-emphasize their synchronous participation by shifting work to and enabling sensemaking during post-meeting asynchronous activities.","Towards this goal, we propose the design concept of meeting bridges, or information artifacts that can encapsulate meeting information towards bridging to and facilitating post-meeting activities.","Through 13 interviews and a survey of 198 information workers, we learn how people use online meeting information after meetings are over, finding five main uses: as an archive, as task reminders, to onboard or support inclusion, for group sensemaking, and as a launching point for follow-on collaboration.","However, we also find that current common meeting artifacts, such as notes and recordings, present challenges in serving as meeting bridges.","After conducting co-design sessions with 16 participants, we distill key principles for the design of meeting bridges to optimally support asynchronous collaboration goals.","Overall, our findings point to the opportunity of designing information artifacts that not only support users to access but also continue to transform and engage in meeting information post-meeting."],"url":"http://arxiv.org/abs/2402.03259v1"}
{"created":"2024-02-05 18:15:50","title":"Freeze-Tag in $L_1$ has Wake-up Time Five","abstract":"The Freeze-Tag Problem, introduced in Arkin et al. (SODA'02) consists of waking up a swarm of $n$ robots, starting from a single active robot. In the basic geometric version, every robot is given coordinates in the plane. As soon as a robot is awakened, it can move towards inactive robots to wake them up. The goal is to minimize the wake-up time of the last robot, the makespan.   Despite significant progress on the computational complexity of this problem and on approximation algorithms, the characterization of exact bounds on the makespan remains one of the main open questions. In this paper, we settle this question for the $\\ell_1$-norm, showing that a makespan of at most $5r$ can always be achieved, where $r$ is the maximum distance between the initial active robot and any sleeping robot. Moreover, a schedule achieving a makespan of at most $5r$ can be computed in optimal time $O(n)$. Both bounds, the time and the makespan are optimal. This implies a new upper bound of $5\\sqrt{2}r \\approx 7.07r$ on the makespan in the $\\ell_2$-norm, improving the best known bound so far $(5+2\\sqrt{2}+\\sqrt{5})r \\approx 10.06r$.","sentences":["The Freeze-Tag Problem, introduced in Arkin et al.","(SODA'02) consists of waking up a swarm of $n$ robots, starting from a single active robot.","In the basic geometric version, every robot is given coordinates in the plane.","As soon as a robot is awakened, it can move towards inactive robots to wake them up.","The goal is to minimize the wake-up time of the last robot, the makespan.   ","Despite significant progress on the computational complexity of this problem and on approximation algorithms, the characterization of exact bounds on the makespan remains one of the main open questions.","In this paper, we settle this question for the $\\ell_1$-norm, showing that a makespan of at most $5r$ can always be achieved, where $r$ is the maximum distance between the initial active robot and any sleeping robot.","Moreover, a schedule achieving a makespan of at most $5r$ can be computed in optimal time $O(n)$. Both bounds, the time and the makespan are optimal.","This implies a new upper bound of $5\\sqrt{2}r \\approx 7.07r$ on the makespan in the $\\ell_2$-norm, improving the best known bound so far $(5+2\\sqrt{2}+\\sqrt{5})r \\approx 10.06r$."],"url":"http://arxiv.org/abs/2402.03258v1"}
{"created":"2024-02-05 18:14:28","title":"Learning Best-in-Class Policies for the Predict-then-Optimize Framework","abstract":"We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. These losses directly approximate the downstream decision loss and can be optimized using off-the-shelf gradient-based methods. Importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. This implies that optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified and the noise is not centrally symmetric. Insofar as misspecification is commonplace in practice -- especially when we might prefer a simpler, more interpretable model -- PG losses offer a novel, theoretically justified, method for computationally tractable decision-aware learning.","sentences":["We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework.","These losses directly approximate the downstream decision loss and can be optimized using off-the-shelf gradient-based methods.","Importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows.","This implies that optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings.","This is the first such result in misspecified settings and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified and the noise is not centrally symmetric.","Insofar as misspecification is commonplace in practice -- especially when we might prefer a simpler, more interpretable model -- PG losses offer a novel, theoretically justified, method for computationally tractable decision-aware learning."],"url":"http://arxiv.org/abs/2402.03256v1"}
{"created":"2024-02-05 18:12:33","title":"Security Advice for Parents and Children About Content Filtering and Circumvention as Found on YouTube and TikTok","abstract":"In today's digital age, concerns about online security and privacy have become paramount. However, addressing these issues can be difficult, especially within the context of family relationships, wherein parents and children may have conflicting interests. In this environment, parents and children may turn to online security advice to determine how to proceed. In this paper, we examine the advice available to parents and children regarding content filtering and circumvention as found on YouTube and TikTok. In an analysis of 839 videos returned from queries on these topics, we found that half (n=399) provide relevant advice. Our results show that of these videos, roughly three-quarters are accurate, with the remaining one-fourth containing factually incorrect advice. We find that videos targeting children are both more likely to be incorrect and actionable than videos targeting parents, leaving children at increased risk of taking harmful action. Moreover, we find that while advice videos targeting parents will occasionally discuss the ethics of content filtering and device monitoring (including recommendations to respect children's autonomy) no such discussion of the ethics or risks of circumventing content filtering is given to children, leaving them unaware of any risks that may be involved with doing so. Ultimately, our research indicates that video-based social media sites are already effective sources of security advice propagation and that the public would benefit from security researchers and practitioners engaging more with these platforms, both for the creation of content and of tools designed to help with more effective filtering.","sentences":["In today's digital age, concerns about online security and privacy have become paramount.","However, addressing these issues can be difficult, especially within the context of family relationships, wherein parents and children may have conflicting interests.","In this environment, parents and children may turn to online security advice to determine how to proceed.","In this paper, we examine the advice available to parents and children regarding content filtering and circumvention as found on YouTube and TikTok.","In an analysis of 839 videos returned from queries on these topics, we found that half (n=399) provide relevant advice.","Our results show that of these videos, roughly three-quarters are accurate, with the remaining one-fourth containing factually incorrect advice.","We find that videos targeting children are both more likely to be incorrect and actionable than videos targeting parents, leaving children at increased risk of taking harmful action.","Moreover, we find that while advice videos targeting parents will occasionally discuss the ethics of content filtering and device monitoring (including recommendations to respect children's autonomy) no such discussion of the ethics or risks of circumventing content filtering is given to children, leaving them unaware of any risks that may be involved with doing so.","Ultimately, our research indicates that video-based social media sites are already effective sources of security advice propagation and that the public would benefit from security researchers and practitioners engaging more with these platforms, both for the creation of content and of tools designed to help with more effective filtering."],"url":"http://arxiv.org/abs/2402.03255v1"}
{"created":"2024-02-05 18:09:48","title":"Fair Active Ranking from Pairwise Preferences","abstract":"We investigate the problem of probably approximately correct and fair (PACF) ranking of items by adaptively evoking pairwise comparisons. Given a set of $n$ items that belong to disjoint groups, our goal is to find an $(\\epsilon, \\delta)$-PACF-Ranking according to a fair objective function that we propose. We assume access to an oracle, wherein, for each query, the learner can choose a pair of items and receive stochastic winner feedback from the oracle. Our proposed objective function asks to minimize the $\\ell_q$ norm of the error of the groups, where the error of a group is the $\\ell_p$ norm of the error of all the items within that group, for $p, q \\geq 1$. This generalizes the objective function of $\\epsilon$-Best-Ranking, proposed by Saha & Gopalan (2019).   By adopting our objective function, we gain the flexibility to explore fundamental fairness concepts like equal or proportionate errors within a unified framework. Adjusting parameters $p$ and $q$ allows tailoring to specific fairness preferences. We present both group-blind and group-aware algorithms and analyze their sample complexity. We provide matching lower bounds up to certain logarithmic factors for group-blind algorithms. For a restricted class of group-aware algorithms, we show that we can get reasonable lower bounds. We conduct comprehensive experiments on both real-world and synthetic datasets to complement our theoretical findings.","sentences":["We investigate the problem of probably approximately correct and fair (PACF) ranking of items by adaptively evoking pairwise comparisons.","Given a set of $n$ items that belong to disjoint groups, our goal is to find an $(\\epsilon, \\delta)$-PACF-Ranking according to a fair objective function that we propose.","We assume access to an oracle, wherein, for each query, the learner can choose a pair of items and receive stochastic winner feedback from the oracle.","Our proposed objective function asks to minimize the $\\ell_q$ norm of the error of the groups, where the error of a group is the $\\ell_p$ norm of the error of all the items within that group, for $p, q \\geq 1$.","This generalizes the objective function of $\\epsilon$-Best-Ranking, proposed by Saha & Gopalan (2019).   ","By adopting our objective function, we gain the flexibility to explore fundamental fairness concepts like equal or proportionate errors within a unified framework.","Adjusting parameters $p$ and $q$ allows tailoring to specific fairness preferences.","We present both group-blind and group-aware algorithms and analyze their sample complexity.","We provide matching lower bounds up to certain logarithmic factors for group-blind algorithms.","For a restricted class of group-aware algorithms, we show that we can get reasonable lower bounds.","We conduct comprehensive experiments on both real-world and synthetic datasets to complement our theoretical findings."],"url":"http://arxiv.org/abs/2402.03252v1"}
{"created":"2024-02-05 18:09:33","title":"CLIP Can Understand Depth","abstract":"Recent studies on generalizing CLIP for monocular depth estimation reveal that CLIP pre-trained on web-crawled data is inefficient for deriving proper similarities between image patches and depth-related prompts. In this paper, we adapt CLIP for meaningful quality of monocular depth estimation with dense prediction, without fine-tuning its original vision-language alignment. By jointly training a compact deconvolutional decoder with a tiny learnable embedding matrix named mirror, as a static prompt for its text encoder, CLIP is enabled to understand depth. With this approach, our model exhibits impressive performance matching several previous state-of-the-art vision-only models on the NYU Depth v2 and KITTI datasets, outperforming every CLIP-based depth estimation model with a large margin. Experiments on temporal depth consistency and spatial continuity demonstrate that the prior knowledge of CLIP can be effectively refined by our proposed framework. Furthermore, an ablation study on mirror proves that the resulting model estimates depth utilizing knowledge not only from the image encoder but also text encoder despite not being given any prompt written in a human way. This research demonstrates that through minimal adjustments, the prior knowledge of vision-language foundation models, such as CLIP, can be generalized even to domains where learning during pretraining is challenging. We facilitate future works focused on methods to adjust suboptimal prior knowledge of vision-language models using non-human language prompts, achieving performance on par with task-specific state-of-the-art methodologies.","sentences":["Recent studies on generalizing CLIP for monocular depth estimation reveal that CLIP pre-trained on web-crawled data is inefficient for deriving proper similarities between image patches and depth-related prompts.","In this paper, we adapt CLIP for meaningful quality of monocular depth estimation with dense prediction, without fine-tuning its original vision-language alignment.","By jointly training a compact deconvolutional decoder with a tiny learnable embedding matrix named mirror, as a static prompt for its text encoder, CLIP is enabled to understand depth.","With this approach, our model exhibits impressive performance matching several previous state-of-the-art vision-only models on the NYU Depth v2 and KITTI datasets, outperforming every CLIP-based depth estimation model with a large margin.","Experiments on temporal depth consistency and spatial continuity demonstrate that the prior knowledge of CLIP can be effectively refined by our proposed framework.","Furthermore, an ablation study on mirror proves that the resulting model estimates depth utilizing knowledge not only from the image encoder but also text encoder despite not being given any prompt written in a human way.","This research demonstrates that through minimal adjustments, the prior knowledge of vision-language foundation models, such as CLIP, can be generalized even to domains where learning during pretraining is challenging.","We facilitate future works focused on methods to adjust suboptimal prior knowledge of vision-language models using non-human language prompts, achieving performance on par with task-specific state-of-the-art methodologies."],"url":"http://arxiv.org/abs/2402.03251v1"}
{"created":"2024-02-05 18:05:34","title":"HEANA: A Hybrid Time-Amplitude Analog Optical Accelerator with Flexible Dataflows for Energy-Efficient CNN Inference","abstract":"Several photonic microring resonators (MRRs) based analog accelerators have been proposed to accelerate the inference of integer-quantized CNNs with remarkably higher throughput and energy efficiency compared to their electronic counterparts. However, the existing analog photonic accelerators suffer from three shortcomings: (i) severe hampering of wavelength parallelism due to various crosstalk effects, (ii) inflexibility of supporting various dataflows other than the weight-stationary dataflow, and (iii) failure in fully leveraging the ability of photodetectors to perform in-situ accumulations. These shortcomings collectively hamper the performance and energy efficiency of prior accelerators. To tackle these shortcomings, we present a novel Hybrid timE Amplitude aNalog optical Accelerator, called HEANA. HEANA employs hybrid time-amplitude analog optical multipliers (TAOMs) that increase the flexibility of HEANA to support multiple dataflows. A spectrally hitless arrangement of TAOMs significantly reduces the crosstalk effects, thereby increasing the wavelength parallelism in HEANA. Moreover, HEANA employs our invented balanced photo-charge accumulators (BPCAs) that enable buffer-less, in-situ, temporal accumulations to eliminate the need to use reduction networks in HEANA, relieving it from related latency and energy overheads. Our evaluation for the inference of four modern CNNs indicates that HEANA provides improvements of atleast 66x and 84x in frames-per-second (FPS) and FPS/W (energy-efficiency), respectively, for equal-area comparisons, on gmean over two MRR-based analog CNN accelerators from prior work.","sentences":["Several photonic microring resonators (MRRs) based analog accelerators have been proposed to accelerate the inference of integer-quantized CNNs with remarkably higher throughput and energy efficiency compared to their electronic counterparts.","However, the existing analog photonic accelerators suffer from three shortcomings: (i) severe hampering of wavelength parallelism due to various crosstalk effects, (ii) inflexibility of supporting various dataflows other than the weight-stationary dataflow, and (iii) failure in fully leveraging the ability of photodetectors to perform in-situ accumulations.","These shortcomings collectively hamper the performance and energy efficiency of prior accelerators.","To tackle these shortcomings, we present a novel","Hybrid timE","Amplitude aNalog optical Accelerator, called HEANA.","HEANA employs hybrid time-amplitude analog optical multipliers (TAOMs) that increase the flexibility of HEANA to support multiple dataflows.","A spectrally hitless arrangement of TAOMs significantly reduces the crosstalk effects, thereby increasing the wavelength parallelism in HEANA.","Moreover, HEANA employs our invented balanced photo-charge accumulators (BPCAs) that enable buffer-less, in-situ, temporal accumulations to eliminate the need to use reduction networks in HEANA, relieving it from related latency and energy overheads.","Our evaluation for the inference of four modern CNNs indicates that HEANA provides improvements of atleast 66x and 84x in frames-per-second (FPS) and FPS/W (energy-efficiency), respectively, for equal-area comparisons, on gmean over two MRR-based analog CNN accelerators from prior work."],"url":"http://arxiv.org/abs/2402.03247v1"}
{"created":"2024-02-05 18:03:53","title":"SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM","abstract":"Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation. Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations. Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rendering ability.","sentences":["Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation.","Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations.","Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions.","Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality.","Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rendering ability."],"url":"http://arxiv.org/abs/2402.03246v1"}
{"created":"2024-02-05 17:59:00","title":"Skill Set Optimization: Reinforcing Language Model Behavior via Transferable Skills","abstract":"Large language models (LLMs) have recently been used for sequential decision making in interactive environments. However, leveraging environment reward signals for continual LLM actor improvement is not straightforward. We propose Skill Set Optimization (SSO) for improving LLM actor performance through constructing and refining sets of transferable skills. SSO constructs skills by extracting common subtrajectories with high rewards and generating subgoals and instructions to represent each skill. These skills are provided to the LLM actor in-context to reinforce behaviors with high rewards. Then, SSO further refines the skill set by pruning skills that do not continue to result in high rewards. We evaluate our method in the classic videogame NetHack and the text environment ScienceWorld to demonstrate SSO's ability to optimize a set of skills and perform in-context policy improvement. SSO outperforms baselines by 40% in our custom NetHack task and outperforms the previous state-of-the-art in ScienceWorld by 35%.","sentences":["Large language models (LLMs) have recently been used for sequential decision making in interactive environments.","However, leveraging environment reward signals for continual LLM actor improvement is not straightforward.","We propose Skill Set Optimization (SSO) for improving LLM actor performance through constructing and refining sets of transferable skills.","SSO constructs skills by extracting common subtrajectories with high rewards and generating subgoals and instructions to represent each skill.","These skills are provided to the LLM actor in-context to reinforce behaviors with high rewards.","Then, SSO further refines the skill set by pruning skills that do not continue to result in high rewards.","We evaluate our method in the classic videogame NetHack and the text environment ScienceWorld to demonstrate SSO's ability to optimize a set of skills and perform in-context policy improvement.","SSO outperforms baselines by 40% in our custom NetHack task and outperforms the previous state-of-the-art in ScienceWorld by 35%."],"url":"http://arxiv.org/abs/2402.03244v1"}
{"created":"2024-02-05 17:58:17","title":"PINN-BO: A Black-box Optimization Algorithm using Physics-Informed Neural Networks","abstract":"Black-box optimization is a powerful approach for discovering global optima in noisy and expensive black-box functions, a problem widely encountered in real-world scenarios. Recently, there has been a growing interest in leveraging domain knowledge to enhance the efficacy of machine learning methods. Partial Differential Equations (PDEs) often provide an effective means for elucidating the fundamental principles governing the black-box functions. In this paper, we propose PINN-BO, a black-box optimization algorithm employing Physics-Informed Neural Networks that integrates the knowledge from Partial Differential Equations (PDEs) to improve the sample efficiency of the optimization. We analyze the theoretical behavior of our algorithm in terms of regret bound using advances in NTK theory and prove that the use of the PDE alongside the black-box function evaluations, PINN-BO leads to a tighter regret bound. We perform several experiments on a variety of optimization tasks and show that our algorithm is more sample-efficient compared to existing methods.","sentences":["Black-box optimization is a powerful approach for discovering global optima in noisy and expensive black-box functions, a problem widely encountered in real-world scenarios.","Recently, there has been a growing interest in leveraging domain knowledge to enhance the efficacy of machine learning methods.","Partial Differential Equations (PDEs) often provide an effective means for elucidating the fundamental principles governing the black-box functions.","In this paper, we propose PINN-BO, a black-box optimization algorithm employing Physics-Informed Neural Networks that integrates the knowledge from Partial Differential Equations (PDEs) to improve the sample efficiency of the optimization.","We analyze the theoretical behavior of our algorithm in terms of regret bound using advances in NTK theory and prove that the use of the PDE alongside the black-box function evaluations, PINN-BO leads to a tighter regret bound.","We perform several experiments on a variety of optimization tasks and show that our algorithm is more sample-efficient compared to existing methods."],"url":"http://arxiv.org/abs/2402.03243v1"}
{"created":"2024-02-05 17:57:26","title":"JOBSKAPE: A Framework for Generating Synthetic Job Postings to Enhance Skill Matching","abstract":"Recent approaches in skill matching, employing synthetic training data for classification or similarity model training, have shown promising results, reducing the need for time-consuming and expensive annotations. However, previous synthetic datasets have limitations, such as featuring only one skill per sentence and generally comprising short sentences. In this paper, we introduce JobSkape, a framework to generate synthetic data that tackles these limitations, specifically designed to enhance skill-to-taxonomy matching. Within this framework, we create SkillSkape, a comprehensive open-source synthetic dataset of job postings tailored for skill-matching tasks. We introduce several offline metrics that show that our dataset resembles real-world data. Additionally, we present a multi-step pipeline for skill extraction and matching tasks using large language models (LLMs), benchmarking against known supervised methodologies. We outline that the downstream evaluation results on real-world data can beat baselines, underscoring its efficacy and adaptability.","sentences":["Recent approaches in skill matching, employing synthetic training data for classification or similarity model training, have shown promising results, reducing the need for time-consuming and expensive annotations.","However, previous synthetic datasets have limitations, such as featuring only one skill per sentence and generally comprising short sentences.","In this paper, we introduce JobSkape, a framework to generate synthetic data that tackles these limitations, specifically designed to enhance skill-to-taxonomy matching.","Within this framework, we create SkillSkape, a comprehensive open-source synthetic dataset of job postings tailored for skill-matching tasks.","We introduce several offline metrics that show that our dataset resembles real-world data.","Additionally, we present a multi-step pipeline for skill extraction and matching tasks using large language models (LLMs), benchmarking against known supervised methodologies.","We outline that the downstream evaluation results on real-world data can beat baselines, underscoring its efficacy and adaptability."],"url":"http://arxiv.org/abs/2402.03242v1"}
{"created":"2024-02-05 17:56:41","title":"FROSTER: Frozen CLIP Is A Strong Teacher for Open-Vocabulary Action Recognition","abstract":"In this paper, we introduce FROSTER, an effective framework for open-vocabulary action recognition. The CLIP model has achieved remarkable success in a range of image-based tasks, benefiting from its strong generalization capability stemming from pretaining on massive image-text pairs. However, applying CLIP directly to the open-vocabulary action recognition task is challenging due to the absence of temporal information in CLIP's pretraining. Further, fine-tuning CLIP on action recognition datasets may lead to overfitting and hinder its generalizability, resulting in unsatisfactory results when dealing with unseen actions.   To address these issues, FROSTER employs a residual feature distillation approach to ensure that CLIP retains its generalization capability while effectively adapting to the action recognition task. Specifically, the residual feature distillation treats the frozen CLIP model as a teacher to maintain the generalizability exhibited by the original CLIP and supervises the feature learning for the extraction of video-specific features to bridge the gap between images and videos. Meanwhile, it uses a residual sub-network for feature distillation to reach a balance between the two distinct objectives of learning generalizable and video-specific features.   We extensively evaluate FROSTER on open-vocabulary action recognition benchmarks under both base-to-novel and cross-dataset settings. FROSTER consistently achieves state-of-the-art performance on all datasets across the board. Project page: https://visual-ai.github.io/froster.","sentences":["In this paper, we introduce FROSTER, an effective framework for open-vocabulary action recognition.","The CLIP model has achieved remarkable success in a range of image-based tasks, benefiting from its strong generalization capability stemming from pretaining on massive image-text pairs.","However, applying CLIP directly to the open-vocabulary action recognition task is challenging due to the absence of temporal information in CLIP's pretraining.","Further, fine-tuning CLIP on action recognition datasets may lead to overfitting and hinder its generalizability, resulting in unsatisfactory results when dealing with unseen actions.   ","To address these issues, FROSTER employs a residual feature distillation approach to ensure that CLIP retains its generalization capability while effectively adapting to the action recognition task.","Specifically, the residual feature distillation treats the frozen CLIP model as a teacher to maintain the generalizability exhibited by the original CLIP and supervises the feature learning for the extraction of video-specific features to bridge the gap between images and videos.","Meanwhile, it uses a residual sub-network for feature distillation to reach a balance between the two distinct objectives of learning generalizable and video-specific features.   ","We extensively evaluate FROSTER on open-vocabulary action recognition benchmarks under both base-to-novel and cross-dataset settings.","FROSTER consistently achieves state-of-the-art performance on all datasets across the board.","Project page: https://visual-ai.github.io/froster."],"url":"http://arxiv.org/abs/2402.03241v1"}
{"created":"2024-02-05 17:55:51","title":"Bluesky and the AT Protocol: Usable Decentralized Social Media","abstract":"Bluesky is a new social network built upon the AT Protocol, a decentralized foundation for public social media. It was launched in private beta in February 2023, and has grown to over 3 million registered users in the following year. In this paper we introduce the architecture of Bluesky and the AT Protocol, which is inspired by the web itself, but modernized to include streams of real-time updates and cryptographic authentication. We explain how the technical design of Bluesky is informed by our goals: to enable decentralization by having multiple interoperable providers for every part of the system; to make it easy for users to switch providers; to give users agency over the content they see; and to provide a simple user experience that does not burden users with complexity arising from the system's decentralized nature. The system's openness allows anybody to contribute to content moderation and community management, and we invite the research community to use Bluesky as a dataset and testing ground for new approaches in social media moderation.","sentences":["Bluesky is a new social network built upon the AT Protocol, a decentralized foundation for public social media.","It was launched in private beta in February 2023, and has grown to over 3 million registered users in the following year.","In this paper we introduce the architecture of Bluesky and the AT Protocol, which is inspired by the web itself, but modernized to include streams of real-time updates and cryptographic authentication.","We explain how the technical design of Bluesky is informed by our goals: to enable decentralization by having multiple interoperable providers for every part of the system; to make it easy for users to switch providers; to give users agency over the content they see; and to provide a simple user experience that does not burden users with complexity arising from the system's decentralized nature.","The system's openness allows anybody to contribute to content moderation and community management, and we invite the research community to use Bluesky as a dataset and testing ground for new approaches in social media moderation."],"url":"http://arxiv.org/abs/2402.03239v1"}
{"created":"2024-02-05 17:52:58","title":"ActiveAnno3D -- An Active Learning Framework for Multi-Modal 3D Object Detection","abstract":"The curation of large-scale datasets is still costly and requires much time and resources. Data is often manually labeled, and the challenge of creating high-quality datasets remains. In this work, we fill the research gap using active learning for multi-modal 3D object detection. We propose ActiveAnno3D, an active learning framework to select data samples for labeling that are of maximum informativeness for training. We explore various continuous training methods and integrate the most efficient method regarding computational demand and detection performance. Furthermore, we perform extensive experiments and ablation studies with BEVFusion and PV-RCNN on the nuScenes and TUM Traffic Intersection dataset. We show that we can achieve almost the same performance with PV-RCNN and the entropy-based query strategy when using only half of the training data (77.25 mAP compared to 83.50 mAP) of the TUM Traffic Intersection dataset. BEVFusion achieved an mAP of 64.31 when using half of the training data and 75.0 mAP when using the complete nuScenes dataset. We integrate our active learning framework into the proAnno labeling tool to enable AI-assisted data selection and labeling and minimize the labeling costs. Finally, we provide code, weights, and visualization results on our website: https://active3d-framework.github.io/active3d-framework.","sentences":["The curation of large-scale datasets is still costly and requires much time and resources.","Data is often manually labeled, and the challenge of creating high-quality datasets remains.","In this work, we fill the research gap using active learning for multi-modal 3D object detection.","We propose ActiveAnno3D, an active learning framework to select data samples for labeling that are of maximum informativeness for training.","We explore various continuous training methods and integrate the most efficient method regarding computational demand and detection performance.","Furthermore, we perform extensive experiments and ablation studies with BEVFusion and PV-RCNN on the nuScenes and TUM Traffic Intersection dataset.","We show that we can achieve almost the same performance with PV-RCNN and the entropy-based query strategy when using only half of the training data (77.25 mAP compared to 83.50 mAP) of the TUM Traffic Intersection dataset.","BEVFusion achieved an mAP of 64.31 when using half of the training data and 75.0 mAP when using the complete nuScenes dataset.","We integrate our active learning framework into the proAnno labeling tool to enable AI-assisted data selection and labeling and minimize the labeling costs.","Finally, we provide code, weights, and visualization results on our website: https://active3d-framework.github.io/active3d-framework."],"url":"http://arxiv.org/abs/2402.03235v1"}
{"created":"2024-02-05 17:45:12","title":"Smart Flow Matching: On The Theory of Flow Matching Algorithms with Applications","abstract":"The paper presents the exact formula for the vector field that minimizes the loss for the standard flow. This formula depends analytically on a given distribution \\rho_0 and an unknown one \\rho_1. Based on the presented formula, a new loss and algorithm for training a vector field model in the style of Conditional Flow Matching are provided. Our loss, in comparison to the standard Conditional Flow Matching approach, exhibits smaller variance when evaluated through Monte Carlo sampling methods. Numerical experiments on synthetic models and models on tabular data of large dimensions demonstrate better learning results with the use of the presented algorithm.","sentences":["The paper presents the exact formula for the vector field that minimizes the loss for the standard flow.","This formula depends analytically on a given distribution \\rho_0 and an unknown one \\rho_1.","Based on the presented formula, a new loss and algorithm for training a vector field model in the style of Conditional Flow Matching are provided.","Our loss, in comparison to the standard Conditional Flow Matching approach, exhibits smaller variance when evaluated through Monte Carlo sampling methods.","Numerical experiments on synthetic models and models on tabular data of large dimensions demonstrate better learning results with the use of the presented algorithm."],"url":"http://arxiv.org/abs/2402.03232v1"}
{"created":"2024-02-05 17:43:02","title":"CT-based Anatomical Segmentation for Thoracic Surgical Planning: A Benchmark Study for 3D U-shaped Deep Learning Models","abstract":"Recent rising interests in patient-specific thoracic surgical planning and simulation require efficient and robust creation of digital anatomical models from automatic medical image segmentation algorithms. Deep learning (DL) is now state-of-the-art in various radiological tasks, and U-shaped DL models have particularly excelled in medical image segmentation since the inception of the 2D UNet. To date, many variants of U-shaped models have been proposed by the integration of different attention mechanisms and network configurations. Leveraging the recent development of large multi-label databases, systematic benchmark studies for these models can provide valuable insights for clinical deployment and future model designs, but such studies are still rare. We conduct the first benchmark study for variants of 3D U-shaped models (3DUNet, STUNet, AttentionUNet, SwinUNETR, FocalSegNet, and a novel 3D SwinUnet with four variants) with a focus on CT-based anatomical segmentation for thoracic surgery. Our study systematically examines the impact of different attention mechanisms, number of resolution stages, and network configurations on segmentation accuracy and computational complexity. To allow cross-reference with other recent benchmarking studies, we also included a performance assessment of the BTCV abdominal structural segmentation. With the STUNet ranking at the top, our study demonstrated the value of CNN-based U-shaped models for the investigated tasks and the benefit of residual blocks in network configuration designs to boost segmentation performance.","sentences":["Recent rising interests in patient-specific thoracic surgical planning and simulation require efficient and robust creation of digital anatomical models from automatic medical image segmentation algorithms.","Deep learning (DL) is now state-of-the-art in various radiological tasks, and U-shaped DL models have particularly excelled in medical image segmentation since the inception of the 2D UNet.","To date, many variants of U-shaped models have been proposed by the integration of different attention mechanisms and network configurations.","Leveraging the recent development of large multi-label databases, systematic benchmark studies for these models can provide valuable insights for clinical deployment and future model designs, but such studies are still rare.","We conduct the first benchmark study for variants of 3D U-shaped models (3DUNet, STUNet, AttentionUNet, SwinUNETR, FocalSegNet, and a novel 3D SwinUnet with four variants) with a focus on CT-based anatomical segmentation for thoracic surgery.","Our study systematically examines the impact of different attention mechanisms, number of resolution stages, and network configurations on segmentation accuracy and computational complexity.","To allow cross-reference with other recent benchmarking studies, we also included a performance assessment of the BTCV abdominal structural segmentation.","With the STUNet ranking at the top, our study demonstrated the value of CNN-based U-shaped models for the investigated tasks and the benefit of residual blocks in network configuration designs to boost segmentation performance."],"url":"http://arxiv.org/abs/2402.03230v1"}
{"created":"2024-02-05 17:38:49","title":"IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of brain MR images","abstract":"In MRI studies, the aggregation of imaging data from multiple acquisition sites enhances sample size but may introduce site-related variabilities that hinder consistency in subsequent analyses. Deep learning methods for image translation have emerged as a solution for harmonizing MR images across sites. In this study, we introduce IGUANe (Image Generation with Unified Adversarial Networks), an original 3D model that leverages the strengths of domain translation and straightforward application of style transfer methods for multicenter brain MR image harmonization. IGUANe extends CycleGAN architecture by integrating an arbitrary number of domains for training through a many-to-one strategy. During inference, the model can be applied to any image, even from an unknown acquisition site, making it a universal generator for harmonization. Trained on a dataset comprising T1-weighted images from 11 different scanners, IGUANe was evaluated on data from unseen sites. The assessments included the transformation of MR images with traveling subjects, the preservation of pairwise distances between MR images within domains, the evolution of volumetric patterns related to age and Alzheimer$^\\prime$s disease (AD), and the performance in age regression and patient classification tasks. Comparisons with other harmonization and normalization methods suggest that IGUANe better preserves individual information in MR images and is more suitable for maintaining and reinforcing variabilities related to age and AD. Future studies may further assess IGUANe in other multicenter contexts, either using the same model or retraining it for applications to different image modalities.","sentences":["In MRI studies, the aggregation of imaging data from multiple acquisition sites enhances sample size but may introduce site-related variabilities that hinder consistency in subsequent analyses.","Deep learning methods for image translation have emerged as a solution for harmonizing MR images across sites.","In this study, we introduce IGUANe (Image Generation with Unified Adversarial Networks), an original 3D model that leverages the strengths of domain translation and straightforward application of style transfer methods for multicenter brain MR image harmonization.","IGUANe extends CycleGAN architecture by integrating an arbitrary number of domains for training through a many-to-one strategy.","During inference, the model can be applied to any image, even from an unknown acquisition site, making it a universal generator for harmonization.","Trained on a dataset comprising T1-weighted images from 11 different scanners, IGUANe was evaluated on data from unseen sites.","The assessments included the transformation of MR images with traveling subjects, the preservation of pairwise distances between MR images within domains, the evolution of volumetric patterns related to age and Alzheimer$^\\prime$s disease (AD), and the performance in age regression and patient classification tasks.","Comparisons with other harmonization and normalization methods suggest that IGUANe better preserves individual information in MR images and is more suitable for maintaining and reinforcing variabilities related to age and AD.","Future studies may further assess IGUANe in other multicenter contexts, either using the same model or retraining it for applications to different image modalities."],"url":"http://arxiv.org/abs/2402.03227v1"}
{"created":"2024-02-05 17:37:46","title":"FuseMoE: Mixture-of-Experts Transformers for Fleximodal Fusion","abstract":"As machine learning models in critical fields increasingly grapple with multimodal data, they face the dual challenges of handling a wide array of modalities, often incomplete due to missing elements, and the temporal irregularity and sparsity of collected samples. Successfully leveraging this complex data, while overcoming the scarcity of high-quality training samples, is key to improving these models' predictive performance. We introduce ``FuseMoE'', a mixture-of-experts framework incorporated with an innovative gating function. Designed to integrate a diverse number of modalities, FuseMoE is effective in managing scenarios with missing modalities and irregularly sampled data trajectories. Theoretically, our unique gating function contributes to enhanced convergence rates, leading to better performance in multiple downstream tasks. The practical utility of FuseMoE in real world is validated by a challenging set of clinical risk prediction tasks.","sentences":["As machine learning models in critical fields increasingly grapple with multimodal data, they face the dual challenges of handling a wide array of modalities, often incomplete due to missing elements, and the temporal irregularity and sparsity of collected samples.","Successfully leveraging this complex data, while overcoming the scarcity of high-quality training samples, is key to improving these models' predictive performance.","We introduce ``FuseMoE'', a mixture-of-experts framework incorporated with an innovative gating function.","Designed to integrate a diverse number of modalities, FuseMoE is effective in managing scenarios with missing modalities and irregularly sampled data trajectories.","Theoretically, our unique gating function contributes to enhanced convergence rates, leading to better performance in multiple downstream tasks.","The practical utility of FuseMoE in real world is validated by a challenging set of clinical risk prediction tasks."],"url":"http://arxiv.org/abs/2402.03226v1"}
{"created":"2024-02-05 17:36:19","title":"English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts","abstract":"Emotion classification in text is a challenging and subjective task, due to the involved cognitive inference processes that are required to interpret a textual stimulus. In addition, the set of emotion categories is highly domain-specific. For instance, literature analysis might require the use of aesthetic emotions (e.g., finding something beautiful), and social media analysis could benefit from fine-grained sets (e.g., separating anger from annoyance) in contrast to basic emotion categories. This renders the task an interesting field for zero-shot classifications, in which the label set is not known at model development time. Unfortunately, most resources for emotion analysis are English, and therefore, most studies on emotion analysis have been performed in English, including those that involve prompting language models for text labels. This leaves us with a research gap that we address in this paper: In which language should we prompt for emotion labels on non-English texts? This is particularly of interest when we have access to a multilingual large language model, because we could request labels with English prompts even for non-English data. Our experiments with natural language inference-based language models show that it is consistently better to use English prompts even if the data is in a different language.","sentences":["Emotion classification in text is a challenging and subjective task, due to the involved cognitive inference processes that are required to interpret a textual stimulus.","In addition, the set of emotion categories is highly domain-specific.","For instance, literature analysis might require the use of aesthetic emotions (e.g., finding something beautiful), and social media analysis could benefit from fine-grained sets (e.g., separating anger from annoyance) in contrast to basic emotion categories.","This renders the task an interesting field for zero-shot classifications, in which the label set is not known at model development time.","Unfortunately, most resources for emotion analysis are English, and therefore, most studies on emotion analysis have been performed in English, including those that involve prompting language models for text labels.","This leaves us with a research gap that we address in this paper: In which language should we prompt for emotion labels on non-English texts?","This is particularly of interest when we have access to a multilingual large language model, because we could request labels with English prompts even for non-English data.","Our experiments with natural language inference-based language models show that it is consistently better to use English prompts even if the data is in a different language."],"url":"http://arxiv.org/abs/2402.03223v1"}
{"created":"2024-02-05 17:33:22","title":"\"Define Your Terms\" : Enhancing Efficient Offensive Speech Classification with Definition","abstract":"The propagation of offensive content through social media channels has garnered attention of the research community. Multiple works have proposed various semantically related yet subtle distinct categories of offensive speech. In this work, we explore meta-earning approaches to leverage the diversity of offensive speech corpora to enhance their reliable and efficient detection. We propose a joint embedding architecture that incorporates the input's label and definition for classification via Prototypical Network. Our model achieves at least 75% of the maximal F1-score while using less than 10% of the available training data across 4 datasets. Our experimental findings also provide a case study of training strategies valuable to combat resource scarcity.","sentences":["The propagation of offensive content through social media channels has garnered attention of the research community.","Multiple works have proposed various semantically related yet subtle distinct categories of offensive speech.","In this work, we explore meta-earning approaches to leverage the diversity of offensive speech corpora to enhance their reliable and efficient detection.","We propose a joint embedding architecture that incorporates the input's label and definition for classification via Prototypical Network.","Our model achieves at least 75% of the maximal F1-score while using less than 10% of the available training data across 4 datasets.","Our experimental findings also provide a case study of training strategies valuable to combat resource scarcity."],"url":"http://arxiv.org/abs/2402.03221v1"}
{"created":"2024-02-05 17:26:49","title":"BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation","abstract":"In this paper, we present a new embedding model, called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It can support more than 100 working languages, leading to new state-of-the-art performances on multi-lingual and cross-lingual retrieval tasks. It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval, which provides a unified model foundation for real-world IR applications. It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens. The effective training of M3-Embedding involves the following technical contributions. We propose a novel self-knowledge distillation approach, where the relevance scores from different retrieval functionalities can be integrated as the teacher signal to enhance the training quality. We also optimize the batching strategy, enabling a large batch size and high training throughput to ensure the discriminativeness of embeddings. To the best of our knowledge, M3-Embedding is the first embedding model which realizes such a strong versatility. The model and code will be publicly available at https://github.com/FlagOpen/FlagEmbedding.","sentences":["In this paper, we present a new embedding model, called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity.","It can support more than 100 working languages, leading to new state-of-the-art performances on multi-lingual and cross-lingual retrieval tasks.","It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval, which provides a unified model foundation for real-world IR applications.","It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens.","The effective training of M3-Embedding involves the following technical contributions.","We propose a novel self-knowledge distillation approach, where the relevance scores from different retrieval functionalities can be integrated as the teacher signal to enhance the training quality.","We also optimize the batching strategy, enabling a large batch size and high training throughput to ensure the discriminativeness of embeddings.","To the best of our knowledge, M3-Embedding is the first embedding model which realizes such a strong versatility.","The model and code will be publicly available at https://github.com/FlagOpen/FlagEmbedding."],"url":"http://arxiv.org/abs/2402.03216v1"}
{"created":"2024-02-05 17:25:04","title":"Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?","abstract":"The advent of generative AI images has completely disrupted the art world. Identifying AI generated images from human art is a challenging problem whose impact is growing over time. The failure to address this problem allows bad actors to defraud individuals paying a premium for human art, and companies whose stated policies forbid AI imagery. This is also critical for AI model trainers, who need to filter training data to avoid potential model collapse. There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques. In this paper, we seek to understand how well these approaches can perform against today's modern generative models in both benign and adversarial settings. We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 4000+ professional artists, and 13 expert artists experienced at detecting AI). Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives). We believe these weaknesses will remain as models continue to evolve, and use our data to demonstrate why a combined team of human and automated detectors provides the best combination of accuracy and robustness.","sentences":["The advent of generative AI images has completely disrupted the art world.","Identifying AI generated images from human art is a challenging problem whose impact is growing over time.","The failure to address this problem allows bad actors to defraud individuals paying a premium for human art, and companies whose stated policies forbid AI imagery.","This is also critical for AI model trainers, who need to filter training data to avoid potential model collapse.","There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques.","In this paper, we seek to understand how well these approaches can perform against today's modern generative models in both benign and adversarial settings.","We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 4000+ professional artists, and 13 expert artists experienced at detecting AI).","Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives).","We believe these weaknesses will remain as models continue to evolve, and use our data to demonstrate why a combined team of human and automated detectors provides the best combination of accuracy and robustness."],"url":"http://arxiv.org/abs/2402.03214v1"}
{"created":"2024-02-05 17:17:57","title":"Light and Optimal Schr\u00f6dinger Bridge Matching","abstract":"Schr\\\"odinger Bridges (SB) have recently gained the attention of the ML community as a promising extension of classic diffusion models which is also interconnected to the Entropic Optimal Transport (EOT). Recent solvers for SB exploit the pervasive bridge matching procedures. Such procedures aim to recover a stochastic process transporting the mass between distributions given only a transport plan between them. In particular, given the EOT plan, these procedures can be adapted to solve SB. This fact is heavily exploited by recent works giving rives to matching-based SB solvers. The cornerstone here is recovering the EOT plan: recent works either use heuristical approximations (e.g., the minibatch OT) or establish iterative matching procedures which by the design accumulate the error during the training. We address these limitations and propose a novel procedure to learn SB which we call the \\textbf{optimal Schr\\\"odinger bridge matching}. It exploits the optimal parameterization of the diffusion process and provably recovers the SB process \\textbf{(a)} with a single bridge matching step and \\textbf{(b)} with arbitrary transport plan as the input. Furthermore, we show that the optimal bridge matching objective coincides with the recently discovered energy-based modeling (EBM) objectives to learn EOT/SB. Inspired by this observation, we develop a light solver (which we call LightSB-M) to implement optimal matching in practice using the Gaussian mixture parameterization of the Schr\\\"odinger potential. We experimentally showcase the performance of our solver in a range of practical tasks. The code for the LightSB-M solver can be found at \\url{https://github.com/SKholkin/LightSB-Matching}.","sentences":["Schr\\\"odinger Bridges (SB) have recently gained the attention of the ML community as a promising extension of classic diffusion models which is also interconnected to the Entropic Optimal Transport (EOT).","Recent solvers for SB exploit the pervasive bridge matching procedures.","Such procedures aim to recover a stochastic process transporting the mass between distributions given only a transport plan between them.","In particular, given the EOT plan, these procedures can be adapted to solve SB.","This fact is heavily exploited by recent works giving rives to matching-based SB solvers.","The cornerstone here is recovering the EOT plan: recent works either use heuristical approximations (e.g., the minibatch OT) or establish iterative matching procedures which by the design accumulate the error during the training.","We address these limitations and propose a novel procedure to learn SB which we call the \\textbf{optimal Schr\\\"odinger bridge matching}.","It exploits the optimal parameterization of the diffusion process and provably recovers the SB process \\textbf{(a)} with a single bridge matching step and \\textbf{(b)} with arbitrary transport plan as the input.","Furthermore, we show that the optimal bridge matching objective coincides with the recently discovered energy-based modeling (EBM) objectives to learn EOT/SB.","Inspired by this observation, we develop a light solver (which we call LightSB-M) to implement optimal matching in practice using the Gaussian mixture parameterization of the Schr\\\"odinger potential.","We experimentally showcase the performance of our solver in a range of practical tasks.","The code for the LightSB-M solver can be found at \\url{https://github.com/SKholkin/LightSB-Matching}."],"url":"http://arxiv.org/abs/2402.03207v1"}
{"created":"2024-02-05 17:15:00","title":"Multi-agent Reinforcement Learning for Energy Saving in Multi-Cell Massive MIMO Systems","abstract":"We develop a multi-agent reinforcement learning (MARL) algorithm to minimize the total energy consumption of multiple massive MIMO (multiple-input multiple-output) base stations (BSs) in a multi-cell network while preserving the overall quality-of-service (QoS) by making decisions on the multi-level advanced sleep modes (ASMs) and antenna switching of these BSs. The problem is modeled as a decentralized partially observable Markov decision process (DEC-POMDP) to enable collaboration between individual BSs, which is necessary to tackle inter-cell interference. A multi-agent proximal policy optimization (MAPPO) algorithm is designed to learn a collaborative BS control policy. To enhance its scalability, a modified version called MAPPO-neighbor policy is further proposed. Simulation results demonstrate that the trained MAPPO agent achieves better performance compared to baseline policies. Specifically, compared to the auto sleep mode 1 (symbol-level sleeping) algorithm, the MAPPO-neighbor policy reduces power consumption by approximately 8.7% during low-traffic hours and improves energy efficiency by approximately 19% during high-traffic hours, respectively.","sentences":["We develop a multi-agent reinforcement learning (MARL) algorithm to minimize the total energy consumption of multiple massive MIMO (multiple-input multiple-output) base stations (BSs) in a multi-cell network while preserving the overall quality-of-service (QoS) by making decisions on the multi-level advanced sleep modes (ASMs) and antenna switching of these BSs.","The problem is modeled as a decentralized partially observable Markov decision process (DEC-POMDP) to enable collaboration between individual BSs, which is necessary to tackle inter-cell interference.","A multi-agent proximal policy optimization (MAPPO) algorithm is designed to learn a collaborative BS control policy.","To enhance its scalability, a modified version called MAPPO-neighbor policy is further proposed.","Simulation results demonstrate that the trained MAPPO agent achieves better performance compared to baseline policies.","Specifically, compared to the auto sleep mode 1 (symbol-level sleeping) algorithm, the MAPPO-neighbor policy reduces power consumption by approximately 8.7% during low-traffic hours and improves energy efficiency by approximately 19% during high-traffic hours, respectively."],"url":"http://arxiv.org/abs/2402.03204v1"}
{"created":"2024-02-05 17:13:12","title":"Leveraging IRS Induced Time Delay for Enhanced Physical Layer Security in VLC Systems","abstract":"Indoor visible light communication (VLC) is considered secure against attackers outside the confined area where the light propagates, but it is still susceptible to interception from inside the coverage area. A new technology, intelligent reflecting surfaces (IRS), has been recently introduced, offering a way to enhance physical layer security (PLS). Most research on IRS-assisted VLC assumes the same time of arrival from all reflecting elements and overlooks the effect of time delay and the associated intersymbol interference. This paper tackles, for the first time, the effect of time delay on the secrecy rate in VLC systems. Our results show that, at a fixed light-emitting diode (LED) power of 3W, the secrecy rate can be enhanced by up to 253\\% at random positions for the legitimate user when the eavesdropper is located within a 1-meter radius of the LED. Our results also show that careful allocation of the IRS elements can lead to enhanced PLS even when the eavesdropper has a more favourable position and, thus, a better channel gain than the legitimate user.","sentences":["Indoor visible light communication (VLC) is considered secure against attackers outside the confined area where the light propagates, but it is still susceptible to interception from inside the coverage area.","A new technology, intelligent reflecting surfaces (IRS), has been recently introduced, offering a way to enhance physical layer security (PLS).","Most research on IRS-assisted VLC assumes the same time of arrival from all reflecting elements and overlooks the effect of time delay and the associated intersymbol interference.","This paper tackles, for the first time, the effect of time delay on the secrecy rate in VLC systems.","Our results show that, at a fixed light-emitting diode (LED) power of 3W, the secrecy rate can be enhanced by up to 253\\% at random positions for the legitimate user when the eavesdropper is located within a 1-meter radius of the LED.","Our results also show that careful allocation of the IRS elements can lead to enhanced PLS even when the eavesdropper has a more favourable position and, thus, a better channel gain than the legitimate user."],"url":"http://arxiv.org/abs/2402.03202v1"}
{"created":"2024-02-05 17:12:21","title":"Guidance with Spherical Gaussian Constraint for Conditional Diffusion","abstract":"Recent advances in diffusion models attempt to handle conditional generative tasks by utilizing a differentiable loss function for guidance without the need for additional training. While these methods achieved certain success, they often compromise on sample quality and require small guidance step sizes, leading to longer sampling processes. This paper reveals that the fundamental issue lies in the manifold deviation during the sampling process when loss guidance is employed. We theoretically show the existence of manifold deviation by establishing a certain lower bound for the estimation error of the loss guidance. To mitigate this problem, we propose Diffusion with Spherical Gaussian constraint (DSG), drawing inspiration from the concentration phenomenon in high-dimensional Gaussian distributions. DSG effectively constrains the guidance step within the intermediate data manifold through optimization and enables the use of larger guidance steps. Furthermore, we present a closed-form solution for DSG denoising with the Spherical Gaussian constraint. Notably, DSG can seamlessly integrate as a plugin module within existing training-free conditional diffusion methods. Implementing DSG merely involves a few lines of additional code with almost no extra computational overhead, yet it leads to significant performance improvements. Comprehensive experimental results in various conditional generation tasks validate the superiority and adaptability of DSG in terms of both sample quality and time efficiency.","sentences":["Recent advances in diffusion models attempt to handle conditional generative tasks by utilizing a differentiable loss function for guidance without the need for additional training.","While these methods achieved certain success, they often compromise on sample quality and require small guidance step sizes, leading to longer sampling processes.","This paper reveals that the fundamental issue lies in the manifold deviation during the sampling process when loss guidance is employed.","We theoretically show the existence of manifold deviation by establishing a certain lower bound for the estimation error of the loss guidance.","To mitigate this problem, we propose Diffusion with Spherical Gaussian constraint (DSG), drawing inspiration from the concentration phenomenon in high-dimensional Gaussian distributions.","DSG effectively constrains the guidance step within the intermediate data manifold through optimization and enables the use of larger guidance steps.","Furthermore, we present a closed-form solution for DSG denoising with the Spherical Gaussian constraint.","Notably, DSG can seamlessly integrate as a plugin module within existing training-free conditional diffusion methods.","Implementing DSG merely involves a few lines of additional code with almost no extra computational overhead, yet it leads to significant performance improvements.","Comprehensive experimental results in various conditional generation tasks validate the superiority and adaptability of DSG in terms of both sample quality and time efficiency."],"url":"http://arxiv.org/abs/2402.03201v1"}
{"created":"2024-02-05 17:03:10","title":"SOAP: A Social Authentication Protocol","abstract":"Social authentication has been suggested as a usable authentication ceremony to replace manual key authentication in messaging applications. Using social authentication, chat partners authenticate their peers using digital identities managed by identity providers. In this paper, we formally define social authentication, present a protocol called SOAP that largely automates social authentication, formally prove SOAP's security, and demonstrate SOAP's practicality in two prototypes. One prototype is web-based, and the other is implemented in the open-source Signal messaging application.   Using SOAP, users can significantly raise the bar for compromising their messaging accounts. In contrast to the default security provided by messaging applications such as Signal and WhatsApp, attackers must compromise both the messaging account and all identity provider-managed identities to attack a victim. In addition to its security and automation, SOAP is straightforward to adopt as it is built on top of the well-established OpenID Connect protocol.","sentences":["Social authentication has been suggested as a usable authentication ceremony to replace manual key authentication in messaging applications.","Using social authentication, chat partners authenticate their peers using digital identities managed by identity providers.","In this paper, we formally define social authentication, present a protocol called SOAP that largely automates social authentication, formally prove SOAP's security, and demonstrate SOAP's practicality in two prototypes.","One prototype is web-based, and the other is implemented in the open-source Signal messaging application.   ","Using SOAP, users can significantly raise the bar for compromising their messaging accounts.","In contrast to the default security provided by messaging applications such as Signal and WhatsApp, attackers must compromise both the messaging account and all identity provider-managed identities to attack a victim.","In addition to its security and automation, SOAP is straightforward to adopt as it is built on top of the well-established OpenID Connect protocol."],"url":"http://arxiv.org/abs/2402.03199v1"}
{"created":"2024-02-05 17:01:15","title":"Lightweight Masking Against Static Power Side-Channel Attacks","abstract":"This paper presents a novel defense strategy against static power side-channel attacks (PSCAs), a critical threat to cryptographic security. Our method is based on (1) carefully tuning high-Vth versus low-Vth cell selection during synthesis, accounting for both security and timing impact, and (2), at runtime, randomly switching the operation between these cells. This approach serves to significantly obscure static power patterns, which are at the heart of static PSCAs. Our experimental results on a commercial 28nm node show a drastic increase in the effort required for a successful attack, namely up to 96 times more traces. When compared to prior countermeasures, ours incurs little cost, making it a lightweight defense.","sentences":["This paper presents a novel defense strategy against static power side-channel attacks (PSCAs), a critical threat to cryptographic security.","Our method is based on (1) carefully tuning high-Vth versus low-Vth cell selection during synthesis, accounting for both security and timing impact, and (2), at runtime, randomly switching the operation between these cells.","This approach serves to significantly obscure static power patterns, which are at the heart of static PSCAs.","Our experimental results on a commercial 28nm node show a drastic increase in the effort required for a successful attack, namely up to 96 times more traces.","When compared to prior countermeasures, ours incurs little cost, making it a lightweight defense."],"url":"http://arxiv.org/abs/2402.03196v1"}
{"created":"2024-02-05 16:57:24","title":"Isotropy, Clusters, and Classifiers","abstract":"Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion. Evidence has been accrued both for and against enforcing isotropy in embedding spaces. In the present paper, we stress that isotropy imposes requirements on the embedding space that are not compatible with the presence of clusters -- which also negatively impacts linear classification objectives. We demonstrate this fact empirically and use it to shed light on previous results from the literature.","sentences":["Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion.","Evidence has been accrued both for and against enforcing isotropy in embedding spaces.","In the present paper, we stress that isotropy imposes requirements on the embedding space that are not compatible with the presence of clusters -- which also negatively impacts linear classification objectives.","We demonstrate this fact empirically and use it to shed light on previous results from the literature."],"url":"http://arxiv.org/abs/2402.03191v1"}
{"created":"2024-02-05 16:56:11","title":"Unified Hallucination Detection for Multimodal Large Language Models","abstract":"Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment. Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity. In response to these challenges, our work expands the investigative horizons of hallucination detection. We present a novel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate the evaluation of advancements in hallucination detection methods. Additionally, we unveil a novel unified multimodal hallucination detection framework, UNIHD, which leverages a suite of auxiliary tools to validate the occurrence of hallucinations robustly. We demonstrate the effectiveness of UNIHD through meticulous evaluation and comprehensive analysis. We also provide strategic insights on the application of specific tools for addressing various categories of hallucinations.","sentences":["Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination.","The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment.","Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity.","In response to these challenges, our work expands the investigative horizons of hallucination detection.","We present a novel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate the evaluation of advancements in hallucination detection methods.","Additionally, we unveil a novel unified multimodal hallucination detection framework, UNIHD, which leverages a suite of auxiliary tools to validate the occurrence of hallucinations robustly.","We demonstrate the effectiveness of UNIHD through meticulous evaluation and comprehensive analysis.","We also provide strategic insights on the application of specific tools for addressing various categories of hallucinations."],"url":"http://arxiv.org/abs/2402.03190v1"}
{"created":"2024-02-05 16:53:54","title":"Towards mitigating uncann(eye)ness in face swaps via gaze-centric loss terms","abstract":"Advances in face swapping have enabled the automatic generation of highly realistic faces. Yet face swaps are perceived differently than when looking at real faces, with key differences in viewer behavior surrounding the eyes. Face swapping algorithms generally place no emphasis on the eyes, relying on pixel or feature matching losses that consider the entire face to guide the training process. We further investigate viewer perception of face swaps, focusing our analysis on the presence of an uncanny valley effect. We additionally propose a novel loss equation for the training of face swapping models, leveraging a pretrained gaze estimation network to directly improve representation of the eyes. We confirm that viewed face swaps do elicit uncanny responses from viewers. Our proposed improvements significant reduce viewing angle errors between face swaps and their source material. Our method additionally reduces the prevalence of the eyes as a deciding factor when viewers perform deepfake detection tasks. Our findings have implications on face swapping for special effects, as digital avatars, as privacy mechanisms, and more; negative responses from users could limit effectiveness in said applications. Our gaze improvements are a first step towards alleviating negative viewer perceptions via a targeted approach.","sentences":["Advances in face swapping have enabled the automatic generation of highly realistic faces.","Yet face swaps are perceived differently than when looking at real faces, with key differences in viewer behavior surrounding the eyes.","Face swapping algorithms generally place no emphasis on the eyes, relying on pixel or feature matching losses that consider the entire face to guide the training process.","We further investigate viewer perception of face swaps, focusing our analysis on the presence of an uncanny valley effect.","We additionally propose a novel loss equation for the training of face swapping models, leveraging a pretrained gaze estimation network to directly improve representation of the eyes.","We confirm that viewed face swaps do elicit uncanny responses from viewers.","Our proposed improvements significant reduce viewing angle errors between face swaps and their source material.","Our method additionally reduces the prevalence of the eyes as a deciding factor when viewers perform deepfake detection tasks.","Our findings have implications on face swapping for special effects, as digital avatars, as privacy mechanisms, and more; negative responses from users could limit effectiveness in said applications.","Our gaze improvements are a first step towards alleviating negative viewer perceptions via a targeted approach."],"url":"http://arxiv.org/abs/2402.03188v1"}
{"created":"2024-02-05 16:50:39","title":"Charting The Evolution of Solidity Error Handling","abstract":"The usage of error handling in Solidity smart contracts is vital because smart contracts perform transactions that should be verified. Transactions that are not carefully handled, may lead to program crashes and vulnerabilities, implying financial loss and legal consequences. While Solidity designers attempt to constantly update the language with new features, including error-handling (EH) features, it is necessary for developers to promptly absorb how to use them. We conduct a large-scale empirical study on 283K unique open-source smart contracts to identify patterns regarding the usage of Solidity EH features over time. Overall, the usage of most EH features is limited. However, we observe an upward trend (> 60%) in the usage of a Solidity-tailored EH feature, i.e., require. This indicates that designers of modern programming languages may consider making error handling more tailored to the purposes of each language. Our analysis on 102 versions of the Solidity documentation indicates the volatile nature of Solidity, as the language changes frequently, i.e., there are changes on EH features once or twice a year. Such frequent releases may confuse smart contract developers, discouraging them to carefully read the Solidity documentation, and correctly adopt EH features. Furthermore, our findings reveal that nearly 70% of the examined smart contracts are exposed to potential failures due to missing error handing, e.g., unchecked external calls. Therefore, the use of EH features should be further supported via a more informative documentation containing (1) representative and meaningful examples and (2) details about the impact of potential EH misuses.","sentences":["The usage of error handling in Solidity smart contracts is vital because smart contracts perform transactions that should be verified.","Transactions that are not carefully handled, may lead to program crashes and vulnerabilities, implying financial loss and legal consequences.","While Solidity designers attempt to constantly update the language with new features, including error-handling (EH) features, it is necessary for developers to promptly absorb how to use them.","We conduct a large-scale empirical study on 283K unique open-source smart contracts to identify patterns regarding the usage of Solidity EH features over time.","Overall, the usage of most EH features is limited.","However, we observe an upward trend (> 60%) in the usage of a Solidity-tailored EH feature, i.e., require.","This indicates that designers of modern programming languages may consider making error handling more tailored to the purposes of each language.","Our analysis on 102 versions of the Solidity documentation indicates the volatile nature of Solidity, as the language changes frequently, i.e., there are changes on EH features once or twice a year.","Such frequent releases may confuse smart contract developers, discouraging them to carefully read the Solidity documentation, and correctly adopt EH features.","Furthermore, our findings reveal that nearly 70% of the examined smart contracts are exposed to potential failures due to missing error handing, e.g., unchecked external calls.","Therefore, the use of EH features should be further supported via a more informative documentation containing (1) representative and meaningful examples and (2) details about the impact of potential EH misuses."],"url":"http://arxiv.org/abs/2402.03186v1"}
{"created":"2024-02-05 16:47:13","title":"Predicting Configuration Performance in Multiple Environments with Sequential Meta-learning","abstract":"Learning and predicting the performance of given software configurations are of high importance to many software engineering activities. While configurable software systems will almost certainly face diverse running environments (e.g., version, hardware, and workload), current work often either builds performance models under a single environment or fails to properly handle data from diverse settings, hence restricting their accuracy for new environments. In this paper, we target configuration performance learning under multiple environments. We do so by designing SeMPL - a meta-learning framework that learns the common understanding from configurations measured in distinct (meta) environments and generalizes them to the unforeseen, target environment. What makes it unique is that unlike common meta-learning frameworks (e.g., MAML and MetaSGD) that train the meta environments in parallel, we train them sequentially, one at a time. The order of training naturally allows discriminating the contributions among meta environments in the meta-model built, which fits better with the characteristic of configuration data that is known to dramatically differ between different environments. Through comparing with 15 state-of-the-art models under nine systems, our extensive experimental results demonstrate that SeMPL performs considerably better on 89% of the systems with up to 99% accuracy improvement, while being data-efficient, leading to a maximum of 3.86x speedup. All code and data can be found at our repository: https://github.com/ideas-labo/SeMPL.","sentences":["Learning and predicting the performance of given software configurations are of high importance to many software engineering activities.","While configurable software systems will almost certainly face diverse running environments (e.g., version, hardware, and workload), current work often either builds performance models under a single environment or fails to properly handle data from diverse settings, hence restricting their accuracy for new environments.","In this paper, we target configuration performance learning under multiple environments.","We do so by designing SeMPL - a meta-learning framework that learns the common understanding from configurations measured in distinct (meta) environments and generalizes them to the unforeseen, target environment.","What makes it unique is that unlike common meta-learning frameworks (e.g., MAML and MetaSGD) that train the meta environments in parallel, we train them sequentially, one at a time.","The order of training naturally allows discriminating the contributions among meta environments in the meta-model built, which fits better with the characteristic of configuration data that is known to dramatically differ between different environments.","Through comparing with 15 state-of-the-art models under nine systems, our extensive experimental results demonstrate that SeMPL performs considerably better on 89% of the systems with up to 99% accuracy improvement, while being data-efficient, leading to a maximum of 3.86x speedup.","All code and data can be found at our repository: https://github.com/ideas-labo/SeMPL."],"url":"http://arxiv.org/abs/2402.03183v1"}
{"created":"2024-02-05 16:46:35","title":"Empowering Time Series Analysis with Large Language Models: A Survey","abstract":"Recently, remarkable progress has been made over large language models (LLMs), demonstrating their unprecedented capability in varieties of natural language tasks. However, completely training a large general-purpose model from the scratch is challenging for time series analysis, due to the large volumes and varieties of time series data, as well as the non-stationarity that leads to concept drift impeding continuous model adaptation and re-training. Recent advances have shown that pre-trained LLMs can be exploited to capture complex dependencies in time series data and facilitate various applications. In this survey, we provide a systematic overview of existing methods that leverage LLMs for time series analysis. Specifically, we first state the challenges and motivations of applying language models in the context of time series as well as brief preliminaries of LLMs. Next, we summarize the general pipeline for LLM-based time series analysis, categorize existing methods into different groups (i.e., direct query, tokenization, prompt design, fine-tune, and model integration), and highlight the key ideas within each group. We also discuss the applications of LLMs for both general and spatial-temporal time series data, tailored to specific domains. Finally, we thoroughly discuss future research opportunities to empower time series analysis with LLMs.","sentences":["Recently, remarkable progress has been made over large language models (LLMs), demonstrating their unprecedented capability in varieties of natural language tasks.","However, completely training a large general-purpose model from the scratch is challenging for time series analysis, due to the large volumes and varieties of time series data, as well as the non-stationarity that leads to concept drift impeding continuous model adaptation and re-training.","Recent advances have shown that pre-trained LLMs can be exploited to capture complex dependencies in time series data and facilitate various applications.","In this survey, we provide a systematic overview of existing methods that leverage LLMs for time series analysis.","Specifically, we first state the challenges and motivations of applying language models in the context of time series as well as brief preliminaries of LLMs.","Next, we summarize the general pipeline for LLM-based time series analysis, categorize existing methods into different groups (i.e., direct query, tokenization, prompt design, fine-tune, and model integration), and highlight the key ideas within each group.","We also discuss the applications of LLMs for both general and spatial-temporal time series data, tailored to specific domains.","Finally, we thoroughly discuss future research opportunities to empower time series analysis with LLMs."],"url":"http://arxiv.org/abs/2402.03182v1"}
{"created":"2024-02-05 16:46:16","title":"C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models","abstract":"Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk functions under test distribution shifts. We prove that RAG achieves a lower conformal generation risk than that of a single LLM when the quality of the retrieval model and transformer is non-trivial. Our intensive empirical results demonstrate the soundness and tightness of our conformal generation risk guarantees across four widely-used NLP datasets on four state-of-the-art retrieval models.","sentences":["Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments.","Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored.","In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks.","We propose C-RAG, the first framework to certify generation risks for RAG models.","Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk.","We also provide theoretical guarantees on conformal generation risks for general bounded risk functions under test distribution shifts.","We prove that RAG achieves a lower conformal generation risk than that of a single LLM when the quality of the retrieval model and transformer is non-trivial.","Our intensive empirical results demonstrate the soundness and tightness of our conformal generation risk guarantees across four widely-used NLP datasets on four state-of-the-art retrieval models."],"url":"http://arxiv.org/abs/2402.03181v1"}
{"created":"2024-02-05 16:44:17","title":"CIDAR: Culturally Relevant Instruction Dataset For Arabic","abstract":"Instruction tuning has emerged as a prominent methodology for teaching Large Language Models (LLMs) to follow instructions. However, current instruction datasets predominantly cater to English or are derived from English-dominated LLMs, resulting in inherent biases toward Western culture. This bias significantly impacts the linguistic structures of non-English languages such as Arabic, which has a distinct grammar reflective of the diverse cultures across the Arab region. This paper addresses this limitation by introducing CIDAR: https://hf.co/datasets/arbml/CIDAR, the first open Arabic instruction-tuning dataset culturally-aligned by human reviewers. CIDAR contains 10,000 instruction and output pairs that represent the Arab region. We discuss the cultural relevance of CIDAR via the analysis and comparison to other models fine-tuned on other datasets. Our experiments show that CIDAR can help enrich research efforts in aligning LLMs with the Arabic culture. All the code is available at https://github.com/ARBML/CIDAR.","sentences":["Instruction tuning has emerged as a prominent methodology for teaching Large Language Models (LLMs) to follow instructions.","However, current instruction datasets predominantly cater to English or are derived from English-dominated LLMs, resulting in inherent biases toward Western culture.","This bias significantly impacts the linguistic structures of non-English languages such as Arabic, which has a distinct grammar reflective of the diverse cultures across the Arab region.","This paper addresses this limitation by introducing CIDAR: https://hf.co/datasets/arbml/CIDAR, the first open Arabic instruction-tuning dataset culturally-aligned by human reviewers.","CIDAR contains 10,000 instruction and output pairs that represent the Arab region.","We discuss the cultural relevance of CIDAR via the analysis and comparison to other models fine-tuned on other datasets.","Our experiments show that CIDAR can help enrich research efforts in aligning LLMs with the Arabic culture.","All the code is available at https://github.com/ARBML/CIDAR."],"url":"http://arxiv.org/abs/2402.03177v1"}
{"created":"2024-02-05 16:43:53","title":"Comparison of Topic Modelling Approaches in the Banking Context","abstract":"Topic modelling is a prominent task for automatic topic extraction in many applications such as sentiment analysis and recommendation systems. The approach is vital for service industries to monitor their customer discussions. The use of traditional approaches such as Latent Dirichlet Allocation (LDA) for topic discovery has shown great performances, however, they are not consistent in their results as these approaches suffer from data sparseness and inability to model the word order in a document. Thus, this study presents the use of Kernel Principal Component Analysis (KernelPCA) and K-means Clustering in the BERTopic architecture. We have prepared a new dataset using tweets from customers of Nigerian banks and we use this to compare the topic modelling approaches. Our findings showed KernelPCA and K-means in the BERTopic architecture-produced coherent topics with a coherence score of 0.8463.","sentences":["Topic modelling is a prominent task for automatic topic extraction in many applications such as sentiment analysis and recommendation systems.","The approach is vital for service industries to monitor their customer discussions.","The use of traditional approaches such as Latent Dirichlet Allocation (LDA) for topic discovery has shown great performances, however, they are not consistent in their results as these approaches suffer from data sparseness and inability to model the word order in a document.","Thus, this study presents the use of Kernel Principal Component Analysis (KernelPCA) and K-means Clustering in the BERTopic architecture.","We have prepared a new dataset using tweets from customers of Nigerian banks and we use this to compare the topic modelling approaches.","Our findings showed KernelPCA and K-means in the BERTopic architecture-produced coherent topics with a coherence score of 0.8463."],"url":"http://arxiv.org/abs/2402.03176v1"}
{"created":"2024-02-05 16:42:10","title":"The Matrix: A Bayesian learning model for LLMs","abstract":"In this paper, we introduce a Bayesian learning model to understand the behavior of Large Language Models (LLMs). We explore the optimization metric of LLMs, which is based on predicting the next token, and develop a novel model grounded in this principle. Our approach involves constructing an ideal generative text model represented by a multinomial transition probability matrix with a prior, and we examine how LLMs approximate this matrix. We discuss the continuity of the mapping between embeddings and multinomial distributions, and present the Dirichlet approximation theorem to approximate any prior. Additionally, we demonstrate how text generation by LLMs aligns with Bayesian learning principles and delve into the implications for in-context learning, specifically explaining why in-context learning emerges in larger models where prompts are considered as samples to be updated. Our findings indicate that the behavior of LLMs is consistent with Bayesian Learning, offering new insights into their functioning and potential applications.","sentences":["In this paper, we introduce a Bayesian learning model to understand the behavior of Large Language Models (LLMs).","We explore the optimization metric of LLMs, which is based on predicting the next token, and develop a novel model grounded in this principle.","Our approach involves constructing an ideal generative text model represented by a multinomial transition probability matrix with a prior, and we examine how LLMs approximate this matrix.","We discuss the continuity of the mapping between embeddings and multinomial distributions, and present the Dirichlet approximation theorem to approximate any prior.","Additionally, we demonstrate how text generation by LLMs aligns with Bayesian learning principles and delve into the implications for in-context learning, specifically explaining why in-context learning emerges in larger models where prompts are considered as samples to be updated.","Our findings indicate that the behavior of LLMs is consistent with Bayesian Learning, offering new insights into their functioning and potential applications."],"url":"http://arxiv.org/abs/2402.03175v1"}
{"created":"2024-02-05 16:41:02","title":"Multi: Multimodal Understanding Leaderboard with Text and Images","abstract":"Rapid progress in multimodal large language models (MLLMs) highlights the need to introduce challenging yet realistic benchmarks to the academic community. Existing benchmarks primarily focus on simple natural image understanding, but Multi emerges as a cutting-edge benchmark for MLLMs, offering a comprehensive dataset for evaluating MLLMs against understanding complex figures and tables, and scientific questions. This benchmark, reflecting current realistic examination styles, provides multimodal inputs and requires responses that are either precise or open-ended, similar to real-life school tests. It challenges MLLMs with a variety of tasks, ranging from formula derivation to image detail analysis, and cross-modality reasoning. Multi includes over 18,000 questions, with a focus on science-based QA in diverse formats. We also introduce Multi-Elite, a 500-question subset for testing the extremities of MLLMs, and Multi-Extend, which enhances In-Context Learning research with more than 4,500 knowledge pieces. Our evaluation indicates significant potential for MLLM advancement, with GPT-4V achieving a 63.7% accuracy rate on Multi, in contrast to other MLLMs scoring between 31.3% and 53.7%. Multi serves not only as a robust evaluation platform but also paves the way for the development of expert-level AI.","sentences":["Rapid progress in multimodal large language models (MLLMs) highlights the need to introduce challenging yet realistic benchmarks to the academic community.","Existing benchmarks primarily focus on simple natural image understanding, but Multi emerges as a cutting-edge benchmark for MLLMs, offering a comprehensive dataset for evaluating MLLMs against understanding complex figures and tables, and scientific questions.","This benchmark, reflecting current realistic examination styles, provides multimodal inputs and requires responses that are either precise or open-ended, similar to real-life school tests.","It challenges MLLMs with a variety of tasks, ranging from formula derivation to image detail analysis, and cross-modality reasoning.","Multi includes over 18,000 questions, with a focus on science-based QA in diverse formats.","We also introduce Multi-Elite, a 500-question subset for testing the extremities of MLLMs, and Multi-Extend, which enhances In-Context Learning research with more than 4,500 knowledge pieces.","Our evaluation indicates significant potential for MLLM advancement, with GPT-4V achieving a 63.7% accuracy rate on Multi, in contrast to other MLLMs scoring between 31.3% and 53.7%.","Multi serves not only as a robust evaluation platform but also paves the way for the development of expert-level AI."],"url":"http://arxiv.org/abs/2402.03173v1"}
{"created":"2024-02-05 16:40:23","title":"Accurate and Well-Calibrated ICD Code Assignment Through Attention Over Diverse Label Embeddings","abstract":"Although the International Classification of Diseases (ICD) has been adopted worldwide, manually assigning ICD codes to clinical text is time-consuming, error-prone, and expensive, motivating the development of automated approaches. This paper describes a novel approach for automated ICD coding, combining several ideas from previous related work. We specifically employ a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, we explored either (a) adapting the base encoder model into a Longformer, or (b) dividing the text into chunks and processing each chunk independently. The representations produced by the encoder are combined with a label embedding mechanism that explores diverse ICD code synonyms. Experiments with different splits of the MIMIC-III dataset show that the proposed approach outperforms the current state-of-the-art models in ICD coding, with the label embeddings significantly contributing to the good performance. Our approach also leads to properly calibrated classification results, which can effectively inform downstream tasks such as quantification.","sentences":["Although the International Classification of Diseases (ICD) has been adopted worldwide, manually assigning ICD codes to clinical text is time-consuming, error-prone, and expensive, motivating the development of automated approaches.","This paper describes a novel approach for automated ICD coding, combining several ideas from previous related work.","We specifically employ a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, we explored either (a) adapting the base encoder model into a Longformer, or (b) dividing the text into chunks and processing each chunk independently.","The representations produced by the encoder are combined with a label embedding mechanism that explores diverse ICD code synonyms.","Experiments with different splits of the MIMIC-III dataset show that the proposed approach outperforms the current state-of-the-art models in ICD coding, with the label embeddings significantly contributing to the good performance.","Our approach also leads to properly calibrated classification results, which can effectively inform downstream tasks such as quantification."],"url":"http://arxiv.org/abs/2402.03172v1"}
{"created":"2024-02-05 16:39:15","title":"Homograph Attacks on Maghreb Sentiment Analyzers","abstract":"We examine the impact of homograph attacks on the Sentiment Analysis (SA) task of different Arabic dialects from the Maghreb North-African countries. Homograph attacks result in a 65.3% decrease in transformer classification from an F1-score of 0.95 to 0.33 when data is written in \"Arabizi\". The goal of this study is to highlight LLMs weaknesses' and to prioritize ethical and responsible Machine Learning.","sentences":["We examine the impact of homograph attacks on the Sentiment Analysis (SA) task of different Arabic dialects from the Maghreb North-African countries.","Homograph attacks result in a 65.3% decrease in transformer classification from an F1-score of 0.95 to 0.33 when data is written in \"Arabizi\".","The goal of this study is to highlight LLMs weaknesses' and to prioritize ethical and responsible Machine Learning."],"url":"http://arxiv.org/abs/2402.03171v1"}
{"created":"2024-02-05 16:35:29","title":"RRWNet: Recursive Refinement Network for Effective Retinal Artery/Vein Segmentation and Classification","abstract":"The caliber and configuration of retinal blood vessels serve as important biomarkers for various diseases and medical conditions. A thorough analysis of the retinal vasculature requires the segmentation of blood vessels and their classification into arteries and veins, which is typically performed on color fundus images obtained by retinography, a widely used imaging technique. Nonetheless, manually performing these tasks is labor-intensive and prone to human error. Various automated methods have been proposed to address this problem. However, the current state of art in artery/vein segmentation and classification faces challenges due to manifest classification errors that affect the topological consistency of segmentation maps. This study presents an innovative end-to-end framework, RRWNet, designed to recursively refine semantic segmentation maps and correct manifest classification errors. The framework consists of a fully convolutional neural network with a Base subnetwork that generates base segmentation maps from input images, and a Recursive Refinement subnetwork that iteratively and recursively improves these maps. Evaluation on public datasets demonstrates the state-of-the-art performance of the proposed method, yielding more topologically consistent segmentation maps with fewer manifest classification errors than existing approaches. In addition, the Recursive Refinement module proves effective in post-processing segmentation maps from other methods, automatically correcting classification errors and improving topological consistency. The model code, weights, and predictions are publicly available at https://github.com/j-morano/rrwnet.","sentences":["The caliber and configuration of retinal blood vessels serve as important biomarkers for various diseases and medical conditions.","A thorough analysis of the retinal vasculature requires the segmentation of blood vessels and their classification into arteries and veins, which is typically performed on color fundus images obtained by retinography, a widely used imaging technique.","Nonetheless, manually performing these tasks is labor-intensive and prone to human error.","Various automated methods have been proposed to address this problem.","However, the current state of art in artery/vein segmentation and classification faces challenges due to manifest classification errors that affect the topological consistency of segmentation maps.","This study presents an innovative end-to-end framework, RRWNet, designed to recursively refine semantic segmentation maps and correct manifest classification errors.","The framework consists of a fully convolutional neural network with a Base subnetwork that generates base segmentation maps from input images, and a Recursive Refinement subnetwork that iteratively and recursively improves these maps.","Evaluation on public datasets demonstrates the state-of-the-art performance of the proposed method, yielding more topologically consistent segmentation maps with fewer manifest classification errors than existing approaches.","In addition, the Recursive Refinement module proves effective in post-processing segmentation maps from other methods, automatically correcting classification errors and improving topological consistency.","The model code, weights, and predictions are publicly available at https://github.com/j-morano/rrwnet."],"url":"http://arxiv.org/abs/2402.03166v1"}
{"created":"2024-02-05 16:32:12","title":"Decidable Reasoning About Time in Finite-Domain Situation Calculus Theories","abstract":"Representing time is crucial for cyber-physical systems and has been studied extensively in the Situation Calculus. The most commonly used approach represents time by adding a real-valued fluent $\\mathit{time}(a)$ that attaches a time point to each action and consequently to each situation. We show that in this approach, checking whether there is a reachable situation that satisfies a given formula is undecidable, even if the domain of discourse is restricted to a finite set of objects. We present an alternative approach based on well-established results from timed automata theory by introducing clocks as real-valued fluents with restricted successor state axioms and comparison operators. %that only allow comparisons against fixed rationals. With this restriction, we can show that the reachability problem for finite-domain basic action theories is decidable. Finally, we apply our results on Golog program realization by presenting a decidable procedure for determining an action sequence that is a successful execution of a given program.","sentences":["Representing time is crucial for cyber-physical systems and has been studied extensively in the Situation Calculus.","The most commonly used approach represents time by adding a real-valued fluent $\\mathit{time}(a)$ that attaches a time point to each action and consequently to each situation.","We show that in this approach, checking whether there is a reachable situation that satisfies a given formula is undecidable, even if the domain of discourse is restricted to a finite set of objects.","We present an alternative approach based on well-established results from timed automata theory by introducing clocks as real-valued fluents with restricted successor state axioms and comparison operators.","%that only allow comparisons against fixed rationals.","With this restriction, we can show that the reachability problem for finite-domain basic action theories is decidable.","Finally, we apply our results on Golog program realization by presenting a decidable procedure for determining an action sequence that is a successful execution of a given program."],"url":"http://arxiv.org/abs/2402.03164v1"}
{"created":"2024-02-05 16:31:03","title":"Linguistic features for sentence difficulty prediction in ABSA","abstract":"One of the challenges of natural language understanding is to deal with the subjectivity of sentences, which may express opinions and emotions that add layers of complexity and nuance. Sentiment analysis is a field that aims to extract and analyze these subjective elements from text, and it can be applied at different levels of granularity, such as document, paragraph, sentence, or aspect. Aspect-based sentiment analysis is a well-studied topic with many available data sets and models. However, there is no clear definition of what makes a sentence difficult for aspect-based sentiment analysis. In this paper, we explore this question by conducting an experiment with three data sets: \"Laptops\", \"Restaurants\", and \"MTSC\" (Multi-Target-dependent Sentiment Classification), and a merged version of these three datasets. We study the impact of domain diversity and syntactic diversity on difficulty. We use a combination of classifiers to identify the most difficult sentences and analyze their characteristics. We employ two ways of defining sentence difficulty. The first one is binary and labels a sentence as difficult if the classifiers fail to correctly predict the sentiment polarity. The second one is a six-level scale based on how many of the top five best-performing classifiers can correctly predict the sentiment polarity. We also define 9 linguistic features that, combined, aim at estimating the difficulty at sentence level.","sentences":["One of the challenges of natural language understanding is to deal with the subjectivity of sentences, which may express opinions and emotions that add layers of complexity and nuance.","Sentiment analysis is a field that aims to extract and analyze these subjective elements from text, and it can be applied at different levels of granularity, such as document, paragraph, sentence, or aspect.","Aspect-based sentiment analysis is a well-studied topic with many available data sets and models.","However, there is no clear definition of what makes a sentence difficult for aspect-based sentiment analysis.","In this paper, we explore this question by conducting an experiment with three data sets: \"Laptops\", \"Restaurants\", and \"MTSC\" (Multi-Target-dependent Sentiment Classification), and a merged version of these three datasets.","We study the impact of domain diversity and syntactic diversity on difficulty.","We use a combination of classifiers to identify the most difficult sentences and analyze their characteristics.","We employ two ways of defining sentence difficulty.","The first one is binary and labels a sentence as difficult if the classifiers fail to correctly predict the sentiment polarity.","The second one is a six-level scale based on how many of the top five best-performing classifiers can correctly predict the sentiment polarity.","We also define 9 linguistic features that, combined, aim at estimating the difficulty at sentence level."],"url":"http://arxiv.org/abs/2402.03163v1"}
{"created":"2024-02-05 16:30:57","title":"Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion","abstract":"Recent text-to-video diffusion models have achieved impressive progress. In practice, users often desire the ability to control object motion and camera movement independently for customized video creation. However, current methods lack the focus on separately controlling object motion and camera movement in a decoupled manner, which limits the controllability and flexibility of text-to-video models. In this paper, we introduce Direct-a-Video, a system that allows users to independently specify motions for one or multiple objects and/or camera movements, as if directing a video. We propose a simple yet effective strategy for the decoupled control of object motion and camera movement. Object motion is controlled through spatial cross-attention modulation using the model's inherent priors, requiring no additional optimization. For camera movement, we introduce new temporal cross-attention layers to interpret quantitative camera movement parameters. We further employ an augmentation-based approach to train these layers in a self-supervised manner on a small-scale dataset, eliminating the need for explicit motion annotation. Both components operate independently, allowing individual or combined control, and can generalize to open-domain scenarios. Extensive experiments demonstrate the superiority and effectiveness of our method. Project page: https://direct-a-video.github.io/.","sentences":["Recent text-to-video diffusion models have achieved impressive progress.","In practice, users often desire the ability to control object motion and camera movement independently for customized video creation.","However, current methods lack the focus on separately controlling object motion and camera movement in a decoupled manner, which limits the controllability and flexibility of text-to-video models.","In this paper, we introduce Direct-a-Video, a system that allows users to independently specify motions for one or multiple objects and/or camera movements, as if directing a video.","We propose a simple yet effective strategy for the decoupled control of object motion and camera movement.","Object motion is controlled through spatial cross-attention modulation using the model's inherent priors, requiring no additional optimization.","For camera movement, we introduce new temporal cross-attention layers to interpret quantitative camera movement parameters.","We further employ an augmentation-based approach to train these layers in a self-supervised manner on a small-scale dataset, eliminating the need for explicit motion annotation.","Both components operate independently, allowing individual or combined control, and can generalize to open-domain scenarios.","Extensive experiments demonstrate the superiority and effectiveness of our method.","Project page: https://direct-a-video.github.io/."],"url":"http://arxiv.org/abs/2402.03162v1"}
{"created":"2024-02-05 16:30:49","title":"Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization","abstract":"In light of recent advances in multimodal Large Language Models (LLMs), there is increasing attention to scaling them from image-text data to more informative real-world videos. Compared to static images, video poses unique challenges for effective large-scale pre-training due to the modeling of its spatiotemporal dynamics. In this paper, we address such limitations in video-language pre-training with an efficient video decomposition that represents each video as keyframes and temporal motions. These are then adapted to an LLM using well-designed tokenizers that discretize visual and temporal information as a few tokens, thus enabling unified generative pre-training of videos, images, and text. At inference, the generated tokens from the LLM are carefully recovered to the original continuous pixel space to create various video content. Our proposed framework is both capable of comprehending and generating image and video content, as demonstrated by its competitive performance across 13 multimodal benchmarks in image and video understanding and generation. Our code and models will be available at https://video-lavit.github.io.","sentences":["In light of recent advances in multimodal Large Language Models (LLMs), there is increasing attention to scaling them from image-text data to more informative real-world videos.","Compared to static images, video poses unique challenges for effective large-scale pre-training due to the modeling of its spatiotemporal dynamics.","In this paper, we address such limitations in video-language pre-training with an efficient video decomposition that represents each video as keyframes and temporal motions.","These are then adapted to an LLM using well-designed tokenizers that discretize visual and temporal information as a few tokens, thus enabling unified generative pre-training of videos, images, and text.","At inference, the generated tokens from the LLM are carefully recovered to the original continuous pixel space to create various video content.","Our proposed framework is both capable of comprehending and generating image and video content, as demonstrated by its competitive performance across 13 multimodal benchmarks in image and video understanding and generation.","Our code and models will be available at https://video-lavit.github.io."],"url":"http://arxiv.org/abs/2402.03161v1"}
{"created":"2024-02-05 16:27:59","title":"Optimal and Near-Optimal Adaptive Vector Quantization","abstract":"Quantization is a fundamental optimization for many machine-learning use cases, including compressing gradients, model weights and activations, and datasets. The most accurate form of quantization is \\emph{adaptive}, where the error is minimized with respect to a given input, rather than optimizing for the worst case. However, optimal adaptive quantization methods are considered infeasible in terms of both their runtime and memory requirements.   We revisit the Adaptive Vector Quantization (AVQ) problem and present algorithms that find optimal solutions with asymptotically improved time and space complexity. We also present an even faster near-optimal algorithm for large inputs. Our experiments show our algorithms may open the door to using AVQ more extensively in a variety of machine learning applications.","sentences":["Quantization is a fundamental optimization for many machine-learning use cases, including compressing gradients, model weights and activations, and datasets.","The most accurate form of quantization is \\emph{adaptive}, where the error is minimized with respect to a given input, rather than optimizing for the worst case.","However, optimal adaptive quantization methods are considered infeasible in terms of both their runtime and memory requirements.   ","We revisit the Adaptive Vector Quantization (AVQ) problem and present algorithms that find optimal solutions with asymptotically improved time and space complexity.","We also present an even faster near-optimal algorithm for large inputs.","Our experiments show our algorithms may open the door to using AVQ more extensively in a variety of machine learning applications."],"url":"http://arxiv.org/abs/2402.03158v1"}
{"created":"2024-02-05 16:24:12","title":"DogSurf: Quadruped Robot Capable of GRU-based Surface Recognition for Blind Person Navigation","abstract":"This paper introduces DogSurf - a newapproach of using quadruped robots to help visually impaired people navigate in real world. The presented method allows the quadruped robot to detect slippery surfaces, and to use audio and haptic feedback to inform the user when to stop. A state-of-the-art GRU-based neural network architecture with mean accuracy of 99.925% was proposed for the task of multiclass surface classification for quadruped robots. A dataset was collected on a Unitree Go1 Edu robot. The dataset and code have been posted to the public domain.","sentences":["This paper introduces DogSurf - a newapproach of using quadruped robots to help visually impaired people navigate in real world.","The presented method allows the quadruped robot to detect slippery surfaces, and to use audio and haptic feedback to inform the user when to stop.","A state-of-the-art GRU-based neural network architecture with mean accuracy of 99.925% was proposed for the task of multiclass surface classification for quadruped robots.","A dataset was collected on a Unitree Go1 Edu robot.","The dataset and code have been posted to the public domain."],"url":"http://arxiv.org/abs/2402.03156v1"}
{"created":"2024-02-05 16:19:53","title":"Learning solutions of parametric Navier-Stokes with physics-informed neural networks","abstract":"We leverage Physics-Informed Neural Networks (PINNs) to learn solution functions of parametric Navier-Stokes Equations (NSE). Our proposed approach results in a feasible optimization problem setup that bypasses PINNs' limitations in converging to solutions of highly nonlinear parametric-PDEs like NSE. We consider the parameter(s) of interest as inputs of PINNs along with spatio-temporal coordinates, and train PINNs on generated numerical solutions of parametric-PDES for instances of the parameters. We perform experiments on the classical 2D flow past cylinder problem aiming to learn velocities and pressure functions over a range of Reynolds numbers as parameter of interest. Provision of training data from generated numerical simulations allows for interpolation of the solution functions for a range of parameters. Therefore, we compare PINNs with unconstrained conventional Neural Networks (NN) on this problem setup to investigate the effectiveness of considering the PDEs regularization in the loss function. We show that our proposed approach results in optimizing PINN models that learn the solution functions while making sure that flow predictions are in line with conservational laws of mass and momentum. Our results show that PINN results in accurate prediction of gradients compared to NN model, this is clearly visible in predicted vorticity fields given that none of these models were trained on vorticity labels.","sentences":["We leverage Physics-Informed Neural Networks (PINNs) to learn solution functions of parametric Navier-Stokes Equations (NSE).","Our proposed approach results in a feasible optimization problem setup that bypasses PINNs' limitations in converging to solutions of highly nonlinear parametric-PDEs like NSE.","We consider the parameter(s) of interest as inputs of PINNs along with spatio-temporal coordinates, and train PINNs on generated numerical solutions of parametric-PDES for instances of the parameters.","We perform experiments on the classical 2D flow past cylinder problem aiming to learn velocities and pressure functions over a range of Reynolds numbers as parameter of interest.","Provision of training data from generated numerical simulations allows for interpolation of the solution functions for a range of parameters.","Therefore, we compare PINNs with unconstrained conventional Neural Networks (NN) on this problem setup to investigate the effectiveness of considering the PDEs regularization in the loss function.","We show that our proposed approach results in optimizing PINN models that learn the solution functions while making sure that flow predictions are in line with conservational laws of mass and momentum.","Our results show that PINN results in accurate prediction of gradients compared to NN model, this is clearly visible in predicted vorticity fields given that none of these models were trained on vorticity labels."],"url":"http://arxiv.org/abs/2402.03153v1"}
{"created":"2024-02-05 16:16:17","title":"A Comparative Analysis of Microrings Based Incoherent Photonic GEMM Accelerators","abstract":"Several microring resonator (MRR) based analog photonic architectures have been proposed to accelerate general matrix-matrix multiplications (GEMMs) in deep neural networks with exceptional throughput and energy efficiency. To implement GEMM functions, these MRR-based architectures, in general, manipulate optical signals in five different ways: (i) Splitting (copying) of multiple optical signals to achieve a certain fan-out, (ii) Aggregation (multiplexing) of multiple optical signals to achieve a certain fan-in, (iii) Modulation of optical signals to imprint input values onto analog signal amplitude, (iv) Weighting of modulated optical signals to achieve analog input-weight multiplication, (v) Summation of optical signals. The MRR-based GEMM accelerators undertake the first four ways of signal manipulation in an arbitrary order ignoring the possible impact of the order of these manipulations on their performance. In this paper, we conduct a detailed analysis of accelerator organizations with three different orders of these manipulations: (1) Modulation-Aggregation-Splitting-Weighting (MASW), (2) Aggregation-Splitting-Modulation-Weighting (ASMW), and (3) Splitting-Modulation-Weighting-Aggregation (SMWA). We show that these organizations affect the crosstalk noise and optical signal losses in different magnitudes, which renders these organizations with different levels of processing parallelism at the circuit level, and different magnitudes of throughput and energy-area efficiency at the system level. Our evaluation results for four CNN models show that SMWA organization achieves up to 4.4$\\times$, 5$\\times$, and 5.2$\\times$ better throughput, energy efficiency, and area-energy efficiency, respectively, compared to ASMW and MASW organizations on average.","sentences":["Several microring resonator (MRR) based analog photonic architectures have been proposed to accelerate general matrix-matrix multiplications (GEMMs) in deep neural networks with exceptional throughput and energy efficiency.","To implement GEMM functions, these MRR-based architectures, in general, manipulate optical signals in five different ways: (i) Splitting (copying) of multiple optical signals to achieve a certain fan-out, (ii) Aggregation (multiplexing) of multiple optical signals to achieve a certain fan-in, (iii) Modulation of optical signals to imprint input values onto analog signal amplitude, (iv) Weighting of modulated optical signals to achieve analog input-weight multiplication, (v) Summation of optical signals.","The MRR-based GEMM accelerators undertake the first four ways of signal manipulation in an arbitrary order ignoring the possible impact of the order of these manipulations on their performance.","In this paper, we conduct a detailed analysis of accelerator organizations with three different orders of these manipulations: (1) Modulation-Aggregation-Splitting-Weighting (MASW), (2) Aggregation-Splitting-Modulation-Weighting (ASMW), and (3) Splitting-Modulation-Weighting-Aggregation (SMWA).","We show that these organizations affect the crosstalk noise and optical signal losses in different magnitudes, which renders these organizations with different levels of processing parallelism at the circuit level, and different magnitudes of throughput and energy-area efficiency at the system level.","Our evaluation results for four CNN models show that SMWA organization achieves up to 4.4$\\times$, 5$\\times$, and 5.2$\\times$ better throughput, energy efficiency, and area-energy efficiency, respectively, compared to ASMW and MASW organizations on average."],"url":"http://arxiv.org/abs/2402.03149v1"}
{"created":"2024-02-05 16:15:11","title":"Proof Theory and Decision Procedures for Deontic STIT Logics","abstract":"This paper addresses the automation of reasoning with deontic STIT logics by means of proof theory. Our methodology consists of leveraging sound and cut-free complete sequent-style calculi to write a proof-search algorithm deciding deontic, multi-agent STIT logics with (un)limited choice. In order to ensure the termination of our proof-search algorithm, we introduce a special loop-checking mechanism. Despite the acknowledged potential for deontic reasoning in the context of autonomous vehicles and other areas of AI, this work is the first to provide a syntactic decision procedure for deontic STIT logics. Our proof-search procedures are designed to provide verifiable witnesses/certificates of the (in)validity of formulae, which permit an analysis of the (non)theoremhood of formulae and act as explanations thereof. We utilize our proof-search algorithm to address agent-based normative reasoning tasks such as compliance checking.","sentences":["This paper addresses the automation of reasoning with deontic STIT logics by means of proof theory.","Our methodology consists of leveraging sound and cut-free complete sequent-style calculi to write a proof-search algorithm deciding deontic, multi-agent STIT logics with (un)limited choice.","In order to ensure the termination of our proof-search algorithm, we introduce a special loop-checking mechanism.","Despite the acknowledged potential for deontic reasoning in the context of autonomous vehicles and other areas of AI, this work is the first to provide a syntactic decision procedure for deontic STIT logics.","Our proof-search procedures are designed to provide verifiable witnesses/certificates of the (in)validity of formulae, which permit an analysis of the (non)theoremhood of formulae and act as explanations thereof.","We utilize our proof-search algorithm to address agent-based normative reasoning tasks such as compliance checking."],"url":"http://arxiv.org/abs/2402.03148v1"}
{"created":"2024-02-05 16:13:54","title":"Detecting Scams Using Large Language Models","abstract":"Large Language Models (LLMs) have gained prominence in various applications, including security. This paper explores the utility of LLMs in scam detection, a critical aspect of cybersecurity. Unlike traditional applications, we propose a novel use case for LLMs to identify scams, such as phishing, advance fee fraud, and romance scams. We present notable security applications of LLMs and discuss the unique challenges posed by scams. Specifically, we outline the key steps involved in building an effective scam detector using LLMs, emphasizing data collection, preprocessing, model selection, training, and integration into target systems. Additionally, we conduct a preliminary evaluation using GPT-3.5 and GPT-4 on a duplicated email, highlighting their proficiency in identifying common signs of phishing or scam emails. The results demonstrate the models' effectiveness in recognizing suspicious elements, but we emphasize the need for a comprehensive assessment across various language tasks. The paper concludes by underlining the importance of ongoing refinement and collaboration with cybersecurity experts to adapt to evolving threats.","sentences":["Large Language Models (LLMs) have gained prominence in various applications, including security.","This paper explores the utility of LLMs in scam detection, a critical aspect of cybersecurity.","Unlike traditional applications, we propose a novel use case for LLMs to identify scams, such as phishing, advance fee fraud, and romance scams.","We present notable security applications of LLMs and discuss the unique challenges posed by scams.","Specifically, we outline the key steps involved in building an effective scam detector using LLMs, emphasizing data collection, preprocessing, model selection, training, and integration into target systems.","Additionally, we conduct a preliminary evaluation using GPT-3.5 and GPT-4 on a duplicated email, highlighting their proficiency in identifying common signs of phishing or scam emails.","The results demonstrate the models' effectiveness in recognizing suspicious elements, but we emphasize the need for a comprehensive assessment across various language tasks.","The paper concludes by underlining the importance of ongoing refinement and collaboration with cybersecurity experts to adapt to evolving threats."],"url":"http://arxiv.org/abs/2402.03147v1"}
{"created":"2024-02-05 16:13:00","title":"A Multi-step Loss Function for Robust Learning of the Dynamics in Model-based Reinforcement Learning","abstract":"In model-based reinforcement learning, most algorithms rely on simulating trajectories from one-step models of the dynamics learned on data. A critical challenge of this approach is the compounding of one-step prediction errors as the length of the trajectory grows. In this paper we tackle this issue by using a multi-step objective to train one-step models. Our objective is a weighted sum of the mean squared error (MSE) loss at various future horizons. We find that this new loss is particularly useful when the data is noisy (additive Gaussian noise in the observations), which is often the case in real-life environments. To support the multi-step loss, first we study its properties in two tractable cases: i) uni-dimensional linear system, and ii) two-parameter non-linear system. Second, we show in a variety of tasks (environments or datasets) that the models learned with this loss achieve a significant improvement in terms of the averaged R2-score on future prediction horizons. Finally, in the pure batch reinforcement learning setting, we demonstrate that one-step models serve as strong baselines when dynamics are deterministic, while multi-step models would be more advantageous in the presence of noise, highlighting the potential of our approach in real-world applications.","sentences":["In model-based reinforcement learning, most algorithms rely on simulating trajectories from one-step models of the dynamics learned on data.","A critical challenge of this approach is the compounding of one-step prediction errors as the length of the trajectory grows.","In this paper we tackle this issue by using a multi-step objective to train one-step models.","Our objective is a weighted sum of the mean squared error (MSE) loss at various future horizons.","We find that this new loss is particularly useful when the data is noisy (additive Gaussian noise in the observations), which is often the case in real-life environments.","To support the multi-step loss, first we study its properties in two tractable cases: i) uni-dimensional linear system, and ii) two-parameter non-linear system.","Second, we show in a variety of tasks (environments or datasets) that the models learned with this loss achieve a significant improvement in terms of the averaged R2-score on future prediction horizons.","Finally, in the pure batch reinforcement learning setting, we demonstrate that one-step models serve as strong baselines when dynamics are deterministic, while multi-step models would be more advantageous in the presence of noise, highlighting the potential of our approach in real-world applications."],"url":"http://arxiv.org/abs/2402.03146v1"}
{"created":"2024-02-05 16:12:27","title":"Computing Generic Fibres of Polynomial Ideals with FGLM and Hensel Lifting","abstract":"We describe a version of the FGLM algorithm that can be used to compute generic fibers of positive-dimensional polynomial ideals. It combines the FGLM algorithm with a Hensel lifting strategy. We show that this algorithm has a complexity quasi-linear in the number of lifting steps. Some provided experimental data also demonstrates the practical efficacy of our algorithm. Additionally, we sketch a related Hensel lifting method to compute Gr\\\"obner bases using so-called tracers.","sentences":["We describe a version of the FGLM algorithm that can be used to compute generic fibers of positive-dimensional polynomial ideals.","It combines the FGLM algorithm with a Hensel lifting strategy.","We show that this algorithm has a complexity quasi-linear in the number of lifting steps.","Some provided experimental data also demonstrates the practical efficacy of our algorithm.","Additionally, we sketch a related Hensel lifting method to compute Gr\\\"obner bases using so-called tracers."],"url":"http://arxiv.org/abs/2402.03144v1"}
{"created":"2024-02-05 16:11:43","title":"Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for Large Language Models","abstract":"Neural network pruning has become increasingly crucial due to the complexity of neural network models and their widespread use in various fields. Existing pruning algorithms often suffer from limitations such as architecture specificity, excessive complexity and reliance on complex calculations, rendering them impractical for real-world applications. In this paper, we propose KEN: a straightforward, universal and unstructured pruning algorithm based on Kernel Density Estimation (KDE). KEN aims to construct optimized transformer models by selectively preserving the most significant parameters while restoring others to their pre-training state. This approach maintains model performance while allowing storage of only the optimized subnetwork, leading to significant memory savings. Extensive evaluations on seven transformer models demonstrate that KEN achieves equal or better performance than the original models with a minimum parameter reduction of 25%. In-depth comparisons against other pruning and PEFT algorithms confirm KEN effectiveness. Furthermore, we introduce KEN_viz, an explainable tool that visualizes the optimized model composition and the subnetwork selected by KEN.","sentences":["Neural network pruning has become increasingly crucial due to the complexity of neural network models and their widespread use in various fields.","Existing pruning algorithms often suffer from limitations such as architecture specificity, excessive complexity and reliance on complex calculations, rendering them impractical for real-world applications.","In this paper, we propose KEN: a straightforward, universal and unstructured pruning algorithm based on Kernel Density Estimation (KDE).","KEN aims to construct optimized transformer models by selectively preserving the most significant parameters while restoring others to their pre-training state.","This approach maintains model performance while allowing storage of only the optimized subnetwork, leading to significant memory savings.","Extensive evaluations on seven transformer models demonstrate that KEN achieves equal or better performance than the original models with a minimum parameter reduction of 25%.","In-depth comparisons against other pruning and PEFT algorithms confirm KEN effectiveness.","Furthermore, we introduce KEN_viz, an explainable tool that visualizes the optimized model composition and the subnetwork selected by KEN."],"url":"http://arxiv.org/abs/2402.03142v1"}
{"created":"2024-02-05 16:11:03","title":"Boosting Long-Delayed Reinforcement Learning with Auxiliary Short-Delayed Task","abstract":"Reinforcement learning is challenging in delayed scenarios, a common real-world situation where observations and interactions occur with delays. State-of-the-art (SOTA) state-augmentation techniques either suffer from the state-space explosion along with the delayed steps, or performance degeneration in stochastic environments. To address these challenges, our novel Auxiliary-Delayed Reinforcement Learning (AD-RL) leverages an auxiliary short-delayed task to accelerate the learning on a long-delayed task without compromising the performance in stochastic environments. Specifically, AD-RL learns the value function in the short-delayed task and then employs it with the bootstrapping and policy improvement techniques in the long-delayed task. We theoretically show that this can greatly reduce the sample complexity compared to directly learning on the original long-delayed task. On deterministic and stochastic benchmarks, our method remarkably outperforms the SOTAs in both sample efficiency and policy performance.","sentences":["Reinforcement learning is challenging in delayed scenarios, a common real-world situation where observations and interactions occur with delays.","State-of-the-art (SOTA) state-augmentation techniques either suffer from the state-space explosion along with the delayed steps, or performance degeneration in stochastic environments.","To address these challenges, our novel Auxiliary-Delayed Reinforcement Learning (AD-RL) leverages an auxiliary short-delayed task to accelerate the learning on a long-delayed task without compromising the performance in stochastic environments.","Specifically, AD-RL learns the value function in the short-delayed task and then employs it with the bootstrapping and policy improvement techniques in the long-delayed task.","We theoretically show that this can greatly reduce the sample complexity compared to directly learning on the original long-delayed task.","On deterministic and stochastic benchmarks, our method remarkably outperforms the SOTAs in both sample efficiency and policy performance."],"url":"http://arxiv.org/abs/2402.03141v1"}
{"created":"2024-02-05 16:09:35","title":"Enhancing Neural Subset Selection: Integrating Background Information into Set Representations","abstract":"Learning neural subset selection tasks, such as compound selection in AI-aided drug discovery, have become increasingly pivotal across diverse applications. The existing methodologies in the field primarily concentrate on constructing models that capture the relationship between utility function values and subsets within their respective supersets. However, these approaches tend to overlook the valuable information contained within the superset when utilizing neural networks to model set functions. In this work, we address this oversight by adopting a probabilistic perspective. Our theoretical findings demonstrate that when the target value is conditioned on both the input set and subset, it is essential to incorporate an \\textit{invariant sufficient statistic} of the superset into the subset of interest for effective learning. This ensures that the output value remains invariant to permutations of the subset and its corresponding superset, enabling identification of the specific superset from which the subset originated. Motivated by these insights, we propose a simple yet effective information aggregation module designed to merge the representations of subsets and supersets from a permutation invariance perspective. Comprehensive empirical evaluations across diverse tasks and datasets validate the enhanced efficacy of our approach over conventional methods, underscoring the practicality and potency of our proposed strategies in real-world contexts.","sentences":["Learning neural subset selection tasks, such as compound selection in AI-aided drug discovery, have become increasingly pivotal across diverse applications.","The existing methodologies in the field primarily concentrate on constructing models that capture the relationship between utility function values and subsets within their respective supersets.","However, these approaches tend to overlook the valuable information contained within the superset when utilizing neural networks to model set functions.","In this work, we address this oversight by adopting a probabilistic perspective.","Our theoretical findings demonstrate that when the target value is conditioned on both the input set and subset, it is essential to incorporate an \\textit{invariant sufficient statistic} of the superset into the subset of interest for effective learning.","This ensures that the output value remains invariant to permutations of the subset and its corresponding superset, enabling identification of the specific superset from which the subset originated.","Motivated by these insights, we propose a simple yet effective information aggregation module designed to merge the representations of subsets and supersets from a permutation invariance perspective.","Comprehensive empirical evaluations across diverse tasks and datasets validate the enhanced efficacy of our approach over conventional methods, underscoring the practicality and potency of our proposed strategies in real-world contexts."],"url":"http://arxiv.org/abs/2402.03139v1"}
{"created":"2024-02-05 16:08:58","title":"Just Cluster It: An Approach for Exploration in High-Dimensions using Clustering and Pre-Trained Representations","abstract":"In this paper we adopt a representation-centric perspective on exploration in reinforcement learning, viewing exploration fundamentally as a density estimation problem. We investigate the effectiveness of clustering representations for exploration in 3-D environments, based on the observation that the importance of pixel changes between transitions is less pronounced in 3-D environments compared to 2-D environments, where pixel changes between transitions are typically distinct and significant. We propose a method that performs episodic and global clustering on random representations and on pre-trained DINO representations to count states, i.e, estimate pseudo-counts. Surprisingly, even random features can be clustered effectively to count states in 3-D environments, however when these become visually more complex, pre-trained DINO representations are more effective thanks to the pre-trained inductive biases in the representations. Overall, this presents a pathway for integrating pre-trained biases into exploration. We evaluate our approach on the VizDoom and Habitat environments, demonstrating that our method surpasses other well-known exploration methods in these settings.","sentences":["In this paper we adopt a representation-centric perspective on exploration in reinforcement learning, viewing exploration fundamentally as a density estimation problem.","We investigate the effectiveness of clustering representations for exploration in 3-D environments, based on the observation that the importance of pixel changes between transitions is less pronounced in 3-D environments compared to 2-D environments, where pixel changes between transitions are typically distinct and significant.","We propose a method that performs episodic and global clustering on random representations and on pre-trained DINO representations to count states, i.e, estimate pseudo-counts.","Surprisingly, even random features can be clustered effectively to count states in 3-D environments, however when these become visually more complex, pre-trained DINO representations are more effective thanks to the pre-trained inductive biases in the representations.","Overall, this presents a pathway for integrating pre-trained biases into exploration.","We evaluate our approach on the VizDoom and Habitat environments, demonstrating that our method surpasses other well-known exploration methods in these settings."],"url":"http://arxiv.org/abs/2402.03138v1"}
{"created":"2024-02-05 16:05:32","title":"Sociolinguistically Informed Interpretability: A Case Study on Hinglish Emotion Classification","abstract":"Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression, especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also conclude from the misclassifications that the models may overgeneralise this heuristic to other infrequent examples where this sociolinguistic phenomenon does not apply.","sentences":["Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression, especially with code-mixed data.","Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages.","Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions.","To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset.","Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression.","Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce.","We also conclude from the misclassifications that the models may overgeneralise this heuristic to other infrequent examples where this sociolinguistic phenomenon does not apply."],"url":"http://arxiv.org/abs/2402.03137v1"}
{"created":"2024-02-05 16:03:44","title":"Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games","abstract":"The combination of self-play and planning has achieved great successes in sequential games, for instance in Chess and Go. However, adapting algorithms such as AlphaZero to simultaneous games poses a new challenge. In these games, missing information about concurrent actions of other agents is a limiting factor as they may select different Nash equilibria or do not play optimally at all. Thus, it is vital to model the behavior of the other agents when interacting with them in simultaneous games. To this end, we propose Albatross: AlphaZero for Learning Bounded-rational Agents and Temperature-based Response Optimization using Simulated Self-play. Albatross learns to play the novel equilibrium concept of a Smooth Best Response Logit Equilibrium (SBRLE), which enables cooperation and competition with agents of any playing strength. We perform an extensive evaluation of Albatross on a set of cooperative and competitive simultaneous perfect-information games. In contrast to AlphaZero, Albatross is able to exploit weak agents in the competitive game of Battlesnake. Additionally, it yields an improvement of 37.6% compared to previous state of the art in the cooperative Overcooked benchmark.","sentences":["The combination of self-play and planning has achieved great successes in sequential games, for instance in Chess and Go.","However, adapting algorithms such as AlphaZero to simultaneous games poses a new challenge.","In these games, missing information about concurrent actions of other agents is a limiting factor as they may select different Nash equilibria or do not play optimally at all.","Thus, it is vital to model the behavior of the other agents when interacting with them in simultaneous games.","To this end, we propose Albatross: AlphaZero for Learning Bounded-rational Agents and Temperature-based Response Optimization using Simulated Self-play.","Albatross learns to play the novel equilibrium concept of a Smooth Best Response Logit Equilibrium (SBRLE), which enables cooperation and competition with agents of any playing strength.","We perform an extensive evaluation of Albatross on a set of cooperative and competitive simultaneous perfect-information games.","In contrast to AlphaZero, Albatross is able to exploit weak agents in the competitive game of Battlesnake.","Additionally, it yields an improvement of 37.6% compared to previous state of the art in the cooperative Overcooked benchmark."],"url":"http://arxiv.org/abs/2402.03136v1"}
{"created":"2024-02-05 16:01:15","title":"GPU-Accelerated 3D Polygon Visibility Volumes for Synergistic Perception and Navigation","abstract":"UAV missions often require specific geometric constraints to be satisfied between ground locations and the vehicle location. Such requirements are typical for contexts where line-of-sight must be maintained between the vehicle location and the ground control location and are also important in surveillance applications where the UAV wishes to be able to sense, e.g., with a camera sensor, a specific region within a complex geometric environment. This problem is further complicated when the ground location is generalized to a convex 2D polygonal region. This article describes the theory and implementation of a system which can quickly calculate the 3D volume that encloses all 3D coordinates from which a 2D convex planar region can be entirely viewed; referred to as a visibility volume. The proposed approach computes visibility volumes using a combination of depth map computation using GPU-acceleration and geometric boolean operations. Solutions to this problem require complex 3D geometric analysis techniques that must execute using arbitrary precision arithmetic on a collection of discontinuous and non-analytic surfaces. Post-processing steps incorporate navigational constraints to further restrict the enclosed coordinates to include both visibility and navigation constraints. Integration of sensing visibility constraints with navigational constraints yields a range of navigable space where a vehicle will satisfy both perceptual sensing and navigational needs of the mission. This algorithm then provides a synergistic perception and navigation sensitive solution yielding a volume of coordinates in 3D that satisfy both the mission path and sensing needs.","sentences":["UAV missions often require specific geometric constraints to be satisfied between ground locations and the vehicle location.","Such requirements are typical for contexts where line-of-sight must be maintained between the vehicle location and the ground control location and are also important in surveillance applications where the UAV wishes to be able to sense, e.g., with a camera sensor, a specific region within a complex geometric environment.","This problem is further complicated when the ground location is generalized to a convex 2D polygonal region.","This article describes the theory and implementation of a system which can quickly calculate the 3D volume that encloses all 3D coordinates from which a 2D convex planar region can be entirely viewed; referred to as a visibility volume.","The proposed approach computes visibility volumes using a combination of depth map computation using GPU-acceleration and geometric boolean operations.","Solutions to this problem require complex 3D geometric analysis techniques that must execute using arbitrary precision arithmetic on a collection of discontinuous and non-analytic surfaces.","Post-processing steps incorporate navigational constraints to further restrict the enclosed coordinates to include both visibility and navigation constraints.","Integration of sensing visibility constraints with navigational constraints yields a range of navigable space where a vehicle will satisfy both perceptual sensing and navigational needs of the mission.","This algorithm then provides a synergistic perception and navigation sensitive solution yielding a volume of coordinates in 3D that satisfy both the mission path and sensing needs."],"url":"http://arxiv.org/abs/2402.03135v1"}
{"created":"2024-02-05 16:00:30","title":"The Patch Topology in Univalent Foundations","abstract":"Stone locales together with continuous maps form a coreflective subcategory of spectral locales and perfect maps. A proof in the internal language of an elementary topos was previously given by the second-named author. This proof can be easily translated to univalent type theory using resizing axioms. In this work, we show how to achieve such a translation without resizing axioms, by working with large and locally small frames with small bases. This requires predicative reformulations of several fundamental concepts of locale theory in predicative HoTT/UF, which we investigate systematically.","sentences":["Stone locales together with continuous maps form a coreflective subcategory of spectral locales and perfect maps.","A proof in the internal language of an elementary topos was previously given by the second-named author.","This proof can be easily translated to univalent type theory using resizing axioms.","In this work, we show how to achieve such a translation without resizing axioms, by working with large and locally small frames with small bases.","This requires predicative reformulations of several fundamental concepts of locale theory in predicative HoTT/UF, which we investigate systematically."],"url":"http://arxiv.org/abs/2402.03134v1"}
{"created":"2024-02-05 15:57:32","title":"Constrained Decoding for Cross-lingual Label Projection","abstract":"Zero-shot cross-lingual transfer utilizing multilingual LLMs has become a popular learning paradigm for low-resource languages with no labeled training data. However, for NLP tasks that involve fine-grained predictions on words and phrases, the performance of zero-shot cross-lingual transfer learning lags far behind supervised fine-tuning methods. Therefore, it is common to exploit translation and label projection to further improve the performance by (1) translating training data that is available in a high-resource language (e.g., English) together with the gold labels into low-resource languages, and/or (2) translating test data in low-resource languages to a high-source language to run inference on, then projecting the predicted span-level labels back onto the original test data. However, state-of-the-art marker-based label projection methods suffer from translation quality degradation due to the extra label markers injected in the input to the translation model. In this work, we explore a new direction that leverages constrained decoding for label projection to overcome the aforementioned issues. Our new method not only can preserve the quality of translated texts but also has the versatility of being applicable to both translating training and translating test data strategies. This versatility is crucial as our experiments reveal that translating test data can lead to a considerable boost in performance compared to translating only training data. We evaluate on two cross-lingual transfer tasks, namely Named Entity Recognition and Event Argument Extraction, spanning 20 languages. The results demonstrate that our approach outperforms the state-of-the-art marker-based method by a large margin and also shows better performance than other label projection methods that rely on external word alignment.","sentences":["Zero-shot cross-lingual transfer utilizing multilingual LLMs has become a popular learning paradigm for low-resource languages with no labeled training data.","However, for NLP tasks that involve fine-grained predictions on words and phrases, the performance of zero-shot cross-lingual transfer learning lags far behind supervised fine-tuning methods.","Therefore, it is common to exploit translation and label projection to further improve the performance by (1) translating training data that is available in a high-resource language (e.g., English) together with the gold labels into low-resource languages, and/or (2) translating test data in low-resource languages to a high-source language to run inference on, then projecting the predicted span-level labels back onto the original test data.","However, state-of-the-art marker-based label projection methods suffer from translation quality degradation due to the extra label markers injected in the input to the translation model.","In this work, we explore a new direction that leverages constrained decoding for label projection to overcome the aforementioned issues.","Our new method not only can preserve the quality of translated texts but also has the versatility of being applicable to both translating training and translating test data strategies.","This versatility is crucial as our experiments reveal that translating test data can lead to a considerable boost in performance compared to translating only training data.","We evaluate on two cross-lingual transfer tasks, namely Named Entity Recognition and Event Argument Extraction, spanning 20 languages.","The results demonstrate that our approach outperforms the state-of-the-art marker-based method by a large margin and also shows better performance than other label projection methods that rely on external word alignment."],"url":"http://arxiv.org/abs/2402.03131v1"}
{"created":"2024-02-05 15:56:19","title":"User-Centric Evaluation of ChatGPT Capability of Generating R Program Code","abstract":"This paper reports an evaluation of ChatGPT's capability of generating R programming language code from natural language input. A dataset specially designed for generating R program code was constructed with metadata to support scenario-based testing and evaluation of code generation capabilities in various usage scenarios of different levels of difficulty and different types of programs. The evaluation takes a multiple attempt process in which the tester tries to complete the code generation task through a number of attempts until a satisfactory solution is obtained or gives up after a fixed number of maximal attempts. In each attempt the tester formulates a natural language input to ChatGPT based on the previous results and the task to be completed. In addition to the metrics of average numbers of attempts and average amount of time taken to complete the tasks, the final generated solutions are then assessed on a number of quality attributes, including accuracy, completeness, conciseness, readability, well structuredness, logic clarity, depth of ex-planation, and coverage of parameters. Our experiments demonstrated that ChatGPT is in general highly capable of generating high quality R program code as well as textual explanations although it may fail on hard programming tasks. The experiment data also shows that human developers can hardly learn from experiences naturally to improve the skill of using ChatGPT to generate code.","sentences":["This paper reports an evaluation of ChatGPT's capability of generating R programming language code from natural language input.","A dataset specially designed for generating R program code was constructed with metadata to support scenario-based testing and evaluation of code generation capabilities in various usage scenarios of different levels of difficulty and different types of programs.","The evaluation takes a multiple attempt process in which the tester tries to complete the code generation task through a number of attempts until a satisfactory solution is obtained or gives up after a fixed number of maximal attempts.","In each attempt the tester formulates a natural language input to ChatGPT based on the previous results and the task to be completed.","In addition to the metrics of average numbers of attempts and average amount of time taken to complete the tasks, the final generated solutions are then assessed on a number of quality attributes, including accuracy, completeness, conciseness, readability, well structuredness, logic clarity, depth of ex-planation, and coverage of parameters.","Our experiments demonstrated that ChatGPT is in general highly capable of generating high quality R program code as well as textual explanations although it may fail on hard programming tasks.","The experiment data also shows that human developers can hardly learn from experiences naturally to improve the skill of using ChatGPT to generate code."],"url":"http://arxiv.org/abs/2402.03130v1"}
{"created":"2024-02-05 15:51:49","title":"How Free is Parameter-Free Stochastic Optimization?","abstract":"We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free stochastic convex optimization infeasible, and provide a method which is (partially) parameter-free up to the limit indicated by our lower bound.","sentences":["We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters.","Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc.","In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms.","We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions.","Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free stochastic convex optimization infeasible, and provide a method which is (partially) parameter-free up to the limit indicated by our lower bound."],"url":"http://arxiv.org/abs/2402.03126v1"}
{"created":"2024-02-05 15:51:38","title":"Shape Manipulation of Bevel-Tip Needles for Prostate Biopsy Procedures: A Comparison of Two Resolved-Rate Controllers","abstract":"Prostate cancer diagnosis continues to encounter challenges, often due to imprecise needle placement in standard biopsies. Several control strategies have been developed to compensate for needle tip prediction inaccuracies, however none were compared against each other, and it is unclear whether any of them can be safely and universally applied in clinical settings. This paper compares the performance of two resolved-rate controllers, derived from a mechanics-based and a data-driven approach, for bevel-tip needle control using needle shape manipulation through a template. We demonstrate for a simulated 12-core biopsy procedure under model parameter uncertainty that the mechanics-based controller can better reach desired targets when only the final goal configuration is presented even with uncertainty on model parameters estimation, and that providing a feasible needle path is crucial in ensuring safe surgical outcomes when either controller is used for needle shape manipulation.","sentences":["Prostate cancer diagnosis continues to encounter challenges, often due to imprecise needle placement in standard biopsies.","Several control strategies have been developed to compensate for needle tip prediction inaccuracies, however none were compared against each other, and it is unclear whether any of them can be safely and universally applied in clinical settings.","This paper compares the performance of two resolved-rate controllers, derived from a mechanics-based and a data-driven approach, for bevel-tip needle control using needle shape manipulation through a template.","We demonstrate for a simulated 12-core biopsy procedure under model parameter uncertainty that the mechanics-based controller can better reach desired targets when only the final goal configuration is presented even with uncertainty on model parameters estimation, and that providing a feasible needle path is crucial in ensuring safe surgical outcomes when either controller is used for needle shape manipulation."],"url":"http://arxiv.org/abs/2402.03125v1"}
{"created":"2024-02-05 15:51:34","title":"Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks","abstract":"Gradient inversion attacks aim to reconstruct local training data from intermediate gradients exposed in the federated learning framework. Despite successful attacks, all previous methods, starting from reconstructing a single data point and then relaxing the single-image limit to batch level, are only tested under hard label constraints. Even for single-image reconstruction, we still lack an analysis-based algorithm to recover augmented soft labels. In this work, we change the focus from enlarging batchsize to investigating the hard label constraints, considering a more realistic circumstance where label smoothing and mixup techniques are used in the training process. In particular, we are the first to initiate a novel algorithm to simultaneously recover the ground-truth augmented label and the input feature of the last fully-connected layer from single-input gradients, and provide a necessary condition for any analytical-based label recovery methods. Extensive experiments testify to the label recovery accuracy, as well as the benefits to the following image reconstruction. We believe soft labels in classification tasks are worth further attention in gradient inversion attacks.","sentences":["Gradient inversion attacks aim to reconstruct local training data from intermediate gradients exposed in the federated learning framework.","Despite successful attacks, all previous methods, starting from reconstructing a single data point and then relaxing the single-image limit to batch level, are only tested under hard label constraints.","Even for single-image reconstruction, we still lack an analysis-based algorithm to recover augmented soft labels.","In this work, we change the focus from enlarging batchsize to investigating the hard label constraints, considering a more realistic circumstance where label smoothing and mixup techniques are used in the training process.","In particular, we are the first to initiate a novel algorithm to simultaneously recover the ground-truth augmented label and the input feature of the last fully-connected layer from single-input gradients, and provide a necessary condition for any analytical-based label recovery methods.","Extensive experiments testify to the label recovery accuracy, as well as the benefits to the following image reconstruction.","We believe soft labels in classification tasks are worth further attention in gradient inversion attacks."],"url":"http://arxiv.org/abs/2402.03124v1"}
{"created":"2024-02-05 15:47:54","title":"Good Teachers Explain: Explanation-Enhanced Knowledge Distillation","abstract":"Knowledge Distillation (KD) has proven effective for compressing large teacher models into smaller student models. While it is well known that student models can achieve similar accuracies as the teachers, it has also been shown that they nonetheless often do not learn the same function. It is, however, often highly desirable that the student's and teacher's functions share similar properties such as basing the prediction on the same input features, as this ensures that students learn the 'right features' from the teachers. In this work, we explore whether this can be achieved by not only optimizing the classic KD loss but also the similarity of the explanations generated by the teacher and the student. Despite the idea being simple and intuitive, we find that our proposed 'explanation-enhanced' KD (e$^2$KD) (1) consistently provides large gains in terms of accuracy and student-teacher agreement, (2) ensures that the student learns from the teacher to be right for the right reasons and to give similar explanations, and (3) is robust with respect to the model architectures, the amount of training data, and even works with 'approximate', pre-computed explanations.","sentences":["Knowledge Distillation (KD) has proven effective for compressing large teacher models into smaller student models.","While it is well known that student models can achieve similar accuracies as the teachers, it has also been shown that they nonetheless often do not learn the same function.","It is, however, often highly desirable that the student's and teacher's functions share similar properties such as basing the prediction on the same input features, as this ensures that students learn the 'right features' from the teachers.","In this work, we explore whether this can be achieved by not only optimizing the classic KD loss but also the similarity of the explanations generated by the teacher and the student.","Despite the idea being simple and intuitive, we find that our proposed 'explanation-enhanced' KD (e$^2$KD) (1) consistently provides large gains in terms of accuracy and student-teacher agreement, (2) ensures that the student learns from the teacher to be right for the right reasons and to give similar explanations, and (3) is robust with respect to the model architectures, the amount of training data, and even works with 'approximate', pre-computed explanations."],"url":"http://arxiv.org/abs/2402.03119v1"}
{"created":"2024-02-05 15:45:59","title":"Feature-Action Design Patterns for Storytelling Visualizations with Time Series Data","abstract":"We present a method to create storytelling visualization with time series data. Many personal decisions nowadays rely on access to dynamic data regularly, as we have seen during the COVID-19 pandemic. It is thus desirable to construct storytelling visualization for dynamic data that is selected by an individual for a specific context. Because of the need to tell data-dependent stories, predefined storyboards based on known data cannot accommodate dynamic data easily nor scale up to many different individuals and contexts. Motivated initially by the need to communicate time series data during the COVID-19 pandemic, we developed a novel computer-assisted method for meta-authoring of stories, which enables the design of storyboards that include feature-action patterns in anticipation of potential features that may appear in dynamically arrived or selected data. In addition to meta-storyboards involving COVID-19 data, we also present storyboards for telling stories about progress in a machine learning workflow. Our approach is complementary to traditional methods for authoring storytelling visualization, and provides an efficient means to construct data-dependent storyboards for different data-streams of similar contexts.","sentences":["We present a method to create storytelling visualization with time series data.","Many personal decisions nowadays rely on access to dynamic data regularly, as we have seen during the COVID-19 pandemic.","It is thus desirable to construct storytelling visualization for dynamic data that is selected by an individual for a specific context.","Because of the need to tell data-dependent stories, predefined storyboards based on known data cannot accommodate dynamic data easily nor scale up to many different individuals and contexts.","Motivated initially by the need to communicate time series data during the COVID-19 pandemic, we developed a novel computer-assisted method for meta-authoring of stories, which enables the design of storyboards that include feature-action patterns in anticipation of potential features that may appear in dynamically arrived or selected data.","In addition to meta-storyboards involving COVID-19 data, we also present storyboards for telling stories about progress in a machine learning workflow.","Our approach is complementary to traditional methods for authoring storytelling visualization, and provides an efficient means to construct data-dependent storyboards for different data-streams of similar contexts."],"url":"http://arxiv.org/abs/2402.03116v1"}
{"created":"2024-02-05 15:45:55","title":"Discovering interpretable models of scientific image data with deep learning","abstract":"How can we find interpretable, domain-appropriate models of natural phenomena given some complex, raw data such as images? Can we use such models to derive scientific insight from the data? In this paper, we propose some methods for achieving this. In particular, we implement disentangled representation learning, sparse deep neural network training and symbolic regression, and assess their usefulness in forming interpretable models of complex image data. We demonstrate their relevance to the field of bioimaging using a well-studied test problem of classifying cell states in microscopy data. We find that such methods can produce highly parsimonious models that achieve $\\sim98\\%$ of the accuracy of black-box benchmark models, with a tiny fraction of the complexity. We explore the utility of such interpretable models in producing scientific explanations of the underlying biological phenomenon.","sentences":["How can we find interpretable, domain-appropriate models of natural phenomena given some complex, raw data such as images?","Can we use such models to derive scientific insight from the data?","In this paper, we propose some methods for achieving this.","In particular, we implement disentangled representation learning, sparse deep neural network training and symbolic regression, and assess their usefulness in forming interpretable models of complex image data.","We demonstrate their relevance to the field of bioimaging using a well-studied test problem of classifying cell states in microscopy data.","We find that such methods can produce highly parsimonious models that achieve $\\sim98\\%$ of the accuracy of black-box benchmark models, with a tiny fraction of the complexity.","We explore the utility of such interpretable models in producing scientific explanations of the underlying biological phenomenon."],"url":"http://arxiv.org/abs/2402.03115v1"}
{"created":"2024-02-05 15:45:11","title":"Augmenting Security and Privacy in the Virtual Realm: An Analysis of Extended Reality Devices","abstract":"In this work, we present a device-centric analysis of security and privacy attacks and defenses on Extended Reality (XR) devices, highlighting the need for robust and privacy-aware security mechanisms. Based on our analysis, we present future research directions and propose design considerations to help ensure the security and privacy of XR devices.","sentences":["In this work, we present a device-centric analysis of security and privacy attacks and defenses on Extended Reality (XR) devices, highlighting the need for robust and privacy-aware security mechanisms.","Based on our analysis, we present future research directions and propose design considerations to help ensure the security and privacy of XR devices."],"url":"http://arxiv.org/abs/2402.03114v1"}
{"created":"2024-02-05 15:44:43","title":"Infrared Spectra Prediction for Diazo Groups Utilizing a Machine Learning Approach with Structural Attention Mechanism","abstract":"Infrared (IR) spectroscopy is a pivotal technique in chemical research for elucidating molecular structures and dynamics through vibrational and rotational transitions. However, the intricate molecular fingerprints characterized by unique vibrational and rotational patterns present substantial analytical challenges. Here, we present a machine learning approach employing a Structural Attention Mechanism tailored to enhance the prediction and interpretation of infrared spectra, particularly for diazo compounds. Our model distinguishes itself by honing in on chemical information proximal to functional groups, thereby significantly bolstering the accuracy, robustness, and interpretability of spectral predictions. This method not only demystifies the correlations between infrared spectral features and molecular structures but also offers a scalable and efficient paradigm for dissecting complex molecular interactions.","sentences":["Infrared (IR) spectroscopy is a pivotal technique in chemical research for elucidating molecular structures and dynamics through vibrational and rotational transitions.","However, the intricate molecular fingerprints characterized by unique vibrational and rotational patterns present substantial analytical challenges.","Here, we present a machine learning approach employing a Structural Attention Mechanism tailored to enhance the prediction and interpretation of infrared spectra, particularly for diazo compounds.","Our model distinguishes itself by honing in on chemical information proximal to functional groups, thereby significantly bolstering the accuracy, robustness, and interpretability of spectral predictions.","This method not only demystifies the correlations between infrared spectral features and molecular structures but also offers a scalable and efficient paradigm for dissecting complex molecular interactions."],"url":"http://arxiv.org/abs/2402.03112v1"}
{"created":"2024-02-05 15:44:16","title":"Computing roadmaps in unbounded smooth real algebraic sets II: algorithm and complexity","abstract":"A roadmap for an algebraic set $V$ defined by polynomials with coefficients in some real field, say $\\mathbb{R}$, is an algebraic curve contained in $V$ whose intersection with all connected components of $V\\cap\\mathbb{R}^{n}$ is connected. These objects, introduced by Canny, can be used to answer connectivity queries over $V\\cap \\mathbb{R}^{n}$ provided that they are required to contain the finite set of query points $\\mathcal{P}\\subset V$; in this case,we say that the roadmap is associated to $(V, \\mathcal{P})$.   In this paper, we make effective a connectivity result we previously proved, to design a Monte Carlo algorithm which, on input (i) a finite sequence of polynomials defining $V$ (and satisfying some regularity assumptions) and (ii) an algebraic representation of finitely many query points $\\mathcal{P}$ in $V$, computes a roadmap for $(V, \\mathcal{P})$. This algorithm generalizes the nearly optimal one introduced by the last two authors by dropping a boundedness assumption on the real trace of $V$.   The output size and running times of our algorithm are both polynomial in $(nD)^{n\\log d}$, where $D$ is the maximal degree of the input equations and $d$ is the dimension of $V$. As far as we know, the best previously known algorithm dealing with such sets has an output size and running time polynomial in $(nD)^{n\\log^2 n}$.","sentences":["A roadmap for an algebraic set $V$ defined by polynomials with coefficients in some real field, say $\\mathbb{R}$, is an algebraic curve contained in $V$ whose intersection with all connected components of $V\\cap\\mathbb{R}^{n}$ is connected.","These objects, introduced by Canny, can be used to answer connectivity queries over $V\\cap \\mathbb{R}^{n}$ provided that they are required to contain the finite set of query points $\\mathcal{P}\\subset V$; in this case,we say that the roadmap is associated to $(V, \\mathcal{P})$.   ","In this paper, we make effective a connectivity result we previously proved, to design a Monte Carlo algorithm which, on input (i) a finite sequence of polynomials defining $V$ (and satisfying some regularity assumptions) and (ii) an algebraic representation of finitely many query points $\\mathcal{P}$ in $V$, computes a roadmap for $(V, \\mathcal{P})$.","This algorithm generalizes the nearly optimal one introduced by the last two authors by dropping a boundedness assumption on the real trace of $V$.   The output size and running times of our algorithm are both polynomial in $(nD)^{n\\log d}$, where $D$ is the maximal degree of the input equations and $d$ is the dimension of $V$. As far as we know, the best previously known algorithm dealing with such sets has an output size and running time polynomial in $(nD)^{n\\log^2 n}$."],"url":"http://arxiv.org/abs/2402.03111v1"}
{"created":"2024-02-05 15:38:01","title":"Non-Stationary Latent Auto-Regressive Bandits","abstract":"We consider the stochastic multi-armed bandit problem with non-stationary rewards. We present a novel formulation of non-stationarity in the environment where changes in the mean reward of the arms over time are due to some unknown, latent, auto-regressive (AR) state of order $k$. We call this new environment the latent AR bandit. Different forms of the latent AR bandit appear in many real-world settings, especially in emerging scientific fields such as behavioral health or education where there are few mechanistic models of the environment. If the AR order $k$ is known, we propose an algorithm that achieves $\\tilde{O}(k\\sqrt{T})$ regret in this setting. Empirically, our algorithm outperforms standard UCB across multiple non-stationary environments, even if $k$ is mis-specified.","sentences":["We consider the stochastic multi-armed bandit problem with non-stationary rewards.","We present a novel formulation of non-stationarity in the environment where changes in the mean reward of the arms over time are due to some unknown, latent, auto-regressive (AR) state of order $k$.","We call this new environment the latent AR bandit.","Different forms of the latent AR bandit appear in many real-world settings, especially in emerging scientific fields such as behavioral health or education where there are few mechanistic models of the environment.","If the AR order $k$ is known, we propose an algorithm that achieves $\\tilde{O}(k\\sqrt{T})$ regret in this setting.","Empirically, our algorithm outperforms standard UCB across multiple non-stationary environments, even if $k$ is mis-specified."],"url":"http://arxiv.org/abs/2402.03110v1"}
{"created":"2024-02-05 15:37:02","title":"Computing with Clocks","abstract":"Clocks are a central part of many computing paradigms, and are mainly used to synchronise the delicate operation of switching, necessary to drive modern computational processes. Unfortunately, this synchronisation process is reaching a natural ``apocalypse''. No longer can clock scaling be used as a blunt tool to accelerate computation, we are up against the natural limits of switching and synchronisation across large processors. Therefore, we need to rethink how time is utilised in computation, using it more naturally in the role of representing data. This can be achieved by using a time interval delineated by discrete start and end events, and by re-casting computational operations into the time domain. With this, computer systems can be developed that are naturally scaleable in time and space, and can use ambient time references built to the best effort of the available technology.   Our ambition is to better manage the energy/computation time trade-off, and to explicitly embed the resolution of the data in the time domain. We aim to recast calculations into the ``for free'' format that time offers, and in addition, perform these calculations at the highest clock or oscillator resolution possible.","sentences":["Clocks are a central part of many computing paradigms, and are mainly used to synchronise the delicate operation of switching, necessary to drive modern computational processes.","Unfortunately, this synchronisation process is reaching a natural ``apocalypse''.","No longer can clock scaling be used as a blunt tool to accelerate computation, we are up against the natural limits of switching and synchronisation across large processors.","Therefore, we need to rethink how time is utilised in computation, using it more naturally in the role of representing data.","This can be achieved by using a time interval delineated by discrete start and end events, and by re-casting computational operations into the time domain.","With this, computer systems can be developed that are naturally scaleable in time and space, and can use ambient time references built to the best effort of the available technology.   ","Our ambition is to better manage the energy/computation time trade-off, and to explicitly embed the resolution of the data in the time domain.","We aim to recast calculations into the ``for free'' format that time offers, and in addition, perform these calculations at the highest clock or oscillator resolution possible."],"url":"http://arxiv.org/abs/2402.03109v1"}
{"created":"2024-02-05 15:33:38","title":"DARTS: Diffusion Approximated Residual Time Sampling for Low Variance Time-of-flight Rendering in Homogeneous Scattering Medium","abstract":"Time-of-flight (ToF) devices have greatly propelled the advancement of various multi-modal perception applications. However, due to complexity in both sampling path construction and vertex connection in time domain, it is extremely challenging to accurately render time-resolved information in ToF device simulation, particularly in scenes involving complex geometric structures, diverse materials and volumetric scattering media. Existing works either exhibit significant bias or variance in ToF rendering tasks or prove ineffective in scenes involving participating media and camera-warped settings. To address this challenge, in this paper, we integrate the transient diffusion theory into path construction to generate the unbiased full transport of time-resolved radiance. Additionally, we devise an elliptical sampling method to provide controllable vertex connection satisfying any required photon traversal time. To our knowledge, our work is the first to explore importance sampling according to transient radiance, enabling temporal path construction of higher quality in multiple scattering settings. Extensive experiments show that our sampling method can significantly improve both quality and efficiency of ToF rendering within both path tracing and photon-based frameworks, with at least a 5x MSE reduction versus SOTA methods in equal rendering time. Our method introduces no memory overhead and negligible extra computation compared to the boost in speed, providing a straightforward plug-in for various existing rendering frameworks.","sentences":["Time-of-flight (ToF) devices have greatly propelled the advancement of various multi-modal perception applications.","However, due to complexity in both sampling path construction and vertex connection in time domain, it is extremely challenging to accurately render time-resolved information in ToF device simulation, particularly in scenes involving complex geometric structures, diverse materials and volumetric scattering media.","Existing works either exhibit significant bias or variance in ToF rendering tasks or prove ineffective in scenes involving participating media and camera-warped settings.","To address this challenge, in this paper, we integrate the transient diffusion theory into path construction to generate the unbiased full transport of time-resolved radiance.","Additionally, we devise an elliptical sampling method to provide controllable vertex connection satisfying any required photon traversal time.","To our knowledge, our work is the first to explore importance sampling according to transient radiance, enabling temporal path construction of higher quality in multiple scattering settings.","Extensive experiments show that our sampling method can significantly improve both quality and efficiency of ToF rendering within both path tracing and photon-based frameworks, with at least a 5x MSE reduction versus SOTA methods in equal rendering time.","Our method introduces no memory overhead and negligible extra computation compared to the boost in speed, providing a straightforward plug-in for various existing rendering frameworks."],"url":"http://arxiv.org/abs/2402.03106v1"}
